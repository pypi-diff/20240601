# Comparing `tmp/viqi_api-0.6.4.87-py3-none-any.whl.zip` & `tmp/viqi_api-0.6.4.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,30 +1,30 @@
-Zip file size: 82171 bytes, number of entries: 28
--rw-rw-rw-  2.0 unx      417 b- defN 24-Jun-01 01:14 vqapi/README.md
--rw-r--r--  2.0 unx      294 b- defN 24-Jun-01 01:14 vqapi/__init__.py
--rw-r--r--  2.0 unx     1746 b- defN 24-Jun-01 01:14 vqapi/blockable_module.py
--rw-r--r--  2.0 unx    28745 b- defN 24-Jun-01 01:14 vqapi/bqclass.py
--rw-r--r--  2.0 unx     1595 b- defN 24-Jun-01 01:14 vqapi/casauth.py
--rw-r--r--  2.0 unx     6977 b- defN 24-Jun-01 01:14 vqapi/cmd.py
--rw-r--r--  2.0 unx    50189 b- defN 24-Jun-01 01:14 vqapi/comm.py
--rw-r--r--  2.0 unx    15725 b- defN 24-Jun-01 01:14 vqapi/exception.py
--rw-r--r--  2.0 unx     4846 b- defN 24-Jun-01 01:14 vqapi/plugins.py
--rw-r--r--  2.0 unx    14011 b- defN 24-Jun-01 01:14 vqapi/util.py
--rw-r--r--  2.0 unx      418 b- defN 24-Jun-01 01:14 vqapi/version.py
--rw-r--r--  2.0 unx    58002 b- defN 24-Jun-01 01:14 vqapi/vqclass.py
--rw-r--r--  2.0 unx    11632 b- defN 24-Jun-01 01:14 vqapi/vqquery.py
--rw-r--r--  2.0 unx     4604 b- defN 24-Jun-01 01:14 vqapi/xmldict.py
--rw-rw-rw-  2.0 unx        8 b- defN 24-Jun-01 01:14 vqapi/RequestsMonkeyPatch/__init__.py
--rw-rw-rw-  2.0 unx      138 b- defN 24-Jun-01 01:14 vqapi/RequestsMonkeyPatch/monkeypatch.py
--rw-rw-rw-  2.0 unx     2009 b- defN 24-Jun-01 01:14 vqapi/RequestsMonkeyPatch/requests_patch.py
--rw-rw-rw-  2.0 unx      120 b- defN 24-Jun-01 01:14 vqapi/services/__init__.py
--rw-rw-rw-  2.0 unx    17133 b- defN 24-Jun-01 01:14 vqapi/services/base_proxy.py
--rw-rw-rw-  2.0 unx    32418 b- defN 24-Jun-01 01:14 vqapi/services/core_services.py
--rw-rw-rw-  2.0 unx     1891 b- defN 24-Jun-01 01:14 vqapi/services/factory.py
--rw-rw-rw-  2.0 unx     3519 b- defN 24-Jun-01 01:14 vqapi/services/image_proxy.py
--rw-rw-rw-  2.0 unx    32494 b- defN 24-Jun-01 01:14 vqapi/services/import_proxy.py
--rw-rw-rw-  2.0 unx    11637 b- defN 24-Jun-01 01:14 vqapi/services/table_proxy.py
--rw-r--r--  2.0 unx     2216 b- defN 24-Jun-01 01:14 viqi_api-0.6.4.87.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Jun-01 01:14 viqi_api-0.6.4.87.dist-info/WHEEL
--rw-r--r--  2.0 unx        6 b- defN 24-Jun-01 01:14 viqi_api-0.6.4.87.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2226 b- defN 24-Jun-01 01:14 viqi_api-0.6.4.87.dist-info/RECORD
-28 files, 305108 bytes uncompressed, 78647 bytes compressed:  74.2%
+Zip file size: 69744 bytes, number of entries: 28
+-rw-rw-rw-  2.0 unx      417 b- defN 23-Apr-26 04:04 vqapi/README.md
+-rw-r--r--  2.0 unx      276 b- defN 23-Apr-26 04:04 vqapi/__init__.py
+-rw-r--r--  2.0 unx     1746 b- defN 23-Apr-26 04:04 vqapi/blockable_module.py
+-rw-r--r--  2.0 unx    28745 b- defN 23-Apr-26 04:04 vqapi/bqclass.py
+-rw-r--r--  2.0 unx     1595 b- defN 23-Apr-26 04:04 vqapi/casauth.py
+-rw-r--r--  2.0 unx     6106 b- defN 23-Apr-26 04:04 vqapi/cmd.py
+-rw-r--r--  2.0 unx    49773 b- defN 23-Apr-26 04:04 vqapi/comm.py
+-rw-r--r--  2.0 unx    14629 b- defN 23-Apr-26 04:04 vqapi/exception.py
+-rw-r--r--  2.0 unx     4722 b- defN 23-Apr-26 04:04 vqapi/plugins.py
+-rw-r--r--  2.0 unx    13926 b- defN 23-Apr-26 04:04 vqapi/util.py
+-rw-r--r--  2.0 unx      165 b- defN 23-Apr-26 04:04 vqapi/version.py
+-rw-r--r--  2.0 unx    33627 b- defN 23-Apr-26 04:04 vqapi/vqclass.py
+-rw-r--r--  2.0 unx    11337 b- defN 23-Apr-26 04:04 vqapi/vqquery.py
+-rw-r--r--  2.0 unx     4604 b- defN 23-Apr-26 04:04 vqapi/xmldict.py
+-rw-rw-rw-  2.0 unx        8 b- defN 23-Apr-26 04:04 vqapi/RequestsMonkeyPatch/__init__.py
+-rw-rw-rw-  2.0 unx      138 b- defN 23-Apr-26 04:04 vqapi/RequestsMonkeyPatch/monkeypatch.py
+-rw-rw-rw-  2.0 unx     2010 b- defN 23-Apr-26 04:04 vqapi/RequestsMonkeyPatch/requests_patch.py
+-rw-rw-rw-  2.0 unx       67 b- defN 23-Apr-26 04:04 vqapi/services/__init__.py
+-rw-rw-rw-  2.0 unx    14441 b- defN 23-Apr-26 04:04 vqapi/services/base_proxy.py
+-rw-rw-rw-  2.0 unx    20591 b- defN 23-Apr-26 04:04 vqapi/services/core_services.py
+-rw-rw-rw-  2.0 unx     1862 b- defN 23-Apr-26 04:04 vqapi/services/factory.py
+-rw-rw-rw-  2.0 unx     3519 b- defN 23-Apr-26 04:04 vqapi/services/image_proxy.py
+-rw-rw-rw-  2.0 unx    22829 b- defN 23-Apr-26 04:04 vqapi/services/import_proxy.py
+-rw-rw-rw-  2.0 unx     7533 b- defN 23-Apr-26 04:04 vqapi/services/table_proxy.py
+-rw-r--r--  2.0 unx     1569 b- defN 23-Apr-26 04:04 viqi_api-0.6.4.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-26 04:04 viqi_api-0.6.4.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx        6 b- defN 23-Apr-26 04:04 viqi_api-0.6.4.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2220 b- defN 23-Apr-26 04:04 viqi_api-0.6.4.9.dist-info/RECORD
+28 files, 248553 bytes uncompressed, 66228 bytes compressed:  73.4%
```

## zipnote {}

```diff
@@ -66,20 +66,20 @@
 
 Filename: vqapi/services/import_proxy.py
 Comment: 
 
 Filename: vqapi/services/table_proxy.py
 Comment: 
 
-Filename: viqi_api-0.6.4.87.dist-info/METADATA
+Filename: viqi_api-0.6.4.9.dist-info/METADATA
 Comment: 
 
-Filename: viqi_api-0.6.4.87.dist-info/WHEEL
+Filename: viqi_api-0.6.4.9.dist-info/WHEEL
 Comment: 
 
-Filename: viqi_api-0.6.4.87.dist-info/top_level.txt
+Filename: viqi_api-0.6.4.9.dist-info/top_level.txt
 Comment: 
 
-Filename: viqi_api-0.6.4.87.dist-info/RECORD
+Filename: viqi_api-0.6.4.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## vqapi/__init__.py

```diff
@@ -1,10 +1,11 @@
 #
+
+
 from .cmd import bisque_argument_parser, bisque_config, bisque_session
-from .comm import BQServer, BQSession
-from .exception import *
+from .comm import *
 from .services import ResponseFile, ResponseFolder
 from .vqclass import *
+from .exception import *
 
-__author__ = "ViQi Inc"
-__copyright__ = "2018-2023 ViQi Inc"
-__project__ = "vqapi"
+# import logging
+# logging.getLogger(__name__).addHandler(logging.NullHandler())
```

## vqapi/cmd.py

```diff
@@ -6,15 +6,15 @@
 
 # import sys
 # import time
 from configparser import RawConfigParser
 
 import urllib3
 
-from .vqclass import VQSession
+from .comm import BQSession
 
 # Check the directories in order for the config, the 1st one is the default for writing new config
 CONFIG_PATHS = [
     "~/config/viqi/profiles" if os.name == "nt" else "~/.config/viqi/profiles",
     "~/viqi/config" if os.name == "nt" else "~/.viqi/config",
     "~/bisque/config" if os.name == "nt" else "~/.bisque/config",
 ]
@@ -45,96 +45,87 @@
 
 def bisque_config(parser=None, args=None, write_config=True):
     """Manage bisque config file"""
     # user = password = root = config = alias_user = None
     if parser is None:
         parser = bisque_argument_parser()
     pargs = parser.parse_args(args=args)
+    config = RawConfigParser()
     if pargs.config is None:
         # Find config file
         for confd in CONFIG_PATHS:
             confd = os.path.expanduser(confd)
             if os.path.exists(confd):
                 pargs.config = confd
                 break
 
-    # Read a profile from the config file if needed
-    config = RawConfigParser()
-    if not (pargs.host and pargs.user and pargs.password) and os.path.exists(os.path.expanduser(pargs.config)):
+    if os.path.exists(os.path.expanduser(pargs.config)):
         config.read(os.path.expanduser(pargs.config))
         try:
             profile = config[pargs.profile]
             pargs.host = profile.get("host")
             pargs.user = profile.get("user")
             pargs.password = profile.get("password")
             pargs.alias = profile.get("alias", None)
         except KeyError:
             print(f"No or incomplete profile named {pargs.profile}")
 
-    # Collect input if user/profile is incomplete
+    # if pargs.host:
+    #    root = pargs.host
     if pargs.credentials and not (pargs.user or pargs.password):
         pargs.user, pargs.password = pargs.credentials.split(":")
-    if not pargs.host and pargs.profile != "default":  # and pargs.user and pargs.password:
+    if not (pargs.host and pargs.user and pargs.password):
         print(f"Please configure how to connect to bisque with profile {pargs.profile}")
         if write_config:
             if pargs.config is None:
                 pargs.config = CONFIG_PATHS[0]
             pargs.host = input(f"BisQue URL [{pargs.host}] ") or pargs.host
             pargs.user = input(f"username[{pargs.user}] ") or pargs.user
             pargs.password = input(f"password[{pargs.password}]: ") or pargs.password
-
-            if input(f"Write profile {pargs.profile} to {pargs.config} [y/N]") == "y":
-                config_file = os.path.expanduser(pargs.config)
-                if not os.path.isdir(os.path.dirname(config_file)):
-                    os.makedirs(os.path.dirname(config_file))
-                profile = {}
-                with open(config_file, "w") as conf:
-                    if pargs.host.strip():
-                        profile["host"] = posixpath.join(pargs.host.strip(), "")
-                    if pargs.user.strip():
-                        profile["user"] = pargs.user.strip()
-                    if pargs.password.strip():
-                        profile["password"] = pargs.password.strip()
-                    if profile:
-                        config[pargs.profile] = profile
-                        config.write(conf)
-                        print(f"profile {pargs.profile}  has been saved to {pargs.config}")
-                    else:
-                        print("No profile created")
+            config_file = os.path.expanduser(pargs.config)
+            if not os.path.isdir(os.path.dirname(config_file)):
+                os.makedirs(os.path.dirname(config_file))
+            with open(config_file, "w") as conf:
+                config[pargs.profile] = {
+                    "host": posixpath.join(pargs.host.strip(), ""),
+                    "user": pargs.user.strip(),
+                    "password": pargs.password.strip(),
+                }
+            config.write(conf)
+            print("configuration has been saved to", pargs.config)
 
     return pargs
 
 
-def bisque_session(
-    parser: argparse.ArgumentParser = None,
-    args: argparse.Namespace | list[str] = None,
-    root_logger=None,
-    show_pass: bool = False,
-) -> VQSession:
-    """
-    Get a session for command line tools using arguments and ~/.config/viqi/profiles files.
-
+def bisque_session(parser=None, args=None, root_logger=None):
+    """Get a bisque session for command line tools using arguments and ~/.bisque/config files
     Args:
-        parser: a configured ArgumentParser
-        args: List of strings
-        root_logger: logger to use
-        show_pass: show password used
+     parser : a configured ArgumentParser
+     args   : List of strings
 
     Returns:
-        initialized session
-
-    Examples:
-        Create a file ~/.config/viqi/profiles with content:\n
-           [science-user2]\n
-           host=https://science.viqiai.cloud\n
-           user=myuser2\n
-           password=mysecret2
+      session, args  : tuple with session and args
 
-        >>> from vqapi import bisque_session
-        >>> session = bisque_session(args=["--profile=science-user2"])
+    Usage:
+    parser = bisque_argument_parser ("MyCommand")
+    parser.add_argument ('newarg', help='any specific argument')
+    args = parser.parse_args()
+    session, pargs = bisque_session(args)
+
+    ~/.bisque/config:
+    [default]
+    host=
+    user=
+    password=
+
+    [testing]
+    host=
+    user=
+    password=
+    alias=
     """
     from argparse import Namespace
 
     if not isinstance(args, Namespace):
         pargs = bisque_config(parser=parser, args=args)
     else:
         pargs = args
@@ -152,27 +143,26 @@
                 "debug": logging.DEBUG,
                 "info": logging.INFO,
                 "warn": logging.WARN,
                 "error": logging.ERROR,
             }.get(pargs.debug.lower(), logging.DEBUG)
         )
 
-    if pargs.host:  # and pargs.user and pargs.password:
-        session = VQSession()
+    if pargs.host and pargs.user and pargs.password:
+        session = BQSession()
         urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
         session.c.verify = False
-        print(f"connecting {pargs.host} with {pargs.user} and {(pargs.password if show_pass else '*****')}")
         session = session.init_local(
             bisque_root=pargs.host,
             user=pargs.user,
             pwd=pargs.password,
             create_mex=False,
             as_user=pargs.alias,
         )
         if session is None:
-            print(f"Could not create session with host={pargs.host} user={pargs.user}. Check your config")
+            print(f"Could not create bisque session with host={pargs.host} user={pargs.user}. Check your config")
             return session
         if not pargs.quiet:
             print("Session for  ", pargs.host, " for user ", session.user, " created")
         session.parse_args = pargs
         session.server_version = "viqi1"
     return session
```

## vqapi/comm.py

```diff
@@ -46,38 +46,39 @@
 SYNOPSIS
 ========
 
 DESCRIPTION
 ===========
 
 """
+import cgi
 import itertools
 
 # import urlparse
 # import urllib
 import logging
 import pickle
 import posixpath
 import urllib.parse
-from collections import OrderedDict
-from email.message import Message
 
 import requests
-from bq.metadoc.formats import InvalidFormat, Metadoc, anyxml_to_etree
 from requests import Session
 from requests.adapters import HTTPAdapter
 from requests.auth import AuthBase, HTTPBasicAuth
 
 # from requests.packages.urllib3.util.retry import Retry
 from urllib3 import Retry
 
+from collections import OrderedDict
+
+from bq.metadoc.formats import InvalidFormat, Metadoc, anyxml_to_etree
+
 from .bqclass import BQFactory, BQNode
 from .exception import BQApiError, CommErrorFactory
-from .services import BaseServiceProxy
-from .services.factory import ServiceFactory
+from .services import ServiceFactory
 from .util import is_uniq_code
 
 # from .RequestsMonkeyPatch import requests_patch#allows multipart form to accept unicode
 
 try:
     from .casauth import caslogin
 
@@ -87,44 +88,31 @@
 
 
 log = logging.getLogger("vqapi.comm")
 
 # SERVICES = ['']
 
 
-# realiably determine mimetype
-# https://stackoverflow.com/questions/32330152/how-can-i-parse-the-value-of-content-type-from-an-http-header-response
-
-
-def parse_content_type(content_type: str) -> tuple[str, dict[str, str]]:
-    _CONTENT_TYPE = "content-type"
-    email = Message()
-    email[_CONTENT_TYPE] = content_type
-    params = email.get_params()
-    # The first param is the mime-type the later ones are the attributes like "charset"
-    return params[0][0], dict(params[1:])
-
-
 def decodexml(self):
     if not self.content:
         return None
     try:
-        mimetype, options = parse_content_type(self.headers["content-type"])
+        mimetype, options = cgi.parse_header(self.headers["content-type"])
         if mimetype in ("application/xml", "text/xml"):  # TODO: use inputters!!!!
             if self.text == str(None):
                 # None was returned from a normally XML returning API fct
                 # TODO: should not mark it as XML in the header
                 return None
             if self.headers.get("x-viqi-content-type", "") == "application/xml+tag":
                 return Metadoc.from_tagxml(self.text)
             else:
                 return Metadoc.from_naturalxml(self.text)
         return None
     except InvalidFormat:
-        log.error("XML expected: got content-type:%s body:%s", self.headers["content-type"], self.content)
+        log.error("XML expected but got %s %s", self.headers["content-type"], self.content)
         raise BQApiError(f"Bad xml content for request: {self.url}:{self.content} ")
 
 
 class MexAuth(AuthBase):
     """
     Bisque's Mex Authentication
     """
@@ -373,47 +361,41 @@
         self.mex = None
         self.services = {}
         self.new = set()
         self.dirty = set()
         self.deleted = set()
         self.bisque_root = None
         self.factory = BQFactory(self)
-        self.dryrun = False  # Deprecated for removal
+        self.dryrun = False
         self.delete_mex = None
         self.delete_build = None
         self.service_map = {}
         self.parse_args = None  # initilized by some cmd.py
 
     # Pickle protocol
     def __getstate__(self):
         return (
             self.bisque_root,
-            self.c.cookies.get("mex_session"),
-            {str(key): str(val) for key, val in self.service_map.items()},
+            self.c.cookies["mex_session"],
+            { str(key):str(val) for key,val in self.service_map.items()},
             self.parse_args,
         )
 
     def __setstate__(self, tple):
         self.bisque_root = tple[0]
         self.c = BQServer()
-        self.c.cookies.update({"mex_session": tple[1]})
+        self.c.cookies["mex_session"] = tple[1]
         self.c.root = self.bisque_root
         self.service_map = tple[2]
         self.parse_args = tple[3]
         self.factory = BQFactory(self)
-        self.delete_mex = None
-        self.delete_build = None
         self.setup_retry()
-        self._load_services()
 
     def copy(self):
-        adapters = self.c.adapters
-        newobj = pickle.loads(pickle.dumps(self))
-        newobj.c.adapters = adapters
-        return newobj
+        return pickle.loads(pickle.dumps(self))
 
     ############################
     # Establish a bisque session
     ############################
     def _create_mex(self, user, moduleuri):
         # for now, just create an empty mex doc...
         # TODO: fix this using new module/build/mex service
@@ -483,54 +465,57 @@
             users = r.findall("./user") if r else []
             return len(users) > 0
         except BQApiError:
             return False
 
     def setup_retry(
         self,
-        retries=30,
-        backoff_factor=1,
+        retries=10,
+        backoff_factor=0.5,
         status_forcelist=frozenset([413, 429, 502, 503, 504]),
     ):
-        # """Add retries to core library
-        #
-        # @param retries: Max number  of retries before giving up (throws exception urllib3.exceptions.MaxRetryError)
-        # @param backoff_factor: sleep for  {backoff factor} * (2 ** ({number of total retries} - 1)) on retry
-        # @param status_forcelist : http Status codes that  will retry
-        #
-        # urllib3  Retry.BACKOFF_MAX is set to 120 so 30 retries will be 3071 seconds before failure (50 min)
-        # """
-        # This allows other adapter to not be overwritten by us
-        if self.bisque_root in self.c.adapters:
-            return
+        """Add retries to core library
+
+        @param retries: Max number  of retries before giving up (throws exception urllib3.exceptions.MaxRetryError)
+        @param backoff_factor: sleep for  {backoff factor} * (2 ** ({number of total retries} - 1)) on retry
+        @param status_forcelist : http Status codes that  will retry
 
+        urllib3  Retry.BACKOFF_MAX is set to 120 so 30 retries will be 3071 seconds before failure (50 min)
+        """
         retry = Retry(
             total=retries,
             read=retries,
             connect=retries,
             backoff_factor=backoff_factor,
             status_forcelist=status_forcelist,
             respect_retry_after_header=True,
             allowed_methods=frozenset(
                 {"DELETE", "GET", "HEAD", "OPTIONS", "PUT", "TRACE", "POST", "PATCH"}
             ),  # include POST and PATCH retries
             # (TODO: need to make sure all POST/PATCH requests use etag versioning)
         )
-        retry.RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 502, 503, 504])
+        retry.RETRY_AFTER_STATUS_CODES = frozenset([307, 321, 413, 429, 502, 503, 504])
         adapter = HTTPAdapter(max_retries=retry)
         self.c.mount(self.bisque_root, adapter)
 
     def init(
         self,
         bisque_url,
         credentials=None,
         moduleuri=None,
         create_mex=False,
         enable_cache=False,
     ):
+        """Create  session by connect to with bisque_url
+
+        @param bisque_url: The bisque root or MEX url
+        @param credetials : A tuple (user, pass) or (mex, token)
+        @param moduleuri :  The module URI of the mex for this session
+        @param create_mex : Create a new Mex session for this run
+        """
         self.bisque_root = self.c.root = bisque_url
         self.setup_retry()
         self._load_services()
         if credentials:
             if credentials[0].lower() == "mex":
                 return self.init_mex(bisque_url, credentials[1])
             auth_service = self.service("auth_service")
@@ -563,84 +548,95 @@
         pwd,
         moduleuri=None,
         bisque_root=None,
         create_mex=True,
         as_user=None,
         enable_cache=False,
     ):
+        """
+        Initalizes a local session
+
+        @param: user - a bisque user
+        @param: pwd - the bisque user's password
+        @param: moduleuri - module uri to be set to the mex (Only matter if create mex is set to true) (moduleuri: None)
+        @param: bisque_root - the root of the bisque system the user is trying to access (bisque_root: None)
+        @param: create_mex - creates a mex session under the user (default: True)
+
+        @return: self
+        """
+
         if bisque_root is not None:
             self.bisque_root = bisque_root
             self.c.root = bisque_root
 
+        self.c.authenticate_basic(user, pwd)
         self.setup_retry()
         self._load_services()
         # Switch user if needed
         self.user = user
-        user_session = {}
-        if user is not None:
-            auth = self.service("auths")
-            user_session = auth.login(user, pwd)
-            if not user_session:  # is not None and not session._check_session():  # Forces cookie load
-                log.error("Session failed to be created.. please check credentials")
-                return None
-
-        session = self
-        if as_user and "admin" in user_session.get("group", ""):
+        if as_user:
             admin = self.service("admin")
-            sess_alias = admin.login_as(as_user)
-            auth = self.service("auths")
-            user_session = auth.get_session()
-            if not user_session:
-                log.error("Session failed to be created.. please check credentials")
-                return None
-            sess_alias.user = as_user
-            session = sess_alias
+            user_id = admin.login_as(as_user)
+            self.user = as_user
+            if user_id is None:
+                log.error("Unable to login as %s", as_user)
+                log.info("Logged in %s", as_user)
+                self.user = None
 
-        session.mex = None
-        session.cache_enable(enable_cache)
-
-        if user is not None and create_mex and moduleuri:
-            session._create_mex(user, moduleuri)
+        if not self._check_session():
+            log.error("Session failed to be created.. please check credentials")
+            return None
+        self.mex = None
+        self.cache_enable(enable_cache)
 
-        session.c.auth = None
-        # atexit.register(self.logout)
+        if create_mex:
+            self._create_mex(user, moduleuri)
 
-        return session
+        return self
 
     def init_mex(self, mex_url, token, user=None, bisque_root=None, enable_cache=False):
+        """
+        Initalizing a local session from a mex
+
+        @param: mex_url - the mex url to initalize the session from
+        @param: token - the mex token to access the mex
+        @param: user - the owner of the mex (Does not have to be provided if already
+        provided in the token) (default: None)
+        @param: bisque_root - the root of the bisque system the user is trying to access (bisque_root: None)
+
+        @return self
+        """
         if bisque_root is None:
             # This assumes that bisque_root is http://host.org:port/
             # mex_tuple = list(urllib.parse.urlparse(mex_url))
             # mex_tuple[2:5] = "", "", ""
             # bisque_root = urllib.parse.urlunparse(mex_tuple)
             o = urllib.parse.urlparse(mex_url)
-            bisque_root = o._replace(path="", params="", query="", fragment="").geturl()
+            bisque_root = o._replace(path='', params='', query='', fragment='').geturl()
 
         self.bisque_root = bisque_root
         self.c.root = bisque_root
         self.c.authenticate_mex(token, user=user)
         self.setup_retry()
         self._load_services()
         self.mex = self.fetchxml(mex_url, view="deep")
         if self.mex is None:
             log.error("Invalid session authentication")
             self.c.auth = None
         self.cache_enable(enable_cache)
         return self
 
     def init_request(self, request, enable_cache=False):
-        #         """
-        #         Initializing a local session from a request.
-        #
-        #         Args:
-        #             request: pyramid request
-        #
-        #         Returns:
-        #             VQSession
-        #         """
+        """
+        Initializing a local session from a request
+
+        @param: request - pyramid request
+
+        @return self
+        """
         bisque_root = request.host_url
         self.bisque_root = bisque_root
         self.c.root = bisque_root
         self.c.authenticate_mex(request.session.get("mex_auth"))
         self.setup_retry()
         self._load_services()
         self.mex = self.fetchxml(request.session.get("mex_uri"), view="deep")
@@ -655,29 +651,29 @@
         user,
         pwd,
         moduleuri=None,
         bisque_root=None,
         create_mex=False,
         enable_cache=True,
     ):
-        #         """Initalizes a cas session
-        #
-        #         @param: user - a bisque user
-        #         @param: pwd - the bisque user's password
-        #         @param: moduleuri - module uri to be set to the mex (Only matter if create mex is set to true) (moduleuri: None)
-        #         @param: bisque_root - the root of the bisque system the user is trying to access (bisque_root: None)
-        #         @param: create_mex - creates a mex session under the user (default: True)
-        #         @return: self
-        #
-        #         Example
-        #         >>>from vqapi import BQSession
-        #         >>>s = BQSession()
-        #         >>>s.init_cas (CASNAME, CASPASS, bisque_root='http://bisque.iplantcollaborative.org', create_mex=False)
-        #         >>>s.fetchxml('/data_serice/image', limit=10)
-        #         """
+        """Initalizes a cas session
+
+        @param: user - a bisque user
+        @param: pwd - the bisque user's password
+        @param: moduleuri - module uri to be set to the mex (Only matter if create mex is set to true) (moduleuri: None)
+        @param: bisque_root - the root of the bisque system the user is trying to access (bisque_root: None)
+        @param: create_mex - creates a mex session under the user (default: True)
+        @return: self
+
+        Example
+        >>>from vqapi import BQSession
+        >>>s = BQSession()
+        >>>s.init_cas (CASNAME, CASPASS, bisque_root='http://bisque.iplantcollaborative.org', create_mex=False)
+        >>>s.fetchxml('/data_serice/image', limit=10)
+        """
         if not CAS_SUPPORT:
             raise BQApiError("CAS not support.. please check installation")
 
         if bisque_root is None:
             raise BQApiError("cas login requires bisque_root")
 
         self.bisque_root = bisque_root
@@ -724,21 +720,14 @@
                 user=user,
                 pwd=pwd,
                 moduleuri=moduleuri,
                 bisque_root=bisque_root,
                 create_mex=create_mex,
             )
 
-    def logout(self):
-        """
-        Close and logout current session.
-        """
-        auth = self.service("auths")
-        return auth.logout()
-
     def cache_enable(self, enabled: bool = False):
         # This is an obfuscated variable .. see https://github.com/requests-cache/requests-cache/blob/main/requests_cache/session.py
         # self.c._disabled = not enabled
         pass
 
     def close(self):
         self._clean_mex()
@@ -762,18 +751,18 @@
             elif t == "list[number]":
                 return [float(tok) for tok in v.split(";")]
             return v
         except AttributeError:
             return None
 
     def parameter_value(self, name=None, p=None):
-        # """
-        # Get value of mex input parameter with given name.
-        # Returns single value, list of values, or a metadoc if complex value.
-        # """
+        """
+        Get value of mex input parameter with given name.
+        Returns single value, list of values, or a metadoc if complex value.
+        """
         if p is None:
             p = self.parameter(name)
         else:
             name = p[0].tag if isinstance(p, list) else p.tag
 
         if p is None:
             return None
@@ -816,19 +805,19 @@
             return p
         inputs = self.mex.path_query("inputs//*")
         for i in inputs:
             p[i.tag] = self.parameter_value(p=i)
         return p
 
     def get_mex_inputs(self):
-        # """
-        # Get all input parameters in mex.
-        #
-        # @return: map parameter name -> {'type':..., 'value':..., ...} or [ map parameter name -> {'type':..., 'value':..., ...}, ... ] if blocked iter
-        # """
+        """
+        Get all input parameters in mex.
+
+        @return: map parameter name -> {'type':..., 'value':..., ...} or [ map parameter name -> {'type':..., 'value':..., ...}, ... ] if blocked iter
+        """
 
         def _xml2dict(e):
             kids = {key: e.attrib[key] for key in e.attrib if key in ["type", "value"]}
             if e.text:
                 kids["value"] = e.text
             for k, g in itertools.groupby(e, lambda x: x.tag):
                 g = [_xml2dict(x) for x in g]
@@ -851,50 +840,50 @@
             for inner_mex in self.mex.path_query("./mex"):
                 res.append(_get_mex_params(inner_mex))
         else:
             res = _get_mex_params(self.mex)
         return res
 
     def get_mex_outputs(self):
-        # """
-        # Get all outputs in mex.
-        # """
+        """
+        Get all outputs in mex.
+        """
         if self.mex is None:
             return {}
         # re-fetch mex to get outputs
         mex = self.fetchxml(self.mex.get("uri"), view="deep,clean")
         outp = mex.path_query("outputs")
         if not outp:
             return {}
         return outp[0].to_json()["outputs"]
 
     def get_mex_execute_options(self):
-        # """
-        # Get execute options in mex.
-        #
-        # @return: map option name -> value
-        # """
+        """
+        Get execute options in mex.
+
+        @return: map option name -> value
+        """
         p = {}
         if self.mex is None:
             return p
         for exop in self.mex.path_query("execute_options/*"):
             p[exop.tag] = exop.text
         return p
 
     def fetchxml(self, url, path=None, **params):
-        # """
-        # Fetch an xml object from the url
-        #
-        # @param: url - A url to fetch from
-        # @param: path - a location on the file system were one wishes the response to be stored (default: None)
-        # @param: odict - ordered dictionary of params will be added to url for when the order matters
-        # @param: params - params will be added to url
-        #
-        # @return Metadoc
-        # """
+        """
+        Fetch an xml object from the url
+
+        @param: url - A url to fetch from
+        @param: path - a location on the file system were one wishes the response to be stored (default: None)
+        @param: odict - ordered dictionary of params will be added to url for when the order matters
+        @param: params - params will be added to url
+
+        @return Metadoc
+        """
         url = self.c.prepare_url(url, **params)
         log.debug("fetchxml %s " % url)
         if path:
             return self.c.fetch(
                 url,
                 headers={
                     "Content-Type": "application/xml+tag",
@@ -909,37 +898,37 @@
                     "Content-Type": "application/xml+tag",
                     "Accept": "application/xml+tag",
                 },
             )
             return Metadoc.from_tagxml(r)
 
     def postxml(self, url, xml, path=None, method="POST", **params):
-        # """
-        # Post xml allowed with files to bisque
-        #
-        # @param: url - the url to make to the request
-        # @param: xml - an xml document that is post at the url location (accepts either string or Metadoc)
-        # @param: path - a location on the file system were one wishes the response to be stored (default: None)
-        # @param method - the method of the http request (HEAD,GET,POST,PUT,DELETE,...) (default: POST)
-        # @param: odict - ordered dictionary of params will be added to url for when the order matters
-        # @param: params - params will be added to url
-        #
-        # @return: Metadoc or path to the file were the response was stored
-        # """
+        """
+        Post xml allowed with files to bisque
+
+        @param: url - the url to make to the request
+        @param: xml - an xml document that is post at the url location (accepts either string or Metadoc)
+        @param: path - a location on the file system were one wishes the response to be stored (default: None)
+        @param method - the method of the http request (HEAD,GET,POST,PUT,DELETE,...) (default: POST)
+        @param: odict - ordered dictionary of params will be added to url for when the order matters
+        @param: params - params will be added to url
+
+        @return: Metadoc or path to the file were the response was stored
+        """
 
         if not isinstance(xml, (str, bytes)):
             xml = xml.to_tagxml()
 
         log.debug(f"postxml {url}  content {xml} ")
 
         url = self.c.prepare_url(url, **params)
 
         try:
             r = None
-            if not getattr(self, "dryrun", False):
+            if not self.dryrun:
                 r = self.c.push(
                     url,
                     content=xml,
                     method=method,
                     path=path,
                     headers={
                         "Content-Type": "application/xml+tag",
@@ -950,15 +939,15 @@
                 return r
             return r and Metadoc.from_tagxml(r)
         except InvalidFormat as e:
             log.exception("Problem with post response %s", e)
             return r
 
     def deletexml(self, url):
-        # "Delete a resource"
+        "Delete a resource"
         url = self.c.prepare_url(url)
         r = self.c.webreq(method="delete", url=url)
         return r
 
     #     def fetchblob(self, url, path=None, **params):
     #         """
     #             Requests for a blob
@@ -1027,24 +1016,34 @@
     #     return self.c.push(url,
     #                        content=m,
     #                        headers={'Accept': 'text/xml', 'Content-Type':m.content_type},
     #                        path=path, method=method)
     # raise BQApiError("improper parameters for postblob: must use paramater xml or filename or both ")
 
     def service_url(self, service_type, path="", query=None):
+        """
+        @param service_type:
+        @param path:
+        @param query:
+
+        @return
+        """
         service = self.service(service_type)
         return service.construct(path, query)
         # root = self.service_map.get(service_type, None)
         # if root is None:
         #    raise BQApiError('Not a service type')
         # if query:
         #    path = "{}?{}".format(path, urllib.parse.urlencode(query))
         # return urllib.parse.urljoin(str(root), str(path))
 
     def _load_services(self):
+        """
+        @return
+        """
         self.service_map = {"services": posixpath.join(self.c.root, "services")}
         services = self.service("services")
         try:
             service_list = services.get(timeout=5).doc()
             smap = {}
             for service in service_list:
                 smap[service.get("type")] = service.text
@@ -1053,24 +1052,16 @@
                     smap[new_name] = service.text
             self.service_map = smap
         except BQApiError as ce:
             log.error(f"While loading services {ce}")
         except requests.exceptions.Timeout:
             pass
 
-    def service(self, service_name: str) -> BaseServiceProxy:
-        """
-        Return a sevice for this session.
-
-        Args:
-            service_name: name of the service (e.g., "mexes" or "mex_service")
-
-        Returns:
-            service proxy
-        """
+    def service(self, service_name):
+        """Return a sevice for this session"""
         if isinstance(self.service_map.get(service_name, ""), str):
             self.service_map[service_name] = ServiceFactory.make(self, service_name)
         return self.service_map[service_name]
 
     #############################
     # Classes and Type
     #############################
@@ -1104,24 +1095,24 @@
         for elem in children:
             append_mex(mex, elem)
 
     ##############################
     # Mex
     ##############################
     def update_mex(self, status, tags=None, gobjects=None, children=None, reload=False, merge=False):
-        # """save an updated mex with the addition
-        #
-        # @param status:  The current status of the mex
-        # @param tags: list of Metadoc|JSON dict objects (can be nested) of form { 'name': 'value', ... }
-        # @param gobjects: list of Metadoc|JSON dict objects (can be nested) of form { 'name': 'value', ... }
-        # @param children: list of tuple (type, obj array) i.e [('mex', [dict1, dict2, ...]), ('bla', [dict3, dict4, ...])]
-        # @param reload:
-        # @param merge: merge "outputs"/"inputs" section if needed
-        # @return
-        # """
+        """save an updated mex with the addition
+
+        @param status:  The current status of the mex
+        @param tags: list of Metadoc|JSON dict objects (can be nested) of form { 'name': 'value', ... }
+        @param gobjects: list of Metadoc|JSON dict objects (can be nested) of form { 'name': 'value', ... }
+        @param children: list of tuple (type, obj array) i.e [('mex', [dict1, dict2, ...]), ('bla', [dict3, dict4, ...])]
+        @param reload:
+        @param merge: merge "outputs"/"inputs" section if needed
+        @return
+        """
         tags = tags or []
         gobjects = gobjects or []
         children = children or []
 
         attr_only = not any((tags, gobjects, children))
 
         # IF merge is requested, check if needed
@@ -1178,14 +1169,23 @@
         )
         if reload and content is not None:
             self.mex = content
             return self.mex
         return None
 
     def finish_mex(self, status="FINISHED", tags=None, gobjects=None, children=None, msg=None):
+        """
+        @param status:
+        @param tags:
+        @param gobject:
+        @param children:
+        @param msg:
+
+        @return
+        """
         tags = tags or []
         gobjects = gobjects or []
         children = children or []
 
         if msg is not None:
             tags.append({"message": msg})
         try:
@@ -1205,39 +1205,42 @@
                     status="FAILED",
                     tags=[{"error_message": "Error during saving (status %s)" % ce.response_code}],
                 )
             except Exception:
                 log.exception("Cannot finish/fail Mex ")
 
     def fail_mex(self, msg):
+        """
+        @param msg:
+        """
         if msg is not None:
             tags = [{"error_message": msg}]
         self.finish_mex(status="FAILED", tags=tags)
 
     def _begin_mex(self, moduleuri):
-        # """create a mex on the server for this run"""
+        """create a mex on the server for this run"""
         pass
 
     ##############################
     # Module control
     ##############################
     def run_modules(self, module_list, pre_run=None, post_run=None, callback_fct=None):
-        # """Run one or more modules in parallel.
-        #
-        #:param module_list: List of modules to run
-        #:type  module_list: [ { moduleuri: ..., inputs: { param1:val1, param2:val2, ...}, parent_mex: ... }, {...}, ... ]
-        #:param pre_run: module entrypoint to call before run (or None if no prerun)
-        #:type pre_run: str
-        #:param post_run: module entrypoint to call after run (or None if no postrun)
-        #:type post_run: str
-        #:param callback_fct: function to call on completion (None: block until completion)
-        #:type  callback_fct: fct(mex_list=list(str))
-        #:returns: list of mex URIs, one for each module
-        #:rtype: list(str)
-        # """
+        """Run one or more modules in parallel.
+
+        :param module_list: List of modules to run
+        :type  module_list: [ { moduleuri: ..., inputs: { param1:val1, param2:val2, ...}, parent_mex: ... }, {...}, ... ]
+        :param pre_run: module entrypoint to call before run (or None if no prerun)
+        :type pre_run: str
+        :param post_run: module entrypoint to call after run (or None if no postrun)
+        :type post_run: str
+        :param callback_fct: function to call on completion (None: block until completion)
+        :type  callback_fct: fct(mex_list=list(str))
+        :returns: list of mex URIs, one for each module
+        :rtype: list(str)
+        """
         # TODO: create MEX according to params and POST it to module_service
         pass
 
     #     ##############################
     #     # Resources
     #     ##############################
     #     def query(self, resource_type, **kw):
@@ -1249,15 +1252,21 @@
     #         items = self.fetchxml (queryurl)
     #         for item in items:
     #             results.append (item)
     #         return results
     #
     #
     def load(self, url, **params):
-        """Load a bisque object"""
+        """Load a bisque object
+
+        @param url:
+        @param params:
+
+        @return
+        """
         # if view not in url:
         #    url = url + "?view=%s" % view
         try:
             xml = self.fetchxml(url, **params)
             if xml.tag == "response":
                 xml = xml[0]
             bqo = self.factory.from_etree(xml.to_tagxml_etree())
@@ -1271,14 +1280,20 @@
     #         "Delete an object and all children"
     #         url = bqo.uri or url
     #         if url is not None:
     #             return self.deletexml(url)
     #
     #
     def save(self, bqo, url=None, **kw):
+        """
+        @param bqo:
+        @param url:
+        @param kw:
+        @return
+        """
         try:
             # original = bqo
 
             # Find an object (or parent with a valild uri)
             url = url or bqo.uri
             if url is None:
                 while url is None and bqo.parent:
```

## vqapi/exception.py

```diff
@@ -26,20 +26,14 @@
 
 
 class BQException(Exception):
     """
     BQException
     """
 
-    def __init__(self, *args, **kw):  # allow named args
-        if kw:
-            super().__init__(*args, kw)
-        else:
-            super().__init__(*args)
-
     http_code = 500  # should be overwritten to indicate corresponding code
     empty_body = False
 
 
 class BQApiError(BQException):
     """Exception in API usage"""
 
@@ -79,17 +73,14 @@
     def __str__(self):
         msg = f"{self.__class__.__name__}:{self.args[0]}"
         if not hasattr(self, "response_url"):
             return msg
         else:
             return f"{self.response_url}, status={self.response_code}, headers={self.response_headers}, {msg}"
 
-    def get_msg(self):
-        return str(self.args[0])
-
 
 class IllegalOperation(BQApiError):
     """Illegal Operation"""
 
     http_code = 400
 
 
@@ -115,16 +106,14 @@
 
     http_code = 415
 
 
 class ServiceError(BQApiError):
     """Any error during in a service"""
 
-    http_code = 400
-
 
 class NoAuthorizationError(BQApiError):
     """User is not authorized for action
 
     Pass a redirect url if can be resolved
     """
 
@@ -160,26 +149,14 @@
 
 class ConfigurationError(BQApiError):
     """Problem was found with the configuration"""
 
     http_code = 400
 
 
-class InvalidQuery(BQApiError):
-    """bad query/request structure"""
-
-    http_code = 400
-
-
-class BadFormat(BQApiError):
-    """resource is not in a recognized or allowed format needed for op"""
-
-    http_code = 500
-
-
 #################################################
 #  Data/Index service exceptions
 #################################################
 
 
 class StoreError(BQApiError):
     """non specific store error (should not be used)"""
@@ -242,14 +219,20 @@
 
 class DocAccessForbidden(StoreAbortError):
     """access to doc not permitted"""
 
     http_code = 403
 
 
+class InvalidQuery(StoreError):
+    """bad query structure"""
+
+    http_code = 400
+
+
 class IndexNotFound(StoreError):
     """referenced index not found"""
 
     http_code = 404
 
 
 #################################################
@@ -273,19 +256,19 @@
 
     Attributes:
         timeout_range: a range of seconds for a re-request: (1, 15)
     """
 
     http_code = http_code_future_not_ready
 
-    def __init__(self, timeout_range=None, location="", msg=None):
+    def __init__(self, timeout_range=None, location=""):
         self.timeout_range = timeout_range or (1, 20)
         self.retry_after = random.randint(self.timeout_range[0], self.timeout_range[1])
         self.location = location
-        super().__init__(msg=msg or "Blob is being transferred. Come back later.")
+        super().__init__(msg="Blob is being transferred. Come back later.")
 
 
 class ResourceNotFoundError(BQApiError):
     """Raised when resource not found"""
 
     http_code = 404
 
@@ -408,29 +391,29 @@
     Attributes:
         code: Response error code, same as HTTP response code
         message: String explaining the exact reason for the failure
     """
 
     http_code = 400
 
-    def __init__(self, code=400, message=None, msg=None):
+    def __init__(self, code, message):
         self.http_code = code
-        super().__init__(msg=message or msg)
+        super().__init__(msg=message)
 
 
 class ImageServiceFuture(BQApiError):
     """Raised when any operation timeout or is already locked
 
     Attributes:
         timeout_range: a range of seconds for a re-request: (1, 15)
     """
 
     http_code = http_code_future_not_ready
 
-    def __init__(self, timeout_range=None, location="", msg=None):
+    def __init__(self, timeout_range=None, location=""):
         self.timeout_range = timeout_range or (1, 20)
         self.retry_after = random.randint(self.timeout_range[0], self.timeout_range[1])
         self.location = location
         super().__init__(msg="image future")
 
 
 #################################################
@@ -464,56 +447,22 @@
 
     Attributes:
         timeout_range: a range of seconds for a re-request: (1, 15)
     """
 
     http_code = http_code_future_not_ready
 
-    def __init__(self, timeout_range=None, location="", msg=None):
+    def __init__(self, timeout_range=None, location=""):
         self.timeout_range = timeout_range or (1, 20)
         self.retry_after = random.randint(self.timeout_range[0], self.timeout_range[1])
         self.location = location
         super().__init__(msg="Table access delayed. Come back later.")
 
 
 #################################################
-#  Import/Ingest service exceptions
-#################################################
-
-
-class IngestError(BQApiError):
-    """Raised when issue with Ingest/Registration"""
-
-    http_code = 400
-
-
-class ExportError(BQApiError):
-    """Raised when issue with Export"""
-
-    http_code = 400
-
-
-#################################################
-#  Preference exceptions
-#################################################
-
-
-class PreferenceError(BQApiError):
-    """Raised when issue with Export"""
-
-    http_code = 400
-
-
-class NotifyError(BQApiError):
-    """Raised when issue with Notify"""
-
-    http_code = 400
-
-
-#################################################
 #  Map between exception and http code
 #################################################
 
 # Conversion rules:
 # -----------------
 #
 #   http body                      exception
```

## vqapi/plugins.py

```diff
@@ -1,11 +1,10 @@
 """Utilities for loading `plugins' from python namespace and entrypoints
 
 """
-
 import importlib
 import sys
 
 if sys.version_info < (3, 10):
     from importlib_metadata import entry_points
 else:
     from importlib.metadata import entry_points
@@ -95,18 +94,16 @@
             if module_ns == ".":
                 module_ns = ""
             module_ns = package + module_ns
 
     def safe_import(name):
         try:
             return importlib.import_module(name)
-        except (ImportError, ModuleNotFoundError) as exc:
-            log.warn('Failed to import %s because "%s"', name, exc)
-        except Exception:
-            log.exception("while importing %s", name)
+        except ImportError:
+            log.exception("Failed to import %s", name)
 
     modules = {name: safe_import(name) for finder, name, ispkg in iter_namespace(module_ns)}
     plugins = {}
     if filter_plugins:
         plugins.update(flatten(filter_plugins(name, value) for name, value in modules.items()))
     else:
         plugins.update(dict(modules.items()))
```

## vqapi/util.py

```diff
@@ -201,25 +201,23 @@
     if uselocalpath:
         # Skip 'file:'
         path = image.value
         if path.startswith("file:"):
             path = path[5:]
         return {uri: path}
 
-#     url = session.service_url("blob_service", path=image.resource_uniq)
-#     blobdata = session.c.fetch(url)
-
+    url = session.service_url("blob_service", path=image.resource_uniq)
+    blobdata = session.c.fetch(url)
     if os.path.isdir(dest):
         outdest = os.path.join(dest, os.path.basename(name))
     else:
         outdest = os.path.join(".", os.path.basename(name))
-
-    blobs = session.service("blobs")
-    with blobs.read_chunk(blob_id=image.resource_uniq, as_stream=True) as f:
-        f.copy_into(outdest)
+    f = open(outdest, "wb")
+    f.write(blobdata)
+    f.close()
     return {uri: outdest}
 
 
 def fetch_image_planes(session, uri, dest=None, uselocalpath=False):
     """
     fetch all the image planes of an image locally
     @param session: the bqsession
```

## vqapi/version.py

```diff
@@ -1,16 +1,4 @@
 # file generated by setuptools_scm
 # don't change, don't track in version control
-TYPE_CHECKING = False
-if TYPE_CHECKING:
-    from typing import Tuple, Union
-    VERSION_TUPLE = Tuple[Union[int, str], ...]
-else:
-    VERSION_TUPLE = object
-
-version: str
-__version__: str
-__version_tuple__: VERSION_TUPLE
-version_tuple: VERSION_TUPLE
-
-__version__ = version = '0.6.4.87'
-__version_tuple__ = version_tuple = (0, 6, 4, 87)
+__version__ = version = '0.6.4.9'
+__version_tuple__ = version_tuple = (0, 6, 4, 9)
```

## vqapi/vqclass.py

```diff
@@ -1,85 +1,50 @@
 import copy
 import inspect
 import json
 import logging
 import sys
 import time
-from typing import Union
+from typing import List, Tuple
 
-from bq.metadoc.formats import RESERVED_TAGNAMES, Metadoc, anyxml_to_etree
+from bq.metadoc.formats import Metadoc, anyxml_to_etree
 
-from vqapi.comm import BQSession
+from vqapi import BQSession
 from vqapi.exception import BQApiError
-from vqapi.vqquery import get_provenance, run_sparql_query, run_tag_query
+from vqapi.vqquery import get_provenance, run_sparql_query
 
 log = logging.getLogger("vqapi.vqclass")
 
 
 def get_header(res, name):
     return res.headers.get(name, "").lstrip("W/")[
         1:-1
     ]  # remove entity tag and quotes (why is this not done by pyramid?)
 
 
 def _get_param_types(param, default="string"):
     param_type = param.get_attr("type", default)
-    if param_type in ("resource", "document"):
+    if param_type == "resource":
         acc_types = param.path_query("./template/accepted_type")
         if len(acc_types) > 0:
             param_type = [acc_type.get_value() for acc_type in acc_types]
     if not isinstance(param_type, list):
         param_type = [param_type]
     return param_type
 
-def _get_param_label(param):
-    label = param.path_query("./template/label")
-    if len(label) > 0:
-        return label[0].get_value()
-    else:
-        return None
-
 
 def _fetch_subdoc(sess: "VQSession", doc_id: str, node_id: str) -> Metadoc:
     meta = sess.service("meta")
     return meta.request(
         method="get",
         path=f"/{doc_id}@{node_id}",
         params={"view": "deep,clean"},
         render="doc",
     )
 
-def _parse_sizeof(num: Union[int, float, str]) -> Union[int, float]:
-    """
-    Convert common memory sizes
-
-    Args:
-      num: a string size such as "1MB", "4kb", "3.2tb"
-
-    Returns:
-     an integer in bytes
-    """
-    # dicts are ordered so insert longest to shortest order for match
-    units = {
-        "kb": 1024,
-        "mb": 1024**2,
-        "gb": 1024**3,
-        "tb": 1024**4,
-        "pb": 1024**5,
-        "b": 1,
-    }
-    if isinstance(num, str):
-        for sz, mult in units.items():
-            if num.lower().endswith(sz):
-                return int(float(num[: -len(sz)]) * mult)
-    try:
-        return int(num)
-    except ValueError:
-        return float(num)
-
 
 def copy_as_not_impl(other_class):
     """
     Decorator that adds a method returning "Not Implemented" for each method in other_class
     that has not been defined in this class.
     """
 
@@ -93,144 +58,74 @@
         return cls
 
     return wrapper
 
 
 class VQCollection:
     """
-    Collection of resources (typically result of a query).
+    Collection of resources (typically result of a query)
     """
 
-    def __init__(self, sess, from_query=None, from_tags=None):
+    def __init__(self, sess: "VQSession", from_query: Tuple[str, str] = None):
         self._sess = sess
-        self._from_query = [from_query[0], from_query[1], "", {}] if from_query is not None else None  # from_query = (sparql WHERE str, doc var)
-        self._from_tags = list(from_tags) if from_tags is not None else None  # from_tags = ("resource type", {'tag_query':'...', 'tag_order':'...'})
+        self._from_query = from_query  # from_query = (sparql WHERE str, doc var)
 
-    def order_by(self, order: list) -> "VQCollection":
-        if self._from_query is not None:
-            self._from_query[2] = "ORDER BY " + " ".join([f"{attrorder}(?{self._from_query[1]}/{attrname})" for attrname, attrorder in order])
-        else:
-            self._from_tags[1]["tag_order"] = ",".join([f"{attrname}:{attrorder}" for attrname, attrorder in order])
-        return self
-    
-    def limit(self, limit: int) -> "VQCollection":
-        if self._from_query is not None:
-            self._from_query[3]["limit"] = str(limit)
-        else:
-            self._from_tags[1]["limit"] = str(limit)
-        return self
-    
-    def offset(self, offset: int) -> "VQCollection":
+    def __len__(self):
         if self._from_query is not None:
-            self._from_query[3]["offset"] = str(offset)
-        else:
-            self._from_tags[1]["offset"] = str(offset)
-        return self
-
-    def __len__(self) -> int:
-        """
-        Get number of resources in collection.
-
-        Returns:
-            number of resources
-        """
-        if self._from_query is not None:
-            query, doc_var, order_clause, kwargs = self._from_query
+            query, doc_var = self._from_query
             matches = run_sparql_query(
                 self._sess,
-                f"SELECT COUNT(?{doc_var}/@resource_uniq) AS cnt WHERE {{ {query} }} {order_clause}",
-                **kwargs
+                f"SELECT COUNT(?{doc_var}/@resource_uniq) AS cnt WHERE {{ {query} }}",
             )
-            try:
-                return int(matches[0]["cnt"])
-            except TypeError:
-                return int(matches[0]["cnt"]["@value"])
-        if self._from_tags is not None:
-            rtype, kwargs = self._from_tags
-            kwargs["view"] = "count"
-            matches = run_tag_query(self._sess, rtype, **kwargs)
-            return int(matches.path_query("/result/count/@value")[0])
+            return int(matches[0]["cnt"])
 
     def __iter__(self):
-        """
-        Iterate over resources in collection.
-        """
         if self._from_query is not None:
-            query, doc_var, order_clause, kwargs = self._from_query
+            query, doc_var = self._from_query
             for match in run_sparql_query(
                 self._sess,
-                f"SELECT ?{doc_var}/@resource_uniq AS docid WHERE {{ {query} }} {order_clause}",
-                **kwargs
+                f"SELECT ?{doc_var}/@resource_uniq AS docid WHERE {{ {query} }}",
             ):
                 yield self._sess.load(match["docid"])
-        if self._from_tags is not None:
-            rtype, kwargs = self._from_tags
-            kwargs["view"] = "short"
-            for match in run_tag_query(self._sess, rtype, **kwargs):
-                yield self._sess.load(match.get_docid())
 
     def delete(self):
-        """
-        Delete all resources in collection in a transaction.
-
-        Raises:
-            BQApiError: deletion failed
-        """
-        patchdoc = Metadoc(tag="patch")
         if self._from_query is not None:
             # TODO: should use update query here
-            query, doc_var, order_clause, kwargs = self._from_query
-            for match in run_sparql_query(
+            query, doc_var = self._from_query
+            patchdoc = Metadoc(tag="patch")
+            matches = run_sparql_query(
                 self._sess,
-                f"SELECT ?{doc_var}/@resource_uniq AS docid WHERE {{ {query} }} {order_clause}",
-                **kwargs
-            ):
+                f"SELECT ?{doc_var}/@resource_uniq AS docid WHERE {{ {query} }}",
+            )
+            for match in matches:
                 patchdoc.add_tag("remove", sel=f"/{match['docid']}")
-        if self._from_tags is not None:
-            rtype, kwargs = self._from_tags
-            kwargs["view"] = "short"
-            for match in run_tag_query(self._sess, rtype, **kwargs):
-                patchdoc.add_tag("remove", sel=f"/{match.get_docid()}")
-        meta = self._sess.service("meta")
-        res = meta.request(method="patch", path="/", data=patchdoc, render=None)
-        if res.status_code != 200:
-            raise BQApiError(f"collection could not be deleted: {res.text}")
+            meta = self._sess.service("meta")
+            res = meta.request(method="patch", path="/", data=patchdoc, render=None)
+            if res.status_code != 200:
+                raise BQApiError(f"collection could not be deleted: {res.text}")
 
 
 @copy_as_not_impl(Metadoc)
 class VQResource:
     """
     Class to store any ViQi-backed resource doc;
-    same interface as :external:py:class:`~bq.metadoc.formats.Metadoc` but has extra functions depending on resource type.
+    same interface as Metadoc but has extra functions depending on resource type.
     """
 
-    def __init__(self, sess, doc_uniq=None, doc_version=None, **attrs):
-        # next five lines have to be first to enable refresh
+    def __init__(self, sess: "VQSession", doc_uniq: str = None, doc_version: str = None, **attrs):
+        tag = self.resource_type
         self._doc_uniq = doc_uniq
         self._doc_version = doc_version
+        self._doc = Metadoc(tag=tag, **attrs)
         self._doc_lvls = 0
         self._sess = sess
         self._meta = sess.service("meta")
-        # additional inits (may trigger refresh)
-        tag = self.resource_type
-        self._doc = Metadoc(tag=tag, **attrs)
 
     @staticmethod
     def load(sess: "VQSession", uniq: str) -> "VQResource":
-        """
-        Load a resource from resource UUID.
-        (Same as calling `sess.load(uniq)`.)
-
-        Args:
-            sess: active session
-            uniq: resource UUID
-
-        Returns:
-            loaded resource
-        """
         return sess.load(uniq)
 
     @classmethod
     def find(cls, sess: "VQSession", **kwargs) -> "VQResource":
         raise NotImplementedError(f"find operation not implemented for resource type {cls.resource_type}")
 
     def _refresh(self, lvls: int):
@@ -252,74 +147,48 @@
                 self._doc_version = get_header(res, "ETag")
                 self._doc_lvls = lvls
             elif res.status_code == 304:  # not modified
                 pass
             else:
                 raise BQApiError(f"resource {self._doc_uniq} could not be refreshed")
 
-    def __getattr__(self, name: str) -> str:
+    def __getattr__(self, name):
         if name in ("_doc_uniq", "_doc_version", "_doc", "_doc_lvls", "_sess", "_meta"):
             return self.__dict__[name]
         self._refresh(lvls=1)
         return self._doc.__getattr__(name)
 
-    def __setattr__(self, name: str, val: str):
+    def __setattr__(self, name, val):
         if name in ("_doc_uniq", "_doc_version", "_doc", "_doc_lvls", "_sess", "_meta"):
             self.__dict__[name] = val
             return
         raise NotImplementedError(f'setting of doc attribute "{name}" not implemented')
 
-    def get_docid(self) -> str:
-        """
-        Get UUID of this resource.
-
-        Returns:
-            UUID
-        """
+    def get_docid(self):
         return self._doc_uniq
 
     def get_value(self):
         self._refresh(lvls=1)
         return self._doc.get_value()
 
     def get_attr(self, attr, default=None):
         self._refresh(lvls=1)
         return self._doc.get_attr(attr, default)
 
     def get(self, attr, default=None):
         self._refresh(lvls=1)
         return self._doc.get(attr, default)
 
-    def as_dict(self) -> dict:
-        """
-        Get resource metadata as a JSON dictionary.
-
-        Returns:
-            dict
-        """
+    def to_json(self):
         self._refresh(lvls=sys.maxsize)  # avoid if possible
-        return self._doc.as_dict()
-
-    def as_xml(self) -> str:
-        """
-        Get resource metadata as an XML string.
-
-        Returns:
-            str
-        """
-        self._refresh(lvls=sys.maxsize)  # avoid if possible
-        return self._doc.as_xml()
-
-    # alias
-    to_json = as_dict
+        return self._doc.to_json()
 
     def __str__(self):
-        return f"{self.resource_type}@{self._doc_uniq}"
-
-    __repr__ = __str__
+        self._refresh(lvls=sys.maxsize)  # avoid if possible
+        return self._doc.to_naturalxml()
 
     def path_query(self, path):
         self._refresh(lvls=sys.maxsize)  # TODO: maybe run as server side query?
         return self._doc.path_query(path)
 
     def add_sibling(self, tag, **attrs):
         if self._doc_uniq is not None:
@@ -337,152 +206,23 @@
         return self._doc.delete()
 
     def add_child(self, newchild):
         if self._doc_uniq is not None:
             raise NotImplementedError("updates to stored docs not implemented")
         return self._doc.add_child(newchild)
 
-    def permissions(self) -> str:
-        """
-        Get permissions to this resource (e.g., "read,write")
-
-        Returns:
-            string with comma-separated permissions to this resource
-        """
-        user_id = self._sess.current_user().get_docid()
-        res = self._meta.request(
-                method="get",
-                path="/" + self._doc_uniq + "/auth",
-                render="doc"
-            )
-        matches = res.path_query(f"""user[./@name = "{user_id}"]""")
-        if len(matches) > 0:
-            return matches[0].get_value()
-        else:
-            return "read" if self.get_attr("permission") == "published" else ""
-
-    def as_bytes(self):
-        """
-        Read raw bytes of resource.
-        Careful with large resources!
-
-        Returns:
-            bytes
-        """
-        blob_service = self._sess.service("blobs")
-        with blob_service.read_chunk(self.get_docid(), as_stream=True) as f:
-            return f.readall()
-
-    def as_native(self):
-        """
-        Get resource in best native representation.
-
-        Returns:
-            object
-        """
-        return self.as_bytes()
-
 
 class VQMex(VQResource):
-    """
-    Class representing a Mex (running or past module run).
-    """
-
     resource_type = "mex"
 
-    @classmethod
-    def find(
-        cls, 
-        sess: "VQSession",
-        module_name: str, 
-        version: str = None,
-        status: str | list[str] = None,
-        not_status: str | list[str] = None,
-        _execute_options: dict = None,
-        **kwargs,
-    ) -> VQCollection:
-        """
-        Fetch mex doc(s) for given execute options and inputs.
-
-        Args:
-            sess: session
-            module_name: name of the module
-            version: version tag of build (or None to search in all versions)
-            status: mex statuses to match (e.g., "FINISHED")
-            not_status: mex statuses to NOT match (e.g., ["STOPPED", "FAILED"])
-            _execute_options: execute options to match (e.g., "requested_memory", "requested_gpus")
-            kwargs: input parameters to match (will be mapped to module inputs)
-
-        Returns:
-            collection of mexes that match
-
-        Raises:
-            BQApiError
-        """
-        _execute_options = _execute_options or {}
-        extra_filters = []
-        extra_patterns = []
-        for idx, (exop, exval) in enumerate(_execute_options.items()):
-            extra_patterns.append(f"?exops :/ {exop}:?exop{idx}")
-            try:
-                exval = _parse_sizeof(exval)
-            except ValueError:
-                pass
-            extra_filters.append(f'?exop{idx}/@value_str = "{exval}"')
-        for idx, (argname, argval) in enumerate(kwargs.items()):
-            extra_patterns.append(f"?inp :// {argname}:?arg{idx}")
-            if isinstance(argval, VQResource):
-                argval = argval.get_docid()
-            elif isinstance(argval, list):
-                argval = ";".join(str(param) for param in argval)
-            elif isinstance(argval, bool):
-                argval = ["False","false"] if argval is False else ["True","true"]
-            if isinstance(argval, str):
-                argval = argval.replace(r'"', r'\"')
-            if isinstance(argval, list):
-                extra_filters.append("(" + " OR ".join(f'?arg{idx}/@value_str = "{argval_single}"' for argval_single in argval) + ")")
-            else:
-                extra_filters.append(f'?arg{idx}/@value_str = "{argval}"')
-        if status is not None:
-            if not isinstance(status, list):
-                status = [status]
-            statuses = [f'?mex/@value_str = "{sstatus}"' for sstatus in status]
-            if len(statuses) > 1:
-                extra_filters.append('(' + ' OR '.join(statuses) + ')')
-            else:
-                extra_filters.append(statuses[0])
-        if not_status is not None:
-            if not isinstance(not_status, list):
-                not_status = [not_status]
-            not_statuses = [f'?mex/@value_str != "{not_sstatus}"' for not_sstatus in not_status]
-            extra_filters.append(' AND '.join(not_statuses))
-        if version is not None:
-            extra_filters.append(f'?bld/@name = "{version}"')
-        extra_patterns = ". ".join(extra_patterns)
-        if extra_patterns != "":
-            extra_patterns = ". " + extra_patterns
-        extra_filters = " AND ".join(extra_filters)
-        if extra_filters != "":
-            extra_filters = " AND " + extra_filters
-        where = f"""
-                /mex:?mex :/ build:?bldref. ?bldref :-> /build:?bld. ?bld :/ module:?modref. ?modref :-> /module:?mod.
-                ?mex :/ inputs:?inp.
-                ?mex :/ execute_options:?exops
-                {extra_patterns}
-                FILTER( ?mod/@name = "{module_name}"
-                        {extra_filters} )
-            """
-        log.debug("query for previous mex run: %s", where)
-        return VQCollection(sess, from_query=(where, "mex"))
-
     def wait(self):
         """
         Wait for module to finish or fail.
         """
-        while self.get_value() not in ("FINISHED", "FAILED", "STOPPED"):
+        while self.get_value() not in ("FINISHED", "FAILED"):
             time.sleep(10)
 
     def retry(self):
         """
         (Partially) re-run a failed module with same settings.
         For multi-runs, only failed submexes will be re-run.
         """
@@ -497,126 +237,84 @@
                 data=update_doc,
             )
             if not isinstance(mex_doc, Metadoc):
                 raise BQApiError(f"module could not be restarted: {mex_doc.text}")
         except Exception as exc:
             raise BQApiError(f"module could not be restarted: {str(exc)}")
 
-    def stop(self):
-        """
-        Stop a module run.
-        For multi-runs, this will also stop all sub-runs.
-        """
-        mex_service = self._sess.service("mexes")
-        try:
-            mex_doc = mex_service.request(
-                path=f"/{self.get_docid()}",
-                method="delete",
-                render="doc",
-            )
-            if not isinstance(mex_doc, Metadoc):
-                raise BQApiError(f"module could not be stopped: {mex_doc.text}")
-        except Exception as exc:
-            raise BQApiError(f"module could not be stopped: {str(exc)}")
-
     def get_build(self) -> "VQBuild":
         """
         Get build def for this mex.
 
         Returns:
-            build doc
+            VQBuild: build doc
         """
         self._refresh(lvls=2)
         build_id = self._doc.path_query("//build")[0]
         return VQBuild.load(self._sess, build_id.get_value())
 
-    def get_input(self, input_name: str) -> object:
-        """
-        Retrieve input of module.
-
-        Args:
-            input_name: name of input
-
-        Returns:
-            input value (may be any type, including VQResource subtype)
-        """
-        self._refresh(lvls=sys.maxsize)
-        mex_in = self._doc.path_query(f'/mex/inputs//{input_name}[not(@type) or @type != "group"]')
-        if len(mex_in) == 0:
-            if len(self._doc.path_query("/mex/mex")) > 0:
-                raise BQApiError("this is a mex with submexes; please use get_sub_input or get_sub_inputs")
-            else:
-                raise BQApiError(f'input "{input_name}" not found')
-        in_arg = mex_in[0]
-        return self._get_io_single(
-            arg_type=in_arg.get_attr("type", "doc"),
-            arg_value=in_arg.get_value(),
-            docid=self._doc_uniq,
-            nid=in_arg.get("_id"),
-        )
-
     def get_output(self, output_name: str) -> object:
         """
         Retrieve output of module.
 
         Args:
-            output_name: name of output
+            output_name (str): name of output
 
         Returns:
-            output value (may be any type, including VQResource subtype)
+            object: output value (may be any type, including VQResource subtype)
         """
         self.wait()
         self._refresh(lvls=sys.maxsize)
         mex_out = self._doc.path_query(f'/mex/outputs//{output_name}[not(@type) or @type != "group"]')
         if len(mex_out) == 0:
             if len(self._doc.path_query("/mex/mex")) > 0:
                 raise BQApiError("this is a mex with submexes; please use get_sub_output or get_sub_outputs")
             else:
                 raise BQApiError(f'output "{output_name}" not found')
         out_arg = mex_out[0]
-        return self._get_io_single(
-            arg_type=out_arg.get_attr("type", "doc"),
-            arg_value=out_arg.get_value(),
-            docid=self._doc_uniq,
-            nid=out_arg.get("_id"),
+        return self._get_output_single(
+            out_arg_type=out_arg.get_attr("type", "doc"),
+            out_arg_value=out_arg.get_value(),
+            out_docid=self._doc_uniq,
+            out_id=out_arg.get("_id"),
         )
 
     def get_qc(self, qc_name: str) -> object:
         """
         Retrieve generated qc data of module.
 
         Args:
-            qc_name: name of qc output
+            qc_name (str): name of qc output
 
         Returns:
-            output value (may be any type, including VQResource subtype)
+            object: output value (may be any type, including VQResource subtype)
         """
         self.wait()
         self._refresh(lvls=sys.maxsize)
         mex_out = self._doc.path_query(f'/mex/qc//{qc_name}[not(@type) or @type != "group"]')
         if len(mex_out) == 0:
             raise BQApiError(f'qc data "{qc_name}" not found')
         out_arg = mex_out[0]
-        return self._get_io_single(
-            arg_type=out_arg.get_attr("type", "doc"),
-            arg_value=out_arg.get_value(),
-            docid=self._doc_uniq,
-            nid=out_arg.get("_id"),
+        return self._get_output_single(
+            out_arg_type=out_arg.get_attr("type", "doc"),
+            out_arg_value=out_arg.get_value(),
+            out_docid=self._doc_uniq,
+            out_id=out_arg.get("_id"),
         )
 
     def get_sub_output(self, output_name: str, **selectors) -> object:
         """
         Retrieve output in specific submex of a multimex run.
 
         Args:
-            output_name: name of output
+            output_name (str): name of output
             selectors: one or more mex input tags/values to specify which submex
 
         Returns:
-            output value (may be any type, including VQResource)
+            object: output value (may be any type, including VQResource)
         """
         if len(selectors) == 0:
             raise BQApiError("need at least one selector to find output")
         self.wait()
         extra_patterns = []
         extra_filters = []
         for idx, (key, val) in enumerate(selectors.items()):
@@ -648,23 +346,23 @@
         return self._get_sub_output_single(
             out_arg_type=matches[0]["out_type"] or "doc",
             out_arg_value=matches[0]["out_val"] or None,
             out_docid=matches[0]["out_docid"],
             out_id=matches[0]["out_id"],
         )
 
-    def get_sub_outputs(self, output_name: str) -> list[object]:
+    def get_sub_outputs(self, output_name: str) -> List[object]:
         """
         Retrieve specific outputs in all submexes of a multimex run.
 
         Args:
-            output_name: name of output
+            output_name (str): name of output
 
         Returns:
-            list of output values (each may be any type, including VQResource)
+            List[object]: list of output values (each may be any type, including VQResource)
         """
         self.wait()
         query = f"""
             SELECT ?out/@resource_uniq AS out_docid
                    ?out/@node_id AS out_id
                    ?out/@type AS out_type
                    ?out/@value_str AS out_val
@@ -675,49 +373,47 @@
                         ?out/@name = "{output_name}" )
             }}
             """
         matches = run_sparql_query(self._sess, query)
         if len(matches) == 0:
             raise BQApiError(f'no outputs "{output_name}" found')
         return [
-            self._get_io_single(
-                arg_type=match["out_type"] or "doc",
-                arg_value=match["out_val"] or None,
-                docid=match["out_docid"],
-                nid=match["out_id"],
+            self._get_output_single(
+                out_arg_type=match["out_type"] or "doc",
+                out_arg_value=match["out_val"] or None,
+                out_docid=match["out_docid"],
+                out_id=match["out_id"],
             )
             for match in matches
         ]
 
-    def _get_io_single(self, arg_type, arg_value, docid, nid):
-        if arg_type == "number":
+    def _get_output_single(self, out_arg_type, out_arg_value, out_docid, out_id):
+        if out_arg_type == "number":
             try:
-                return int(arg_value)
+                return int(out_arg_value)
             except ValueError:
                 try:
-                    return float(arg_value)
+                    return float(out_arg_value)
                 except ValueError:
-                    return arg_value
-        elif arg_type == "string":
-            return arg_value
-        elif arg_type == "doc":
-            return _fetch_subdoc(self._sess, docid, nid)
+                    return out_arg_value
+        elif out_arg_type == "string":
+            return out_arg_value
+        elif out_arg_type == "doc":
+            return _fetch_subdoc(self._sess, out_docid, out_id)
+        elif out_arg_type in self._sess.factory.resources:
+            return self._sess.load(out_arg_value)
         else:
-            # try to load as a VQResource; if it fails, return doc
-            try:
-                return self._sess.load(arg_value)
-            except BQApiError:
-                return _fetch_subdoc(self._sess, docid, nid)
+            return _fetch_subdoc(self._sess, out_docid, out_id)
 
     def get_sub_states(self) -> dict:
         """
         Retrieve states in all submexes of a multimex run.
 
         Returns:
-            submex states and counts
+            dict: submex states and counts
         """
         query = f"""
             SELECT ?submex/@value_str AS state
                    COUNT(?submex/@value_str) AS count
             WHERE {{
                 /mex:?this :/ mex:?mexref. ?mexref :-> /mex:?submex
                 FILTER( ?this/@resource_uniq = "{self._doc_uniq}" )
@@ -728,140 +424,68 @@
         return {match["state"]: int(match["count"]) for match in matches}
 
     def get_all_mexes(self) -> VQCollection:
         """
         Get collection of mex and all its submexes.
 
         Returns:
-            collection of mex and submexes
+            VQCollection: collection of mex and submexes
         """
         query = f"""{{ /mex:?mex FILTER( ?mex/@resource_uniq = "{self._doc_uniq}" ) }} UNION
                     {{ /mex:?supermex :/ mex:?mexref. ?mexref :-> /mex:?mex FILTER( ?supermex/@resource_uniq = "{self._doc_uniq}" ) }}"""
         return VQCollection(self._sess, from_query=(query, "mex"))
 
-    as_native = VQResource.as_dict
-
 
 class VQModule(VQResource):
-    """
-    Class representing an analysis Module.
-    """
-
     resource_type = "module"
 
     @property
-    def inputs(self) -> list[tuple[str, str, str]]:
+    def inputs(self) -> List[Tuple[str, str, object]]:
         """
         Get list of input names.
 
         Returns:
-            list of (input name, input type, label)
+            List[Tuple[str,str,object]]: list of (input name, input type, default value)
         """
         self._refresh(lvls=sys.maxsize)
         return [
-            (module_arg.get_attr("name"), _get_param_types(module_arg), _get_param_label(module_arg))
+            (module_arg.get_attr("name"), _get_param_types(module_arg))
             for module_arg in self._doc.path_query('/module/inputs//*[not(@type) or @type != "group"][./template]')
         ]
 
     @property
-    def outputs(self) -> list[tuple[str, str]]:
+    def outputs(self) -> List[Tuple[str, str]]:
         """
         Get list of output names.
 
         Returns:
-            list of (output name, output type)
+            List[Tuple[str,str]]: list of (output name, output type)
         """
         self._refresh(lvls=sys.maxsize)
         return [
-            (module_arg.get_attr("name"), _get_param_types(module_arg, "doc"), _get_param_label(module_arg))
+            (module_arg.get_attr("name"), _get_param_types(module_arg, "doc"))
             for module_arg in self._doc.path_query('/module/outputs//*[not(@type) or @type != "group"][./template]')
         ]
 
-    def inputname_to_label(self, inputname: str) -> str:
-        """
-        Convert internal input name to UI label.
-
-        Args:
-            inputname: input name to convert
-
-        Returns:
-            UI label if found, else None
-        """
-        for inputname_iter, _, label_iter in self.inputs:
-            if inputname_iter == inputname:
-                return label_iter
-        return None
-        
-    def label_to_inputname(self, label: str) -> str:
-        """
-        Convert UI label to internal input name.
-
-        Args:
-            label: UI label to convert
-
-        Returns:
-            internal input name if found, else None
-        """
-        for inputname_iter, _, label_iter in self.inputs:
-            if label_iter == label:
-                return inputname_iter
-        return None
-
-    def outputname_to_label(self, outputname: str) -> str:
-        """
-        Convert internal output name to UI label.
-
-        Args:
-            outputname: output name to convert
-
-        Returns:
-            UI label if found, else None
-        """
-        for outputname_iter, _, label_iter in self.outputs:
-            if outputname_iter == outputname:
-                return label_iter
-        return None
-        
-    def label_to_outputname(self, label: str) -> str:
-        """
-        Convert UI label to internal output name.
-
-        Args:
-            label: UI label to convert
-
-        Returns:
-            internal output name if found, else None
-        """
-        for outputname_iter, _, label_iter in self.outputs:
-            if label_iter == label:
-                return outputname_iter
-        return None
-
-    as_native = VQResource.as_dict
-
-
-class VQBuild(VQModule):
-    """
-    Class representing a Build (specific analysis module version).
-    """
 
+class VQBuild(VQResource):
     resource_type = "build"
 
     @classmethod
     def find(cls, sess: "VQSession", module_name: str, version: str) -> "VQBuild":
         """
         Fetch build doc for given module/version combo.
 
         Args:
-            sess: session
-            module_name: name of the module
-            version: version tag of build
+            sess (VQSession): session
+            module_name (str): name of the module
+            version (str): version tag of build
 
         Returns:
-            build doc
+            VQBuild: build doc
 
         Raises:
             BQApiError
         """
         # TODO: the following could be moved into the lower level build api
         query = f"""
             SELECT ?bld/@resource_uniq AS build_id
@@ -879,178 +503,68 @@
         return VQResource.load(sess, matches[0]["build_id"])
 
     def get_module(self) -> VQModule:
         """
         Get module def for this build.
 
         Returns:
-            module doc
+            VQModule: module doc
         """
         self._refresh(lvls=2)
         module_id = self._doc.path_query("//module")[0]
         return VQModule.load(self._sess, module_id.get_value())
 
     @property
-    def inputs(self) -> list[tuple[str, str, str]]:
+    def inputs(self) -> List[Tuple[str, str, object]]:
         """
         Get list of input names.
 
         Returns:
-            list of (input name, input type, label)
+            List[Tuple[str,str,object]]: list of (input name, input type, default value)
         """
         self._refresh(lvls=sys.maxsize)
         return [
-            (module_arg.get_attr("name"), _get_param_types(module_arg), _get_param_label(module_arg))
+            (module_arg.get_attr("name"), _get_param_types(module_arg))
             for module_arg in self._doc.path_query('/build/inputs//*[not(@type) or @type != "group"][./template]')
         ]
 
     @property
-    def outputs(self) -> list[tuple[str, str]]:
+    def outputs(self) -> List[Tuple[str, str]]:
         """
         Get list of output names.
 
         Returns:
-            list of (output name, output type)
+            List[Tuple[str,str]]: list of (output name, output type)
         """
         self._refresh(lvls=sys.maxsize)
         return [
-            (module_arg.get_attr("name"), _get_param_types(module_arg, "doc"), _get_param_label(module_arg))
+            (module_arg.get_attr("name"), _get_param_types(module_arg, "doc"))
             for module_arg in self._doc.path_query('/build/outputs//*[not(@type) or @type != "group"][./template]')
         ]
 
-    def last_good_run(
-        self,
-        _keep_log: bool = False,
-        _extra_tags: dict = None,
-        _execute_options: dict = None,
-        _merge_outputs: list = None,
-        _ignore_version: bool = False,
-        **kwargs,
-    ) -> VQMex:
-        """
-        Find latest previous successful run with given input parameters.
-        
-        Args:
-            _keep_log: preserve log of run in module execution dir (not used)
-            _extra_tags: extra tags to be added to Mex (not used)
-            _execute_options: execute options to match (e.g., "requested_memory", "requested_gpus")
-            _merge_outputs: list of output names for submex output merging (not used)
-            _ignore_version: if True, search in all available module versions
-            kwargs: input parameters to match (will be mapped to module inputs)
-
-        Returns:
-            mex doc of latest run
-
-        Raises:
-            BQApiError
-        """
-        return self.last_run(_keep_log=_keep_log,
-                             _extra_tags=_extra_tags,
-                             _execute_options=_execute_options,
-                             _merge_outputs=_merge_outputs,
-                             _last_run_status="FINISHED",
-                             _ignore_version=_ignore_version,
-                             **kwargs)
-        
-    def last_bad_run(
-        self,
-        _keep_log: bool = False,
-        _extra_tags: dict = None,
-        _execute_options: dict = None,
-        _merge_outputs: list = None,
-        _ignore_version: bool = False,
-        **kwargs,
-    ) -> VQMex:
-        """
-        Find latest previous failed run with given input parameters.
-        
-        Args:
-            _keep_log: preserve log of run in module execution dir (not used)
-            _extra_tags: extra tags to be added to Mex (not used)
-            _execute_options: execute options to match (e.g., "requested_memory", "requested_gpus")
-            _merge_outputs: list of output names for submex output merging (not used)
-            _ignore_version: if True, search in all available module versions
-            kwargs: input parameters to match (will be mapped to module inputs)
-
-        Returns:
-            mex doc of latest run
-
-        Raises:
-            BQApiError
-        """
-        return self.last_run(_keep_log=_keep_log,
-                             _extra_tags=_extra_tags,
-                             _execute_options=_execute_options,
-                             _merge_outputs=_merge_outputs,
-                             _last_run_status="FAILED",
-                             _ignore_version=_ignore_version,
-                             **kwargs)
-
-    def last_run(
-        self,
-        _keep_log: bool = False,
-        _extra_tags: dict = None,
-        _execute_options: dict = None,
-        _merge_outputs: list = None,
-        _last_run_status: str | list[str] = None,
-        _last_run_not_status: str | list[str] = None,
-        _ignore_version: bool = False,
-        **kwargs,
-    ) -> VQMex:
-        """
-        Find latest previous run with given input parameters.
-        
-        Args:
-            _keep_log: preserve log of run in module execution dir (not used)
-            _extra_tags: extra tags to be added to Mex (not used)
-            _execute_options: execute options to match (e.g., "requested_memory", "requested_gpus")
-            _merge_outputs: list of output names for submex output merging (not used)
-            _last_run_status: allowed statuses of run
-            _last_run_not_status: not allowed statuses of run
-            _ignore_version: if True, search in all available module versions
-            kwargs: input parameters to match (will be mapped to module inputs)
-
-        Returns:
-            mex doc of latest run
-
-        Raises:
-            BQApiError
-        """
-        module_name = self.get_module().get("name")
-        version = self.get("name") if _ignore_version is False else None
-        res = self._sess.find("mex", module_name=module_name, version=version, status=_last_run_status, not_status=_last_run_not_status, _execute_options=_execute_options, **kwargs)
-        if isinstance(res, VQCollection):
-            match = None
-            for match in res.order_by([("@created", "desc")]).limit(1):  # only get the latest
-                break
-            if match is None:
-                raise BQApiError("no matching run found")
-            res = match
-        return res
-
-    def run(
+    def start(
         self,
         _keep_log: bool = False,
         _extra_tags: dict = None,
         _execute_options: dict = None,
         _merge_outputs: list = None,
         **kwargs,
     ) -> VQMex:
         """
         Start this build with the given input parameters.
 
         Args:
-            _keep_log: preserve log of run in module execution dir
-            _extra_tags: extra tags to be added to Mex
-            _execute_options: override execute options (e.g., "requested_memory", "requested_gpus")
-            _merge_outputs: list of output names for submex output merging
+            _keep_log (bool): preserve log of run in module execution dir
+            _extra_tags (dict): extra tags to be added to Mex
+            _execute_options (dict): override execute options (e.g., "requested_memory", "requested_gpus")
+            _merge_outputs (list): list of output names for submex output merging
             kwargs: input parameters (will be mapped to module inputs)
 
         Returns:
-            mex doc
+            VQMex: mex doc
 
         Raises:
             BQApiError
         """
 
         self._refresh(lvls=sys.maxsize)  # we need most of the doc anyway
 
@@ -1070,71 +584,54 @@
         for param_name, param_val in kwargs.items():
             module_arg = mex_inputs.path_query(f'/inputs//{param_name}[not(@type) or @type != "group"][./template]')
             if len(module_arg) == 0:
                 raise BQApiError(f'Unknown module parameter "{param_name}"')
             module_arg = module_arg[0]
             single_param_val = param_val
             skip_typecheck = False
-            is_list_iter = False
             if isinstance(param_val, VQDataset) and param_name in iterables and iterables[param_name] == "dataset":
                 add_iterables[param_name] = "dataset"
                 skip_typecheck = True  # would need to check the type of elements of dataset
             elif isinstance(param_val, list) and not any(
                 ptype.startswith("list") for ptype in _get_param_types(module_arg)
             ):
                 if param_name in iterables and iterables[param_name] == "list":
                     add_iterables[param_name] = "list"
                     single_param_val = param_val[0]
-                    param_val = ",".join([str(val) for val in param_val])
-                    is_list_iter = True
+                    param_val = ",".join(param_val)
                 else:
                     raise BQApiError(f'List of values provided for non-iterable parameter "{param_name}"')
             if not skip_typecheck:
                 if (
                     (isinstance(single_param_val, bool) and "boolean" not in _get_param_types(module_arg))
                     or (
                         isinstance(single_param_val, (int, float, complex))
-                        and not isinstance(single_param_val, bool)
                         and "number" not in _get_param_types(module_arg)
                     )
-                    or (
-                        isinstance(single_param_val, str)
-                        and "string" not in _get_param_types(module_arg)
-                        and "combo" not in _get_param_types(module_arg)
-                    )
+                    or (isinstance(single_param_val, str) and "string" not in _get_param_types(module_arg))
                     or (
                         isinstance(single_param_val, list)
                         and not any(ptype.startswith("list") for ptype in _get_param_types(module_arg))
                     )
                     or (
                         isinstance(single_param_val, VQResource)
                         and single_param_val.resource_type not in _get_param_types(module_arg)
                         and "resource" not in _get_param_types(module_arg)
                     )
                 ):
-                    if not isinstance(single_param_val, str) or all(
-                        ptype in ("number", "boolean") or ptype in RESERVED_TAGNAMES or ptype.startswith("list")
-                        for ptype in _get_param_types(module_arg)
-                    ):
-                        raise BQApiError(
-                            f'Type mismatch for module parameter "{param_name}"; expected: {_get_param_types(module_arg)} got: {type(single_param_val)}'
-                        )
-                    else:
-                        log.info('passing parameter "%s" (type %s) as string', param_name, _get_param_types(module_arg))
+                    raise BQApiError(
+                        f'Type mismatch for module parameter "{param_name}"; expected: {_get_param_types(module_arg)} got: {type(single_param_val)}'
+                    )
             if isinstance(param_val, VQResource):
                 module_arg.set_value(param_val.get_docid())
                 module_arg.set_attr("type", param_val.resource_type)
             elif isinstance(param_val, list):
                 module_arg.set_value(";".join(str(param) for param in param_val))
-            elif isinstance(param_val, bool):
-                module_arg.set_value("true" if param_val is True else "false")
             else:
                 module_arg.set_value(str(param_val))
-                if is_list_iter:
-                    module_arg.set_attr("type", "list")  # mark as a list for iteration
 
         # remove templates
         for templ in mex_inputs.path_query("//template"):
             templ.delete()
 
         # add inputs to mex
         mex_doc.add_child(mex_inputs)
@@ -1170,64 +667,22 @@
                 raise BQApiError(f"module could not be started: {mex_doc.text}")
         except Exception as exc:
             raise BQApiError(f"module could not be started: {str(exc)}")
 
         # return created mex resource
         return VQMex.load(self._sess, mex_doc.get_docid())
 
-    def find_or_run(
-        self,
-        _keep_log: bool = False,
-        _extra_tags: dict = None,
-        _execute_options: dict = None,
-        _merge_outputs: list = None,
-        **kwargs,
-    ) -> VQMex:
-        """
-        Find successful run with the given input parameters or start a new one if none found.
-
-        Args:
-            _keep_log: preserve log of run in module execution dir
-            _extra_tags: extra tags to be added to Mex
-            _execute_options: override execute options (e.g., "requested_memory", "requested_gpus")
-            _merge_outputs: list of output names for submex output merging
-            kwargs: input parameters (will be mapped to module inputs)
-
-        Returns:
-            mex doc
-
-        Raises:
-            BQApiError
-        """
-        try:
-            return self.last_good_run(_keep_log=_keep_log,
-                                      _extra_tags=_extra_tags,
-                                      _execute_options=_execute_options,
-                                      _merge_outputs=_merge_outputs,
-                                      **kwargs)
-        except BQApiError:
-            # not found => start it
-            return self.run(_keep_log=_keep_log,
-                            _extra_tags=_extra_tags,
-                            _execute_options=_execute_options,
-                            _merge_outputs=_merge_outputs,
-                            **kwargs)
-
-    start = run
-
-    as_native = VQResource.as_dict
-
 
 class VQTableContainer(VQResource):
     resource_type = "tablecontainer"
 
     @staticmethod
     def concat(
         sess: "VQSession",
-        table_containers: list["VQTableContainer"],
+        table_containers: List["VQTableContainer"],
         in_path: str,
         out_path: str,
         dim: int,
     ) -> "VQTableContainer":
         pass  # !!!
 
     def get_array(self, path, slices=None):
@@ -1243,118 +698,43 @@
             as_dataframe=as_dataframe,
         )
 
 
 class VQTable(VQResource):
     resource_type = "table"
 
-    def get_table(self, slices=None, as_dataframe=True):
-        table_service = self._sess.service("tables")
-        return table_service.load_table(
-            table_uniq=self.get_docid(),
-            path="",
-            slices=slices,
-            as_dataframe=as_dataframe,
-        )
-
-    as_native = get_table
-
 
 class VQDataset(VQResource):
     resource_type = "dataset"
 
-    as_native = VQResource.as_dict
-
 
 class VQConnoisseur(VQResource):
     resource_type = "connoisseur"
 
-    as_native = VQResource.as_dict
-
-
-class VQUser(VQResource):
-    resource_type = "user"
-
-    @classmethod
-    def find(cls, sess: "VQSession") -> "VQUser":
-        """
-        Fetch current user.
-
-        Args:
-            sess: session
-
-        Returns:
-            user doc
-
-        Raises:
-            BQApiError
-        """
-        query = """
-            SELECT ?usr/@resource_uniq AS user_id
-            WHERE {{
-                /user:?usr
-            }}
-            """
-        matches = run_sparql_query(sess, query, wpublic="owner")
-        if len(matches) == 0:
-            raise BQApiError('no current user found')
-        if len(matches) > 1:
-            raise BQApiError('multiple users found')
-        return VQResource.load(sess, matches[0]["user_id"])
-
-    as_native = VQResource.as_dict
-
 
 class VQPlotly(VQResource):
     resource_type = "plotly"
 
-    def as_plotly(self):
+    def show(self):
         """
         Get plot as plotly figure.
 
         Returns:
             plotly.graph_objects.Figure
         """
         try:
             from plotly.graph_objects import Figure
         except ImportError:
-            raise BQApiError("as_plotly requires installed plotly package")
+            raise BQApiError("show requires installed plotly package")
 
         blob_service = self._sess.service("blobs")
         with blob_service.read_chunk(self.get_docid(), as_stream=True) as f:
             stored_fig = json.loads(f.readall().decode("utf-8"))
             return Figure(data=stored_fig[0], layout=stored_fig[1])
 
-    # alias for backward comp
-    show = as_plotly
-
-    as_native = as_plotly
-
-
-class VQHTML(VQResource):
-    resource_type = "html"
-
-    def as_html(self):
-        """
-        Get as html object.
-
-        Returns:
-            plotly.graph_objects.Figure
-        """
-        try:
-            from IPython.core.display import HTML
-        except ImportError:
-            raise BQApiError("as_html requires installed IPython package")
-
-        blob_service = self._sess.service("blobs")
-        with blob_service.read_chunk(self.get_docid(), as_stream=True) as f:
-            return HTML(f.readall().decode("utf-8"))
-
-    as_native = as_html
-
 
 class VQImage(VQResource):
     resource_type = "image"
 
     def __init__(self, *args, **kw):
         super().__init__(*args, **kw)
         self._geometry = None
@@ -1435,39 +815,34 @@
             raise BQApiError(f"resource {uniq} could not be loaded")
         doc_version = get_header(res, "ETag")
         doc = res.doc()
         resource_type = doc.tag
         attrs = {"value": doc.get_value()}
         for attr in doc.attrib:
             attrs[attr] = doc.get(attr)
-        c = self.resources.get(resource_type, VQResource)
-        c.resource_type = resource_type
+        c = self.resources.get(resource_type)
         return c(session, doc_uniq=uniq, doc_version=doc_version, **attrs)
 
-    def find(self, session: BQSession, resource_type: str, **kwargs) -> VQResource | VQCollection:
+    def find(self, session: BQSession, resource_type: str, **kwargs) -> VQResource:
         """
         Find a resource based on resource specific search args.
 
         Args:
             session (BQSession): initialized session
             resource_type (str): the type of the resource
             kwargs: type-specific search args
 
         Returns:
-            the found resource or a collection of matching resources
+            VQResource: the found resource
         """
         c = self.resources.get(resource_type)
         return c.find(session, **kwargs)
 
 
 class VQSession(BQSession):
-    """
-    A session with a ViQi server.
-    """
-
     def __init__(self):
         super().__init__()
         self.factory = VQFactory()
         self._deltas = []
 
     def __getstate__(self):
         return super().__getstate__(), self.factory, self._deltas
@@ -1482,164 +857,72 @@
         bisque_url,
         credentials=None,
         moduleuri=None,
         create_mex=False,
         enable_cache=True,
     ):
         res = super().init(bisque_url, credentials, moduleuri, create_mex, enable_cache=enable_cache)
-        # self.factory = VQFactory()
-        # self._init_cache()
+        #self.factory = VQFactory()
+        #self._init_cache()
         return res
 
     def init_local(
         self,
-        user: str,
-        pwd: str,
-        moduleuri: str = None,
-        bisque_root: str = None,
-        create_mex: bool = True,
-        as_user: str = None,
-        enable_cache: bool = False,
-    ) -> "VQSession":
-        """
-        Initialize a session based on user name and password.
-
-        Args:
-            user: user id (email)
-            pwd: password
-            moduleuri: module uri to be set to the mex (only matters if create_mex is set to True)
-            bisque_root: the root URL of the ViQi platform the user is trying to access
-            create_mex: creates a mex session under the user
-            as_user: switch session to specified user id (only for admin)
-            enable_cache: enable request caching under this session (should be False)
-
-        Returns
-            initialized session
-
-        Examples:
-            >>> sess = VQSession().init_local("clang@viqiai.com", "pass", bisque_root="https://science.viqiai.cloud", create_mex=False)
-        """
+        user,
+        pwd,
+        moduleuri=None,
+        bisque_root=None,
+        create_mex=True,
+        as_user=None,
+        enable_cache=False,
+    ):
         res = super().init_local(
-            user=user,
-            pwd=pwd,
-            moduleuri=moduleuri,
-            bisque_root=bisque_root,
-            create_mex=create_mex,
-            as_user=as_user,
+            user,
+            pwd,
+            moduleuri,
+            bisque_root,
+            create_mex,
+            as_user,
             enable_cache=enable_cache,
         )
-        # self.factory = VQFactory()
-        # self._init_cache()
+        #self.factory = VQFactory()
+        #self._init_cache()
         return res
 
-    def init_mex(
-        self, mex_url: str, token: str, user: str = None, bisque_root: str = None, enable_cache: bool = False
-    ) -> "VQSession":
-        """
-        Initialize a session based on a mex url and token (typically used for debug mexes).
-
-        Args:
-            mex_url: mex url to initalize the session from
-            token: the mex token to access the mex
-            bisque_root: the root URL of the ViQi platform the user is trying to access
-            enable_cache: enable request caching under this session (should be False)
-
-        Returns
-            initialized session
-
-        Examples:
-            >>> sess = VQSession().init_mex("https://science.viqiai.cloud/00-dkjqbdkjqdgq", "kfjffwerf__whhhe8fye-89fhwe8h", bisque_root="https://science.viqiai.cloud")
-        """
+    def init_mex(self, mex_url, token, user=None, bisque_root=None, enable_cache=False):
         res = super().init_mex(mex_url, token, user, bisque_root, enable_cache=enable_cache)
         ##self.factory = VQFactory()
-        # self._init_cache()
+        #self._init_cache()
         return res
 
     def init_request(self, request, enable_cache=True):
         res = super().init_request(request, enable_cache=enable_cache)
-        # self.factory = VQFactory()
-        # self._init_cache()
+        #self.factory = VQFactory()
+        #self._init_cache()
         return res
 
     def load(self, uniq: str) -> VQResource:
-        """
-        Load a resource from resource UUID.
-
-        Args:
-            uniq: resource UUID
-
-        Returns:
-            loaded resource
-        """
         return self.factory.load(self, uniq)
 
     def flush(self):
         """
         Write any pending doc changes back to ViQi server.
         """
         if len(self._deltas) > 0:
             # some local changes => try to write them back as PATCH
             raise NotImplementedError(
                 "write back of metadata docs not implemented"
             )  # need to write back if any changes or new doc (might throw version conflict!)
 
-    def find(self, resource_type: str, **kwargs) -> VQResource | VQCollection:
-        """
-        Find a resource based on resource specific search args.
-
-        Args:
-            resource_type: the type of the resource
-            kwargs: type-specific search args
-
-        Returns:
-            the found resource or a collection if multiple matches
-        """
+    def find(self, resource_type: str, **kwargs) -> VQResource:
         return self.factory.find(self, resource_type, **kwargs)
 
     def select_from_sparql(self, pattern: str, select_var: str) -> VQCollection:
-        """
-        Select one or more resources based on a SPARQL WHERE clause.
-
-        Args:
-            pattern: the SPARQL WHERE clause
-            select_var: the variable in the pattern that identifies the resources to select
-
-        Returns:
-            collection of resources that match pattern
-
-        Examples:
-            >>> res = sess.select_from_sparql("/mex:?mex :/ outputs:?out. ?out :/ image:?imgref. ?imgref :-> /image:?img", "img")
-        """
         return VQCollection(self, from_query=(pattern, select_var))
 
-    def select_from_tags(self, resource_type: str, **kwargs) -> VQCollection:
-        """
-        Select one or more resources based on a tag query.
-
-        Args:
-            resource_type: the resource type to find
-            kwargs: the tag query
-
-        Returns:
-            collection of resources that match pattern
-
-        Examples:
-            >>> res = sess.select_from_tags("image", tag_query="plate:1234 AND @ts:>=2023-01-01")
-        """
-        return VQCollection(self, from_tags=(resource_type, kwargs))
-
-    def current_user(self) -> VQUser:
-        """
-        Return current user.
-
-        Returns:
-            user resource
-        """
-        return self.find("user")
-
     def get_provenance(
         self,
         seed: VQResource,
         upstream: bool = True,
         downstream: bool = True,
         max_fanout: int = 3,
         out_format: str = "dot",
```

## vqapi/vqquery.py

```diff
@@ -1,22 +1,18 @@
 import logging
 from collections import namedtuple
 from functools import lru_cache
 from typing import List
 
-from bq.metadoc.formats import Metadoc
-
 from vqapi.exception import BQApiError
 
 log = logging.getLogger("vqapi.vqquery")
 
 
 def run_sparql_query(sess: "VQSession", query: str, **kwargs) -> List:  # noqa
-    if "wpublic" not in kwargs:
-        kwargs["wpublic"] = "1"  # search all visible by default
     meta = sess.service("meta")
     matches = meta.request(
         method="get",
         path="/",
         params={"sparql_query": " ".join(query.split()), **kwargs},
         render="doc",
     ).to_json()["result"]
@@ -25,27 +21,14 @@
         if not isinstance(matches, list):
             matches = [matches]
     except KeyError:
         matches = []
     return matches
 
 
-def run_tag_query(sess: "VQSession", rtype: str, **kwargs) -> Metadoc:  # noqa
-    if "wpublic" not in kwargs:
-        kwargs["wpublic"] = "1"  # search all visible by default
-    meta = sess.service("meta")
-    matches = meta.request(
-        method="get",
-        path=f"/{rtype}",
-        params=kwargs,
-        render="doc",
-    )
-    return matches
-
-
 def get_provenance(
     sess: "VQSession",  # noqa
     seed: "VQResource",  # noqa
     upstream: bool = True,
     downstream: bool = True,
     max_fanout: int = 3,
     out_format: str = "dot",
@@ -108,16 +91,17 @@
     def _input_resources(res: Node) -> List[Node]:
         # return all input resources of mex
         # if res is supermex, look in all sub-mexes, otherwise look in res
         query = f"""
             SELECT ?in/@type AS in_type
                    ?in/@value_str AS in_val
             WHERE {{
-                /mex:?submex :/ inputs:?inputs. ?inputs :// tag:?in
-                FILTER( ?submex/@resource_uniq = "{res.id}" )
+                /mex:?submex :/ tag:?inputs. ?inputs :/ tag:?in
+                FILTER( ?submex/@resource_uniq = "{res.id}" AND
+                        ?inputs/@name = "inputs" )
             }}
             """
         matches = run_sparql_query(sess, query)
         inputs = []
         for match in matches:
             if match["in_val"] and (match["in_type"] or "string") in list(sess.factory.resources.keys()) + ["resource"]:
                 vqr = sess.load(match["in_val"])
@@ -135,16 +119,17 @@
     def _output_resources(res: Node) -> List[Node]:
         # return all output resources of mex
         # if res is supermex, look in all sub-mexes, otherwise look in res
         query = f"""
             SELECT ?out/@type AS out_type
                    ?out/@value_str AS out_val
             WHERE {{
-                /mex:?submex :/ outputs:?outputs. ?outputs :// tag:?out
-                FILTER( ?submex/@resource_uniq = "{res.id}" )
+                /mex:?submex :/ tag:?outputs. ?outputs :/ tag:?out
+                FILTER( ?submex/@resource_uniq = "{res.id}" AND
+                        ?outputs/@name = "outputs" )
             }}
             """
         matches = run_sparql_query(sess, query)
         outputs = []
         for match in matches:
             if match["out_val"] and (match["out_type"] or "doc") in list(sess.factory.resources.keys()) + ["resource"]:
                 vqr = sess.load(match["out_val"])
@@ -161,16 +146,17 @@
     @lru_cache(maxsize=None)
     def _down_mexes(res: Node) -> List[Node]:
         # return all mexes that have res as input
         nonlocal more_cnt
         query = f"""
             SELECT ?mex/@resource_uniq AS mex_id
             WHERE {{
-                /mex:?mex :/ inputs:?inputs. ?inputs :// tag:?in
+                /mex:?mex :/ tag:?inputs. ?inputs :/ tag:?in
                 FILTER( ?in/@value_str = "{res.id}" AND
+                        ?inputs/@name = "inputs" AND
                         NOT EXISTSP {{ /mex:?supermex :/ mex:?submexref. ?submexref :-> ?mex }} )
             }}
             """
         matches = run_sparql_query(sess, query, limit=max_fanout + 1)
         mexes = []
         for idx, match in enumerate(matches):
             if idx == max_fanout:
@@ -191,16 +177,17 @@
     @lru_cache(maxsize=None)
     def _up_mexes(res: Node) -> List[Node]:
         # return all mexes that have res as output
         nonlocal more_cnt
         query = f"""
             SELECT ?mex/@resource_uniq AS mex_id
             WHERE {{
-                /mex:?mex :/ outputs:?outputs. ?outputs :// tag:?out
+                /mex:?mex :/ tag:?outputs. ?outputs :/ tag:?out
                 FILTER( ?out/@value_str = "{res.id}" AND
+                        ?outputs/@name = "outputs" AND
                         NOT EXISTSP {{ /mex:?supermex :/ mex:?submexref. ?submexref :-> ?mex }} )
             }}
             """
         matches = run_sparql_query(sess, query, limit=max_fanout + 1)
         mexes = []
         for idx, match in enumerate(matches):
             if idx == max_fanout:
```

## vqapi/RequestsMonkeyPatch/requests_patch.py

```diff
@@ -2,14 +2,15 @@
     A patch to format_header_param in urllib3
 
     If a value has unicode the header will be returned
     as 'name="value"; name*=utf-8''value' else
     'name="value"'
 """
 
+
 import email.utils
 
 # import mimetypes
 import warnings
 
 import requests
```

## vqapi/services/__init__.py

```diff
@@ -1,4 +1,3 @@
 #
-from .base_proxy import ResponseFile, ResponseFolder
 from .core_services import *
 from .factory import ServiceFactory
```

## vqapi/services/base_proxy.py

```diff
@@ -1,123 +1,85 @@
+
 # import functools
-import copy
 import hashlib
 import io
 import json
 import logging
 import os
 import shutil
 import tarfile
 import tempfile
 import time
-import urllib
 import urllib.parse
-
 import requests
-from bq.metadoc.formats import Metadoc
+import urllib
 
-from vqapi.exception import BQApiError, code_to_exception, http_code_future_not_ready
 
-# from vqapi.util import is_uniq_code, normalize_unicode
+from bq.metadoc.formats import Metadoc
 
-log = logging.getLogger("vqapi.services")
+from vqapi.exception import http_code_future_not_ready
+from vqapi.exception import BQApiError, FutureNotFoundError, code_to_exception
+#from vqapi.util import is_uniq_code, normalize_unicode
 
+log = logging.getLogger("vqapi.services")
 
 class ResponseFile(io.IOBase):
     """
     IO byte stream to return single file responses. Can be used as context manager.
     """
 
     def __init__(self, response):
         if isinstance(response, str):
             # file path
             self.stream = open(response, "rb")
-            self.response = None
             self.fpath = response
         else:
             response.raw.decode_content = True  # in case of compression
             self.stream = response.raw
-            self.response = response
             self.fpath = None
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         self.stream.close()
 
-    def read(self, size: int = -1) -> bytes:
-        """
-        Read some bytes from stream.
-
-        Args:
-            size: number of bytes to read
-
-        Returns:
-            bytes read
-        """
+    def read(self, size=-1):
         return self.stream.read(size)
 
-    def readall(self) -> bytes:
-        """
-        Read all bytes from stream.
-
-        Returns:
-            bytes read
-        """
+    def readall(self):
         return self.stream.read()
 
     def readinto(self, b):
         raise io.UnsupportedOperation("no readinto in reponse stream")
 
     def close(self):
-        """
-        Close stream.
-        """
         self.stream.close()
 
     def write(self, b):
         raise io.UnsupportedOperation("no write in reponse stream")
 
-    def copy_into(self, localpath: str, full_path: bool = True) -> str:
-        """
-        Copy this file into localpath/ and return its path.
-
-        Args:
-            localpath: local path where to write bytes to
-            full_path: if True, localpath includes the filename; otherwise, localpath is a folder
-
-        Returns:
-            path of generated file
-        """
+    def copy_into(self, localpath):
+        "copy this file into localpath/ and return its path"
         if self.fpath is not None:
             outname = os.path.join(localpath, os.path.basename(self.fpath))
             shutil.copyfile(self.fpath, outname)
         else:
-            outname = os.path.join(localpath, "responsefile") if not full_path else localpath
+            outname = os.path.join(localpath, "responsefile")
             with open(outname, "wb") as fout:
-                for block in self.response.iter_content(chunk_size=16 * 1024 * 1024):  # 16MB
-                    fout.write(block)
-                fout.flush()
+                shutil.copyfileobj(self.stream, fout)
         return outname
 
-    def force_to_filepath(self) -> str:
-        """
-        Force this file into a locally accessible file and return its path.
-
-        Returns:
-            path of generated file
-        """
+    def force_to_filepath(self):
+        "force this file into a locally accessible file and return its path"
         if self.fpath is not None:
             return self.fpath
         else:
             with tempfile.NamedTemporaryFile(mode="w+b", prefix="viqicomm", delete=False) as fout:  # who deletes this?
-                for block in self.response.iter_content(chunk_size=16 * 1024 * 1024):  # 16MB
-                    fout.write(block)
-                fout.flush()
+                shutil.copyfileobj(self.stream, fout)
                 return fout.name
 
 
 class ResponseFolder:
     """
     Class to return folder structure. Can be used as context manager.
     """
@@ -136,48 +98,31 @@
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         if not isinstance(self.stream, str):
             self.stream.close()
 
-    def copy_into(self,
-                  localpath: str,
-                  full_path: bool = True,   # pylint: disable=unused-argument
-                  ) -> str:
-        """
-        Copy this folder structure into localpath/ and return its path.
-
-        Args:
-            localpath: local path where to write bytes to
-            full_path: ignored (just to mirror ResponseFile)
-
-        Returns:
-            path of generated file
-        """
+    def copy_into(self, localpath):
+        "copy this folder structure into localpath/ and return its path"
         if isinstance(self.stream, str):
             outname = os.path.join(localpath, os.path.basename(self.stream))
             shutil.copytree(self.stream, outname)
         else:
             self.stream.extractall(localpath)
             # localpath should now contain a single folder with subfolders/files
             outname = next(
                 os.path.abspath(os.path.join(localpath, name))
                 for name in os.listdir(localpath)
                 if os.path.isdir(os.path.join(localpath, name))
             )
         return outname
 
-    def force_to_filepath(self) -> str:
-        """
-        Force this folder structure into a locally accessible (tar) file and return its path.
-
-        Returns:
-            path of generated file
-        """
+    def force_to_filepath(self):
+        "force this folder structure into a locally accessible (tar) file and return its path"
         with tempfile.NamedTemporaryFile(
             mode="w+b", prefix="viqicomm", suffix=".tar", delete=False
         ) as fout:  # who deletes this?
             if isinstance(self.stream, str):
                 # folder path => package it as single tar file
                 with tarfile.open(fileobj=fout, mode="w") as tout:  # TODO: could compress here
                     tout.add(self.stream, os.path.basename(self.stream), recursive=True)
@@ -207,82 +152,55 @@
 #### would be cool to have service definition language to make these.
 #### TODO more service, renders etc.
 
 
 class BaseServiceProxy:
     # DEFAULT_TIMEOUT=None
     DEFAULT_TIMEOUT = 60 * 60  # 1 hour
-    timeout = DEFAULT_TIMEOUT
-    headers = None
-    render = None
 
-    def __init__(self, session, service_url):  # noqa
+    def __init__(self, session, service_url:str , timeout:int=DEFAULT_TIMEOUT): # noqa
         self.session = session
-        self.service_url = service_url  # if isinstance(service_url, str) else service_url.service_url
+        self.service_url = service_url #if isinstance(service_url, str) else service_url.service_url
+        self.timeout = timeout
 
     def __str__(self):
         return self.service_url
 
     def construct(self, path, params=None):
         url = self.service_url
         if params:
             path = f"{path}?{urllib.parse.urlencode(params)}"
         if path:
             url = urllib.parse.urljoin(str(url), str(path))
         return url
 
-    def __call__(self, timeout=DEFAULT_TIMEOUT, headers=None, render=None):
-        """Allows service global overrides.. used for sub services
-
-        Example:
-           meta = session.service("meta")
-           meta_fast = meta(timeout=1).get( "/00-XXX")
-
-           meta_special = meta(headers  = { 'my-header' : 'my-value'} )
-           meta_special.get( .. )
-
-        """
-        svc = copy.copy(self)
-        svc.timeout = timeout
-        svc.headers = headers
-        svc.render = render
-        return svc
-
     # =================== TODO: get rid of render param ============
     # =================== TODO: move parts of formats.py into api section =========================
 
-    def request(
-        self, path: str | None = None, params: dict | None = None, method: str = "get", render: str | None = None, **kw
-    ):
+    def request(self, path=None, params=None, method="get", render=None, **kw):
         """
-        Generic REST-type request to the service (should not be called, use service specific functions instead).
-
-        Args:
-            path: a path relative to service (maybe a string or list)
-            params: a dictionary of value to encode as params
-            method: request type (get, put, post, etc)
-            render: 'doc'/'etree'/'xml' to request doc response, 'json' for JSON response
-
-        Returns:
-            a request.response (INDEPENDENT OF render!)
+        @param path: a path relative to service (maybe a string or list)
+        @param params: a diction of value to encode as params
+        @param method: request type (get, put, post, etc)
+        @param render: 'doc'/'etree'/'xml' to request doc response, 'json' for JSON response
+        @return a request.response (INDEPENDENT OF render!)
         """
         if isinstance(path, list):
             path = "/".join(path)
 
         if path and path[0] == "/":
             path = path[1:]
         if path:
             path = urllib.parse.urljoin(str(self.service_url), str(path))
         else:
             path = str(self.service_url)
 
         # no longer in session https://github.com/requests/requests/issues/3341
         timeout = kw.pop("timeout", self.timeout)
-        headers = kw.pop("headers", self.headers or {})
-        render = render or self.render
+        headers = kw.pop("headers", self.session.c.headers)
         data = kw.get("data")
         if isinstance(data, str):  # hacky way to guess content type
             data = data.lstrip()
             if data[0] == "<":
                 headers["Content-Type"] = "text/xml"  # TODO: -------------- use formatters on kw['data']!!!!
             elif data[0] in ("{", "["):
                 headers["Content-Type"] = "application/json"  # TODO: -------------- use formatters on kw['data']!!!!
@@ -358,36 +276,28 @@
         if content_md5 is not None and content_md5 != content_hasher.hexdigest():
             raise BQApiError(response)
 
         return response
 
 
 class FuturizedServiceProxy(BaseServiceProxy):
-    future_wait = True
-
-    def __call__(self, future_wait=True):
-        svc = super().__call__()
-        svc.future_wait = future_wait
-        return svc
-
     def _wait_for_future(self, future_id: str, retry_time: int = 5) -> Metadoc:
         future_service = self.session.service("futures")
         try:
             future_state = "PENDING"
             while future_state in ("PENDING", "PROCESSING"):
                 time.sleep(retry_time)
                 future_state = future_service.get_state(future_id)
-                log.debug("Future wait %ss", retry_time)
             return future_service.get_result(future_id)
         finally:  # because get_result could throw an exception!
-            # try:
-            #    future_service.delete(future_id)
-            # except FutureNotFoundError:
-            # already deleted
-            pass
+            try:
+                future_service.delete(future_id)
+            except FutureNotFoundError:
+                # already deleted
+                pass
 
     def _reraise_exception(self, response):
         exc = response.headers.get("x-viqi-exception")
         if exc is not None:
             # exception was returned... re-raise it
             code_to_exception(response)
 
@@ -427,44 +337,28 @@
             log.warn("use of render=etree deprecated")
             return Metadoc.convert_back(res.doc())
         elif render == "json":
             return json.loads(res.text) if res.text else res.text
         else:
             return res
 
-    def request(
-        self,
-        path: str = None,
-        params: dict = None,
-        method: str = "get",
-        render: str = None,
-        future_wait: bool | None = None,
-        **kw,
-    ):
+    def request(self, path=None, params=None, method="get", render=None, future_wait=True, **kw):
         """
-        Generic future-handling REST-type request to the service (should not be called, use service specific functions instead).
-
-        Args:
-            path: a path relative to service (maybe a string or list)
-            params: a dictionary of value to encode as params
-            method: request type (get, put, post, etc)
-            render: 'doc'/'etree'/'xml' to request doc response, 'json' for JSON response
-            future_wait: if true, wait for result in case future came back; if false, return even if future doc
-
-        Returns:
-            a request.response (INDEPENDENT OF render!)
+        @param path: a path relative to service (maybe a string or list)
+        @param params: a diction of value to encode as params
+        @param method: request type (get, put, post, etc)
+        @param render: 'doc'/'etree'/'xml' to request doc response, 'json' for JSON response
+        @param future_wait: if true, wait for result in case future came back; if false, return even if future doc
+        @return a request.response (INDEPENDENT OF render!)
         """
         # enable redirects again; futures use code 321 which is not affected by requests redirect handling
         #         kw["allow_redirects"] = kw.get(
         #             "allow_redirects", False
         #         )  # turn off redirects by default as it will interfere with future handling
         response = super().request(path=path, params=params, method=method, render=render, **kw)
 
         # handle two special cases: (1) exception came back, (2) future came back
         self._reraise_exception(response)
-
-        if future_wait is None:
-            future_wait = self.future_wait
         if future_wait:
             response = self._ensure_future_result(response, method=method, render=render, **kw)
 
         return response
```

## vqapi/services/core_services.py

```diff
@@ -1,449 +1,259 @@
 # import functools
 import logging
 import pickle
 import posixpath
 import shutil
 import tempfile
-from urllib.parse import quote as urlquote
-from urllib.parse import unquote as urlunquote
 
 import requests
 from bq.metadoc.formats import Metadoc
 
 from vqapi.exception import BQApiError, code_to_exception
 from vqapi.util import is_uniq_code
 
-from .base_proxy import (
-    BaseServiceProxy,
-    FuturizedServiceProxy,
-    ResponseFile,
-    ResponseFolder,
-)
-
-# from typing import Optional
-
-
 # from botocore.credentials import RefreshableCredentials
 # from botocore.session import get_session
 
+from .base_proxy import ResponseFile, ResponseFolder, BaseServiceProxy, FuturizedServiceProxy
+
 
 log = logging.getLogger("vqapi.services")
 
 
 ################### Helpers ######################
 
 
 def _prepare_mountpath(path: str) -> str:
-    if path.startswith("store://"):
-        path = path[len("store://") :]
-        path = urlunquote(path)  # URLs have to be decoded
+    if path.startswith("store:"):
+        path = path[len("store:") :]
     return path.strip("/")
 
 
 def _prepare_uniq(id: str) -> str:
     if not is_uniq_code(id):
         raise BQApiError(f'"{id}" is not a valid resource id')
     return id
 
 
 def _prepare_uniq_or_alias_or_path(id: str) -> str:
-    if id.startswith("store://"):
-        id = id[len("store://") :]
-        id = urlunquote(id)  # URLs have to be decoded
+    if id.startswith("store:"):
+        id = id[len("store:") :]
     return id.strip("/")
 
 
-class AdminProxy(FuturizedServiceProxy):
-    """
-    AdminProxy is the client-side proxy for admin service, or "admin".
-    This service encompasses all administrative tasks, e.g. creating user accounts and logging in/out.
-
-    Example:
-        >>> admin = vqsession.service("admin")
-    """
 
+class AdminProxy(FuturizedServiceProxy):
     service_name = "admin"
 
-    def login_as(self, login_id: str, create: bool = False) -> "VQSession":  # noqa: F821
-        """
-        Create a new session for the user.
-
-        Args:
-            login_id: user_id or uniq of new user
-            create: if True, create user if it does not exist
-
-        Returns:
-            a logged in VQSession
-        """
-        log.info("login_as %s", login_id)
-
-        user_session = self.session.copy()
-        admin = user_session.service("admin")
-        params = {"create": str(create).lower()}
-        resp = admin.post(f"user/{login_id}/login", params=params)
-        code_to_exception(resp)
-        # For some reason our host admin cookie is kept but with an empty domain
-        # This line removes it.
-        user_session.c.cookies.clear(name="mex_session", domain="", path="/")
-
-        return user_session
-
-    def login_create(self, login_id: str) -> "VQSession":  # noqa: F821
-        """
-        Login as LOGIN_ID, create user if not already created.
-
-        Args:
-            login_id: should be a valid login id (email)
-
-        Returns:
-            a logged in VQSession
-        """
-        log.info("login_create %s", login_id)
-        return self.login_as(login_id=login_id, create=True)
-
-    def create_user(self, login_id: str, password: str, display_name: str = None) -> Metadoc:
-        """
-        Create a new user.
-
-        Args:
-            login_id: valid login id (email)
-            password: login password
-            display_name: user name shown on website
-
-        Returns:
-            user metadata doc
-        """
-        log.info("create %s", login_id)
-        resp = self.post(
-            "user", json={"user": {"password": password, "email": login_id, "display_name": display_name or login_id}}
-        )
-        code_to_exception(resp)
-        return resp.doc()
-
-    def fetch_user(self, login_id: str, view: str = "short") -> Metadoc:
-        """
-        Get user information.
-
-        Args:
-            login_id: valid login id (email)
-            view: amount of detail to return ("short", "full", "deep")
-
-        Returns:
-            user metadata doc
-        """
-        resp = self.get(f"user/{login_id}", params={"view": view})
-        code_to_exception(resp)
-        return resp.doc()
-
-    def delete_user(self, login_id: str):
-        """
-        Delete a user and all resources they own.
-
-        Args:
-            login_id: valid login id (email)
-        """
-        log.info("delete %s", login_id)
-        resp = self.delete(f"user/{login_id}")
-        code_to_exception(resp)
-        return resp.doc()
-
-    def modify_user(self, login_id: str, email: str, display_name: str, passwd: str = None) -> Metadoc:
-        """
-        Change user information.
+    def login_as(self, user_name):
+        data = self.session.service("meta")
+        userxml = data.fetch("user", params={"name": user_name, "wpublic": 1}, render="doc")
+        user_uniq = userxml.find(f"user[@name='{user_name}']")
+        if user_uniq is not None:
+            user_uniq = user_uniq.get("resource_uniq")
+            response = self.fetch(f"user/{user_uniq}/login")
+            response.raise_for_status()
+
+            # check the login succeded
+            user_session = self.session.service("auth_service").get("session", render="doc")
+            user_id = user_session.find("user").get("value")
+            # user_id is /<user_uniq"
+            if user_id[1:] == user_uniq:
+                return user_uniq
+
+        # login failed
+        return None
+
+    def login_create(self, login_id: str) -> requests.Response:
+        """Login as LOGIN_ID , create user if not already create
 
         Args:
-            login_id: valid login id (email)
-            email: new email
-            display_name: new display name
-            passwd: new password
-
+          login_id should be a valid login id (email)
         Returns:
-            user metadata doc
+         a Response
         """
-        user = Metadoc(tag="user")
-        if email:
-            user.add_tag("email", value=email)
-        if display_name:
-            user.add_tag("display_name", value=display_name)
-        if passwd is None:
-            passwd = "***"
-        user.add_tag("password", value=passwd)
-        resp = self.put(f"user/{login_id}", data=user)
-        code_to_exception(resp)
-        return resp.doc()
-
-    def delete_user_resource(self, login_id: str):
-        """
-        Delete a user's resources (but keep user account).
-
-        Args:
-            login_id: valid login id (email)
-        """
-        resp = self.delete(f"user/{login_id}/image")
-        code_to_exception(resp)
-        return resp.doc()
-
-    def sessions(self) -> Metadoc:
-        """
-        Get active sessions.
-
-        Returns:
-            doc with multiple children, one per session
-        """
-        resp = self.get("sessions")
-        code_to_exception(resp)
-        return resp.doc()
-
-    def sessions_delete(self):
-        """
-        Delete all sessions.
-        """
-        resp = self.delete("sessions")
-        code_to_exception(resp)
-        return resp.doc()
+        return self.post(f"user/{login_id}/login?create=true")
 
 
 class AuthProxy(FuturizedServiceProxy):
     service_name = "auths"
-
     def login_providers(self, **kw):
-        return self.get("login_providers", **kw)
+        return self.request("login_providers", **kw)
 
     def credentials(self, **kw):
-        return self.get("credentials", **kw)
+        return self.request("credentials", **kw)
 
-    def get_session(self, **kw) -> dict:  # hides session
-        """Return the users current session or empty dict"""
-        return self._fetch_session()
+    def get_session(self, **kw):  # hides session
+        return self.request("session", **kw)
 
     def get(self, path=None, params=None, render=None, **kw):
         res = super().get(path=path, params=params, render=render, **kw)
         return self._prep_result(res, render)
 
-    def login(self, user, pwd) -> dict:
-        """Login as user
-           will logout of any current session managed
-
-        Returns:
-           if successful
-             a valid session with user, groups, expires, length  timeout, and the version of the server
-           else
-            and empty dict
-        """
-        self.logout()
-        try:
-            self.session.c.authenticate_basic(user, pwd)
-            sess = self._fetch_session()
-            if "user" in sess:
-                return sess
-            return {}
-        finally:
-            # Kill basic auth before leaving
-            self.session.c.auth = None
-
-    def logout(self):
-        # let the server know we are done
-        # resp = self.get("logout_handler")
-        if self.session.c.cookies:
-            self.get("logout_handler", timeout=30, allow_redirects=False)
-            self.session.c.cookies.clear()
-
-    def _fetch_session(self) -> dict:
-        """Used to check that session is actuall active
-        returns:
-           user and group info
-           { user: user-uniq, groups:
-        """
-        try:
-            sess = self.get("session", render="doc")  # self.fetchxml (self.service_url("auth_service", 'session'))
-            sess = sess.to_json()["session"]
-            return sess
-        except BQApiError:
-            return {}
-
-    def valid_user(self):
-        """check if we have a valid user"""
-        sess = self._fetch_session()
-        if "user" in sess:
-            return True
-        return False
-
 
 class BlobProxy(FuturizedServiceProxy):
-    """
-    BlobProxy is the client-side proxy for blob service, or "blobs".
-    This service encompasses operations for creating, deleting and accessing binary files (e.g., raw image bytes).
-
-    Example:
-        >>> blobs = vqsession.service("blobs")
-    """
-
     service_name = "blobs"
 
     def create_blob(self, path: str, blob: object):
         """Create binary resource at given path from the given object/file.
 
         Args:
-            path: mountpath for new blob
-            blob: object to store (if str, is assumed to be local filename)
+            path (str): mountpath for new blob
+            blob (object): object to store (if str, is assumed to be local filename)
 
         Raises:
             DuplicateFile: path already exists
             ResourceNotFoundError: path not valid
             IllegalOperation: blob creation not allowed at given path
             BQApiError: any other error
 
         Examples:
-            >>> blob_service = vqsession.service('blobs')
+            >>> blob_service = bqsession.service('blobs')
             >>> blob_service.create_blob('store://mymount/my/path/name.jpg', '/tmp/image.jpg')
         """
         # prep inputs
-        log.info("create %s", path)
         path = _prepare_mountpath(path)
         if not isinstance(blob, str):
             filedata = pickle.dumps(blob)
-        else:
-            filedata = open(blob, "rb")
 
         try:
-            res = self.post(urlquote(path), headers={"Content-Type": "application/octet-stream"}, data=filedata)
-
+            filedata = open(blob, "rb")
+            res = self.post(path, headers={"Content-Type": "application/octet-stream"}, data=filedata)
             # prep outputs
             code_to_exception(res)
-
         finally:
             if hasattr(filedata, "close"):
                 filedata.close()
 
     def delete_blob(self, path: str):
         """Delete binary resource at given path.
 
         Args:
-            path: mountpath for blob to delete
+            path (str): mountpath for blob to delete
 
         Raises:
             ResourceNotFoundError: path not valid
             IllegalOperation: blob deletion not allowed (e.g., resource is registered or path is container)
             BQApiError: any other error
 
         Examples:
-            >>> blob_service = vqsession.service('blobs')
+            >>> blob_service = bqsession.service('blobs')
             >>> blob_service.delete_blob('store://mymount/my/path/name.jpg')
         """
         # prep inputs
-        log.info("delete %s", path)
         path = _prepare_mountpath(path)
 
-        res = self.delete(urlquote(path))
+        res = self.delete(path)
 
         # prep outputs
         code_to_exception(res)
 
     def register(self, path: str = None, resource: Metadoc = None) -> Metadoc:
         """Register blob at a given mount path.
 
         Args:
-            path: mountpath to blob
-            resource: assign suggested type, permissions and metadata at registration time
+            path (str, optional): mountpath to blob
+            resource (Metadoc, optional): assign suggested type, permissions and metadata at registration time
 
         Returns:
-            resource document
+            Metadoc: resource document
 
         Raises:
             AlreadyRegisteredError: blob already registered
             ResourceNotFoundError: path not valid
             IllegalOperation: blob registration not allowed at given path
             BQApiError: any other error
 
         Examples:
-            >>> blob_service = vqsession.service('blobs')
+            >>> blob_service = bqsession.service('blobs')
             >>> blob_service.register(path='store://mymount/my/path/name.jpg')
             <Metadoc at 0x...>
         """
         # prep inputs
-        log.info("register %s", path)
+        log.debug(f"register {path}")
         path = _prepare_mountpath(path)
 
-        res = self.post(posixpath.join("register", urlquote(path)), data=resource)
+        res = self.post(posixpath.join("register", path), data=resource)
 
         # prep outputs
         code_to_exception(res)
 
         return res.doc()
 
-    def unregister(self, path: str = None, resource: Metadoc = None) -> bool:
+    def unregister(self, path: str = None, resource: Metadoc = None):
         """Unregister blob with given id.
 
         Args:
-            path: mount-path of blob
-            resource: resource to unregister
+            path (str, optional): mount-path of blob
+            resource (Metadoc, optional): resource to unregister
 
         Returns:
-            True, if successfully unregistered
+            bool: True, if successfully unregistered
 
         Raises:
             ResourceNotFoundError: invalid mount-path or id
             NotRegisteredError: blob not registered
 
         Examples:
-            >>> blob_service = vqsession.service('blobs')
+            >>> blob_service = bqsession.service('blobs')
             >>> blob_service.unregister(path='store://mymount/my/path/name.jpg')
             True
         """
         # prep inputs
-        log.info("unregister %s", path)
+        log.debug(f"unregister {path}")
         if path is None and resource is not None:
             path = resource.text.split(",", 1)[0]
+        log.debug(f"unregister {path}")
         path = _prepare_mountpath(path)
 
-        res = self.delete(posixpath.join("register", urlquote(path)))
+        res = self.post(posixpath.join("unregister", path))
 
         # prep outputs
         code_to_exception(res)
 
         return True
 
     def read_chunk(
         self,
         blob_id: str,
         content_selector: str = None,
         vts: str = None,
         as_stream: bool = False,
-    ) -> ResponseFile | ResponseFolder | bytes:
+    ):
         """Read chunk of resource specified by id.
 
         Args:
-            blob_id: mount-path or uuid or alias of blob
-            content_selector: blob-specific selector of subset to return (or all if None)
-            vts: version timestamp to return (or latest if None)
-            as_stream: return chunk as bytes stream (ResponseFile/ResponseFolder), otherwise return as localpath
+            blob_id (uuid): mount-path or uuid or alias of blob
+            content_selector (str): blob-specific selector of subset to return (or all if None)
+            vts (str): version timestamp to return (or latest if None)
+            as_stream (bool): return chunk as bytes stream (ResponseFile/ResponseFolder), otherwise return as localpath
 
         Returns:
-            file obj or folder obj or blob byte array
+            ResponseFile or ResponseFolder or bytes: file obj or folder obj or blob byte array
 
         Raises:
             NoAuthorizationError: no access permission for blob
             ResourceNotFoundError: no blob with given id
             BQApiError: any other error
 
         Examples:
-            >>> blob_service = vqsession.service('blobs')
+            >>> blob_service = bqsession.service('blobs')
             >>> with blob_service.read_chunk('00-123456789', as_stream=True) as fp:
             >>>    fo.read(1024)
         """
         # prep inputs
         blob_id = _prepare_uniq_or_alias_or_path(blob_id)
 
         headers = {}
         if content_selector is not None:
             headers["x-content-selector"] = content_selector
         if vts is not None:
             headers["x-vts"] = vts
-        res = self.get(f"/{urlquote(blob_id)}", headers=headers, stream=as_stream)
+        res = self.get(f"/{blob_id}", headers=headers, stream=as_stream)
 
         # prep outputs
         code_to_exception(res)
 
         if res.headers["content-type"] == "application/x-tar":
             # this is a tarfile of a folder structure
             res = ResponseFolder(res)
@@ -452,47 +262,39 @@
             res = ResponseFile(res)
 
         if as_stream:
             return res
         else:
             # caller wants local copy... this may be never used/needed...
             localpath = tempfile.mkdtemp()  # who deletes this?
-            return res.copy_into(localpath, full_path=False)
+            return res.copy_into(localpath)
 
 
-class DatasetProxy(FuturizedServiceProxy):
-    """
-    DatasetProxy is the client-side proxy for dataset service, or "datasets".
-    This service encompasses operations for creating, deleting and modifying datasets.
-
-    Example:
-        >>> datasets = vqsession.service("datasets")
-    """
 
+class DatasetProxy(FuturizedServiceProxy):
     service_name = "datasets"
 
     def create(self, dataset_name, member_list, **kw):
         """Create a dataset from a list of resource_uniq elements"""
         data = self.session.service("data_service")
         dataset = Metadoc(tag="dataset", name=dataset_name)
         for member_uniq in member_list:
             member = dataset.add_tag("value", type="object")
             member.text = member_uniq
 
         return data.post(data=dataset, render="doc")
-
     def append_member(self, dataset_uniq, resource_uniq, **kw):
         """Append an objects to dataset
         Args:
            resource_uniq: str or list
         """
         data = self.session.service("data_service")
         patch = Metadoc(tag="patch")
         if isinstance(resource_uniq, str):
-            resource_uniq = [resource_uniq]
+            resource_uniq = [ resource_uniq ]
         for uniq in resource_uniq:
             member = Metadoc(tag="value", type="object", value=uniq)
             patch.add_tag(tag="add", sel=f"/{dataset_uniq}").add_child(member)
         data.patch(data=patch)
 
     def delete(self, dataset_uniq, members=False, **kw):
         data = self.session.service("data_service")
@@ -519,60 +321,52 @@
         #     member.delete()
         # if len(members):
         #     return data.put(dataset_uniq, data=dataset, render="doc")
         # return None
 
 
 class MexProxy(FuturizedServiceProxy):
-    """
-    MexProxy is the client-side proxy for mex service, or "mexes".
-    This service encompasses operations for starting and stopping module runs, and for getting run logs.
-
-    Example:
-        >>> mexes = vqsession.service("mexes")
-    """
-
     service_name = "mexes"
 
     def get_all_mexes(self) -> Metadoc:
         """Get module execution (mex) documents for all running modules.
 
         Returns:
-            mex document
+            Metadoc: mex document
 
         Raises:
             BQApiError: any other error
 
         Examples:
-            >>> mex_service = vqsession.service('mexes')
+            >>> mex_service = bqsession.service('mexes')
             >>> mex_service.get_all_mexes()
             <Metadoc at 0x...>
         """
         res = self.get("")
 
         # prep outputs
         code_to_exception(res)
 
         return res.doc()
 
     def get_mex(self, mex_id: str) -> Metadoc:
         """Get module execution (mex) document for the execution specified.
 
         Args:
-            mex_id: mex UUID
+            mex_id (uuid): mex uniq
 
         Returns:
-            mex document
+            Metadoc: mex document
 
         Raises:
             MexNotFoundError: if no mex with given id was found
             BQApiError: any other error
 
         Examples:
-            >>> mex_service = vqsession.service('mexes')
+            >>> mex_service = bqsession.service('mexes')
             >>> mex_service.get_mex('00-123456789')
             <Metadoc at 0x...>
         """
         # prep inputs
         mex_id = _prepare_uniq(mex_id)
 
         res = self.get(f"/{mex_id}")
@@ -582,24 +376,24 @@
 
         return res.doc()
 
     def get_mex_log(self, mex_id: str) -> Metadoc:
         """Get module execution (mex) log for the execution specified.
 
         Args:
-            mex_id: mex UUID
+            mex_id (uuid): execution identifier
 
         Returns:
-            <log>logtext</log>
+            Metadoc: <log>logtext</log>
 
         Raises:
             MexNotFoundError: if no mex with given id was found
 
         Examples:
-            >>> mex_service = vqsession.service('mexes')
+            >>> mex_service = bqsession.service('mexes')
             >>> mex_service.get_mex_log('00-123456789')
             2021-07-02 03:00:56,848 DEBUG [urllib3.connectionpool] (_new_conn) - Starting ne...
         """
         # prep inputs
         mex_id = _prepare_uniq(mex_id)
 
         res = self.get(f"/{mex_id}/log")
@@ -611,15 +405,17 @@
 
     def request(self, path=None, params=None, method="get", render=None, **kw):
         # TODO: add real api fct
         res = super().request(path=path, params=params, method=method, render=render, **kw)
         return self._prep_result(res, render)
 
 
+
 class ExportProxy(FuturizedServiceProxy):
+
     ## service_name = "export"  # NOT Implemented
 
     valid_param = {"files", "datasets", "dirs", "urls", "users", "compression"}
 
     def fetch_export(self, **kw):
         params = {key: val for key, val in list(kw.items()) if key in self.valid_param and val is not None}
         response = self.fetch("stream", params=params, stream=kw.pop("stream", True))
@@ -630,36 +426,29 @@
         if response.status_code == requests.codes.ok:
             with open(localpath, "wb") as f:
                 shutil.copyfileobj(response.raw, f)
         return response
 
 
 class DataProxy(FuturizedServiceProxy):
-    """
-    DataProxy is the client-side proxy for data service, or "meta".
-    This service encompasses operations for creating, deleting and modifying metadata documents, and for querying them.
-
-    Example:
-        >>> meta = vqsession.service("meta")
-    """
-
     service_name = "meta"
 
     # TODO: add real API fcts
     def request(self, path=None, params=None, method="get", render="doc", view=None, **kw):
         if view is not None:
             if isinstance(view, list):
                 view = ",".join(view)
             params = params or {}
             params["view"] = view
 
         res = super().request(path=path, params=params, method=method, render=render, **kw)
 
         # prep outputs
         code_to_exception(res)
+
         return self._prep_result(res, render)
 
     def fetch(self, path=None, params=None, render="doc", **kw):
         return super().fetch(path=path, params=params, render=render, **kw)
 
     def get(self, path=None, params=None, render="doc", **kw):
         return super().get(path=path, params=params, render=render, **kw)
@@ -672,359 +461,178 @@
 
     def put(self, path=None, params=None, render="doc", **kw):
         return super().put(path=path, params=params, render=render, **kw)
 
     def delete(self, path=None, params=None, render=None, **kw):
         return super().delete(path=path, params=params, render=render, **kw)
 
-    def set_attr(self, path, attribute, value):
-        """Set an attribute on the resource (name, atime, etc)"""
-        doc = Metadoc(tag="resource")
-        doc.attrib[attribute] = str(value)
-        res = self.put(path, data=doc, params={"attr_only": "true"})
-        return res
-
 
 class DirProxy(FuturizedServiceProxy):
-    """
-    DirProxy is the client-side proxy for data service, or "dirs".
-    This service encompasses operations for creating and deleting containers/directories, listing directories,
-    and searching in directories.
-
-    Example:
-        >>> dirs = vqsession.service("dirs")
-    """
-
     service_name = "dirs"
 
     def create_container(self, path: str, name: str, container_type: str = "folder"):
         """Create new container with name at given path.
 
         Args:
-            path: mountpath holding new container
-            name: name of new container
-            container_type: type of container to create (e.g., 'folder', 'zip', 'tablecontainer')
+            path (str): mountpath holding new container
+            name (str): name of new container
+            container_type (str): 'folder' or 'tablecontainer'
 
         Raises:
-            NoSuchFileError: file at mount-path does not exist
-            NoSuchPathError: mount-path does not exist
+            IllegalOperation: path already exists
+            ResourceNotFoundError: path not valid
 
         Examples:
-            >>> dir_service = vqsession.service('dirs')
-            >>> dir_service.create_container('/mymount/my/path', 'new_container', container_type='tablecontainer')
+            >>> dir_service = bqsession.service('dirs')
+            >>> dir_service.create_container('store://mymount/my/path', 'new_container', container_type='tablecontainer')
         """
         # prep inputs
         path = _prepare_mountpath(path)
 
         res = self.post(
-            urlquote(path),
+            path,
             data=Metadoc.from_naturalxml(f'<dir name="{name}" type="{container_type}" />'),
         )
 
         # prep outputs
         code_to_exception(res)
 
-    def delete_container(self, path: str, force: bool = False):
-        """Delete container at given path.
-
-        Args:
-            path: mount-path to delete
-            force: if True, delete even if there are associated resources (which will leave resources without binaries);
-                   to delete resources with binaries, use meta.delete
-
-        Raises:
-            NoSuchFileError: file at mount-path does not exist
-            NoSuchPathError: mount-path does not exist
-            IllegalOperation: attempt to delete root container
-
-        Examples:
-            >>> dir_service = vqsession.service('dirs')
-            >>> dir_service.delete_container('/mymount/dir1/dir2')
-        """
-        # prep inputs
-        path = _prepare_mountpath(path)
-
-        res = self.delete(urlquote(path), params={"force": force})
-
-        # prep outputs
-        code_to_exception(res)
-
     def list_files(
         self,
-        path: str,
-        want_meta: bool = False,
-        want_types: bool = False,
-        patterns: list[str] = None,
-        limit: int = 100,
-        offset: int = 0,
-        sort_order: list[tuple] = None,
-    ) -> Metadoc:
+        path,
+        want_meta=False,
+        want_types=False,
+        patterns=None,
+        limit=100,
+        offset=0,
+    ):
         """List all entries (registered and unregistered, resources and containers) at the given path.
 
         Args:
-            path: mount-path to list
-            want_meta: if True, include metadata per entry
-            want_types: if True, include type guesses per entry (slow!)
-            patterns: one or more wildcard patterns for filtering of entries (these are ORed)
-            limit: max number of entries to return
-            offset: starting entry number (for paging)
-            sort_order: sorting order for entries (e.g., [('created', 'asc'), ('name', 'desc')])
+            path (str): mount-path to list
+            want_meta (bool): if True, include metadata per entry
+            want_types (bool): if True, include type guesses per entry (slow!)
+            patterns (list of str): one or more wildcard patterns for filtering of entries (these are ORed)
+            limit (int): max number of entries to return
+            offset (int): starting entry number (for paging)
 
         Returns:
-            doc describing path and all selected entries as children
+            Metadoc: doc describing path and all selected entries as children
 
         Raises:
             NoSuchFileError: file at mount-path does not exist
             NoSuchPathError: mount-path does not exist
             IllegalOperation: mount does not exist
 
         Examples:
-            >>> dir_service = vqsession.service('dirs')
+            >>> dir_service = bqsession.service('dirs')
             >>> str(dir_service.list_files('/mymount/dir1', limit=10))
             '<dir name="mymount" ...> <dir ... /> ... <image ... /> <resource ... /> </dir>'
         """
         # prep inputs
         params = {}
         view_options = []
         if want_meta:
             view_options.append("meta")
         if want_types:
             view_options.append("types")
         if view_options:
             params["view"] = ",".join(view_options)
         if patterns:
             params["patterns"] = ",".join(patterns)
-        if sort_order:
-            params["tag_order"] = ",".join(f"@{attr_name}:{attr_order}" for (attr_name, attr_order) in sort_order)
         params["limit"] = limit
         params["offset"] = offset
 
-        res = self.get(urlquote(path), params=params)
+        res = self.get(path, params=params)
 
         # prep outputs
         code_to_exception(res)
 
         return res.doc()
 
-    def touch(self, path, __xattrs=None, **kw):
-        """Set xattrs on path.
-        DO NOT USE UNLESS YOU KNOW WHAT YOU ARE DOING!
-
-        Args:
-            path: mount-path to touch
-            __xattrs: attributes to set (e.g., {"expanded": False})
-
-        Raises:
-            NoSuchFileError: file at mount-path does not exist
-            NoSuchPathError: mount-path does not exist
-            IllegalOperation: mount does not exist
-        """
-        # prep inputs
-        xattrs = __xattrs or {}
-        xattrs.update(kw)
-
-        res = self.put(urlquote(path), params={key: str(val) for key, val in xattrs.items()})
-
-        # prep outputs
-        code_to_exception(res)
-
-        return res
-
-    def refresh(self, path):
-        """Force a refresh on path and all descendents.
-        DO NOT USE UNLESS YOU KNOW WHAT YOU ARE DOING!
-
-        Args:
-            path: mount-path to refresh
-
-        Raises:
-            NoSuchPathError: mount-path does not exist
-            IllegalOperation: mount does not exist
-        """
-        # prep inputs
-        path = _prepare_mountpath(path)
-
-        res = self.get(urlquote(path), params={"refresh": "true", "view": "deep,count"})
-
-        # prep outputs
-        code_to_exception(res)
-
-        return res
-
 
 class FutureProxy(FuturizedServiceProxy):
-    """
-    FutureProxy is the client-side proxy for future service, or "futures".
-    This service encompasses operations for getting the state and result of futures.
-
-    Example:
-        >>> futures = vqsession.service("futures")
-    """
-
     service_name = "futures"
 
-    def get_state(self, future_id: str) -> str:
+    def get_state(self, future_id):
         """Get state of the future with the given id.
 
         Args:
-            future_id: future UUID
+            future_id: future id
 
         Returns:
-            state of future (e.g., PENDING or FINISHED)
+            str: state of future (e.g., PENDING or FINISHED)
 
         Raises:
             FutureNotFoundError: if no future with given id was found
             BQApiError: any other error
 
         Examples:
-            >>> future_service = vqsession.service('futures')
+            >>> future_service = bqsession.service('futures')
             >>> future_service.get_state('8196770f-ea2e-4bc6-b569-9e29fc031d46')
             'PENDING'
         """
         res = self.get(f"/{future_id}")
 
         # prep outputs
         code_to_exception(res)
 
         return res.doc().get("state")
 
-    def get_result(self, future_id: str) -> Metadoc:
+    def get_result(self, future_id):
         """Get result of the future with the given id.
 
         Args:
-            future_id: future UUID
+            future_id: future id
 
         Returns:
-            result of the future or None, if no result
+            Metadoc: result of the future or None, if no result
 
         Raises:
             ValueError: result can not be rendered as doc
             FutureNotFoundError: if no future with given id was found
             FutureNotReadyError: if future result is not ready yet
             BQApiError: any other error
             Exception: any exception raised by the async task
 
         Examples:
-            >>> future_service = vqsession.service('futures')
+            >>> future_service = bqsession.service('futures')
             >>> future_service.get_result('8196770f-ea2e-4bc6-b569-9e29fc031d46')
             <Metadoc at 0x...>
         """
         res = self.get(f"/{future_id}/result")
 
         # prep outputs
         code_to_exception(res)
 
         return res.doc()
 
-    def delete(self, future_id: str):
+    def delete(self, future_id):
         """Delete future with the given id.
 
         Args:
-            future_id: future UUID
+            future_id: future id
 
         Raises:
             FutureNotFoundError: if no future with given id was found
             BQApiError: any other error
 
         Examples:
-            >>> future_service = vqsession.service('futures')
+            >>> future_service = bqsession.service('futures')
             >>> future_service.delete('8196770f-ea2e-4bc6-b569-9e29fc031d46')
         """
         res = super().delete(f"/{future_id}")
 
         # prep outputs
         code_to_exception(res)
 
-
 class ServicesProxy(BaseServiceProxy):
     service_name = "services"
 
 
-class PreferenceProxy(BaseServiceProxy):
-    service_name = "preference"
-
-    def get_value(self, key):
-        res = self.get(key)
-        code_to_exception(res)
-        return res.doc()
-
-
-class NotifyProxy(BaseServiceProxy):
-    service_name = "notify"
-
-    def send_email(
-        self,
-        recipients: str | list[str],
-        subject: str,
-        body: str,
-        attachments: list[str] = None,
-        sender=None,
-        cc: list[str] | None = None,
-        bcc: list[str] | None = None,
-        reply_to: str | None = None,
-    ):
-        """Send an email from viqi1.
-
-        Args:
-           recipients: list of emails
-           subject:   subject of email
-           body:       text  of email
-           attachments:  list of viqi paths files to attach (must be on server)
-           sender: overide the default sender (must be an email address  allowed by the system)
-           cc: list of cc emails
-           bcc: list of bcc emails
-           reply_to: reply_to email
-
-        Returns:
-           a metadoc <result>[ok|fail]</result>
-
-        """
-        if isinstance(recipients, list):
-            recipients = ",".join(recipients)
-        params = {"recipients": recipients, "subject": subject}
-        if sender:
-            params["sender"] = sender
-        if attachments:
-            params["attachments"] = ",".join(attachments)
-        if cc:
-            params["cc"] = ",".join(cc)
-        if bcc:
-            params["bcc"] = ",".join(bcc)
-        if reply_to:
-            params["reply_to"] = reply_to
-
-        res = super().post(
-            "email",
-            params=params,
-            data=body,
-            headers={"Content-Type": "text/plain"},
-        )
-        code_to_exception(res)
-        return res.doc()
-
-    def send_message(self, channel: str, message: str, attachments: list[str] = None):
-        """Send a slack message from viqi1.
-
-        Args:
-           channel:   slack channel to send to
-           message:  text of message to send
-           attachments:  list of viqi paths files to attach (must be on server)
-
-        Returns:
-           a metadoc <result>[ok|fail]</result>
-        """
-        params = {"channel": channel, "message": message}
-        if attachments:
-            params["attachments"] = ",".join(attachments)
-
-        res = super().post("message", params=params, headers={"Content-Type": "text/plain"})
-        code_to_exception(res)
-        return res.doc()
-
-
 def test_module():
     from vqapi import VQSession
 
     session = VQSession().init_local("admin", "admin", "http://localhost:8080")
     admin = session.service("admin")
     data = session.service("data_service")
     # admin.user(uniq).login().fetch ()
```

## vqapi/services/factory.py

```diff
@@ -1,10 +1,11 @@
+
 import logging
 
-from vqapi.plugins import filter_classes, find_plugins
+from vqapi.plugins import find_plugins, filter_classes
 
 from .base_proxy import FuturizedServiceProxy
 
 log = logging.getLogger("vqapi.services")
 
 # SERVICE_PROXIES = {
 #     "admin": AdminProxy,
@@ -17,31 +18,30 @@
 #     "tables": TableProxy,
 #     "pixels": ImageProxy,
 #     "dirs": DirProxy,
 #     "services": BaseServiceProxy,
 #     "futures": FutureProxy,
 # }
 
-
 def import_proxies(name, module):
     """Filter for transfer plugins modules for classes with attribute 'transfer_method'"""
     return [(cls.service_name, cls) for nm, cls in filter_classes(name, module) if hasattr(cls, "service_name")]
 
-
 class ServiceFactory:
+
     SERVICE_PROXIES = dict(find_plugins(".", import_proxies))
 
     # new unified service names (allow all variants for now)
     # TODO: change once all service names are final
     RENAMED_SERVICES = {
         "image_service": "pixels",
         "data_service": "meta",
         "dataset_service": "datasets",
         "auth_service": "auths",
-        # "preference": "preferences", # KGK NOT RENAMED in viqi1
+        "preference": "preferences",
         "table": "tables",
         "pipeline": "pipelines",
         "blob_service": "blobs",
         "mex_service": "mexes",
     }
 
     @classmethod
```

## vqapi/services/image_proxy.py

 * *Ordering differences only*

```diff
@@ -1,19 +1,19 @@
+
 import io
-import logging
-import os
 import tempfile
+import os
+import logging
 
 import tifffile
 
 from .base_proxy import FuturizedServiceProxy
 
 log = logging.getLogger("vqapi.services")
 
-
 class ImageProxy(FuturizedServiceProxy):
     service_name = "pixels"
 
     class ImagePixels:
         """manage requests to the image pixels"""
 
         def __init__(self, image_service, image_uniq):
```

## vqapi/services/import_proxy.py

```diff
@@ -32,63 +32,61 @@
 ## NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS        ##
 ## SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.              ##
 ##                                                                           ##
 ## The views and conclusions contained in the software and documentation     ##
 ## are those of the authors and should not be interpreted as representing    ##
 ## official policies, either expressed or implied, of <copyright holder>.    ##
 ###############################################################################
+"""
+SYNOPSIS
+========
+import proxy plugin
+
+DESCRIPTION
+===========
+
+Client side import methods
+
+"""
 
-import concurrent.futures
-import fnmatch
-import logging
-import os
 import posixpath
-import random
+import logging
 import string
-import threading
-from queue import Queue
+import random
+import os
+import time
+
 from typing import BinaryIO, Callable, Dict, Optional
-from urllib.parse import quote as urlquote
 
 import boto3
 import botocore
-
-# import pytz
 import tenacity
-from botocore.credentials import RefreshableCredentials
-from botocore.session import get_session
 from bq.metadoc.formats import Metadoc
 from requests_toolbelt import MultipartEncoder
 
 from vqapi.exception import BQApiError, code_to_exception
 from vqapi.util import normalize_unicode
 
-from .base_proxy import FuturizedServiceProxy
-
+from .base_proxy import  FuturizedServiceProxy
 log = logging.getLogger("vqapi.services")
 
-# End token for loading files to be transferred
-_FILES_LOADED = object()
-
-
 def id_generator(size=6, chars=string.ascii_uppercase + string.digits):
     return "".join(random.choice(chars) for _ in range(size))
 
 
 class ImportProxy(FuturizedServiceProxy):
     service_name = "import"
-    upload_prefix = "/home/uploads"  # TODO fetch from user prefences
-    upload_default_mount = "/home"  # TODO fetch from user
 
     def __init__(self, *args, **kw):
         super().__init__(*args, **kw)
+        self.upload_prefix = "/home/uploads"  # TODO fetch from user prefences
+        self.upload_default_mount = "/home"  # TODO fetch from user
         self.protocol_info_map = {"/home": None}  # Map of store to best protocol
 
-    @classmethod
-    def destination_path(cls, srcpath, dstpath):
+    def destination_path(self, srcpath, dstpath):
         """Create a valid destination path from src and dst
 
         Examples:
           Source known, destination None
           destination_path("filename.tif", None) -> upload_prefix/filename.tif
           destination_path("path2/to/file/filename.tif", None) -> upload_prefix/path/to/file/filename.tif
           destination_path("/home/user/path2/to/file/filename.tif", None) -> upload_pefix/filename.tif
@@ -97,220 +95,147 @@
           destination_path(None, "filename.tif") -> upload_mount/filename.tif
           destination_path(None, "relatitive_path/filename.tif") -> upload_mount/relative_path/filename.tif
           destination_path(None, "/home/project/to/path/filename.tif") -> "/home/project/to/path/filename.tif"
 
           Source and Destination -> use dest
           destination_path("filename.tif", "filename.tif") -> upload_mount/filename.tif
           destination_path("path2/to/file/filename.tif", "filename.tif") -> $upload_mount/filename.tif
-          destination_path("path2/to/file/filename.tif", "relative_path/filename.tif") -> $upload_mount/relatice_path/filename.tif
+          destination_path("path2/to/file/filename.tif", "relative_path/filename.tif") -> $upload_mount/path/to/file/filename.tif
           destination_path("/home/user/path2/to/file/filename.tif", "/home/poject/path2/filename.tif") -> /home/project/path2/filename.tif
 
           Source and Destination Dir (marked by trailing "/" -> use src + dest
-          destination_path("filename.tif", "apath/") -> $upload_mount/apath/filename.tif
+          destination_path("filename.tif", "apath/") -> $upload_mount/apath/tfilename.tif
           destination_path("path2/to/file/filename.tif", "apath/") -> $upload_mount/apath/filename.tif
           destination_path("/home/user/path2/to/file/filename.tif", "/home/mount/apath/") -> /home/mount/apath/filename.tif
 
         """
         if dstpath is None:
-            dstpath = cls.upload_prefix
-            if srcpath[0] == "/":
-                # srcpath is fullpath.. we cannot really guess how much of path to copy so just use name
-                return posixpath.join(dstpath, os.path.basename(srcpath))
-            # join relative path to default_prefix
+            dstpath = self.upload_prefix
+            if srcpath == "/":
+                return posixpath.join(dstpath, srcpath[1:])
             return posixpath.join(dstpath, srcpath)
 
         if dstpath[-1] == "/":  # DIR destination
             dstpath = posixpath.join(dstpath, os.path.basename(srcpath))
 
         if dstpath[0] != "/":  # NOT absolute upload, join with def
-            dstpath = posixpath.join(cls.upload_default_mount, dstpath)
+            return posixpath.join(self.upload_default_mount, dstpath)
 
         return dstpath
 
     # @functools.lru_cache(maxsize=None)
-    def transfer_protocol_info(self, dirpath: str = None, protocol: str = None) -> Optional[Metadoc]:
+    def transfer_protocol_info(self, path: str = None, protocol: str = None) -> Optional[Metadoc]:
         """Return proto info for best transfer_protocol
 
         Args:
-            dirpath : the destination directory storepath
+            path : the destination storepath
         Returns:
            A proto_info dict: with protocol specific information
         """
-        if dirpath is None:
-            dirpath = self.upload_prefix
-        if dirpath[0] == "/":
-            dirpath = dirpath[1:]
-
-        # protocol dependes on directory of path.. strip filename
-        # path = os.path.dirname(path)
-        mount, dirpath = dirpath.split("/", 1)  # 'home/hello/aaa.jpg' -> ['home', 'hello', 'aaa.jpg']
-        if (mount, protocol, dirpath) in self.protocol_info_map:
-            # log.info("CACHED %s", dirpath)
-            return self.protocol_info_map[(mount, protocol, dirpath)]
+        if path is None:
+            path = self.upload_prefix
+        if path[0] == "/":
+            path = path[1:]
+
+        dirpath = os.path.dirname(path)
+        mount = dirpath.split("/")[0]  # 'home/hello/aaa.jpg' -> ['home', 'hello', 'aaa.jpg']
+        if (mount, protocol) in self.protocol_info_map:
+            return self.protocol_info_map[(mount, protocol)]
 
         if protocol is not None:
-            available_protocols = [Metadoc.create_doc("protocol", type=protocol)]
+            available_protocols = [Metadoc.create_doc("prototcol", type=protocol)]
         else:
-            url = posixpath.join("/transfer_protocol", mount, urlquote(dirpath))
-            log.debug("protocol check %s", url)
-            protocols = self.fetch(url)
+            protocols = self.fetch(posixpath.join("/transfer_protocol", dirpath))
             # Choose the preferred one by order
             code_to_exception(protocols)
             proto_doc = protocols.doc()
             # log.info("PROTO %s", str(proto_doc))
             available_protocols = proto_doc.path_query("protocol")
 
         for proto in available_protocols:
             # check if we know one
             if hasattr(self, "transfer_" + proto.attrib["type"]):
                 # we know how to transfer, grab info
                 proto_info = self.fetch(
-                    posixpath.join("/transfer_protocol", mount, urlquote(dirpath)),
+                    posixpath.join("/transfer_protocol", dirpath),
                     params={"protocol": proto.attrib["type"]},
                 )
                 code_to_exception(proto_info)
                 proto_info = proto_info.doc()
-                self.protocol_info_map[(mount, None, dirpath)] = proto_info
-                self.protocol_info_map[(mount, proto, dirpath)] = proto_info
+                self.protocol_info_map[(mount, None)] = proto_info
+                self.protocol_info_map[(mount, proto)] = proto_info
                 return proto_info
         return None
 
-    def transfer_batch(
-        self,
-        srcs: str | list,
-        dstdir: str = None,
-        xml: Metadoc = None,
-        callback: Callable = None,
-        protocol: str = None,
-        register: bool = True,
-    ):
-        """Transfer a batch of files and directories  in parallel to a destinatation
-
-        Args
-        """
-        log.debug("transfer_batch %s", srcs)
-        file_queue = Queue()
-        futuremap = {}
-        localvar = threading.local()
-        localvar.session = self.session
-
-        if isinstance(srcs, str) or not hasattr(srcs, "__iter__"):
-            srcs = [srcs]
-
-        with concurrent.futures.ThreadPoolExecutor(
-            max_workers=os.cpu_count(), initializer=thread_session_initialize, initargs=(self.session, localvar)
-        ) as executor:
-
-            # Load the file_queue in a task in case  this is large tree
-            futuremap = {executor.submit(initiate_batch_transfer, srcs=srcs, file_queue=file_queue): _FILES_LOADED}
-            transferred, failed = self.parallel_transfer(localvar, executor, futuremap, file_queue)
-        log.debug("batch transferred:%s  failed:%s", transferred, failed)
-
-        # current handled by s3_transfer itself.
-        # if transferred:
-        #    dirs = self.session.service("dirs")
-        #    dirs.refresh(os.path.commonpath(srcs))
-
-        return transferred, failed
-
-    def parallel_transfer(self, localvar, executor, futuremap, file_queue):
-        """process the tranfer queue using the parallel threads EXECUTER
-        Args:
-           localvar.session : threadlocal variable for accessing session
-           executer:  A ThreadPoolManager
-           futuremap:  dict[future]->filepath
-           filequeue:  thread queue of futures to process
-        """
-        transferred = []
-        failed = []
-        # Futuremap is a dict thread fture-> (filepath| LOADED_TOKEN)
-        # Should arrive here with a task filling the file_queue
-        while futuremap:
-            # Wait for/force a task to finish, but bail after 1 sec so we check the file_queue
-            done, not_done = concurrent.futures.wait(
-                futuremap, timeout=1, return_when=concurrent.futures.FIRST_COMPLETED
-            )
-            # process any completed futures
-            for future in done:
-                try:
-                    file_path = futuremap.pop(future)
-                    future_res = future.result()
-                    if file_path == _FILES_LOADED:
-                        log.info("loaded %s files for transfer", future_res)
-                        continue
-                    transferred.append(file_path)
-                except (TimeoutError, concurrent.futures.CancelledError):
-                    failed.append((file_path, "timeout or cancelleed"))
-                except Exception as exc:
-                    log.exception("%s generated an exception: %s", file_path, exc)
-                    failed.append((file_path, exc))
-
-            # Grab any files waiting to be uploaded and add them as tasks
-            while not file_queue.empty():
-                file_tuple = file_queue.get()
-                futuremap[executor.submit(thread_upload, localvar, file_tuple)] = file_tuple[1]
-
-        return transferred, failed
-
     def transfer_file(
         self,
         srcpath: str,
         dstpath: str = None,
         xml: Metadoc = None,
         callback: Callable = None,
         protocol: str = None,
-        register: bool = True,
+        register: bool = True
     ):
         """Transfer a file to the system
         Args:
           srcpath : the path to the local file or filename to give to the file object
           xml     :
         """
         with open(srcpath, "rb") as src:
             return self.transfer_fileobj(
-                src, xml=xml, callback=callback, srcpath=srcpath, dstpath=dstpath, protocol=protocol, register=register
+                src,
+                xml=xml,
+                callback=callback,
+                srcpath=srcpath,
+                dstpath=dstpath,
+                protocol=protocol,
+                register=register
             )
 
     def transfer_fileobj(
         self,
         fileobj: BinaryIO,
         srcpath: str = None,
         dstpath: str = None,
         xml: Metadoc = None,
         callback: Callable = None,
         protocol: str = None,
-        register: bool = True,
+        register: bool = True
     ):
         if srcpath is None and hasattr(fileobj, "name"):
             srcpath = fileobj.name
         dstpath = self.destination_path(srcpath, dstpath)
-        log.info("transfer %s -> %s", srcpath, dstpath)
-        transfer_info = self.transfer_protocol_info(dirpath=os.path.dirname(dstpath), protocol=protocol)
+        transfer_info = self.transfer_protocol_info(path=dstpath, protocol=protocol)
         # log.info("TRANS %s", str(transfer_info))
         # Use the protocol to  find a method to transfer the file
         if transfer_info is not None:
             protocol = transfer_info.path_query("protocol")[0]
             transfer_fct = getattr(self, "transfer_" + protocol.attrib["type"])
             if transfer_fct is not None:
                 return transfer_fct(
                     fileobj=fileobj,
                     dstpath=dstpath,
                     xml=xml,
                     callback=callback,
                     transfer_info=transfer_info,
-                    register=register,
+                    register=register
                 )
         raise BQApiError("No transfer protocol supported for file transfer")
 
     def transfer_multipart(
-        self, fileobj: BinaryIO, dstpath: str, xml=None, callback=None, transfer_info=None, register=True
+        self,
+        fileobj: BinaryIO,
+        dstpath: str,
+        xml=None,
+        callback=None,
+        transfer_info=None,
+        register=True
     ):
-        log.info("transfer_multpart %s -> %s", fileobj.name, dstpath)
         fields = {}
-        filename = normalize_unicode(fileobj.name)
+        filename = normalize_unicode(fileobj.__name__)
         fields["file"] = (
             os.path.basename(filename),
             fileobj,
             "application/octet-stream",
         )
         if xml is not None:
             fields["file_resource"] = (None, xml, "application/xml")
@@ -335,28 +260,27 @@
                 data=m,
                 headers={"Accept": "text/xml", "Content-Type": m.content_type},
             )
             code_to_exception(response)
             return response.doc()
 
     def transfer_binary(self, fileobj, dstpath, xml=None, callback=None, transfer_info=None, register=True):
-        log.info("transfer_binary %s -> %s", fileobj.name, dstpath)
         response = self.post(
-            posixpath.join("transfer_direct", urlquote(dstpath[1:])),
+            posixpath.join("transfer_direct", dstpath[1:]),
             data=fileobj,
             headers={"Content-Type": "application/octet-stream"},
         )
         code_to_exception(response)
 
         if xml is None:
             return None
 
-        if register and xml is not None:
-            blobs = self.session.service("blobs")
-            blob = blobs.register(path=dstpath[1:], resource=xml)
+        blobs = self.session.service("blobs")
+
+        blob = blobs.register(path=dstpath[1:], resource=xml)
 
         # blob = blobs.register(posixpath.join(path, filename))
         # if xml:
         #     meta = self.session.service('meta')
         #     # Find the uploaded blob and register with XML
         #     for kid in Metadoc.from_tagxml(xml):
         #         blob.append(kid)
@@ -399,47 +323,46 @@
                           </Destination>
                      </protocol>
                    </transfer>
         Returns:
          the list of files transferred
         """
         # Get cliend creds from info
-        log.info("transfer_s3 %s -> %s", fileobj.name, dstpath)
 
         filename = os.path.basename(dstpath)
-        # partial_path = "/".join(dstpath.split("/")[2:-1])
+        #partial_path = "/".join(dstpath.split("/")[2:-1])
         partial_path = ""
         try:
             upload_ok = False
             s3client = None
             for _ in range(3):  # Attempt upload 3 times with expired token handling
                 info = transfer_info.path_query("//info")[0].to_json()
                 s3_info = info["info"]
                 log.debug(
-                    "S3 INFO %s destpath:%s filename:%s fileobj:%s",
+                    "INFO %s destpath:%s filename:%s fileobj:%s",
                     s3_info,
                     dstpath,
                     filename,
                     fileobj,
                 )
                 if s3client is None:
-                    s3client = self._s3_client(s3_info, transfer_info)
+                    s3client = self._s3_session(s3_info["Credentials"])
 
                 try:
                     if not self._s3_dir_exists(s3client, s3_info, partial_path):
                         self._s3_create_dirs(s3client, s3_info, partial_path)
                     s3client.upload_fileobj(
                         fileobj,
                         Bucket=s3_info["Destination"]["S3"]["Bucket"],
                         Key=posixpath.join(
                             s3_info["Destination"]["S3"]["Folder"],
                             partial_path,
                             filename,
                         ),
-                        Callback=self._s3_progress(fileobj, callback=callback),
+                        Callback=callback,
                         ExtraArgs={
                             "Metadata": {
                                 "user-agent": "aws-fsx-lustre",
                                 "file-permissions": "0100660",
                                 "file-owner": s3_info["Destination"]["S3"]["Uid"],
                                 "file-group": s3_info["Destination"]["S3"]["Gid"],
                             }
@@ -456,30 +379,26 @@
                         s3client = None
                         fileobj = open(fileobj.name, "rb")  # Potential File Obj Leak
                         continue
 
             if not upload_ok:
                 raise BQApiError(f"Failed upload of {filename}. S3 token invalid")
 
-            dirs = self.session.service("dirs")
-            dirs.refresh(dstpath)
-
             if xml is None or not register:
                 return None
 
             # register the uploaded file with xml if available
-            # dirs = self.session.service("dirs")
             blobs = self.session.service("blobs")
             if isinstance(xml, str):
                 xml = Metadoc.from_naturalxml(xml)
 
             try:
-                # time.sleep(2)
-                # dirs.list_files(dstpath)  # KGK: List needed to force s3 transfer pathdb (review server side)
+                time.sleep(2)
                 for attempt in tenacity.Retrying(stop=tenacity.stop_after_attempt(3), wait=tenacity.wait_fixed(2)):
+                    log.info(f"REGISTER {dstpath}")
                     blobdoc = blobs.register(path=dstpath, resource=xml)
                     return blobdoc
             except tenacity.RetryError:
                 log.error("Regsitration failed after upload")
 
         except boto3.exceptions.S3UploadFailedError:
             log.exception("During upload of %s", filename)
@@ -523,30 +442,33 @@
                     "file-group": s3_info["Destination"]["S3"]["Gid"],
                 },
             )
         except botocore.exceptions.ClientError as error:
             code = error.response["Error"]["Code"]
             log.debug("ended on %s", code)
 
-    def _s3_client(self, s3_info, transfer_info: Dict):
+    def _s3_session(self, s3_info: Dict):
         """Create a long-lasting s3 Session suitable for caching
         Args:
            s3_info : {"AccessKeyId": "ID",
                        "SessionToken": "Token", "SecretAccessKey":
                        "Secret", "Expiration": "Expires"}
 
         Returns:
           a S3 boto client
         TODO :  Utilize a refreshable credential provider
                 https://stackoverflow.com/questions/61899028/where-can-i-find-the-documentation-for-writing-custom-aws-credential-provider-us
         """
-        log.debug("s3 session create client")
-        # session = boto3.session.Session()  # see https://github.com/boto/boto3/issues/801
-        session = RefreshableBotoSession(self, s3_info, transfer_info).refreshable_session()
-        s3client = session.client("s3")
+        session = boto3.session.Session()  # see https://github.com/boto/boto3/issues/801
+        s3client = session.client(
+            "s3",
+            aws_access_key_id=s3_info["AccessKeyId"],
+            aws_secret_access_key=s3_info["SecretAccessKey"],
+            aws_session_token=s3_info["SessionToken"],
+        )
         return s3client
 
         raise BQApiError("transfer_s3 not implemented")
 
     def _s3_refresh(self, transfer_info: Metadoc) -> Metadoc:
         """Fetch new credential when expired
             info    : metadoc
@@ -567,203 +489,58 @@
                             </3>
                           </Destination>
                      </protocol>
                    </transfer>
         Returns:
          the list of files transferred
         """
-        info = self.post("/transfer_protocol", data=transfer_info)
-        code_to_exception(info)
-        info = info.doc()
-        log.info("s3_session refresh %s", info.to_json())
-        return info
-
-    def _s3_progress(self, fileobj, callback):
-        return S3Progress(fileobj, callback=callback)
+        transfer_info = self.post("transfer_protocol", data=transfer_info)
+        return transfer_info
 
     def transfer_fsxlustre(self, *args, **kw) -> Metadoc:
         return self.transfer_s3(*args, **kw)
 
-    def ingester_list(self) -> Metadoc:
+    def register_list(self, script_name) -> Metadoc:
         """List available scripts"""
-        scripts = self.fetch("ingest")
+        scripts = self.fetch("register")
         code_to_exception(scripts)
         return scripts.doc()
 
-    def ingester_run(self, script_name, storepath, preview=True, **processor_args) -> Metadoc:
+    def register_run(self, script_name, storepath) -> Metadoc:
         """Run a registration script"""
         run = Metadoc(tag="resource")
-        run.add_tag("processor", value=script_name)
+        run.add_tag("script", value=script_name)
         run.add_tag("path", value=storepath)
-        if processor_args:
-            for k, v in processor_args.items():
-                run.add_tag(k, value=v)
-        resp = self.post("ingest", data=run, params={"preview": preview})
+        resp = self.post("register", data=run)
         code_to_exception(resp)
         return resp.doc()
 
+    def import_register_run(self, script_name, storepath, params):
+        """Run an importer script
+            echo "<request><script>avia-plate</script> <path>store://local/2022-12-12/experiment1</path> </request>"|  http -a admin:admin POST http://hq.viqi.org:8180/import/register  content-type:application/xml
+        Args:
+          <resource>
+            <script>avia-plate</script>
+            <path>store://local/2022-12-12/experiment1</path>
+            <params>
+              <blah></blah>
+              <blah></blah>
+            </params>
+          </resource>
+
+        { "resource" : {  "script": "avia-plate", "path": "store://local/2022-12-12/experiment1" } }
+
+        """
+        # Retrieve scsript and params from request
+        # prep inputs
+        path = "register"
+
+        body = Metadoc(tag="resource")
+        body.add_tag("script", value=script_name)
+        body.add_tag("path", value=storepath)
+        body.add_child(params)
+        res = self.post(path, data=body)
 
-class S3Progress:
-    def __init__(self, fileobj, size=None, callback=None):
-        self._filename = fileobj.name
-        self._size = float(size or os.fstat(fileobj.fileno()).st_size)
-        self._transferred = 0
-        self._lock = threading.Lock()
-        self.callback = callback
-
-    def __call__(self, transferred):
-        with self._lock:
-            self._transferred += transferred
-            value = (self._transferred / self._size) * 100
-            log.debug("S3 transfer %s %s/%s (%.2f%%)", self._filename, self._transferred, self._size, value)
-
-        if self.callback:
-            self.callback(transferred)
-
-
-class RefreshableBotoSession:
-    """
-    Boto Helper class which lets us create a refreshable session so that we can cache the client or resource.
-
-    Usage
-    -----
-    session = RefreshableBotoSession().refreshable_session()
-
-    client = session.client("s3") # we now can cache this client object without worrying about expiring credentials
-    """
-
-    def __init__(self, service, s3_info, transfer_info):
-        """
-        aws_creds { AccessKeyId, SecretAccessKey, SessionToken, Expiration, }
-        """
-
-        self.import_service = service
-        self.creds = s3_info["Credentials"]
-        self.info = transfer_info
-
-        # self.aws_access_key_id  = creds["AccessKeyId"]
-        ##self.aws_secret_access_key  = creds["SecretAccessKey"]
-        # self.aws_session_token  = creds["SessionToken"]
-
-    def __get_session_credentials(self):
-        """
-        Get session credentials
-        """
-        if self.creds:
-            credentials = {
-                "access_key": self.creds.get("AccessKeyId"),
-                "secret_key": self.creds.get("SecretAccessKey"),
-                "token": self.creds.get("SessionToken"),
-                "expiry_time": self.creds.get("Expiration"),
-            }
-            self.creds = None
-            log.debug("original credentals %s", credentials)
-            return credentials
-
-        info = self.import_service._s3_refresh(self.info)
-        creds = info.path_query("//info")[0].to_json()["info"]["Credentials"]
-        credentials = {
-            "access_key": creds.get("AccessKeyId"),
-            "secret_key": creds.get("SecretAccessKey"),
-            "token": creds.get("SessionToken"),
-            "expiry_time": creds.get("Expiration"),
-        }
-
-        # session_credentials = session.get_credentials().get_frozen_credentials()
-        # credentials = {
-        #     "access_key": session_credentials.access_key,
-        #     "secret_key": session_credentials.secret_key,
-        #     "token": session_credentials.token,
-        #     "expiry_time": datetime.fromtimestamp(time() + self.session_ttl).replace(tzinfo=pytz.utc).isoformat(),
-        # }
-        log.debug("refresh credentals %s", credentials)
-
-        return credentials
-
-    def refreshable_session(self) -> boto3.session.Session:
-        """
-        Get refreshable boto3 session.
-        """
-        # Get refreshable credentials
-        refreshable_credentials = RefreshableCredentials.create_from_metadata(
-            metadata=self.__get_session_credentials(),
-            refresh_using=self.__get_session_credentials,
-            method="sts-assume-role",
-        )
-
-        # attach refreshable credentials current session
-        session = get_session()
-        session._credentials = refreshable_credentials
-        # session.set_config_variable("region", self.region_name)
-        autorefresh_session = boto3.session.Session(botocore_session=session)
-
-        return autorefresh_session
-
-
-def initiate_batch_transfer(
-    srcs: list, file_queue: Queue, includes: list[str] | None = None, excludes: list[str] | None = None
-):
-    """Transfer a list of files
-    Args:
-      srcs: a single str or list of directories/files to transfer
-      file_queue: a thread queue to add entries
-      includes: a list of glob expressions to include in transfer
-      excludes: a list of glob expressions to exclude from transfer
-
-    Returns:
-      The number of files added to the queue
-
-    """
-
-    file_count = 0
-
-    def add_files(files, root):
-        nonlocal file_count  # get file_count from outside scope
-        root = os.path.join(root, "")
-        for f1 in files:
-            if includes and not any(fnmatch.fnmatch(f1, include) for include in includes):
-                log.info("Skipping %s: not included", f1)
-                continue
-            if excludes and any(fnmatch.fnmatch(f1, exclude) for exclude in excludes):
-                log.info("Skipping %s: excluded", f1)
-                continue
-            log.debug("appending %s with root %s", f1, root)
-            # metatable.append(f1, root)
-            # Add full localpath and partial destination path
-            file_queue.put((f1, f1[len(root) :]))
-            file_count += 1
-
-    for srctree in srcs:
-        if os.path.isdir(srctree):
-            directory = os.path.abspath(srctree).replace("\\", "/")
-            parent = os.path.dirname(directory).replace("\\", "/")
-            for root, _, files in os.walk(directory):
-                add_files((os.path.join(root, f1).replace("\\", "/") for f1 in files), root=parent)
-        elif os.path.isfile(srctree):
-            parent = os.path.dirname(srctree).replace("\\", "/")
-            add_files([srctree.replace("\\", "/")], root=parent)
-
-    return file_count
-
-
-def thread_session_initialize(session, localvar):
-    """Create a cloned session
-    and import service for use by threaded_upload
-    This is called once for each thread created by ThreadPool
-    """
-    localvar.session = session.copy()
-    localvar.import_svc = session.service("import")
-
-
-def thread_upload(localvar, file_tuple: tuple[str, str]):
-    """Upload a single file
-    Args:
-       localvar is a threadlocal object containing session, and imp_svc (import_service instance)
-
-    """
-    imp_svc = localvar.import_svc
-
-    full_path = file_tuple[0]
-    partial_path = file_tuple[1]
+        # prep outputs
+        code_to_exception(res)
 
-    log.info("thread_upload of %s", partial_path)
-    imp_svc.transfer_file(srcpath=full_path, dstpath=partial_path)
+        return res.doc()
```

## vqapi/services/table_proxy.py

```diff
@@ -32,61 +32,62 @@
 ## NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS        ##
 ## SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.              ##
 ##                                                                           ##
 ## The views and conclusions contained in the software and documentation     ##
 ## are those of the authors and should not be interpreted as representing    ##
 ## official policies, either expressed or implied, of <copyright holder>.    ##
 ###############################################################################
+"""
+SYNOPSIS
+========
 
+
+DESCRIPTION
+===========
+
+"""
 import json
 import logging
 import os
 import posixpath
 import shutil
 import tempfile
 
-import numpy as np
-import pandas as pd
 import tables
+import pandas as pd
+import numpy as np
+
+
 from bq.metadoc.formats import Metadoc
 
 from vqapi.exception import BQApiError
 
-from .base_proxy import FuturizedServiceProxy
-
 # from botocore.credentials import RefreshableCredentials
 # from botocore.session import get_session
 
+from .base_proxy import FuturizedServiceProxy
 
 log = logging.getLogger("vqapi.services")
 
-
-def _to_dtype(typestr: str):
-    if typestr in ("str", "string", "image"):
-        return "O"
-    else:
-        return typestr
-
-
 class TableProxy(FuturizedServiceProxy):
-    service_name = "tables"
+    service_name = "table"
 
-    def load_array(self, table_uniq, path, slices=None, want_info=False, use_binary_transfer=True):
+    def load_array(self, table_uniq, path, slices=None, want_info=False):
         """
         Load array from BisQue.
         """
         slices = slices or []
         if table_uniq.startswith("http"):
             table_uniq = table_uniq.split("/")[-1]
         slice_list = []
         for single_slice in slices:
             if isinstance(single_slice, slice):
                 slice_list.append(
                     "{};{}".format(
-                        "" if single_slice.start is None else single_slice.start,
+                        single_slice.start or "",
                         "" if single_slice.stop is None else single_slice.stop - 1,
                     )
                 )
             elif isinstance(single_slice, int):
                 slice_list.append(f"{single_slice};{single_slice}")
             else:
                 raise BQApiError("malformed slice parameter")
@@ -96,77 +97,24 @@
         try:
             num_dims = len(json.loads(info_response.text).get("sizes"))
         except ValueError:
             raise BQApiError("array could not be read")
         # fill slices with missing dims
         for _ in range(num_dims - len(slice_list)):
             slice_list.append(";")
-
-        if use_binary_transfer is False:
-            # JSON TRANSFER -- SAFE BUT MAY BE SLOWER
-            data_url = "/".join([path, ",".join(slice_list), "format:extjs"])
-            response = self.get(data_url)
-            # convert JSON to Numpy array
-            res = json.loads(response.content)
-            res = np.array(
-                [tuple(res["data"][ix]) for ix in range(len(res["data"]))],
-                dtype=[(res["headers"][ix], _to_dtype(res["types"][ix])) for ix in range(len(res["headers"]))],
-            )
-
-        else:
-            # BINARY TRANSFER -- NOT ALWAYS WORKING
-            data_url = "/".join([path, ",".join(slice_list), "format:hdf"])
-            response = self.get(data_url)
-            # convert HDF5 to Numpy array (preserve indices??)
-            with tables.open_file(
-                "array.h5",
-                driver="H5FD_CORE",
-                driver_core_image=response.content,
-                driver_core_backing_store=0,
-            ) as h5file:
-                res = h5file.root.array.read()
-
-            # -------------------------------------------------------------------------------------
-            # convert "|S" (bytearray) columns to correctly decoded "<U" (unicode) columns
-            if res.dtype.kind == "V":  # compound => check each component
-                # remember str cols and their original lengths
-                strcols = {d[0]: int(d[1][2:]) for d in res.dtype.descr if d[1].startswith("|S")}
-                # first, convert any dtype "|Sx" to "|O" to allow for padding with b'\x00'
-                res = res.astype(
-                    [(d[0], "|O") if d[0] in strcols else d for d in res.dtype.descr if d[0] in res.dtype.names]
-                )  # skip cols that are not in names (object types seem to get lost via pytables)
-                # pad any strcol with b'\x00' to be divisible by 4 (since it is assumed utf-32)
-                with np.nditer(res, flags=["refs_ok"], op_flags=["readwrite"]) as it:
-                    for row in it:
-                        for fname in strcols:
-                            row[fname] = (
-                                row[fname].item() + b"\x00" * ((4 - (len(row[fname].item()) % 4)) % 4)
-                            ).decode("utf-32")
-                # next, convert any dtype "|Sx" to "<U(x/4)"
-                res = res.astype(
-                    [
-                        (d[0], f"<U{strcols[d[0]]//4}") if d[0] in strcols else d
-                        for d in res.dtype.descr
-                        if d[0] in res.dtype.names
-                    ]
-                )  # skip cols that are not in names (object types seem to get lost via pytables)
-            else:
-                # single type
-                if res.dtype.descr[0][1].startswith("|S"):
-                    strlen = int(res.dtype.descr[0][1][2:])
-                    # first, convert any dtype "|Sx" to "|O" to allow for padding with b'\x00'
-                    res = res.astype("|O")
-                    # pad any dtype "|Sx" with b'\x00' to be divisible by 4 (since it is assumed utf-32)
-                    with np.nditer(res, flags=["refs_ok"], op_flags=["readwrite"]) as it:
-                        for x in it:
-                            x[...] = (x.item() + b"\x00" * ((4 - (len(x.item()) % 4)) % 4)).decode("utf-32")
-                    # next, convert any dtype "|Sx" to "<U(x/4)"
-                    res = res.astype(f"<U{strlen//4}")
-            # -------------------------------------------------------------------------------------
-
+        data_url = "/".join([path, ",".join(slice_list), "format:hdf"])
+        response = self.get(data_url)
+        # convert HDF5 to Numpy array (preserve indices??)
+        with tables.open_file(
+            "array.h5",
+            driver="H5FD_CORE",
+            driver_core_image=response.content,
+            driver_core_backing_store=0,
+        ) as h5file:
+            res = h5file.root.array.read()
         if want_info:
             return res, json.loads(info_response.text)
         else:
             return res
 
     def store_array(self, array, storepath, name) -> Metadoc:
         """
@@ -194,33 +142,18 @@
         finally:
             shutil.rmtree(dirpath)
 
     def load_table(self, table_uniq, path, slices=None, as_dataframe=True):
         """
         Load table as a numpy recarray or pandas dataframe.
         """
-        ndarr, info = self.load_array(table_uniq, path, slices, want_info=True, use_binary_transfer=False)
-
-        #         # -------------------------------------------------------------------------------------
-        #         # use format "<Ux" for any col of type "<Ux"
-        #         if ndarr.dtype.kind == "V":
-        #             # compound => check each component
-        #             formats = [None]*len(info["types"])
-        #             for ix in range(len(ndarr.dtype)):
-        #                 formats[ix] = ndarr.dtype.descr[ix][1] if ndarr.dtype.descr[ix][1].startswith("<U") else info["types"][ix]
-        #         else:
-        #             # single type
-        #             formats = [ndarr.dtype.descr[0][1] if ndarr.dtype.descr[0][1].startswith("<U") else ty for ty in info["types"]]
-        #         # -------------------------------------------------------------------------------------
-
+        ndarr, info = self.load_array(table_uniq, path, slices, want_info=True)
+        res = np.core.records.fromarrays(ndarr.transpose(), names=info["headers"], formats=info["types"])
         if as_dataframe is True:
-            res = pd.DataFrame(ndarr)
-        else:
-            # return as recarray
-            res = ndarr.view(np.recarray)
+            res = pd.DataFrame.from_records(res)
         return res
 
     def store_table(self, table, storepath, name) -> Metadoc:
         """
         Store numpy recarray or pandas dataframe in BisQue and return resource doc.
         """
         if isinstance(table, pd.DataFrame):
```

## Comparing `viqi_api-0.6.4.87.dist-info/METADATA` & `viqi_api-0.6.4.9.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,95 +1,70 @@
 Metadata-Version: 2.1
-Name: viqi_api
-Version: 0.6.4.87
-Summary: ViQi Python API
-Author-email: ViQi Inc <info@viqi.org>
+Name: viqi-api
+Version: 0.6.4.9
+Summary: ViQi Bisque Module API
+Author: ViQi Inc
+Author-email: info@viqi.org
 Project-URL: homepage, https://www.viqi.org
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.10
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown
 Requires-Dist: configparser
 Requires-Dist: bisque-metadoc
 Requires-Dist: tifffile
 Requires-Dist: simplejson
-Requires-Dist: shortuuid >=1.0.8
+Requires-Dist: shortuuid (>=1.0.8)
 Requires-Dist: tenacity
 Requires-Dist: requests-cache
 Requires-Dist: requests-toolbelt
 Requires-Dist: boto3
 Requires-Dist: importlib-metadata ; python_version < "3.10"
 Provides-Extra: image_service
 Requires-Dist: tifffile ; extra == 'image_service'
 Requires-Dist: tables ; extra == 'image_service'
 Provides-Extra: table_service
 Requires-Dist: numpy ; extra == 'table_service'
 Requires-Dist: pandas ; extra == 'table_service'
 Requires-Dist: tables ; extra == 'table_service'
-Provides-Extra: test
-Requires-Dist: pytest ; extra == 'test'
-Requires-Dist: pytest-cov ; extra == 'test'
-Requires-Dist: webtest ; extra == 'test'
 
 # ViQi API
 
 Low level interface to ViQi services
 
 
 ## Install
 
 
 `pip install viqi-api `
 
 ## Configuration
 
-For command line tools create `~/.config/viqi/profiles`  or `~/config/viqi/profiles`` (windows) with the following
+For command line tools create `~/.config/viqi/profiles` with the following
 
 ```
 [default]
 host=https://science.viqiai.cloud
 user=myuser
 password=mysecret
 
 [science-user2]
 host=https://science.viqiai.cloud
 user=myuser2
 password=mysecret2
 ```
 
-## Documentation
-
-* [Service-oriented API](https://viqi.gitlab.io/viqi-common/bisque-api/soapi.html)
-* [Object-oriented API](https://viqi.gitlab.io/viqi-common/bisque-api/ooapi.html)
-
-
 ## Usage
 
 Example ipython session:
 
 ```
 ipython
 from vqapi import bisque_session
 session = bisque_session(args=["--profile=science-user2"])
 
 meta = session.service("meta")
 user = meta.fetch("user")
 print(user)
-```
-
-If used in script bisque_session will read from sys.argv
-
-myscript.py:
-```
-from vqapi import bisque_session
-session = bisque_session()
-
-meta = session.service("meta")
-user = meta.fetch("user")
-print(user)
-```
 
-Pass args on command line:
-```
-$ python myscript.py --profile=science-user2
 ```
```

## Comparing `viqi_api-0.6.4.87.dist-info/RECORD` & `viqi_api-0.6.4.9.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 vqapi/README.md,sha256=7DM5QUu1mXfOR14RhMMZs1pJcr5GeWoCl68zOkryzZs,417
-vqapi/__init__.py,sha256=UcoIlOlDSHJ5isp4nAkYtRLPvpALAckTSvCTzgFL1Y4,294
+vqapi/__init__.py,sha256=F9hkh1APw6yKTSqAepWKLgf-GJpT-TB0JibG1Fb-MxA,276
 vqapi/blockable_module.py,sha256=zMeKq_h2TZLGAvnvuJbf9K0LdzWHNjs_iRdRaB81f8M,1746
 vqapi/bqclass.py,sha256=wJWMdfULDka_6ts2QMFolcsTmXEcYT6F66Ssd7Zf9bQ,28745
 vqapi/casauth.py,sha256=dCmb2VzoyEeo2OL6ffbEutrsmen_ES5hN896TGd5WMw,1595
-vqapi/cmd.py,sha256=eAkEzkOaXj5Ie5-Kb0AhP2B7zd4wC9ln3juy-k79Iac,6977
-vqapi/comm.py,sha256=obSOrIAycApaBfZYdHx_SFKV9ZGAemm3wDsIxSCajbU,50189
-vqapi/exception.py,sha256=6SfgjDzm_gtBDPyEmLgJ-mmMAKStXH4c2Si2rLZehrI,15725
-vqapi/plugins.py,sha256=VcB2wQXEUqXnajIuOX0YZZr-CbYS94N3FTVpu7iVnBE,4846
-vqapi/util.py,sha256=arSjH43Wu_BVRRukgCc6usup6nLzQnoDKRSiL2VJLmo,14011
-vqapi/version.py,sha256=t6cYWJC9gSHOhQl2ccWxL72kWXcJkIwRzRtCTJMuNtM,418
-vqapi/vqclass.py,sha256=j4Ujj1YiItnT6OOunL9CDvvC9LyDcu1xqbjbayY9y5A,58002
-vqapi/vqquery.py,sha256=f5oorv9zA4Q-WoVHf4DfJgfsvkZAtFLUkPcWNhSnyeA,11632
+vqapi/cmd.py,sha256=YJBN0GkqC9pTPKM_HR-zG8tkAHfwUvQP4ahB7Tau69w,6106
+vqapi/comm.py,sha256=by1FlseGPHn7um4wiKePvLMszCy_-URS_54ilSanuTg,49773
+vqapi/exception.py,sha256=dwG5723rL4Txs10sgS6GnuXHLtAEsy-zPUxOG0aZ-aM,14629
+vqapi/plugins.py,sha256=xQ5wx_aRckBumL_Gk5cuaoP6X8w66WHf5SYXk3uX9Zk,4722
+vqapi/util.py,sha256=5veo8qvyT0DXj_pGg6Kq9kHQ_tGUNej_Ze5wj_l1YCA,13926
+vqapi/version.py,sha256=psHcSKylm6MevOU9PmXCrTqLU1N1lDup9jENbsxnsG4,165
+vqapi/vqclass.py,sha256=CwpXAkACNCybtJMVnB6usvNXNfG2_srPIbjMkBcNvWE,33627
+vqapi/vqquery.py,sha256=eCj5EuzGmudAMT0yam9LsD_sJ76niSMWSsYc53ttZJc,11337
 vqapi/xmldict.py,sha256=LlALxsgBZS0Put8rRj6T4S5xMoI1h5gfZvk_bSKivec,4604
 vqapi/RequestsMonkeyPatch/__init__.py,sha256=9_8wL9Scv8_Cs8HJyJHGvx1vwXErsuvlsAqNZLcJQR0,8
 vqapi/RequestsMonkeyPatch/monkeypatch.py,sha256=Dl9WR-wicHkgxKRWZ4yXvs4RMuu9v3CSY3fBMlH3Fl0,138
-vqapi/RequestsMonkeyPatch/requests_patch.py,sha256=2mGGrLVoo4BKODMoCxm-yzRH83Ok16oirw_roMWNdUE,2009
-vqapi/services/__init__.py,sha256=fndmO-p3S3jd5c0cP7dlDj-emxPHjm7X4L_f8PP_YA8,120
-vqapi/services/base_proxy.py,sha256=qrng6HWA1wMRWssDByxRuBtZbUVFvYonNDv-sU11rVE,17133
-vqapi/services/core_services.py,sha256=k5rdz8XAN0hECaTuwzDQh8eaVQhkc6jPhYFa0XFyaI8,32418
-vqapi/services/factory.py,sha256=POH9YIkn4WwU1oBtEPGgpQBA3xBql4bhyJgscLgIUTk,1891
-vqapi/services/image_proxy.py,sha256=zbXoJcmV0Sci-b2pVz7EBhlpyXaFTNhmaKIyyP5250I,3519
-vqapi/services/import_proxy.py,sha256=hM_BbjeMdLPIjwS62jQ7iyf4hKQHQvRbNjn3HpQCRto,32494
-vqapi/services/table_proxy.py,sha256=MzDliaJ0pzVDtW0rE8UDFJHi7B_xE52H9wUua4wxrHc,11637
-viqi_api-0.6.4.87.dist-info/METADATA,sha256=jwBX5-Q603tnI1oldQRYgi-DCaXpwz9nPAeSkvfK_Ek,2216
-viqi_api-0.6.4.87.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-viqi_api-0.6.4.87.dist-info/top_level.txt,sha256=3tj8lcUB1FkjX_EiiFuj3I18i3_LJydRRS0stEFKdJU,6
-viqi_api-0.6.4.87.dist-info/RECORD,,
+vqapi/RequestsMonkeyPatch/requests_patch.py,sha256=CsXlC4OtK1tBVE4I1_ZU75RHGSQgTuSJREqcsM4yjgs,2010
+vqapi/services/__init__.py,sha256=6pkz7gcAcMshSla-fOeBpClaITVQ8IOKLv50TbmPI2Q,67
+vqapi/services/base_proxy.py,sha256=k7zJG5Klow2DmDwHXxCwBuglP47u3oEDdDvIBrzgrEY,14441
+vqapi/services/core_services.py,sha256=rjBTbZC1CpHfFb3KM8DWAIbXss4th_rBSCMYV_FCElc,20591
+vqapi/services/factory.py,sha256=0pRJIf42l8baboCjmgs1b7YKBC8lIoNUkVLaQ1G75w8,1862
+vqapi/services/image_proxy.py,sha256=gJFN7tQ8GCyj_r4Zo2yLTDUmOtVOA8rI7xIbPvfdBe8,3519
+vqapi/services/import_proxy.py,sha256=xo_MOSaNtfbsHP2rf-Bu2gRflFYxbblR0Mu2EwPGRHM,22829
+vqapi/services/table_proxy.py,sha256=vrFG29Q3S6kMHwebTyw217nuVOdyYOrszk8lKrbtOWQ,7533
+viqi_api-0.6.4.9.dist-info/METADATA,sha256=3ck6eMw39H6IRkus6OmnAt5zqdpoNonP-yxZZT5zlzg,1569
+viqi_api-0.6.4.9.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+viqi_api-0.6.4.9.dist-info/top_level.txt,sha256=3tj8lcUB1FkjX_EiiFuj3I18i3_LJydRRS0stEFKdJU,6
+viqi_api-0.6.4.9.dist-info/RECORD,,
```

