# Comparing `tmp/snowflake_core-0.8.0.tar.gz` & `tmp/snowflake_core-0.8.1.tar.gz`

## Comparing `snowflake_core-0.8.0.tar` & `snowflake_core-0.8.1.tar`

### file list

```diff
@@ -1,275 +1,423 @@
--rw-r--r--   0        0        0     2992 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/CHANGELOG.md
--rw-r--r--   0        0        0     1915 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/codegen/README.md
--rw-r--r--   0        0        0      492 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/__init__.py
--rw-r--r--   0        0        0     8890 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_common.py
--rw-r--r--   0        0        0      117 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_constants.py
--rw-r--r--   0        0        0     5463 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_http_requests.py
--rw-r--r--   0        0        0     4865 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_root.py
--rw-r--r--   0        0        0     5956 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/exceptions.py
--rw-r--r--   0        0        0      740 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/rest.py
--rw-r--r--   0        0        0       95 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/version.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/__init__.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/pydantic_compatibility.py
--rw-r--r--   0        0        0     1035 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/snowapi_parameters.py
--rw-r--r--   0        0        0     4197 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/telemetry.py
--rw-r--r--   0        0        0     3692 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/utils.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/__init__.py
--rw-r--r--   0        0        0     9003 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/executor.py
--rw-r--r--   0        0        0     3286 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/rest_errors.py
--rw-r--r--   0        0        0     7859 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_bridge.py
--rw-r--r--   0        0        0      283 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_execute.py
--rw-r--r--   0        0        0     1728 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_request.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/__init__.py
--rw-r--r--   0        0        0     8714 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/computepools_resource.py
--rw-r--r--   0        0        0    16158 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/database_resource.py
--rw-r--r--   0        0        0     5458 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py
--rw-r--r--   0        0        0     1128 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/resource_base.py
--rw-r--r--   0        0        0    13516 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/schema_resource.py
--rw-r--r--   0        0        0    10828 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/services_resource.py
--rw-r--r--   0        0        0    40719 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/table_resource.py
--rw-r--r--   0        0        0    28172 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/task_resource.py
--rw-r--r--   0        0        0    13474 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py
--rw-r--r--   0        0        0      927 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/__init__.py
--rw-r--r--   0        0        0     4617 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_compute_pool.py
--rw-r--r--   0        0        0     1046 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/__init__.py
--rw-r--r--   0        0        0    37790 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_client.py
--rw-r--r--   0        0        0      905 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_response.py
--rw-r--r--   0        0        0    13311 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22715 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/rest.py
--rw-r--r--   0        0        0      212 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api/__init__.py
--rw-r--r--   0        0        0    62546 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py
--rw-r--r--   0        0        0      812 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/__init__.py
--rw-r--r--   0        0        0     7777 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/compute_pool.py
--rw-r--r--   0        0        0     3638 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/error_response.py
--rw-r--r--   0        0        0     2881 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/success_response.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/__init__.py
--rw-r--r--   0        0        0      533 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/__init__.py
--rw-r--r--   0        0        0     2202 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_search_service.py
--rw-r--r--   0        0        0     1030 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/__init__.py
--rw-r--r--   0        0        0    37756 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_client.py
--rw-r--r--   0        0        0      914 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_response.py
--rw-r--r--   0        0        0    13163 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22630 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/rest.py
--rw-r--r--   0        0        0      246 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api/__init__.py
--rw-r--r--   0        0        0    13020 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api/cortex_search_service_api.py
--rw-r--r--   0        0        0      751 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/__init__.py
--rw-r--r--   0        0        0     3562 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/error_response.py
--rw-r--r--   0        0        0     3511 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/query_request.py
--rw-r--r--   0        0        0     3083 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/query_response.py
--rw-r--r--   0        0        0      214 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/__init__.py
--rw-r--r--   0        0        0    10388 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_database.py
--rw-r--r--   0        0        0     1553 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/__init__.py
--rw-r--r--   0        0        0    37756 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_client.py
--rw-r--r--   0        0        0      901 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_response.py
--rw-r--r--   0        0        0    13300 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22713 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/rest.py
--rw-r--r--   0        0        0      198 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api/__init__.py
--rw-r--r--   0        0        0   108817 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/api/database_api.py
--rw-r--r--   0        0        0     1482 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/__init__.py
--rw-r--r--   0        0        0     2974 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/account_identifiers.py
--rw-r--r--   0        0        0    10472 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database.py
--rw-r--r--   0        0        0    11211 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database_clone.py
--rw-r--r--   0        0        0     3632 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/error_response.py
--rw-r--r--   0        0        0     4660 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time.py
--rw-r--r--   0        0        0     3555 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_offset.py
--rw-r--r--   0        0        0     3636 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_statement.py
--rw-r--r--   0        0        0     3636 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py
--rw-r--r--   0        0        0     2875 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/success_response.py
--rw-r--r--   0        0        0      893 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/__init__.py
--rw-r--r--   0        0        0     4078 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_image_repository.py
--rw-r--r--   0        0        0     1108 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/__init__.py
--rw-r--r--   0        0        0    37844 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api_client.py
--rw-r--r--   0        0        0      909 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api_response.py
--rw-r--r--   0        0        0    13340 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22737 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/rest.py
--rw-r--r--   0        0        0      228 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api/__init__.py
--rw-r--r--   0        0        0    39684 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api/image_repository_api.py
--rw-r--r--   0        0        0      858 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/__init__.py
--rw-r--r--   0        0        0     3664 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/error_response.py
--rw-r--r--   0        0        0     5893 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/image_repository.py
--rw-r--r--   0        0        0     2907 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/success_response.py
--rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/__init__.py
--rw-r--r--   0        0        0     6584 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_schema.py
--rw-r--r--   0        0        0     1431 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/__init__.py
--rw-r--r--   0        0        0    37734 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_client.py
--rw-r--r--   0        0        0      899 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_response.py
--rw-r--r--   0        0        0    13290 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22707 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/rest.py
--rw-r--r--   0        0        0      190 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api/__init__.py
--rw-r--r--   0        0        0    61166 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api/schema_api.py
--rw-r--r--   0        0        0     1345 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/__init__.py
--rw-r--r--   0        0        0     3624 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/error_response.py
--rw-r--r--   0        0        0    10773 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/model_schema.py
--rw-r--r--   0        0        0     4646 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time.py
--rw-r--r--   0        0        0     3543 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_offset.py
--rw-r--r--   0        0        0     3624 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_statement.py
--rw-r--r--   0        0        0     3624 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py
--rw-r--r--   0        0        0    11428 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/schema_clone.py
--rw-r--r--   0        0        0     2867 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/success_response.py
--rw-r--r--   0        0        0     1397 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/__init__.py
--rw-r--r--   0        0        0     7275 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_service.py
--rw-r--r--   0        0        0     1597 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/__init__.py
--rw-r--r--   0        0        0    37759 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api_client.py
--rw-r--r--   0        0        0      900 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api_response.py
--rw-r--r--   0        0        0    13310 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22724 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/rest.py
--rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api/__init__.py
--rw-r--r--   0        0        0    84995 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/api/service_api.py
--rw-r--r--   0        0        0     1554 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/__init__.py
--rw-r--r--   0        0        0     3642 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/error_response.py
--rw-r--r--   0        0        0     3319 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py
--rw-r--r--   0        0        0     3377 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py
--rw-r--r--   0        0        0     9733 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service.py
--rw-r--r--   0        0        0     3922 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_endpoint.py
--rw-r--r--   0        0        0     4304 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec.py
--rw-r--r--   0        0        0     3346 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_inline_text.py
--rw-r--r--   0        0        0     3513 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_stage_file.py
--rw-r--r--   0        0        0     2885 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/success_response.py
--rw-r--r--   0        0        0      111 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/__init__.py
--rw-r--r--   0        0        0     1429 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_session.py
--rw-r--r--   0        0        0      958 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/__init__.py
--rw-r--r--   0        0        0    37706 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api_client.py
--rw-r--r--   0        0        0      900 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api_response.py
--rw-r--r--   0        0        0    13307 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22671 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/rest.py
--rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api/__init__.py
--rw-r--r--   0        0        0    10986 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/api/session_api.py
--rw-r--r--   0        0        0      746 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/__init__.py
--rw-r--r--   0        0        0     2947 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/create_session_request.py
--rw-r--r--   0        0        0     4699 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/create_session_response.py
--rw-r--r--   0        0        0     3589 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/error_response.py
--rw-r--r--   0        0        0     4077 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/parameter.py
--rw-r--r--   0        0        0     2832 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/success_response.py
--rw-r--r--   0        0        0     2871 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/token_request.py
--rw-r--r--   0        0        0      347 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/__init__.py
--rw-r--r--   0        0        0    10201 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_table.py
--rw-r--r--   0        0        0     1781 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/__init__.py
--rw-r--r--   0        0        0    37735 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_client.py
--rw-r--r--   0        0        0      898 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_response.py
--rw-r--r--   0        0        0    13299 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22716 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/rest.py
--rw-r--r--   0        0        0      186 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api/__init__.py
--rw-r--r--   0        0        0   130412 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/api/table_api.py
--rw-r--r--   0        0        0     1783 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/__init__.py
--rw-r--r--   0        0        0     4698 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/constraint.py
--rw-r--r--   0        0        0     3632 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/error_response.py
--rw-r--r--   0        0        0     4135 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/foreign_key.py
--rw-r--r--   0        0        0     4651 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time.py
--rw-r--r--   0        0        0     3549 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_offset.py
--rw-r--r--   0        0        0     3630 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_statement.py
--rw-r--r--   0        0        0     3630 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_timestamp.py
--rw-r--r--   0        0        0     3297 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/primary_key.py
--rw-r--r--   0        0        0     2875 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/success_response.py
--rw-r--r--   0        0        0    11896 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table.py
--rw-r--r--   0        0        0    12629 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table_clone.py
--rw-r--r--   0        0        0     6275 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table_column.py
--rw-r--r--   0        0        0     3280 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/unique_key.py
--rw-r--r--   0        0        0      925 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/__init__.py
--rw-r--r--   0        0        0    31115 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_task.py
--rw-r--r--   0        0        0     8563 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/context.py
--rw-r--r--   0        0        0    29476 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/dagv1.py
--rw-r--r--   0        0        0     1270 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/__init__.py
--rw-r--r--   0        0        0    37724 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_client.py
--rw-r--r--   0        0        0      897 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_response.py
--rw-r--r--   0        0        0    13292 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22713 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/rest.py
--rw-r--r--   0        0        0      182 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api/__init__.py
--rw-r--r--   0        0        0   103843 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/api/task_api.py
--rw-r--r--   0        0        0     1146 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/__init__.py
--rw-r--r--   0        0        0     3414 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/cron_schedule.py
--rw-r--r--   0        0        0     3628 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/error_response.py
--rw-r--r--   0        0        0     3231 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/minutes_schedule.py
--rw-r--r--   0        0        0     2871 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/success_response.py
--rw-r--r--   0        0        0    11882 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task.py
--rw-r--r--   0        0        0     7942 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_run.py
--rw-r--r--   0        0        0     4252 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_schedule.py
--rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/task/_internal/__init__.py
--rw-r--r--   0        0        0      307 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/__init__.py
--rw-r--r--   0        0        0     8596 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_warehouse.py
--rw-r--r--   0        0        0     1010 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/__init__.py
--rw-r--r--   0        0        0    37758 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api_client.py
--rw-r--r--   0        0        0      902 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api_response.py
--rw-r--r--   0        0        0    13296 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/configuration.py
--rw-r--r--   0        0        0     1674 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/paging.py
--rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/pydantic_compatibility.py
--rw-r--r--   0        0        0    22707 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/rest.py
--rw-r--r--   0        0        0      202 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api/__init__.py
--rw-r--r--   0        0        0    77524 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api/warehouse_api.py
--rw-r--r--   0        0        0      788 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/__init__.py
--rw-r--r--   0        0        0     3627 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/error_response.py
--rw-r--r--   0        0        0     2870 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/success_response.py
--rw-r--r--   0        0        0    16326 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/warehouse.py
--rw-r--r--   0        0        0       15 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/.gitignore
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/__init__.py
--rw-r--r--   0        0        0      138 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/conftest.py
--rw-r--r--   0        0        0      660 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/utils.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/__init__.py
--rw-r--r--   0        0        0    15745 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/conftest.py
--rw-r--r--   0        0        0     2365 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/setup_manually.py
--rw-r--r--   0        0        0     5305 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_compute_pool.py
--rw-r--r--   0        0        0     2158 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_cortex_search_service.py
--rw-r--r--   0        0        0     6708 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_database.py
--rw-r--r--   0        0        0     1903 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_image_repository.py
--rw-r--r--   0        0        0      381 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_root.py
--rw-r--r--   0        0        0     4004 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_schema.py
--rw-r--r--   0        0        0     6043 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_service.py
--rw-r--r--   0        0        0    15936 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_table.py
--rw-r--r--   0        0        0    13804 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/test_warehouse.py
--rw-r--r--   0        0        0      920 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/utils.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/__init__.py
--rw-r--r--   0        0        0      568 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/conftest.py
--rw-r--r--   0        0        0     7767 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_create_or_update_task.py
--rw-r--r--   0        0        0     9724 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_create_task.py
--rw-r--r--   0        0        0     1580 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_drop_task.py
--rw-r--r--   0        0        0     1608 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_execute_task.py
--rw-r--r--   0        0        0     4397 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_load_task.py
--rw-r--r--   0        0        0    10923 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_python_function.py
--rw-r--r--   0        0        0     3154 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_show_task.py
--rw-r--r--   0        0        0     1396 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/test_task_parameters.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/dag/__init__.py
--rw-r--r--   0        0        0    25597 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/integ/task/dag/test_dag.py
--rw-r--r--   0        0        0       34 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/resources/testCSVheader.csv
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/__init__.py
--rw-r--r--   0        0        0     2349 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/conftest.py
--rw-r--r--   0        0        0     2350 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_common.py
--rw-r--r--   0        0        0     8851 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_database.py
--rw-r--r--   0        0        0     2451 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_schema.py
--rw-r--r--   0        0        0     6199 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/test_table.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/api/__init__.py
--rw-r--r--   0        0        0     4214 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/api/general_api_test.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/__init__.py
--rw-r--r--   0        0        0     7517 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_database.py
--rw-r--r--   0        0        0     7104 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_executor.py
--rw-r--r--   0        0        0     1803 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_rest_errors.py
--rw-r--r--   0        0        0     4838 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/bridge/test_schema.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/__init__.py
--rw-r--r--   0        0        0     1141 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/test_computepool_resource.py
--rw-r--r--   0        0        0     2990 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/test_service.py
--rw-r--r--   0        0        0     1431 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/resources/test_task_resource.py
--rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/__init__.py
--rw-r--r--   0        0        0     1875 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/test_dagv1.py
--rw-r--r--   0        0        0     4427 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/test_task_context.py
--rw-r--r--   0        0        0      710 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/tests/unit/task/test_task_reference.py
--rw-r--r--   0        0        0     1315 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/.gitignore
--rw-r--r--   0        0        0    11339 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/LICENSE
--rw-r--r--   0        0        0      405 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/README.md
--rw-r--r--   0        0        0     4355 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/pyproject.toml
--rw-r--r--   0        0        0     1808 2020-02-02 00:00:00.000000 snowflake_core-0.8.0/PKG-INFO
+-rw-r--r--   0        0        0     3504 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/CHANGELOG.md
+-rw-r--r--   0        0        0     3143 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/codegen/README.md
+-rw-r--r--   0        0        0      492 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/__init__.py
+-rw-r--r--   0        0        0     8866 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_common.py
+-rw-r--r--   0        0        0      117 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_constants.py
+-rw-r--r--   0        0        0     5463 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_http_requests.py
+-rw-r--r--   0        0        0     5324 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_root.py
+-rw-r--r--   0        0        0     6459 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/exceptions.py
+-rw-r--r--   0        0        0      740 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/rest.py
+-rw-r--r--   0        0        0       95 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/version.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/__init__.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/pydantic_compatibility.py
+-rw-r--r--   0        0        0     1035 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/snowapi_parameters.py
+-rw-r--r--   0        0        0     4197 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/telemetry.py
+-rw-r--r--   0        0        0     3794 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/__init__.py
+-rw-r--r--   0        0        0     9003 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/executor.py
+-rw-r--r--   0        0        0     3286 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/rest_errors.py
+-rw-r--r--   0        0        0     7859 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/snow_bridge.py
+-rw-r--r--   0        0        0      283 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/snow_execute.py
+-rw-r--r--   0        0        0     1728 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/snow_request.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/__init__.py
+-rw-r--r--   0        0        0     8714 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/computepools_resource.py
+-rw-r--r--   0        0        0    16158 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/database_resource.py
+-rw-r--r--   0        0        0     5458 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py
+-rw-r--r--   0        0        0     1128 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/resource_base.py
+-rw-r--r--   0        0        0    13830 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/schema_resource.py
+-rw-r--r--   0        0        0    10828 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/services_resource.py
+-rw-r--r--   0        0        0    40719 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/table_resource.py
+-rw-r--r--   0        0        0    28172 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/task_resource.py
+-rw-r--r--   0        0        0    14109 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py
+-rw-r--r--   0        0        0      927 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/__init__.py
+-rw-r--r--   0        0        0     4287 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_compute_pool.py
+-rw-r--r--   0        0        0     1036 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/__init__.py
+-rw-r--r--   0        0        0    39373 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/api_response.py
+-rw-r--r--   0        0        0    13419 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/paging.py
+-rw-r--r--   0        0        0    23736 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/rest.py
+-rw-r--r--   0        0        0      211 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/api/__init__.py
+-rw-r--r--   0        0        0    58309 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py
+-rw-r--r--   0        0        0      805 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/models/__init__.py
+-rw-r--r--   0        0        0     8007 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/models/compute_pool.py
+-rw-r--r--   0        0        0     3619 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/models/error_response.py
+-rw-r--r--   0        0        0     2826 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/models/success_response.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/__init__.py
+-rw-r--r--   0        0        0      533 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/__init__.py
+-rw-r--r--   0        0        0     2202 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_search_service.py
+-rw-r--r--   0        0        0     1021 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/__init__.py
+-rw-r--r--   0        0        0    39349 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/api_response.py
+-rw-r--r--   0        0        0    13272 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/paging.py
+-rw-r--r--   0        0        0      444 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/pydantic_compatibility.py
+-rw-r--r--   0        0        0    23652 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/rest.py
+-rw-r--r--   0        0        0      245 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/api/__init__.py
+-rw-r--r--   0        0        0    14174 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/api/cortex_search_service_api.py
+-rw-r--r--   0        0        0      745 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3535 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/error_response.py
+-rw-r--r--   0        0        0     3477 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/query_request.py
+-rw-r--r--   0        0        0     3005 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/query_response.py
+-rw-r--r--   0        0        0      214 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/__init__.py
+-rw-r--r--   0        0        0    10340 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_database.py
+-rw-r--r--   0        0        0     1544 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/__init__.py
+-rw-r--r--   0        0        0    39340 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/api_response.py
+-rw-r--r--   0        0        0    13409 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/paging.py
+-rw-r--r--   0        0        0    23735 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/rest.py
+-rw-r--r--   0        0        0      197 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/api/__init__.py
+-rw-r--r--   0        0        0   117332 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/api/database_api.py
+-rw-r--r--   0        0        0     1476 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/__init__.py
+-rw-r--r--   0        0        0     2948 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/account_identifiers.py
+-rw-r--r--   0        0        0    10978 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/database.py
+-rw-r--r--   0        0        0    11765 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/database_clone.py
+-rw-r--r--   0        0        0     3618 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/error_response.py
+-rw-r--r--   0        0        0     4822 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time.py
+-rw-r--r--   0        0        0     3564 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time_offset.py
+-rw-r--r--   0        0        0     3645 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time_statement.py
+-rw-r--r--   0        0        0     3645 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py
+-rw-r--r--   0        0        0     2825 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/success_response.py
+-rw-r--r--   0        0        0      290 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/__init__.py
+-rw-r--r--   0        0        0     5937 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_function.py
+-rw-r--r--   0        0        0      243 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_utils.py
+-rw-r--r--   0        0        0     1260 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/__init__.py
+-rw-r--r--   0        0        0    39323 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/api_response.py
+-rw-r--r--   0        0        0    13391 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/paging.py
+-rw-r--r--   0        0        0    23718 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/rest.py
+-rw-r--r--   0        0        0      197 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/api/__init__.py
+-rw-r--r--   0        0        0    55455 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/api/function_api.py
+-rw-r--r--   0        0        0     1123 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3601 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/error_response.py
+-rw-r--r--   0        0        0     6703 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/function.py
+-rw-r--r--   0        0        0     3920 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/function_argument.py
+-rw-r--r--   0        0        0     6374 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/service_function.py
+-rw-r--r--   0        0        0     3654 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/success_accepted_response.py
+-rw-r--r--   0        0        0     2808 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/success_response.py
+-rw-r--r--   0        0        0      620 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/__init__.py
+-rw-r--r--   0        0        0     1613 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_grant.py
+-rw-r--r--   0        0        0     1360 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_grantee.py
+-rw-r--r--   0        0        0     1722 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_grants.py
+-rw-r--r--   0        0        0      461 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_privileges.py
+-rw-r--r--   0        0        0     1325 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_securables.py
+-rw-r--r--   0        0        0      976 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/__init__.py
+-rw-r--r--   0        0        0    39293 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/api_response.py
+-rw-r--r--   0        0        0    13414 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/paging.py
+-rw-r--r--   0        0        0    23744 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/rest.py
+-rw-r--r--   0        0        0      185 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/api/__init__.py
+-rw-r--r--   0        0        0    89825 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/api/grant_api.py
+-rw-r--r--   0        0        0      773 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3627 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/models/error_response.py
+-rw-r--r--   0        0        0     5589 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/models/grant.py
+-rw-r--r--   0        0        0     2834 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/grant/_generated/models/success_response.py
+-rw-r--r--   0        0        0      893 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/__init__.py
+-rw-r--r--   0        0        0     4392 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_image_repository.py
+-rw-r--r--   0        0        0     1232 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/__init__.py
+-rw-r--r--   0        0        0    39416 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/api_response.py
+-rw-r--r--   0        0        0    13448 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/paging.py
+-rw-r--r--   0        0        0    23758 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/rest.py
+-rw-r--r--   0        0        0      227 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/api/__init__.py
+-rw-r--r--   0        0        0    55868 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/api/image_repository_api.py
+-rw-r--r--   0        0        0     1026 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3641 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/error_response.py
+-rw-r--r--   0        0        0     6203 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/image_repository.py
+-rw-r--r--   0        0        0     3173 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/list_images_in_repository200_response.py
+-rw-r--r--   0        0        0     2848 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/success_response.py
+-rw-r--r--   0        0        0      400 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/__init__.py
+-rw-r--r--   0        0        0     4611 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_role.py
+-rw-r--r--   0        0        0      947 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/__init__.py
+-rw-r--r--   0        0        0    39266 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/api_response.py
+-rw-r--r--   0        0        0    13394 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/paging.py
+-rw-r--r--   0        0        0    23725 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/rest.py
+-rw-r--r--   0        0        0      181 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/api/__init__.py
+-rw-r--r--   0        0        0    31316 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/api/role_api.py
+-rw-r--r--   0        0        0      748 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3608 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/models/error_response.py
+-rw-r--r--   0        0        0     5768 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/models/role.py
+-rw-r--r--   0        0        0     2815 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/role/_generated/models/success_response.py
+-rw-r--r--   0        0        0      194 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/__init__.py
+-rw-r--r--   0        0        0     7003 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_schema.py
+-rw-r--r--   0        0        0     1412 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/__init__.py
+-rw-r--r--   0        0        0    39276 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/api_response.py
+-rw-r--r--   0        0        0    13389 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/paging.py
+-rw-r--r--   0        0        0    23719 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/rest.py
+-rw-r--r--   0        0        0      189 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/api/__init__.py
+-rw-r--r--   0        0        0    72879 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/api/schema_api.py
+-rw-r--r--   0        0        0     1329 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3602 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/error_response.py
+-rw-r--r--   0        0        0    11272 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/model_schema.py
+-rw-r--r--   0        0        0     4800 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time.py
+-rw-r--r--   0        0        0     3544 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time_offset.py
+-rw-r--r--   0        0        0     3625 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time_statement.py
+-rw-r--r--   0        0        0     3625 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py
+-rw-r--r--   0        0        0    11975 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/schema_clone.py
+-rw-r--r--   0        0        0     2809 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/success_response.py
+-rw-r--r--   0        0        0     1397 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/__init__.py
+-rw-r--r--   0        0        0     7635 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_service.py
+-rw-r--r--   0        0        0     1588 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/__init__.py
+-rw-r--r--   0        0        0    39343 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/api_response.py
+-rw-r--r--   0        0        0    13419 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/paging.py
+-rw-r--r--   0        0        0    23746 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/rest.py
+-rw-r--r--   0        0        0      193 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/api/__init__.py
+-rw-r--r--   0        0        0    97308 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/api/service_api.py
+-rw-r--r--   0        0        0     1548 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3629 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/error_response.py
+-rw-r--r--   0        0        0     3325 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py
+-rw-r--r--   0        0        0     3383 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py
+-rw-r--r--   0        0        0    10218 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service.py
+-rw-r--r--   0        0        0     3907 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_endpoint.py
+-rw-r--r--   0        0        0     4492 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_spec.py
+-rw-r--r--   0        0        0     3304 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_spec_inline_text.py
+-rw-r--r--   0        0        0     3510 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_spec_stage_file.py
+-rw-r--r--   0        0        0     2836 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/success_response.py
+-rw-r--r--   0        0        0      111 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/__init__.py
+-rw-r--r--   0        0        0     1382 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_session.py
+-rw-r--r--   0        0        0     1294 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/__init__.py
+-rw-r--r--   0        0        0    39290 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/api_response.py
+-rw-r--r--   0        0        0    13440 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/paging.py
+-rw-r--r--   0        0        0    23693 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/rest.py
+-rw-r--r--   0        0        0      193 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/api/__init__.py
+-rw-r--r--   0        0        0    73901 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/api/session_api.py
+-rw-r--r--   0        0        0     1177 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/__init__.py
+-rw-r--r--   0        0        0     2823 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/create_session_request.py
+-rw-r--r--   0        0        0     4860 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/create_session_response.py
+-rw-r--r--   0        0        0     3130 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/current_secondary_roles.py
+-rw-r--r--   0        0        0     2871 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/default_result.py
+-rw-r--r--   0        0        0     3576 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/error_response.py
+-rw-r--r--   0        0        0     2674 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/named_default.py
+-rw-r--r--   0        0        0     4145 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/parameter.py
+-rw-r--r--   0        0        0     2697 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/secondary_roles.py
+-rw-r--r--   0        0        0     2783 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/success_response.py
+-rw-r--r--   0        0        0     2747 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/token_request.py
+-rw-r--r--   0        0        0      988 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/__init__.py
+-rw-r--r--   0        0        0    10048 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_stage.py
+-rw-r--r--   0        0        0     1751 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/__init__.py
+-rw-r--r--   0        0        0    39287 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/api_response.py
+-rw-r--r--   0        0        0    13406 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/paging.py
+-rw-r--r--   0        0        0    23738 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/rest.py
+-rw-r--r--   0        0        0      185 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/api/__init__.py
+-rw-r--r--   0        0        0    67144 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/api/stage_api.py
+-rw-r--r--   0        0        0     1766 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/__init__.py
+-rw-r--r--   0        0        0     4112 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/aws_credentials.py
+-rw-r--r--   0        0        0     3349 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/azure_credentials.py
+-rw-r--r--   0        0        0     4427 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/credentials.py
+-rw-r--r--   0        0        0     3621 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/error_response.py
+-rw-r--r--   0        0        0     4036 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/file_transfer_material.py
+-rw-r--r--   0        0        0     3598 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/presigned_url_request.py
+-rw-r--r--   0        0        0    10530 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/stage.py
+-rw-r--r--   0        0        0     4339 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/stage_directory_table.py
+-rw-r--r--   0        0        0     3792 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/stage_encryption.py
+-rw-r--r--   0        0        0     3610 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/stage_file.py
+-rw-r--r--   0        0        0     3674 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/success_accepted_response.py
+-rw-r--r--   0        0        0     2828 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/success_response.py
+-rw-r--r--   0        0        0      347 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/__init__.py
+-rw-r--r--   0        0        0    10156 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_table.py
+-rw-r--r--   0        0        0     1772 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/__init__.py
+-rw-r--r--   0        0        0    39287 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/api_response.py
+-rw-r--r--   0        0        0    13408 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/paging.py
+-rw-r--r--   0        0        0    23738 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/rest.py
+-rw-r--r--   0        0        0      185 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/api/__init__.py
+-rw-r--r--   0        0        0   156971 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/api/table_api.py
+-rw-r--r--   0        0        0     1777 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/__init__.py
+-rw-r--r--   0        0        0     4858 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/constraint.py
+-rw-r--r--   0        0        0     3621 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/error_response.py
+-rw-r--r--   0        0        0     4143 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/foreign_key.py
+-rw-r--r--   0        0        0     4816 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time.py
+-rw-r--r--   0        0        0     3561 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time_offset.py
+-rw-r--r--   0        0        0     3642 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time_statement.py
+-rw-r--r--   0        0        0     3642 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time_timestamp.py
+-rw-r--r--   0        0        0     3411 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/primary_key.py
+-rw-r--r--   0        0        0     2828 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/success_response.py
+-rw-r--r--   0        0        0    12942 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/table.py
+-rw-r--r--   0        0        0    13723 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/table_clone.py
+-rw-r--r--   0        0        0     6445 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/table_column.py
+-rw-r--r--   0        0        0     3394 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/unique_key.py
+-rw-r--r--   0        0        0      925 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/__init__.py
+-rw-r--r--   0        0        0    31071 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_task.py
+-rw-r--r--   0        0        0     8563 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/context.py
+-rw-r--r--   0        0        0    29468 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/dagv1.py
+-rw-r--r--   0        0        0     1261 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/__init__.py
+-rw-r--r--   0        0        0    39276 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/api_response.py
+-rw-r--r--   0        0        0    13401 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/paging.py
+-rw-r--r--   0        0        0    23735 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/rest.py
+-rw-r--r--   0        0        0      181 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/api/__init__.py
+-rw-r--r--   0        0        0   118397 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/api/task_api.py
+-rw-r--r--   0        0        0     1140 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3395 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/cron_schedule.py
+-rw-r--r--   0        0        0     3618 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/error_response.py
+-rw-r--r--   0        0        0     3209 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/minutes_schedule.py
+-rw-r--r--   0        0        0     2825 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/success_response.py
+-rw-r--r--   0        0        0    12421 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/task.py
+-rw-r--r--   0        0        0     8014 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/task_run.py
+-rw-r--r--   0        0        0     4376 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/task_schedule.py
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/task/_internal/__init__.py
+-rw-r--r--   0        0        0      380 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/__init__.py
+-rw-r--r--   0        0        0     4648 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_user.py
+-rw-r--r--   0        0        0      947 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/__init__.py
+-rw-r--r--   0        0        0    39266 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/api_response.py
+-rw-r--r--   0        0        0    13394 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/paging.py
+-rw-r--r--   0        0        0    23725 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/rest.py
+-rw-r--r--   0        0        0      181 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/api/__init__.py
+-rw-r--r--   0        0        0    37552 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/api/user_api.py
+-rw-r--r--   0        0        0      748 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3608 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/models/error_response.py
+-rw-r--r--   0        0        0     2815 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/models/success_response.py
+-rw-r--r--   0        0        0    16604 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/user/_generated/models/user.py
+-rw-r--r--   0        0        0      307 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/__init__.py
+-rw-r--r--   0        0        0     8547 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_warehouse.py
+-rw-r--r--   0        0        0     1001 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/__init__.py
+-rw-r--r--   0        0        0    39342 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/api_client.py
+-rw-r--r--   0        0        0      990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/api_response.py
+-rw-r--r--   0        0        0    13405 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/configuration.py
+-rw-r--r--   0        0        0     1663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/paging.py
+-rw-r--r--   0        0        0    23729 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/rest.py
+-rw-r--r--   0        0        0      201 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/api/__init__.py
+-rw-r--r--   0        0        0    83941 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/api/warehouse_api.py
+-rw-r--r--   0        0        0      782 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/models/__init__.py
+-rw-r--r--   0        0        0     3612 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/models/error_response.py
+-rw-r--r--   0        0        0     2819 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/models/success_response.py
+-rw-r--r--   0        0        0    17008 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/models/warehouse.py
+-rw-r--r--   0        0        0       15 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/.gitignore
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/__init__.py
+-rw-r--r--   0        0        0      138 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/conftest.py
+-rw-r--r--   0        0        0      660 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/__init__.py
+-rw-r--r--   0        0        0    17177 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/conftest.py
+-rw-r--r--   0        0        0     2365 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/setup_manually.py
+-rw-r--r--   0        0        0     2158 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/test_cortex_search_service.py
+-rw-r--r--   0        0        0      381 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/test_root.py
+-rw-r--r--   0        0        0      911 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/utils.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/compute_pool/__init__.py
+-rw-r--r--   0        0        0     1795 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/compute_pool/test_create_compute_pool.py
+-rw-r--r--   0        0        0      743 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/compute_pool/test_delete_compute_pool.py
+-rw-r--r--   0        0        0     1422 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/compute_pool/test_fetch_compute_pool.py
+-rw-r--r--   0        0        0     1335 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/compute_pool/test_list_compute_pool.py
+-rw-r--r--   0        0        0      923 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/compute_pool/test_resume_suspend_compute_pool.py
+-rw-r--r--   0        0        0     1221 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/compute_pool/test_stop_all_services_on_compute_pool.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/__init__.py
+-rw-r--r--   0        0        0      618 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/conftest.py
+-rw-r--r--   0        0        0     4329 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/test_create_database.py
+-rw-r--r--   0        0        0     2827 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/test_create_or_update_database.py
+-rw-r--r--   0        0        0      720 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/test_delete_database.py
+-rw-r--r--   0        0        0     1108 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/test_fetch_database.py
+-rw-r--r--   0        0        0     3996 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/test_iter_database.py
+-rw-r--r--   0        0        0      711 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/database/test_setup_database.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/function/__init__.py
+-rw-r--r--   0        0        0     1880 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/function/conftest.py
+-rw-r--r--   0        0        0     1480 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/function/test_create_and_fetch_function.py
+-rw-r--r--   0        0        0      950 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/function/test_delete_functions.py
+-rw-r--r--   0        0        0     1012 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/function/test_execute_function.py
+-rw-r--r--   0        0        0     2177 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/function/test_function_in_demo.py
+-rw-r--r--   0        0        0     1297 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/function/test_iter_functions.py
+-rw-r--r--   0        0        0     1556 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/image_repository/test_create_image_repository.py
+-rw-r--r--   0        0        0      762 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/image_repository/test_delete_image_respository.py
+-rw-r--r--   0        0        0      445 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/image_repository/test_fetch_image_repository.py
+-rw-r--r--   0        0        0     1835 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/image_repository/test_iter_image_repository.py
+-rw-r--r--   0        0        0     3028 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/rbac/test_grant.py
+-rw-r--r--   0        0        0     1482 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/role/test_iter_role.py
+-rw-r--r--   0        0        0     1777 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/role/test_role.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/schema/__init__.py
+-rw-r--r--   0        0        0     3804 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/schema/test_create_or_update_schema.py
+-rw-r--r--   0        0        0     3980 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/schema/test_create_schema.py
+-rw-r--r--   0        0        0      716 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/schema/test_delete_schema.py
+-rw-r--r--   0        0        0      544 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/schema/test_fetch_schema.py
+-rw-r--r--   0        0        0     3663 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/schema/test_iter_schema.py
+-rw-r--r--   0        0        0     3937 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/service/test_create_service.py
+-rw-r--r--   0        0        0     1472 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/service/test_delete_service.py
+-rw-r--r--   0        0        0     2945 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/service/test_fetch_service.py
+-rw-r--r--   0        0        0      501 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/service/test_get_endpoints_service.py
+-rw-r--r--   0        0        0     2164 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/service/test_iter_service.py
+-rw-r--r--   0        0        0     2226 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/service/test_suspend_resume_service.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/stage/__init__.py
+-rw-r--r--   0        0        0     1336 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/stage/conftest.py
+-rw-r--r--   0        0        0     1890 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/stage/test_create_stage.py
+-rw-r--r--   0        0        0      697 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/stage/test_delete_stage.py
+-rw-r--r--   0        0        0      500 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/stage/test_fetch_stage.py
+-rw-r--r--   0        0        0     1135 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/stage/test_files_stage.py
+-rw-r--r--   0        0        0      922 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/stage/test_iter_stage.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/__init__.py
+-rw-r--r--   0        0        0     6835 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/conftest.py
+-rw-r--r--   0        0        0     4368 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/test_create_or_update_table.py
+-rw-r--r--   0        0        0     5118 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/test_create_table.py
+-rw-r--r--   0        0        0      434 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/test_delete_and_undelete_table.py
+-rw-r--r--   0        0        0      346 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/test_fetch_table.py
+-rw-r--r--   0        0        0     3072 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/test_iter_table.py
+-rw-r--r--   0        0        0      236 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/test_resume_and_suspend_table.py
+-rw-r--r--   0        0        0     1314 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/table/test_swap_table.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/__init__.py
+-rw-r--r--   0        0        0      568 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/conftest.py
+-rw-r--r--   0        0        0     7767 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_create_or_update_task.py
+-rw-r--r--   0        0        0     9724 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_create_task.py
+-rw-r--r--   0        0        0     1580 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_drop_task.py
+-rw-r--r--   0        0        0     1608 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_execute_task.py
+-rw-r--r--   0        0        0     4397 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_load_task.py
+-rw-r--r--   0        0        0    10923 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_python_function.py
+-rw-r--r--   0        0        0     3154 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_show_task.py
+-rw-r--r--   0        0        0     1396 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/test_task_parameters.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/dag/__init__.py
+-rw-r--r--   0        0        0    25597 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/task/dag/test_dag.py
+-rw-r--r--   0        0        0     1711 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/user/test_create_user.py
+-rw-r--r--   0        0        0      876 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/user/test_delete_user.py
+-rw-r--r--   0        0        0      831 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/user/test_fetch_user.py
+-rw-r--r--   0        0        0     2306 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/user/test_iter_user.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/__init__.py
+-rw-r--r--   0        0        0      961 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_abort_all_queries_warehouse.py
+-rw-r--r--   0        0        0     6121 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_create_or_update_warehouse.py
+-rw-r--r--   0        0        0     2154 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_create_warehouse.py
+-rw-r--r--   0        0        0     1158 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_delete_warehouse.py
+-rw-r--r--   0        0        0     1667 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_fetch_warehouse.py
+-rw-r--r--   0        0        0     1585 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_iter_warehouse.py
+-rw-r--r--   0        0        0     1342 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_rename_warehouse.py
+-rw-r--r--   0        0        0     1874 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/integ/warehouse/test_suspend_and_resume_warehouse.py
+-rw-r--r--   0        0        0      365 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/resources/fake_spec_single_container.yaml
+-rw-r--r--   0        0        0    22807 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/resources/schema.yaml
+-rw-r--r--   0        0        0       34 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/resources/testCSVheader.csv
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/__init__.py
+-rw-r--r--   0        0        0     2349 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/conftest.py
+-rw-r--r--   0        0        0     2350 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/test_common.py
+-rw-r--r--   0        0        0     8851 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/test_database.py
+-rw-r--r--   0        0        0     2381 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/test_schema.py
+-rw-r--r--   0        0        0     6199 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/test_table.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/api/__init__.py
+-rw-r--r--   0        0        0     4214 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/api/general_api_test.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/bridge/__init__.py
+-rw-r--r--   0        0        0     7517 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/bridge/test_database.py
+-rw-r--r--   0        0        0     7104 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/bridge/test_executor.py
+-rw-r--r--   0        0        0     1803 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/bridge/test_rest_errors.py
+-rw-r--r--   0        0        0     4838 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/bridge/test_schema.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/resources/__init__.py
+-rw-r--r--   0        0        0     1141 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/resources/test_computepool_resource.py
+-rw-r--r--   0        0        0     2990 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/resources/test_service.py
+-rw-r--r--   0        0        0     1431 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/resources/test_task_resource.py
+-rw-r--r--   0        0        0       76 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/task/__init__.py
+-rw-r--r--   0        0        0     1875 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/task/test_dagv1.py
+-rw-r--r--   0        0        0     4427 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/task/test_task_context.py
+-rw-r--r--   0        0        0      710 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/tests/unit/task/test_task_reference.py
+-rw-r--r--   0        0        0     1315 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/.gitignore
+-rw-r--r--   0        0        0    11339 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/LICENSE
+-rw-r--r--   0        0        0      405 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/README.md
+-rw-r--r--   0        0        0     4350 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/pyproject.toml
+-rw-r--r--   0        0        0     1803 2020-02-02 00:00:00.000000 snowflake_core-0.8.1/PKG-INFO
```

### Comparing `snowflake_core-0.8.0/CHANGELOG.md` & `snowflake_core-0.8.1/CHANGELOG.md`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,21 @@
 # Release History
 
+## 0.8.1 (2024-05-31)
+
+### New features
+* `with_managed_access` is now an available boolean option in `create_or_update` for `SchemaResource`. This is equivalent to the [WITH MANAGED ACCESS](https://docs.snowflake.com/en/sql-reference/sql/create-schema#optional-parameters) clause in `CREATE SCHEMA`.
+
+    Usage example:
+
+    ```schema.create_or_update(schema_def, with_managed_access = True)```
+
+* Added a `get_endpoints` method for `Service` resources that returns a list of endpoints for a given `Service`.
+
+
 ## 0.8.0 (2024-04-30)
 
 ### Breaking changes
 * The `deep` parameter is removed from `fetch()` on `TableResource` objects. `fetch()` will always return detailed columns and constraints information of a `TableResource`.
 * `create_or_update()` for `Schema`, `Warehouse`, `Database`, `Compute Pool`, resources will (for the time being) not work. `create()` on these resources will still work.  
 * Creating tables using `as_select` will no longer carry over information from any source tables used in the `as_select` query.
 * `data_retention_time_in_days` and `max_data_extension_time_in_days` properties will be inherited from schema or database settings when not explicitly set in a `create_or_update` statement that alters an existing table.
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_common.py` & `snowflake_core-0.8.1/src/snowflake/core/_common.py`

 * *Files 2% similar despite different names*

```diff
@@ -38,18 +38,15 @@
     from snowflake.core.schema import SchemaResource
 
 from snowflake.snowpark import Session
 
 
 T = TypeVar("T")
 
-UNALTERABLE_PARAMETERS = {
-    "name",
-    "tag"
-}
+UNALTERABLE_PARAMETERS = {"name", "tag"}
 
 
 def check_env_parameter_enabled(param: str, default: str = "False") -> bool:
     return os.getenv(
         param,
         default,
     ).lower() in (
@@ -57,39 +54,36 @@
         "t",
         "yes",
         "y",
         "on",
     )
 
 
-def _is_an_update(parameters: Iterable[str]) -> bool:
+def _is_an_update(parameters: Iterable[str], alterable_parameters: Iterable[str]) -> bool:
     """Decide whether the parameters contain update-relevant values.
 
     Parameters:
         parameters: an iterable of parameters in the request
     """
-    return len(set(parameters) - UNALTERABLE_PARAMETERS) > 0
+    return len(set(parameters).intersection(alterable_parameters)) > 0
 
 
 @public
 class ObjectCollectionBC(ABC):
     @property
     @abstractmethod
-    def _session(self) -> Session:
-        ...
+    def _session(self) -> Session: ...
 
     @property
     @abstractmethod
-    def _connection(self) -> SnowflakeConnection:
-        ...
+    def _connection(self) -> SnowflakeConnection: ...
 
     @property
     @abstractmethod
-    def root(self) -> "Root":
-        ...
+    def root(self) -> "Root": ...
 
 
 @public
 class ObjectCollection(ObjectCollectionBC, Generic[T]):
     def __init__(self, ref_class: Type[T]) -> None:
         self._items: Dict[str, T] = {}
         self._ref_class = ref_class
@@ -158,44 +152,37 @@
     def root(self) -> "Root":
         return self.database.collection.root
 
 
 @public
 class ObjectReferenceProtocol(Protocol[T]):
     @property
-    def collection(self) -> ObjectCollection[T]:
-        ...
+    def collection(self) -> ObjectCollection[T]: ...
 
     @property
-    def root(self) -> "Root":
-        ...
+    def root(self) -> "Root": ...
 
 
 @public
 class SchemaObjectReferenceProtocol(Protocol[T]):
     @property
-    def collection(self) -> SchemaObjectCollectionParent[T]:
-        ...
+    def collection(self) -> SchemaObjectCollectionParent[T]: ...
 
     @property
-    def name(self) -> str:
-        ...
+    def name(self) -> str: ...
 
     @property
-    def database(self) -> "DatabaseResource":
-        ...
+    def database(self) -> "DatabaseResource": ...
 
     @property
-    def schema(self) -> "SchemaResource":
-        ...
+    def schema(self) -> "SchemaResource": ...
 
 
 @public
 class ObjectReferenceMixin(Generic[T]):
-
     # Default on/off switch for whether a resource supports the rest API
     _supports_rest_api = False
 
     @property
     def _session(self: ObjectReferenceProtocol[T]) -> Session:
         return self.collection._session
 
@@ -206,15 +193,14 @@
     @property
     def root(self: ObjectReferenceProtocol[T]) -> "Root":
         return self.collection.root
 
 
 @public
 class SchemaObjectReferenceMixin(Generic[T], ObjectReferenceMixin[SchemaObjectCollectionParent[T]]):
-
     @property
     def schema(self: SchemaObjectReferenceProtocol[T]) -> "SchemaResource":
         return self.collection.schema
 
     @property
     def database(self: SchemaObjectReferenceProtocol[T]) -> "DatabaseResource":
         return self.collection.schema.database
@@ -227,14 +213,15 @@
 class CaseInsensitiveEnumMeta(EnumMeta):
     def __init__(cls, *args, **kws) -> None:  # type: ignore
         super().__init__(*args, **kws)
 
         class lookup(dict):  # type: ignore
             def get(self, key, default=None):  # type: ignore
                 return super().get(key.lower(), key.lower())
+
         cls._legacy_mode_map_ = lookup({item.value.lower(): item.name for item in cls})  # type: ignore
 
     def __getitem__(cls, name: str) -> Any:
         converted_name = cls._legacy_mode_map_.get(name)
         return super().__getitem__(converted_name)
 
 
@@ -249,29 +236,28 @@
     source: Annotated[str, StringConstraints(strict=True)] = Field(...)
     point_of_time: Optional["PointOfTime"] = None
 
 
 class PointOfTime(BaseModel):
     point_of_time_type: Annotated[str, StringConstraints(strict=True)] = Field(...)
     reference: Annotated[str, StringConstraints(strict=True)] = Field(
-        ...,
-        description="The relation to the point of time. At the time of writing at and before are supported."
-        )
+        ..., description="The relation to the point of time. At the time of writing at and before are supported."
+    )
     when: Annotated[
         str,
         StringConstraints(strict=True),
     ] = Field(..., description="The actual description of the point of time.")
     __properties = ["point_of_time_type", "reference", "when"]
 
     __discriminator_property_name = "point_of_time_type"
 
     __discriminator_value_class_map = {
-        'offset': 'PointOfTimeOffset',
-        'statement': 'PointOfTimeStatement',
-        'timestamp': 'PointOfTimeTimestamp'
+        "offset": "PointOfTimeOffset",
+        "statement": "PointOfTimeStatement",
+        "timestamp": "PointOfTimeTimestamp",
     }
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_dict(self) -> Dict[str, str]:
@@ -289,29 +275,30 @@
         discriminator = cls.__discriminator_value_class_map.get(discriminator_name)
         assert discriminator is not None
         return discriminator
 
     @classmethod
     def from_dict(
         cls,
-        obj: Dict[
-            str,
-            Optional[str]],
+        obj: Dict[str, Optional[str]],
     ) -> Union[
         "PointOfTimeOffset",
         "PointOfTimeStatement",
         "PointOfTimeTimestamp",
     ]:
         """Create an instance of PointOfTime from a dict."""
         object_type = cls.get_discriminator_value(obj)
         if not object_type:
             raise ValueError(
-                "PointOfTime failed to lookup discriminator value from " +
-                json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
-                ", mapping: " + json.dumps(cls.__discriminator_value_class_map)
+                "PointOfTime failed to lookup discriminator value from "
+                + json.dumps(obj)
+                + ". Discriminator property name: "
+                + cls.__discriminator_property_name
+                + ", mapping: "
+                + json.dumps(cls.__discriminator_value_class_map)
             )
         return getattr(sys.modules[__name__], object_type).from_dict(obj)
 
 
 class PointOfTimeOffset(PointOfTime):
     point_of_time_type: Annotated[str, StringConstraints(strict=True)] = "offset"
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_http_requests.py` & `snowflake_core-0.8.1/src/snowflake/core/_http_requests.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_root.py` & `snowflake_core-0.8.1/src/snowflake/core/_root.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,15 +5,18 @@
 from snowflake.snowpark.session import Session, _active_sessions
 
 from ._common import check_env_parameter_enabled
 from ._internal.snowapi_parameters import SnowApiParameters
 from ._internal.telemetry import ApiTelemetryClient
 from .compute_pool import ComputePoolCollection
 from .database import DatabaseCollection
+from .grant._grants import Grants
+from .role import RoleCollection
 from .session import SnowAPISession
+from .user import UserCollection
 from .warehouse import WarehouseCollection
 
 
 class Root:
     """The entry point of the Snowflake Core Python APIs that manage the Snowflake objects.
 
     Args:
@@ -70,14 +73,17 @@
         self._snowapi_session = SnowAPISession(self)
         self._refresh_parameters()
 
         self._databases = DatabaseCollection(self)
         self._compute_pools = ComputePoolCollection(self)
         self._telemetry_client = ApiTelemetryClient(self._connection)
         self._warehouses = WarehouseCollection(self)
+        self._roles = RoleCollection(self)
+        self._grants = Grants(self)
+        self._users = UserCollection(self)
         self._can_use_rest_api = check_env_parameter_enabled(
             "_SNOWFLAKE_CAN_USE_REST_API",
             "True"
         )
         self._enable_long_running_polling = check_env_parameter_enabled(
             "_SNOWFLAKE_ENABLE_LONG_RUNNING_POLLING"
         )
@@ -115,14 +121,26 @@
         return self._compute_pools
 
     @property
     def warehouses(self) -> WarehouseCollection:
         return self._warehouses
 
     @property
+    def roles(self) -> RoleCollection:
+        return self._roles
+
+    @property
+    def grants(self) -> Grants:
+        return self._grants
+
+    @property
+    def users(self) -> UserCollection:
+        return self._users
+
+    @property
     def _session_token(self) -> Optional[str]:
         # TODO: this needs to be fixed in the connector
         return self._connection.rest.token  # type: ignore[union-attr]
 
     @property
     def _master_token(self) -> Optional[str]:
         # TODO: this needs to be fixed in the connector
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/exceptions.py` & `snowflake_core-0.8.1/src/snowflake/core/exceptions.py`

 * *Files 4% similar despite different names*

```diff
@@ -203,7 +203,29 @@
     def __init__(
         self,
         reason: typing.Optional[str] = None
     ) -> None:
         super().__init__(reason)
         self.reason = reason
 
+
+@public
+class FunctionArgsInvalid(Exception):
+    """Raised when function args are invalid."""
+
+    def __init__(
+        self,
+        reason: typing.Optional[str] = None
+    ) -> None:
+        super().__init__(reason)
+        self.reason = reason
+
+@public
+class FunctionResultInvalid(Exception):
+    """Raised when function result is invalid."""
+
+    def __init__(
+        self,
+        reason: typing.Optional[str] = None
+    ) -> None:
+        super().__init__(reason)
+        self.reason = reason
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/rest.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/snowapi_parameters.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/snowapi_parameters.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/telemetry.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/telemetry.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/utils.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,27 +14,27 @@
 EMPTY_STRING = ""
 DOUBLE_QUOTE = '"'
 ALREADY_QUOTED = compile('^(".+")$')
 UNQUOTED_CASE_INSENSITIVE = compile("^([_A-Za-z]+[_A-Za-z0-9$]*)$")
 # https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html
 SNOWFLAKE_UNQUOTED_ID_PATTERN = r"([a-zA-Z_][\w\$]{0,255})"
 SNOWFLAKE_QUOTED_ID_PATTERN = '("([^"]|""){1,255}")'
-SNOWFLAKE_ID_PATTERN = (
-    f"({SNOWFLAKE_UNQUOTED_ID_PATTERN}|{SNOWFLAKE_QUOTED_ID_PATTERN})"
-)
+SNOWFLAKE_ID_PATTERN = f"({SNOWFLAKE_UNQUOTED_ID_PATTERN}|{SNOWFLAKE_QUOTED_ID_PATTERN})"
 SNOWFLAKE_OBJECT_RE_PATTERN = compile(
     f"^(({SNOWFLAKE_ID_PATTERN}\\.){{0,2}}|({SNOWFLAKE_ID_PATTERN}\\.\\.)){SNOWFLAKE_ID_PATTERN}$"
 )
 
+
 class ApiClientType(Enum):
     NONE = 0
     BRIDGE = 1
     REST = 2
     STORED_PROC = 3
 
+
 def validate_object_name(name: str) -> None:
     if not SNOWFLAKE_OBJECT_RE_PATTERN.match(name):
         raise ValueError(f"The object name '{name}' is invalid.")
 
 
 def is_running_inside_stored_procedure() -> bool:
     """
@@ -44,16 +44,18 @@
         bool: True if snowpy is running inside a stored procedure, False otherwise.
     """
     return PLATFORM == "XP"
 
 
 def validate_quoted_name(name: str) -> str:
     if DOUBLE_QUOTE in name[1:-1].replace(DOUBLE_QUOTE + DOUBLE_QUOTE, EMPTY_STRING):
-        raise ValueError(f"Invalid Identifier {name}. "
-                         f"The inside double quotes need to be escaped when the name itself is double quoted.")
+        raise ValueError(
+            f"Invalid Identifier {name}. "
+            f"The inside double quotes need to be escaped when the name itself is double quoted."
+        )
     else:
         return name
 
 
 def escape_quotes(unescaped: str) -> str:
     return unescaped.replace(DOUBLE_QUOTE, DOUBLE_QUOTE + DOUBLE_QUOTE)
 
@@ -63,27 +65,31 @@
         return validate_quoted_name(name)
     elif UNQUOTED_CASE_INSENSITIVE.match(name):
         return escape_quotes(name.upper())
     else:
         return DOUBLE_QUOTE + escape_quotes(name) + DOUBLE_QUOTE
 
 
+def normalize_and_unquote_name(name: str) -> str:
+    return unquote_name(normalize_name(name))
+
+
 def unquote_name(name: str) -> str:
     if len(name) > 1 and name[0] == name[-1] == '"':
         return name[1:-1]
     return name
 
 
 def try_single_quote_value(value: Any) -> str:
     """Single quote the value if the value is a string and not single quoted yet."""
     if value is None:
         return ""
     if not isinstance(value, str):
         return str(value)
-    if value[0] == "'" and value[-1] == "'": # quote wrapped the string
+    if value[0] == "'" and value[-1] == "'":  # quote wrapped the string
         value = "".join(list(value)[1:-1])
     return f"""'{value.replace("'", "''")}'"""
 
 
 def double_quote_name(name: str) -> str:
     return DOUBLE_QUOTE + escape_quotes(name) + DOUBLE_QUOTE if name else name
 
@@ -100,9 +106,9 @@
     elif datatype == "BOOLEAN":
         if value in (True, "true"):
             return True
         if value in ("", None):
             return None
         return False
     elif datatype == "STRING":
-        return value if value != '' else None
+        return value if value != "" else None
     raise ValueError(f"datatype {datatype} isn't processed.")
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/executor.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/executor.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/rest_errors.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/rest_errors.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_bridge.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/snow_bridge.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/snow_request.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/snow_request.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/computepools_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/computepools_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/database_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/database_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/imagerepo_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/resource_base.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/resource_base.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/schema_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/schema_resource.py`

 * *Files 2% similar despite different names*

```diff
@@ -138,14 +138,22 @@
         if self._schema_name != normalize_name(self._prop["name"]):
             raise BadRequest(f"Schema names are not consistent, {self._schema_name} != {self._prop['name']}.")
 
         try:
             _, db = self.desc_schema()
         except NotFound:
             return self.create_schema()
+
+        managed_access = self._query_params.get("with_managed_access")
+        if managed_access is not None:
+            self.snow_exec.execute(f"""
+                ALTER SCHEMA {self._db_name}.{self._schema_name} 
+                {"ENABLE" if managed_access else "DISABLE"} MANAGED ACCESS
+                """)
+
         coa_sql = [f"ALTER SCHEMA {self._db_name}.{self._schema_name} SET",]
         for prop in self._prop:
             prop_v = self._prop[prop]
             if prop_v == db.get(prop):
                 continue
             if prop == "name":
                 continue
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/services_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/services_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/table_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/table_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/task_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/task_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py` & `snowflake_core-0.8.1/src/snowflake/core/_internal/bridge/resources/warehouse_resource.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,31 +31,40 @@
             "enable_query_acceleration",
             "query_acceleration_max_scale_factor",
             "max_concurrency_level",
             "statement_queued_timeout_in_seconds",
             "statement_timeout_in_seconds",
         ],
         "alter_warehouse_option": [
-            # "wait_for_completion",
+            "warehouse_type",
+            "warehouse_size",
+            "wait_for_completion",
             "max_cluster_count",
             "min_cluster_count",
+            "scaling_policy",
             "auto_suspend",
             "auto_resume",
             # "resource_monitor",
             "comment",
             "enable_query_acceleration",
             # "query_acceleration_max_scale_factor",
             "max_concurrency_level",
             "statement_queued_timeout_in_seconds",
             "statement_timeout_in_seconds",
         ],
         "objectParameters": [
             "max_concurrency_level",
             "statement_queued_timeout_in_seconds",
             "statement_timeout_in_seconds",
+        ],
+        "unset_exceptions": [
+            "warehouse_size",
+            "scaling_policy",
+            "warehouse_type",
+            "wait_for_completion"
         ]
     }
     resource_name = "warehouses"
     warehouse_components = ["api", "v2", "warehouses", "warehouse-name"]
 
     def __init__(self, req: SnowRequest, conn_ob: SnowflakeConnection):
         super().__init__(conn_ob)
@@ -125,40 +134,40 @@
 
     def update_and_set_warehouse(self) -> tuple[str, Dict[str, Any]]:
         for key in WarehouseResource.warehouse_prop_list["required"]:
             if key not in self._prop:
                 raise BadRequest(f"{key} is a required field for Updating a Warehouse")
         if self._warehouse_name != normalize_name(self._prop["name"]):
             raise BadRequest("Property name not consistent. Use rename if you want to change warehouse's name.")
-        if not _is_an_update(self._prop):
+        if not _is_an_update(self._prop, WarehouseResource.warehouse_prop_list["alter_warehouse_option"]):
             raise BadRequest("Can not alter warehouse set with no parameters")
         sql_str = "ALTER WAREHOUSE "
         sql_str += self._prop["name"] + " "
         sql_str += "SET "
-        for key in WarehouseResource.warehouse_prop_list["optional"]:
+        for key in WarehouseResource.warehouse_prop_list["alter_warehouse_option"]:
             if key in self._prop:
                 prop_v = self._prop[key]
                 if key in ("comment",) and prop_v:
                     prop_v = try_single_quote_value(prop_v)
                 sql_str += f"{key.upper()} = {prop_v} "
 
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def update_and_unset_warehouse(self) -> tuple[str, Dict[str, Any]]:
         for key in WarehouseResource.warehouse_prop_list["required"]:
             if key not in self._prop:
                 raise BadRequest(f"{key} is a required field for Updating a Warehouse")
         if self._warehouse_name != normalize_name(self._prop["name"]):
             raise BadRequest("Property name not consistent.")
-        if not _is_an_update(self._prop):
+        unset_parameters = list(set(WarehouseResource.warehouse_prop_list["alter_warehouse_option"]).difference(set(self._prop)).difference(WarehouseResource.warehouse_prop_list["unset_exceptions"]))
+        if len(unset_parameters) == 0:
             raise BadRequest("Can not alter warehouse unset with no parameters")
         sql_str = "ALTER WAREHOUSE "
         sql_str += self._prop["name"] + " "
         sql_str += "UNSET "
-        unset_parameters = list(set(WarehouseResource.warehouse_prop_list["alter_warehouse_option"]).difference(set(self._prop)))
         for i, key in enumerate(unset_parameters):
             if key in WarehouseResource.warehouse_prop_list["alter_warehouse_option"]:
                 sql_str += f"{key.upper()}"
                 if i != len(unset_parameters)-1:
                     sql_str += ", "
 
         return sql_str, self.snow_exec.execute(sql_str)[0]
@@ -196,14 +205,18 @@
         for w in warehouses:
             # Turn is_default and is_current to booleans
             for e in ('is_default', 'is_current'):
                 if e in w:
                     w[e] = (w[e] == 'Y')
             if w["comment"] == "":
                 w["comment"] = None
+            if w['size'] is not None:
+                w['warehouse_size'] = w['size']
+            if w['type'] is not None:
+                w['warehouse_type'] = w['type']
         return warehouses
 
     def describe_warehouse(self) -> tuple[str, Dict[str, Any]]:
         sql_str = f"DESC WAREHOUSE {self._warehouse_name}"
         res = self.snow_exec.execute(sql_str)[0]
         obj_para_sql = f"SHOW PARAMETERS IN WAREHOUSE {self._warehouse_name}"
         object_parameters = self.snow_exec.execute(obj_para_sql)
@@ -252,30 +265,30 @@
 
         for key in filter(
             lambda e: e in self._prop,
             WarehouseResource.warehouse_prop_list["optional"],
         ):
             v = self._prop[key]
             if key == "comment":
-                sql_str += f" COMMENT = {try_single_quote_value(v)}, "
+                sql_str += f" COMMENT = {try_single_quote_value(v)} "
             else:
                 sql_str += f"{key.upper()} = {v} "
         return sql_str, self.snow_exec.execute(sql_str)[0]
 
     def create_or_update_warehouse(self) -> tuple[str, Dict[str, Any]]:
         show_sql = "SHOW WAREHOUSES LIKE '{}'".format(self._prop["name"])
         show_result = self.snow_exec.execute(show_sql)
         exist = False
         for exist_warehouse in show_result:
             if self._prop["name"].upper() == exist_warehouse["name"].upper():
                 self._warehouse_name = normalize_name(self._prop["name"])
                 exist = True
                 break
         if exist:
-            if not _is_an_update(self._prop):
+            if not _is_an_update(self._prop, WarehouseResource.warehouse_prop_list["alter_warehouse_option"]):
                 return "", {"description": "command ignored cause this is not an update"}
             _, ret = self.update_and_set_warehouse()
             _, ret = self.update_and_unset_warehouse()
         else:
             _, ret = self.create_or_replace_warehouse()
         return _, ret
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_compute_pool.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/_compute_pool.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 from typing import TYPE_CHECKING, Iterator, Optional
 
+from pydantic import StrictStr
+
 from snowflake.core._common import AccountObjectCollectionParent, CreateMode, ObjectReferenceMixin
 from snowflake.core._internal.telemetry import api_telemetry
 from snowflake.core.compute_pool._generated.api import ComputePoolApi
 from snowflake.core.compute_pool._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.compute_pool._generated.models.compute_pool import ComputePoolModel as ComputePool
-from snowflake.core.compute_pool._generated.pydantic_compatibility import StrictStr
 
 
 if TYPE_CHECKING:
     from snowflake.core import Root
 
 
 class ComputePoolCollection(AccountObjectCollectionParent["ComputePoolResource"]):
@@ -86,21 +87,14 @@
         self.collection = collection
 
     @property
     def _api(self) -> ComputePoolApi:
         return self.collection._api
 
     @api_telemetry
-    def create_or_update(self, compute_pool: ComputePool) -> None:
-        """Create or update a compute pool in Snowflake."""
-        self._api.create_or_alter_compute_pool(
-            compute_pool.name, compute_pool._to_model(), async_req=False
-        )
-
-    @api_telemetry
     def fetch(self) -> ComputePool:
         """Fetch the compute pool details from Snowflake."""
         return ComputePool._from_model(self.collection._api.fetch_compute_pool(self.name, async_req=False))
 
     @api_telemetry
     def suspend(self) -> None:
         """Suspend the compute pool."""
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Compute Pools API
+    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform common actions on Compute Pool resources.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.compute_pool._generated.api.compute_pool_api import ComputePoolApi
-
 # import ApiClient
 from snowflake.core.compute_pool._generated.api_client import ApiClient
 from snowflake.core.compute_pool._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.compute_pool._generated.models.compute_pool import ComputePool
 from snowflake.core.compute_pool._generated.models.error_response import ErrorResponse
 from snowflake.core.compute_pool._generated.models.success_response import SuccessResponse
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/api_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Image Repository API
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform common actions on Image Repository resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.compute_pool._generated.configuration import Configuration
-import snowflake.core.compute_pool._generated.models
-from snowflake.core.compute_pool._generated import rest
-from snowflake.core.compute_pool._generated.paging import PagedIter
+from snowflake.core.image_repository._generated.configuration import Configuration
+import snowflake.core.image_repository._generated.models
+from snowflake.core.image_repository._generated import rest
+from snowflake.core.image_repository._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,62 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.compute_pool._generated.models, klass)
+                klass = getattr(
+                    snowflake.core.image_repository._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +520,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +671,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for compute_pool. Updating compute_pool '
-                        'objects is not supported yet; use create() for creating a compute_pool.')
+                        'create_or_update is not yet supported for image_repository. Updating image_repository '
+                        'objects is not supported yet; use create() for creating a image_repository.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +700,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +743,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +787,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +824,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +848,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +875,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +941,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +959,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +975,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1010,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/api_response.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.compute_pool._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Task API
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.compute_pool._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.task._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Compute Pools API",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake Task API",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/role/_generated/rest.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Role API
+    The Snowflake Role API is a REST API that you can use to access, update, and perform certain action on Roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/api/compute_pool_api.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,46 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Compute Pools API
+    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform common actions on Compute Pool resources.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
-
+from pydantic import Field, StrictBool, StrictInt, StrictStr, field_validator
 from typing import List, Optional
-
+from typing_extensions import Annotated
 from snowflake.core.compute_pool._generated.models.compute_pool import ComputePool
 from snowflake.core.compute_pool._generated.models.success_response import SuccessResponse
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.compute_pool._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
+
+logger = logging.getLogger(__name__)
 
-logger  = logging.getLogger(__name__)
 
 class ComputePoolApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
@@ -71,15 +65,17 @@
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('compute_pool')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge(
+                    'compute_pool')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -91,31 +87,50 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_compute_pool(self, compute_pool : ComputePool, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, initially_suspended : Annotated[Optional[StrictBool], Field(description="Specifies whether the compute pool is created initially in the suspended state.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a compute pool  # noqa: E501
+    @validate_call
+    def create_compute_pool(
+            self,
+            compute_pool: ComputePool,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            initially_suspended:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Specifies whether the compute pool is created initially in the suspended state."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Creates a compute pool.  # noqa: E501
+
+
+        Creates a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
 
-        Create a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_compute_pool(compute_pool, create_mode, initially_suspended, async_req=True)
         >>> result = thread.get()
-
         :param compute_pool: (required)
         :type compute_pool: ComputePool
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param initially_suspended: Specifies whether the compute pool is created initially in the suspended state.
         :type initially_suspended: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -127,30 +142,51 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_compute_pool_with_http_info(compute_pool, create_mode, initially_suspended, **kwargs)  # noqa: E501
+        return self.create_compute_pool_with_http_info(compute_pool,
+                                                       create_mode,
+                                                       initially_suspended,
+                                                       **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_compute_pool_with_http_info(
+            self,
+            compute_pool: ComputePool,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            initially_suspended:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Specifies whether the compute pool is created initially in the suspended state."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Creates a compute pool.  # noqa: E501
 
-    @validate_arguments
-    def create_compute_pool_with_http_info(self, compute_pool : ComputePool, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, initially_suspended : Annotated[Optional[StrictBool], Field(description="Specifies whether the compute pool is created initially in the suspended state.")] = None, **kwargs):  # noqa: E501
-        """Create a compute pool  # noqa: E501
 
-        Create a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
+        Creates a compute pool, with standard create modifiers as query parameters. See the Compute Pool component definition for what is required to be provided in the request body.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_compute_pool_with_http_info(compute_pool, create_mode, initially_suspended, async_req=True)
         >>> result = thread.get()
-
         :param compute_pool: (required)
         :type compute_pool: ComputePool
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param initially_suspended: Specifies whether the compute pool is created initially in the suspended state.
         :type initially_suspended: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -172,75 +208,66 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'compute_pool',
-            'create_mode',
-            'initially_suspended'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['compute_pool', 'create_mode', 'initially_suspended']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_compute_pool" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_compute_pool" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
+
         if _params.get('initially_suspended') is not None:  # noqa: E501
-            _query_params.append(('initiallySuspended', _params['initially_suspended']))
+            _query_params.append(
+                ('initiallySuspended', _params['initially_suspended']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['compute_pool']:
             _body_params = _params['compute_pool']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -252,208 +279,49 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/compute-pools', 'POST',
+            '/api/v2/compute-pools',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_or_alter_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], compute_pool : ComputePool, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) compute pool.  # noqa: E501
-
-        Create a (or alter an existing) compute pool. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.create_or_alter_compute_pool(name, compute_pool, async_req=True)
-        >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param compute_pool: (required)
-        :type compute_pool: ComputePool
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: SuccessResponse
-        """
-        kwargs['_return_http_data_only'] = True
-        return self.create_or_alter_compute_pool_with_http_info(name, compute_pool, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def create_or_alter_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], compute_pool : ComputePool, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) compute pool.  # noqa: E501
-
-        Create a (or alter an existing) compute pool. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.create_or_alter_compute_pool_with_http_info(name, compute_pool, async_req=True)
-        >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param compute_pool: (required)
-        :type compute_pool: ComputePool
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _return_http_data_only: response data without head status code
-                                       and headers
-        :type _return_http_data_only: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :param _request_auth: set to override the auth_settings for an a single
-                              request; this effectively ignores the authentication
-                              in the spec for a single request.
-        :type _request_auth: dict, optional
-        :type _content_type: string, optional: force content-type for the request
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
-        """
-
-        _params = locals()
-
-        _all_params = [
-            'name',
-            'compute_pool'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
-
-        # validate the arguments
-        for _key, _val in _params['kwargs'].items():
-            if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_or_alter_compute_pool" % _key
-                )
-            _params[_key] = _val
-        del _params['kwargs']
-
-        _collection_formats = {}
-
-        # process the path parameters
-        _path_params = {}
-        if _params['name']:
-            _path_params['name'] = _params['name']
-
-        # process the query parameters
-        _query_params = []
-
-        # process the header parameters
-        _header_params = dict(_params.get('_headers', {}))
-
-        # process the form parameters
-        _form_params = []
-        _files = {}
-
-        # process the body parameter
-        _body_params = None
-        if _params['compute_pool']:
-            _body_params = _params['compute_pool']
-
-        # set the HTTP header `Accept`
-        _header_params['Accept'] = self.api_client.select_header_accept(
-            ['application/json'])  # noqa: E501
+    @validate_call
+    def fetch_compute_pool(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                           **kwargs) -> ComputePool:  # noqa: E501
+        """Fetches a compute pool.  # noqa: E501
 
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
 
-        # authentication setting
-        _auth_settings = []  # noqa: E501
+        Fetches a named compute pool. You can get the name of the compute pool from the `/api/v2/compute-pools` GET request.  # noqa: E501
 
-        _response_types_map = {
-            '200': "SuccessResponse",
-            '400': "ErrorResponse",
-            '401': "ErrorResponse",
-            '403': "ErrorResponse",
-            '404': "ErrorResponse",
-            '405': "ErrorResponse",
-            '500': "ErrorResponse",
-            '503': "ErrorResponse",
-            '504': "ErrorResponse",
-        }
-
-        return self.api_client.call_api(
-            self._root,
-            '/api/v2/compute-pools/{name}', 'PUT',
-            _path_params,
-            _query_params,
-            _header_params,
-            body=_body_params,
-            post_params=_form_params,
-            files=_files,
-            response_types_map=_response_types_map,
-            auth_settings=_auth_settings,
-            async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
-            _preload_content=_params.get('_preload_content', True),
-            _request_timeout=_params.get('_request_timeout'),
-            collection_formats=_collection_formats,
-            _request_auth=_params.get('_request_auth'))
-
-    @validate_arguments
-    def fetch_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> ComputePool:  # noqa: E501
-        """Fetch a compute pool.  # noqa: E501
-
-        Fetch a compute pool using the SHOW command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_compute_pool(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -463,28 +331,34 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: ComputePool
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
+        return self.fetch_compute_pool_with_http_info(name,
+                                                      **kwargs)  # noqa: E501
+
+    @validate_call
+    def fetch_compute_pool_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                          **kwargs):  # noqa: E501
+        """Fetches a compute pool.  # noqa: E501
 
-    @validate_arguments
-    def fetch_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Fetch a compute pool.  # noqa: E501
 
-        Fetch a compute pool using the SHOW command output.  # noqa: E501
+        Fetches a named compute pool. You can get the name of the compute pool from the `/api/v2/compute-pools` GET request.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_compute_pool_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -504,43 +378,33 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(ComputePool, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_compute_pool" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_compute_pool" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -570,46 +434,72 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/compute-pools/{name}', 'GET',
+            '/api/v2/compute-pools/{name}',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_compute_pools(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs) -> Iterable[ComputePool]:  # noqa: E501
-        """List compute pools  # noqa: E501
+    @validate_call
+    def fetch_compute_pools(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            **kwargs) -> Iterable[ComputePool]:  # noqa: E501
+        """Lists compute pools.  # noqa: E501
+
 
         Lists the compute pools under the account.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_compute_pools(like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
-
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -619,32 +509,58 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Iterable[ComputePool]
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_compute_pools_with_http_info(like, starts_with, show_limit, **kwargs)  # noqa: E501
+        return self.fetch_compute_pools_with_http_info(like, starts_with,
+                                                       show_limit,
+                                                       **kwargs)  # noqa: E501
+
+    @validate_call
+    def fetch_compute_pools_with_http_info(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Lists compute pools.  # noqa: E501
 
-    @validate_arguments
-    def fetch_compute_pools_with_http_info(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs):  # noqa: E501
-        """List compute pools  # noqa: E501
 
         Lists the compute pools under the account.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_compute_pools_with_http_info(like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
-
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -664,52 +580,42 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(Iterable[ComputePool], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'like',
-            'starts_with',
-            'show_limit'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['like', 'starts_with', 'show_limit']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_compute_pools" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_compute_pools" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
 
         # process the query parameters
         _query_params = []
+
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
+
         if _params.get('starts_with') is not None:  # noqa: E501
             _query_params.append(('startsWith', _params['starts_with']))
+
         if _params.get('show_limit') is not None:  # noqa: E501
             _query_params.append(('showLimit', _params['show_limit']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -736,42 +642,49 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/compute-pools', 'GET',
+            '/api/v2/compute-pools',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def resume_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
-        """Resume a compute pool  # noqa: E501
+    @validate_call
+    def resume_compute_pool(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Resumes a suspended compute pool.  # noqa: E501
+
+
+        Resume a compute pool, if suspended. If the specified compute pool is already running, no action is taken.  # noqa: E501
 
-        Resume a compute pool, if suspended. This is a no-op if it is already running.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.resume_compute_pool(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -781,28 +694,34 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.resume_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
+        return self.resume_compute_pool_with_http_info(name,
+                                                       **kwargs)  # noqa: E501
+
+    @validate_call
+    def resume_compute_pool_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                           **kwargs):  # noqa: E501
+        """Resumes a suspended compute pool.  # noqa: E501
 
-    @validate_arguments
-    def resume_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Resume a compute pool  # noqa: E501
 
-        Resume a compute pool, if suspended. This is a no-op if it is already running.  # noqa: E501
+        Resume a compute pool, if suspended. If the specified compute pool is already running, no action is taken.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.resume_compute_pool_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -822,43 +741,33 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method resume_compute_pool" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method resume_compute_pool" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -888,42 +797,50 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/compute-pools/{name}:resume', 'POST',
+            '/api/v2/compute-pools/{name}:resume',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def stop_all_services_in_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def stop_all_services_in_compute_pool(
+            self, name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """Stops all services on the compute pool.  # noqa: E501
 
-        Stop all services in the compute pool.  # noqa: E501
+
+        Stops all services in the compute pool.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.stop_all_services_in_compute_pool(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -933,28 +850,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.stop_all_services_in_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
+        return self.stop_all_services_in_compute_pool_with_http_info(
+            name, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def stop_all_services_in_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def stop_all_services_in_compute_pool_with_http_info(
+            self, name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            **kwargs):  # noqa: E501
         """Stops all services on the compute pool.  # noqa: E501
 
-        Stop all services in the compute pool.  # noqa: E501
+
+        Stops all services in the compute pool.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.stop_all_services_in_compute_pool_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -974,43 +898,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method stop_all_services_in_compute_pool" % _key
-                )
+                    " to method stop_all_services_in_compute_pool" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1040,42 +955,49 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/compute-pools/{name}:stopallservices', 'POST',
+            '/api/v2/compute-pools/{name}:stopallservices',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def suspend_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
-        """Perform an action on a compute pool  # noqa: E501
+    @validate_call
+    def suspend_compute_pool(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                             **kwargs) -> SuccessResponse:  # noqa: E501
+        """Suspends an active compute pool.  # noqa: E501
+
+
+        Suspends an active compute pool.  # noqa: E501
 
-        Suspend a compute pool.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.suspend_compute_pool(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1085,28 +1007,34 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_compute_pool_with_http_info(name, **kwargs)  # noqa: E501
+        return self.suspend_compute_pool_with_http_info(name,
+                                                        **kwargs)  # noqa: E501
+
+    @validate_call
+    def suspend_compute_pool_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                            **kwargs):  # noqa: E501
+        """Suspends an active compute pool.  # noqa: E501
 
-    @validate_arguments
-    def suspend_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Perform an action on a compute pool  # noqa: E501
 
-        Suspend a compute pool.  # noqa: E501
+        Suspends an active compute pool.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.suspend_compute_pool_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1126,43 +1054,33 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method suspend_compute_pool" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method suspend_compute_pool" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1192,44 +1110,60 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/compute-pools/{name}:suspend', 'POST',
+            '/api/v2/compute-pools/{name}:suspend',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def delete_compute_pool(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a compute pool  # noqa: E501
+    @validate_call
+    def delete_compute_pool(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Deletes a compute pool.  # noqa: E501
+
+
+        Deletes a compute pool with the given name. If you enable the `ifExists` parameter, the operation succeeds even if the object does not exist. Otherwise, a 404 failure is returned if the object does not exist.  # noqa: E501
 
-        Delete a compute pool with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a 404 failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_compute_pool(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1239,30 +1173,45 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_compute_pool_with_http_info(name, if_exists, **kwargs)  # noqa: E501
+        return self.delete_compute_pool_with_http_info(name, if_exists,
+                                                       **kwargs)  # noqa: E501
+
+    @validate_call
+    def delete_compute_pool_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Deletes a compute pool.  # noqa: E501
 
-    @validate_arguments
-    def delete_compute_pool_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
-        """Delete a compute pool  # noqa: E501
 
-        Delete a compute pool with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a 404 failure if the drop is unsuccessful.  # noqa: E501
+        Deletes a compute pool with the given name. If you enable the `ifExists` parameter, the operation succeeds even if the object does not exist. Otherwise, a 404 failure is returned if the object does not exist.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_compute_pool_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1282,49 +1231,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method delete_compute_pool" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method delete_compute_pool" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -1351,22 +1290,24 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/compute-pools/{name}', 'DELETE',
+            '/api/v2/compute-pools/{name}',
+            'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/user/_generated/models/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake User API
+    The Snowflake User API is a REST API that you can use to access, update, and perform certain action on Users in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
-from snowflake.core.compute_pool._generated.models.compute_pool import ComputePool
-from snowflake.core.compute_pool._generated.models.error_response import ErrorResponse
-from snowflake.core.compute_pool._generated.models.success_response import SuccessResponse
+from snowflake.core.user._generated.models.error_response import ErrorResponse
+from snowflake.core.user._generated.models.success_response import SuccessResponse
+from snowflake.core.user._generated.models.user import User
 
 __all__ = [
-    'ComputePool',
     'ErrorResponse',
     'SuccessResponse',
-]
+    'User',
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/compute_pool.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/models/compute_pool.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,68 +1,94 @@
 # coding: utf-8
-
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Compute Pools API
+    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform common actions on Compute Pool resources.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Optional
 from typing import Union
-from snowflake.core.compute_pool._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
 
 class ComputePool(BaseModel):
-    name: constr(strict=True) = Field(...)
-    min_nodes: StrictInt = Field(...)
-    max_nodes: StrictInt = Field(...)
-    instance_family: StrictStr = Field(...)
+
+    name: Annotated[str, Field(strict=True)]
+
+    min_nodes: StrictInt
+
+    max_nodes: StrictInt
+
+    instance_family: StrictStr
+
     auto_resume: Optional[StrictBool] = None
+
     comment: Optional[StrictStr] = None
+
     state: Optional[StrictStr] = None
+
     num_services: Optional[StrictInt] = None
+
     auto_suspend_secs: Optional[StrictInt] = None
+
     active_nodes: Optional[StrictInt] = None
+
     idle_nodes: Optional[StrictInt] = None
+
     created_on: Optional[datetime] = None
+
     resumed_on: Optional[datetime] = None
+
     updated_on: Optional[datetime] = None
+
     owner: Optional[StrictStr] = None
-    __properties = ["name", "min_nodes", "max_nodes", "instance_family", "auto_resume", "comment", "state", "num_services", "auto_suspend_secs", "active_nodes", "idle_nodes", "created_on", "resumed_on", "updated_on", "owner"]
 
+    __properties = [
+        "name", "min_nodes", "max_nodes", "instance_family", "auto_resume",
+        "comment", "state", "num_services", "auto_suspend_secs",
+        "active_nodes", "idle_nodes", "created_on", "resumed_on", "updated_on",
+        "owner"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('state')
+    @field_validator('state')
     def state_validate_enum(cls, v):
+
         if v is None:
             return v
-
-        if v not in ('UNKNOWN', 'STARTING', 'IDLE', 'ACTIVE', 'STOPPING', 'SUSPENDED', 'RESIZING'):
-            raise ValueError("must validate the enum values ('UNKNOWN', 'STARTING', 'IDLE', 'ACTIVE', 'STOPPING', 'SUSPENDED', 'RESIZING')")
+        if v not in ('UNKNOWN', 'STARTING', 'IDLE', 'ACTIVE', 'STOPPING',
+                     'SUSPENDED', 'RESIZING'):
+            raise ValueError("must validate the enum values ()")
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -72,75 +98,82 @@
     @classmethod
     def from_json(cls, json_str: str) -> ComputePool:
         """Create an instance of ComputePool from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "state",
-                            "num_services",
-                            "active_nodes",
-                            "idle_nodes",
-                            "created_on",
-                            "resumed_on",
-                            "updated_on",
-                            "owner",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "state",
+                           "num_services",
+                           "active_nodes",
+                           "idle_nodes",
+                           "created_on",
+                           "resumed_on",
+                           "updated_on",
+                           "owner",
+                       },
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ComputePool:
         """Create an instance of ComputePool from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ComputePool.parse_obj(obj)
 
         _obj = ComputePool.parse_obj({
-            "name": obj.get("name"),
-
-            "min_nodes": obj.get("min_nodes"),
-
-            "max_nodes": obj.get("max_nodes"),
-
-            "instance_family": obj.get("instance_family"),
-
-            "auto_resume": obj.get("auto_resume"),
-
-            "comment": obj.get("comment"),
-
-            "state": obj.get("state"),
-
-            "num_services": obj.get("num_services"),
-
-            "auto_suspend_secs": obj.get("auto_suspend_secs"),
-
-            "active_nodes": obj.get("active_nodes"),
-
-            "idle_nodes": obj.get("idle_nodes"),
-
-            "created_on": obj.get("created_on"),
-
-            "resumed_on": obj.get("resumed_on"),
-
-            "updated_on": obj.get("updated_on"),
-
-            "owner": obj.get("owner"),
-
+            "name":
+            obj.get("name"),
+            "min_nodes":
+            obj.get("min_nodes"),
+            "max_nodes":
+            obj.get("max_nodes"),
+            "instance_family":
+            obj.get("instance_family"),
+            "auto_resume":
+            obj.get("auto_resume"),
+            "comment":
+            obj.get("comment"),
+            "state":
+            obj.get("state"),
+            "num_services":
+            obj.get("num_services"),
+            "auto_suspend_secs":
+            obj.get("auto_suspend_secs"),
+            "active_nodes":
+            obj.get("active_nodes"),
+            "idle_nodes":
+            obj.get("idle_nodes"),
+            "created_on":
+            obj.get("created_on"),
+            "resumed_on":
+            obj.get("resumed_on"),
+            "updated_on":
+            obj.get("updated_on"),
+            "owner":
+            obj.get("owner"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ComputePoolModel():
+
     def __init__(
         self,
         name: str,
         min_nodes: int,
         max_nodes: int,
         instance_family: str,
         # optional properties
@@ -152,14 +185,15 @@
         active_nodes: Optional[int] = None,
         idle_nodes: Optional[int] = None,
         created_on: Optional[datetime] = None,
         resumed_on: Optional[datetime] = None,
         updated_on: Optional[datetime] = None,
         owner: Optional[str] = None,
     ):
+
         self.name = name
         self.min_nodes = min_nodes
         self.max_nodes = max_nodes
         self.instance_family = instance_family
         self.auto_resume = auto_resume
         self.comment = comment
         self.state = state
@@ -167,83 +201,59 @@
         self.auto_suspend_secs = auto_suspend_secs
         self.active_nodes = active_nodes
         self.idle_nodes = idle_nodes
         self.created_on = created_on
         self.resumed_on = resumed_on
         self.updated_on = updated_on
         self.owner = owner
-    __properties = ["name", "min_nodes", "max_nodes", "instance_family", "auto_resume", "comment", "state", "num_services", "auto_suspend_secs", "active_nodes", "idle_nodes", "created_on", "resumed_on", "updated_on", "owner"]
+
+    __properties = [
+        "name", "min_nodes", "max_nodes", "instance_family", "auto_resume",
+        "comment", "state", "num_services", "auto_suspend_secs",
+        "active_nodes", "idle_nodes", "created_on", "resumed_on", "updated_on",
+        "owner"
+    ]
 
     def _to_model(self):
         return ComputePool(
             name=self.name,
-
             min_nodes=self.min_nodes,
-
             max_nodes=self.max_nodes,
-
             instance_family=self.instance_family,
-
             auto_resume=self.auto_resume,
-
             comment=self.comment,
-
             state=self.state,
-
             num_services=self.num_services,
-
             auto_suspend_secs=self.auto_suspend_secs,
-
             active_nodes=self.active_nodes,
-
             idle_nodes=self.idle_nodes,
-
             created_on=self.created_on,
-
             resumed_on=self.resumed_on,
-
             updated_on=self.updated_on,
-
             owner=self.owner,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ComputePoolModel:
         return ComputePoolModel(
             name=model.name,
-
             min_nodes=model.min_nodes,
-
             max_nodes=model.max_nodes,
-
             instance_family=model.instance_family,
-
             auto_resume=model.auto_resume,
-
             comment=model.comment,
-
             state=model.state,
-
             num_services=model.num_services,
-
             auto_suspend_secs=model.auto_suspend_secs,
-
             active_nodes=model.active_nodes,
-
             idle_nodes=model.idle_nodes,
-
             created_on=model.created_on,
-
             resumed_on=model.resumed_on,
-
             updated_on=model.updated_on,
-
             owner=model.owner,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/error_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Stage API
+    The Snowflake Stage API is a REST API that you can use to access, update, and perform certain actions on stage resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.compute_pool._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/compute_pool/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/compute_pool/_generated/models/success_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Compute Pools API
-
-    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform certain actions on Compute Pool resources.  # noqa: E501
 
+    Snowflake Compute Pools API
+    The Snowflake Compute Pools API is a REST API that you can use to access, update, and perform common actions on Compute Pool resources.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.compute_pool._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_search_service.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_search_service.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Cortex Search REST API
 
+    Cortex Search REST API
     OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
-
     The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.cortex.search_service._generated.api.cortex_search_service_api import CortexSearchServiceApi
-
 # import ApiClient
 from snowflake.core.cortex.search_service._generated.api_client import ApiClient
 from snowflake.core.cortex.search_service._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.cortex.search_service._generated.models.error_response import ErrorResponse
 from snowflake.core.cortex.search_service._generated.models.query_request import QueryRequest
 from snowflake.core.cortex.search_service._generated.models.query_response import QueryResponse
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/api_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Cortex Search REST API
 
+    Cortex Search REST API
     OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
-
     The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,63 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.cortex.search_service._generated.models, klass)
+                klass = getattr(
+                    snowflake.core.cortex.search_service._generated.models,
+                    klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +521,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -624,15 +673,16 @@
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
                         'create_or_update is not yet supported for search_service. Updating search_service '
-                        'objects is not supported yet; use create() for creating a search_service.')
+                        'objects is not supported yet; use create() for creating a search_service.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +701,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +744,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +788,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +825,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +849,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +876,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +942,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +960,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +976,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1011,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/api_response.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.cortex.search_service._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/user/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Cortex Search REST API
-
-    OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
 
-    The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Snowflake User API
+    The Snowflake User API is a REST API that you can use to access, update, and perform certain action on Users in a Snowflake database.  # noqa: E501
+    The version of the OpenAPI document: 0.0.1
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,41 +41,49 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
-        self._base_path = "http://localhost" if host is None else host
+        self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
         """Default server index
         """
         self.server_variables = server_variables or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.cortex.search_service._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.user._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,49 +312,47 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
         return "Python SDK Debug Report:\n"\
                "OS: {env}\n"\
                "Python Version: {pyversion}\n"\
-               "Version of the API: 0.1.0\n"\
+               "Version of the API: 0.0.1\n"\
                "SDK Package Version: 1.0.0".\
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "",
-                'description': "No description provided",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake REST Server",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/rest.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Cortex Search REST API
-
-    OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
 
-    The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
+    The version of the OpenAPI document: 0.0.1
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/api/cortex_search_service_api.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/api/cortex_search_service_api.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,46 +1,40 @@
 # coding: utf-8
-
 """
-    Cortex Search REST API
 
+    Cortex Search REST API
     OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
-
     The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictStr, constr, validator
-
+from pydantic import Field, StrictStr, field_validator
 from typing import Optional
-
+from typing_extensions import Annotated
 from snowflake.core.cortex.search_service._generated.models.query_request import QueryRequest
 from snowflake.core.cortex.search_service._generated.models.query_response import QueryResponse
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.cortex.search_service._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
+
+logger = logging.getLogger(__name__)
 
-logger  = logging.getLogger(__name__)
 
 class CortexSearchServiceApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
@@ -71,15 +65,17 @@
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('search_service')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge(
+                    'search_service')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -91,31 +87,55 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def query_cortex_search_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], service_name : Annotated[StrictStr, Field(..., description="The name of the Cortex Search Service.")], query_request : Optional[QueryRequest] = None, **kwargs) -> QueryResponse:  # noqa: E501
+    @validate_call
+    def query_cortex_search_service(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            service_name: Annotated[
+                StrictStr,
+                Field(description="The name of the Cortex Search Service.")],
+            query_request: Optional[QueryRequest] = None,
+            **kwargs) -> QueryResponse:  # noqa: E501
         """Query a Cortex Search Service.  # noqa: E501
 
+
         Query a Cortex Search Service to get search results.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.query_cortex_search_service(database, var_schema, service_name, query_request, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
         :param service_name: The name of the Cortex Search Service. (required)
         :type service_name: str
         :param query_request:
         :type query_request: QueryRequest
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
@@ -129,30 +149,55 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: QueryResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.query_cortex_search_service_with_http_info(database, var_schema, service_name, query_request, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def query_cortex_search_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], service_name : Annotated[StrictStr, Field(..., description="The name of the Cortex Search Service.")], query_request : Optional[QueryRequest] = None, **kwargs):  # noqa: E501
+        return self.query_cortex_search_service_with_http_info(
+            database, var_schema, service_name, query_request,
+            **kwargs)  # noqa: E501
+
+    @validate_call
+    def query_cortex_search_service_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            service_name: Annotated[
+                StrictStr,
+                Field(description="The name of the Cortex Search Service.")],
+            query_request: Optional[QueryRequest] = None,
+            **kwargs):  # noqa: E501
         """Query a Cortex Search Service.  # noqa: E501
 
+
         Query a Cortex Search Service to get search results.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.query_cortex_search_service_with_http_info(database, var_schema, service_name, query_request, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
         :param service_name: The name of the Cortex Search Service. (required)
         :type service_name: str
         :param query_request:
         :type query_request: QueryRequest
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
@@ -177,49 +222,41 @@
                  returns the request thread.
         :rtype: tuple(QueryResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'service_name',
-            'query_request'
+            'database', 'var_schema', 'service_name', 'query_request'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method query_cortex_search_service" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method query_cortex_search_service" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['service_name']:
             _path_params['service_name'] = _params['service_name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -227,27 +264,28 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['query_request']:
             _body_params = _params['query_request']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "QueryResponse",
             '400': "ErrorResponse",
@@ -259,22 +297,24 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/cortex-search-services/{service_name}:query', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/cortex-search-services/{service_name}:query',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Cortex Search REST API
 
+    Cortex Search REST API
     OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
-
     The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.cortex.search_service._generated.models.error_response import ErrorResponse
 from snowflake.core.cortex.search_service._generated.models.query_request import QueryRequest
 from snowflake.core.cortex.search_service._generated.models.query_response import QueryResponse
 
 __all__ = [
     'ErrorResponse',
     'QueryRequest',
     'QueryResponse',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/error_response.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Cortex Search REST API
 
+    Cortex Search REST API
     OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
-
     The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.cortex.search_service._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/query_request.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/query_request.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Cortex Search REST API
 
+    Cortex Search REST API
     OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
-
     The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Any, Dict, List, Optional
 from typing import Union
-from snowflake.core.cortex.search_service._generated.pydantic_compatibility import BaseModel, Field, StrictInt, StrictStr, conlist
+
+from pydantic import BaseModel, ConfigDict, StrictInt, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class QueryRequest(BaseModel):
-    query: StrictStr = Field(...)
-    columns: conlist(StrictStr) = Field(...)
+
+    query: StrictStr
+
+    columns: List[StrictStr]
+
     filter: Optional[Dict[str, Any]] = None
+
     limit: Optional[StrictInt] = 10
-    __properties = ["query", "columns", "filter", "limit"]
 
+    __properties = ["query", "columns", "filter", "limit"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,82 @@
     @classmethod
     def from_json(cls, json_str: str) -> QueryRequest:
         """Create an instance of QueryRequest from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> QueryRequest:
         """Create an instance of QueryRequest from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return QueryRequest.parse_obj(obj)
 
         _obj = QueryRequest.parse_obj({
-            "query": obj.get("query"),
-
-            "columns": obj.get("columns"),
-
-            "filter": obj.get("filter"),
-
-            "limit": obj.get("limit") if obj.get("limit") is not None else 10,
-
+            "query":
+            obj.get("query"),
+            "columns":
+            obj.get("columns"),
+            "filter":
+            obj.get("filter"),
+            "limit":
+            obj.get("limit") if obj.get("limit") is not None else 10,
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class QueryRequestModel():
+
     def __init__(
         self,
         query: str,
         columns: List[str],
         # optional properties
         filter: Optional[object] = None,
         limit: Optional[int] = 10,
     ):
+
         self.query = query
         self.columns = columns
         self.filter = filter
         self.limit = limit
+
     __properties = ["query", "columns", "filter", "limit"]
 
     def _to_model(self):
         return QueryRequest(
             query=self.query,
-
             columns=self.columns,
-
             filter=self.filter,
-
             limit=self.limit,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> QueryRequestModel:
         return QueryRequestModel(
             query=model.query,
-
             columns=model.columns,
-
             filter=model.filter,
-
             limit=model.limit,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/cortex/search_service/_generated/models/query_response.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/models/query_response.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Cortex Search REST API
 
+    Cortex Search REST API
     OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
-
     The version of the OpenAPI document: 0.1.0
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Any, Dict, List
 from typing import Union
-from snowflake.core.cortex.search_service._generated.pydantic_compatibility import BaseModel, Field, StrictStr, conlist
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List
+
 
 class QueryResponse(BaseModel):
-    results: conlist(Dict[str, Any]) = Field(...)
-    request_id: StrictStr = Field(...)
-    __properties = ["results", "request_id"]
 
+    results: List[Dict[str, Any]]
+
+    request_id: StrictStr
+
+    __properties = ["results", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,66 +44,68 @@
     @classmethod
     def from_json(cls, json_str: str) -> QueryResponse:
         """Create an instance of QueryResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> QueryResponse:
         """Create an instance of QueryResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return QueryResponse.parse_obj(obj)
 
         _obj = QueryResponse.parse_obj({
             "results": obj.get("results"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class QueryResponseModel():
+
     def __init__(
         self,
         results: List[Dict[str, object]],
         request_id: str,
         # optional properties
     ):
+
         self.results = results
         self.request_id = request_id
+
     __properties = ["results", "request_id"]
 
     def _to_model(self):
         return QueryResponse(
             results=self.results,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> QueryResponseModel:
         return QueryResponseModel(
             results=model.results,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_database.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_database.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,19 +1,20 @@
 from functools import cached_property
 from typing import TYPE_CHECKING, Iterator, List, Optional, Union
 
+from pydantic import StrictStr
+
 from snowflake.core._common import AccountObjectCollectionParent, Clone, CreateMode, ObjectReferenceMixin, PointOfTime
 from snowflake.core._internal.telemetry import api_telemetry
 from snowflake.core.database._generated.api import DatabaseApi
 from snowflake.core.database._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.database._generated.models.account_identifiers import AccountIdentifiers
 from snowflake.core.database._generated.models.database import DatabaseModel as Database
 from snowflake.core.database._generated.models.database_clone import DatabaseClone
 from snowflake.core.database._generated.models.point_of_time import PointOfTime as DatabasePointOfTime
-from snowflake.core.database._generated.pydantic_compatibility import StrictStr
 from snowflake.core.schema import SchemaCollection
 
 
 if TYPE_CHECKING:
     from snowflake.core import Root
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Database API
 
+    Snowflake Database API
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.database._generated.api.database_api import DatabaseApi
-
 # import ApiClient
 from snowflake.core.database._generated.api_client import ApiClient
 from snowflake.core.database._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.database._generated.models.account_identifiers import AccountIdentifiers
 from snowflake.core.database._generated.models.database import Database
 from snowflake.core.database._generated.models.database_clone import DatabaseClone
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/api_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Services API
+    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.database._generated.configuration import Configuration
-import snowflake.core.database._generated.models
-from snowflake.core.database._generated import rest
-from snowflake.core.database._generated.paging import PagedIter
+from snowflake.core.service._generated.configuration import Configuration
+import snowflake.core.service._generated.models
+from snowflake.core.service._generated import rest
+from snowflake.core.service._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,62 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.database._generated.models, klass)
+                klass = getattr(snowflake.core.service._generated.models,
+                                klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +520,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +671,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for database. Updating database '
-                        'objects is not supported yet; use create() for creating a database.')
+                        'create_or_update is not yet supported for service. Updating service '
+                        'objects is not supported yet; use create() for creating a service.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +700,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +743,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +787,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +824,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +848,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +875,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +941,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +959,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +975,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1010,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/api_response.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.database._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Services API
+    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.database._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.service._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Database API",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake Services API",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/rest.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Session API
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/api/database_api.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/api/database_api.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,48 +1,42 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
 
+    Snowflake Database API
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
-
+from pydantic import Field, StrictBool, StrictInt, StrictStr, field_validator
 from typing import List, Optional
-
+from typing_extensions import Annotated
 from snowflake.core.database._generated.models.account_identifiers import AccountIdentifiers
 from snowflake.core.database._generated.models.database import Database
 from snowflake.core.database._generated.models.database_clone import DatabaseClone
 from snowflake.core.database._generated.models.success_response import SuccessResponse
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.database._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
+
+logger = logging.getLogger(__name__)
 
-logger  = logging.getLogger(__name__)
 
 class DatabaseApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
@@ -73,15 +67,16 @@
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('database')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge('database')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -93,33 +88,52 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_database(self, database : Database, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a database  # noqa: E501
+    @validate_call
+    def create_database(
+            self,
+            database: Database,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Creates a database.  # noqa: E501
+
+
+        Creates a database, with modifiers as query parameters. You must provide the full database definition when creating a database.  # noqa: E501
 
-        Create a database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_database(database, create_mode, kind, async_req=True)
         >>> result = thread.get()
-
         :param database: (required)
         :type database: Database
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -129,32 +143,51 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_database_with_http_info(database, create_mode, kind, **kwargs)  # noqa: E501
+        return self.create_database_with_http_info(database, create_mode, kind,
+                                                   **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_database_with_http_info(
+            self,
+            database: Database,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Creates a database.  # noqa: E501
 
-    @validate_arguments
-    def create_database_with_http_info(self, database : Database, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
-        """Create a database  # noqa: E501
 
-        Create a database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
+        Creates a database, with modifiers as query parameters. You must provide the full database definition when creating a database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_database_with_http_info(database, create_mode, kind, async_req=True)
         >>> result = thread.get()
-
         :param database: (required)
         :type database: Database
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -174,75 +207,65 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'create_mode',
-            'kind'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'create_mode', 'kind']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_database" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_database" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
+
         if _params.get('kind') is not None:  # noqa: E501
             _query_params.append(('kind', _params['kind']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['database']:
             _body_params = _params['database']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -254,48 +277,78 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases', 'POST',
+            '/api/v2/databases',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_database_from_share(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, share : Annotated[Optional[StrictStr], Field(description="The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a database from a share.  # noqa: E501
+    @validate_call
+    def create_database_from_share(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            share:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "ID of the share from which to create the database, in the form \"<provider_account>.<share_name>\"."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Creates a database from a share.  # noqa: E501
+
+
+        Creates a database from a given share.  # noqa: E501
 
-        Create a database from a given share  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_database_from_share(name, create_mode, share, kind, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param share: The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".
+        :param share: ID of the share from which to create the database, in the form \"<provider_account>.<share_name>\".
         :type share: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -305,34 +358,63 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_database_from_share_with_http_info(name, create_mode, share, kind, **kwargs)  # noqa: E501
+        return self.create_database_from_share_with_http_info(
+            name, create_mode, share, kind, **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_database_from_share_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            share:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "ID of the share from which to create the database, in the form \"<provider_account>.<share_name>\"."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Creates a database from a share.  # noqa: E501
 
-    @validate_arguments
-    def create_database_from_share_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, share : Annotated[Optional[StrictStr], Field(description="The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
-        """Create a database from a share.  # noqa: E501
 
-        Create a database from a given share  # noqa: E501
+        Creates a database from a given share.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_database_from_share_with_http_info(name, create_mode, share, kind, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param share: The share the database should be created from. Should be of the form \"<provider_account>.<share_name>\".
+        :param share: ID of the share from which to create the database, in the form \"<provider_account>.<share_name>\".
         :type share: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -352,55 +434,46 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'create_mode',
-            'share',
-            'kind'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'create_mode', 'share', 'kind']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_database_from_share" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_database_from_share" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
+
         if _params.get('share') is not None:  # noqa: E501
             _query_params.append(('share', _params['share']))
+
         if _params.get('kind') is not None:  # noqa: E501
             _query_params.append(('kind', _params['kind']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -428,42 +501,50 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}:from_share', 'POST',
+            '/api/v2/databases/{name}:from_share',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_or_alter_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database : Database, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) database.  # noqa: E501
+    @validate_call
+    def create_or_alter_database(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                 database: Database,
+                                 **kwargs) -> SuccessResponse:  # noqa: E501
+        """Creates a new, or alters an existing, database.  # noqa: E501
+
+
+        Creates a new, or alters an existing, database. You must provide the full database definition even when altering an existing database.  # noqa: E501
 
-        Create a (or alter an existing) database. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_or_alter_database(name, database, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param database: (required)
         :type database: Database
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -475,28 +556,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_alter_database_with_http_info(name, database, **kwargs)  # noqa: E501
+        return self.create_or_alter_database_with_http_info(
+            name, database, **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_or_alter_database_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                                database: Database,
+                                                **kwargs):  # noqa: E501
+        """Creates a new, or alters an existing, database.  # noqa: E501
 
-    @validate_arguments
-    def create_or_alter_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database : Database, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) database.  # noqa: E501
 
-        Create a (or alter an existing) database. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        Creates a new, or alters an existing, database. You must provide the full database definition even when altering an existing database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_or_alter_database_with_http_info(name, database, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param database: (required)
         :type database: Database
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -518,44 +606,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'database'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'database']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_or_alter_database" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_or_alter_database" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -563,27 +641,28 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['database']:
             _body_params = _params['database']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -594,48 +673,72 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}', 'PUT',
+            '/api/v2/databases/{name}',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def clone_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database_clone : DatabaseClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Clone a database  # noqa: E501
+    @validate_call
+    def clone_database(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            database_clone: DatabaseClone,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Clones a database.  # noqa: E501
+
+
+        Clones an existing database, with modifiers as query parameters. You must provide the full database definition when cloning an existing database.  # noqa: E501
 
-        Clone an existing database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.clone_database(name, database_clone, create_mode, kind, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param database_clone: (required)
         :type database_clone: DatabaseClone
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -645,34 +748,58 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.clone_database_with_http_info(name, database_clone, create_mode, kind, **kwargs)  # noqa: E501
+        return self.clone_database_with_http_info(name, database_clone,
+                                                  create_mode, kind,
+                                                  **kwargs)  # noqa: E501
+
+    @validate_call
+    def clone_database_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            database_clone: DatabaseClone,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Clones a database.  # noqa: E501
 
-    @validate_arguments
-    def clone_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], database_clone : DatabaseClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, **kwargs):  # noqa: E501
-        """Clone a database  # noqa: E501
 
-        Clone an existing database, with modifiers as query parameters. See the database definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
+        Clones an existing database, with modifiers as query parameters. You must provide the full database definition when cloning an existing database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.clone_database_with_http_info(name, database_clone, create_mode, kind, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param database_clone: (required)
         :type database_clone: DatabaseClone
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of database. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of database to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -692,78 +819,68 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'database_clone',
-            'create_mode',
-            'kind'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'database_clone', 'create_mode', 'kind']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method clone_database" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method clone_database" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
+
         if _params.get('kind') is not None:  # noqa: E501
             _query_params.append(('kind', _params['kind']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['database_clone']:
             _body_params = _params['database_clone']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -775,42 +892,52 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}:clone', 'POST',
+            '/api/v2/databases/{name}:clone',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def disable_database_failover(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Disable database failover.  # noqa: E501
+    @validate_call
+    def disable_database_failover(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            account_identifiers: Optional[AccountIdentifiers] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Disables database failover.  # noqa: E501
+
 
         Disables failover for this primary database, meaning no replica of this database (i.e. secondary database) can be promoted to serve as the primary database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_failover(name, account_identifiers, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -822,28 +949,37 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.disable_database_failover_with_http_info(name, account_identifiers, **kwargs)  # noqa: E501
+        return self.disable_database_failover_with_http_info(
+            name, account_identifiers, **kwargs)  # noqa: E501
+
+    @validate_call
+    def disable_database_failover_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            account_identifiers: Optional[AccountIdentifiers] = None,
+            **kwargs):  # noqa: E501
+        """Disables database failover.  # noqa: E501
 
-    @validate_arguments
-    def disable_database_failover_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs):  # noqa: E501
-        """Disable database failover.  # noqa: E501
 
         Disables failover for this primary database, meaning no replica of this database (i.e. secondary database) can be promoted to serve as the primary database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_failover_with_http_info(name, account_identifiers, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -865,44 +1001,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'account_identifiers'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'account_identifiers']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method disable_database_failover" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method disable_database_failover" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -910,27 +1036,28 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['account_identifiers']:
             _body_params = _params['account_identifiers']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -942,42 +1069,52 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}/failover:disable', 'POST',
+            '/api/v2/databases/{name}/failover:disable',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def disable_database_replication(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Disable database replication.  # noqa: E501
+    @validate_call
+    def disable_database_replication(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            account_identifiers: Optional[AccountIdentifiers] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Disables database replication.  # noqa: E501
+
 
         Disables replication for this primary database, meaning no replica of this database (i.e. secondary database) in another account can be refreshed. Any secondary databases remain linked to the primary database, but requests to refresh a secondary database are denied.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_replication(name, account_identifiers, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -989,28 +1126,37 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.disable_database_replication_with_http_info(name, account_identifiers, **kwargs)  # noqa: E501
+        return self.disable_database_replication_with_http_info(
+            name, account_identifiers, **kwargs)  # noqa: E501
+
+    @validate_call
+    def disable_database_replication_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            account_identifiers: Optional[AccountIdentifiers] = None,
+            **kwargs):  # noqa: E501
+        """Disables database replication.  # noqa: E501
 
-    @validate_arguments
-    def disable_database_replication_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : Optional[AccountIdentifiers] = None, **kwargs):  # noqa: E501
-        """Disable database replication.  # noqa: E501
 
         Disables replication for this primary database, meaning no replica of this database (i.e. secondary database) in another account can be refreshed. Any secondary databases remain linked to the primary database, but requests to refresh a secondary database are denied.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.disable_database_replication_with_http_info(name, account_identifiers, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers:
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -1032,44 +1178,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'account_identifiers'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'account_identifiers']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method disable_database_replication" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method disable_database_replication" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1077,27 +1213,28 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['account_identifiers']:
             _body_params = _params['account_identifiers']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -1109,42 +1246,50 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}/replication:disable', 'POST',
+            '/api/v2/databases/{name}/replication:disable',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def enable_database_failover(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Enable database failover.  # noqa: E501
+    @validate_call
+    def enable_database_failover(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                 account_identifiers: AccountIdentifiers,
+                                 **kwargs) -> SuccessResponse:  # noqa: E501
+        """Enables database failover.  # noqa: E501
+
 
         Specifies a comma-separated list of accounts in your organization where a replica of this primary database can be promoted to serve as the primary database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_failover(name, account_identifiers, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1156,28 +1301,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.enable_database_failover_with_http_info(name, account_identifiers, **kwargs)  # noqa: E501
+        return self.enable_database_failover_with_http_info(
+            name, account_identifiers, **kwargs)  # noqa: E501
+
+    @validate_call
+    def enable_database_failover_with_http_info(
+            self, name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            account_identifiers: AccountIdentifiers, **kwargs):  # noqa: E501
+        """Enables database failover.  # noqa: E501
 
-    @validate_arguments
-    def enable_database_failover_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, **kwargs):  # noqa: E501
-        """Enable database failover.  # noqa: E501
 
         Specifies a comma-separated list of accounts in your organization where a replica of this primary database can be promoted to serve as the primary database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_failover_with_http_info(name, account_identifiers, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -1199,44 +1351,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'account_identifiers'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'account_identifiers']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method enable_database_failover" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method enable_database_failover" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1244,27 +1386,28 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['account_identifiers']:
             _body_params = _params['account_identifiers']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -1276,46 +1419,63 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}/failover:enable', 'POST',
+            '/api/v2/databases/{name}/failover:enable',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def enable_database_replication(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, ignore_edition_check : Annotated[Optional[StrictBool], Field(description="Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Enable database replication.  # noqa: E501
+    @validate_call
+    def enable_database_replication(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            account_identifiers: AccountIdentifiers,
+            ignore_edition_check:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to allow replicating data to accounts on lower editions. Default: `true`. For more information, see the <a href=https://docs.snowflake.com/en/sql-reference/sql/alter-database> ALTER DATABASE</a> reference."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Enables database replication.  # noqa: E501
+
 
         Promotes a local database to serve as a primary database for replication. A primary database can be replicated in one or more accounts, allowing users in those accounts to query objects in each secondary (i.e. replica) database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_replication(name, account_identifiers, ignore_edition_check, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
-        :param ignore_edition_check: Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.
+        :param ignore_edition_check: Whether to allow replicating data to accounts on lower editions. Default: `true`. For more information, see the <a href=https://docs.snowflake.com/en/sql-reference/sql/alter-database> ALTER DATABASE</a> reference.
         :type ignore_edition_check: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1325,32 +1485,49 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.enable_database_replication_with_http_info(name, account_identifiers, ignore_edition_check, **kwargs)  # noqa: E501
+        return self.enable_database_replication_with_http_info(
+            name, account_identifiers, ignore_edition_check,
+            **kwargs)  # noqa: E501
+
+    @validate_call
+    def enable_database_replication_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            account_identifiers: AccountIdentifiers,
+            ignore_edition_check:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to allow replicating data to accounts on lower editions. Default: `true`. For more information, see the <a href=https://docs.snowflake.com/en/sql-reference/sql/alter-database> ALTER DATABASE</a> reference."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Enables database replication.  # noqa: E501
 
-    @validate_arguments
-    def enable_database_replication_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], account_identifiers : AccountIdentifiers, ignore_edition_check : Annotated[Optional[StrictBool], Field(description="Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.")] = None, **kwargs):  # noqa: E501
-        """Enable database replication.  # noqa: E501
 
         Promotes a local database to serve as a primary database for replication. A primary database can be replicated in one or more accounts, allowing users in those accounts to query objects in each secondary (i.e. replica) database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.enable_database_replication_with_http_info(name, account_identifiers, ignore_edition_check, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param account_identifiers: (required)
         :type account_identifiers: AccountIdentifiers
-        :param ignore_edition_check: Allows replicating data to accounts on lower editions. Please see https://docs.snowflake.com/en/sql-reference/sql/alter-database for full description.
+        :param ignore_edition_check: Whether to allow replicating data to accounts on lower editions. Default: `true`. For more information, see the <a href=https://docs.snowflake.com/en/sql-reference/sql/alter-database> ALTER DATABASE</a> reference.
         :type ignore_edition_check: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1370,75 +1547,67 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'account_identifiers',
-            'ignore_edition_check'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'account_identifiers', 'ignore_edition_check']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method enable_database_replication" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method enable_database_replication" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('ignore_edition_check') is not None:  # noqa: E501
-            _query_params.append(('ignore_edition_check', _params['ignore_edition_check']))
+            _query_params.append(
+                ('ignore_edition_check', _params['ignore_edition_check']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['account_identifiers']:
             _body_params = _params['account_identifiers']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -1450,42 +1619,49 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}/replication:enable', 'POST',
+            '/api/v2/databases/{name}/replication:enable',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Database:  # noqa: E501
+    @validate_call
+    def fetch_database(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                       **kwargs) -> Database:  # noqa: E501
         """fetch_database  # noqa: E501
 
-        Fetch a database.  # noqa: E501
+
+        Fetches a database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_database(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1497,26 +1673,31 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Database
         """
         kwargs['_return_http_data_only'] = True
         return self.fetch_database_with_http_info(name, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def fetch_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def fetch_database_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                      **kwargs):  # noqa: E501
         """fetch_database  # noqa: E501
 
-        Fetch a database.  # noqa: E501
+
+        Fetches a database.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_database_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1536,43 +1717,33 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(Database, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_database" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_database" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1602,48 +1773,88 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}', 'GET',
+            '/api/v2/databases/{name}',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def list_databases(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Optionally includes dropped databases that have not yet been purged.")] = None, **kwargs) -> Iterable[Database]:  # noqa: E501
-        """List databases  # noqa: E501
+    @validate_call
+    def list_databases(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            from_name:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name."
+            )] = None,
+            history:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Optionally includes dropped databases that have not yet been purged."
+            )] = None,
+            **kwargs) -> Iterable[Database]:  # noqa: E501
+        """Lists databases.  # noqa: E501
+
 
         Lists the accessible databases.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_databases(like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
-
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :param from_name: Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
         :type from_name: str
         :param history: Optionally includes dropped databases that have not yet been purged.
         :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1655,34 +1866,75 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Iterable[Database]
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_databases_with_http_info(like, starts_with, show_limit, from_name, history, **kwargs)  # noqa: E501
+        return self.list_databases_with_http_info(like, starts_with,
+                                                  show_limit, from_name,
+                                                  history,
+                                                  **kwargs)  # noqa: E501
+
+    @validate_call
+    def list_databases_with_http_info(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            from_name:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name."
+            )] = None,
+            history:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Optionally includes dropped databases that have not yet been purged."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Lists databases.  # noqa: E501
 
-    @validate_arguments
-    def list_databases_with_http_info(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Optionally includes dropped databases that have not yet been purged.")] = None, **kwargs):  # noqa: E501
-        """List databases  # noqa: E501
 
         Lists the accessible databases.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_databases_with_http_info(like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
-
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :param from_name: Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
         :type from_name: str
         :param history: Optionally includes dropped databases that have not yet been purged.
         :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -1705,57 +1957,49 @@
                  returns the request thread.
         :rtype: tuple(Iterable[Database], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'like',
-            'starts_with',
-            'show_limit',
-            'from_name',
-            'history'
+            'like', 'starts_with', 'show_limit', 'from_name', 'history'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method list_databases" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method list_databases" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
 
         # process the query parameters
         _query_params = []
+
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
+
         if _params.get('starts_with') is not None:  # noqa: E501
             _query_params.append(('startsWith', _params['starts_with']))
+
         if _params.get('show_limit') is not None:  # noqa: E501
             _query_params.append(('showLimit', _params['show_limit']))
+
         if _params.get('from_name') is not None:  # noqa: E501
             _query_params.append(('fromName', _params['from_name']))
+
         if _params.get('history') is not None:  # noqa: E501
             _query_params.append(('history', _params['history']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -1782,42 +2026,49 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases', 'GET',
+            '/api/v2/databases',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def primary_database_failover(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
-        """Set database as primary.  # noqa: E501
+    @validate_call
+    def primary_database_failover(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                  **kwargs) -> SuccessResponse:  # noqa: E501
+        """Sets a primary database.  # noqa: E501
+
+
+        Promotes the specified secondary (replica) database to serve as the primary database. When promoted, the database becomes writeable. At the same time, the previous primary database becomes a read-only secondary database.  # noqa: E501
 
-        Promotes the specified secondary (replica) database to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.primary_database_failover(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1827,28 +2078,34 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.primary_database_failover_with_http_info(name, **kwargs)  # noqa: E501
+        return self.primary_database_failover_with_http_info(
+            name, **kwargs)  # noqa: E501
+
+    @validate_call
+    def primary_database_failover_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                                 **kwargs):  # noqa: E501
+        """Sets a primary database.  # noqa: E501
+
 
-    @validate_arguments
-    def primary_database_failover_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Set database as primary.  # noqa: E501
+        Promotes the specified secondary (replica) database to serve as the primary database. When promoted, the database becomes writeable. At the same time, the previous primary database becomes a read-only secondary database.  # noqa: E501
 
-        Promotes the specified secondary (replica) database to serve as the primary database.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.primary_database_failover_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1868,43 +2125,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method primary_database_failover" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method primary_database_failover" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1935,42 +2183,50 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}/failover:primary', 'POST',
+            '/api/v2/databases/{name}/failover:primary',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def refresh_database_replication(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
-        """Refresh database replications.  # noqa: E501
+    @validate_call
+    def refresh_database_replication(
+            self, name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Refreshes database replications.  # noqa: E501
+
+
+        Refreshes a secondary database from a snapshot of its primary database. A snapshot includes changes to the objects and data. If you call this endpoint while another refresh for the same replica database is running, it fails and returns an error. Snowflake ensures only one refresh is executed at any given time.  # noqa: E501
 
-        Refreshes a secondary database from a snapshot of its primary database. A snapshot includes changes to the objects and data.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.refresh_database_replication(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1980,28 +2236,34 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.refresh_database_replication_with_http_info(name, **kwargs)  # noqa: E501
+        return self.refresh_database_replication_with_http_info(
+            name, **kwargs)  # noqa: E501
+
+    @validate_call
+    def refresh_database_replication_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                                    **kwargs):  # noqa: E501
+        """Refreshes database replications.  # noqa: E501
+
 
-    @validate_arguments
-    def refresh_database_replication_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Refresh database replications.  # noqa: E501
+        Refreshes a secondary database from a snapshot of its primary database. A snapshot includes changes to the objects and data. If you call this endpoint while another refresh for the same replica database is running, it fails and returns an error. Snowflake ensures only one refresh is executed at any given time.  # noqa: E501
 
-        Refreshes a secondary database from a snapshot of its primary database. A snapshot includes changes to the objects and data.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.refresh_database_replication_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -2021,43 +2283,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method refresh_database_replication" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method refresh_database_replication" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -2088,46 +2341,69 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}/replication:refresh', 'POST',
+            '/api/v2/databases/{name}/replication:refresh',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def delete_database(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a database.  # noqa: E501
+    @validate_call
+    def delete_database(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            restrict:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to drop the database if foreign keys exist that reference any tables in the database. - `true`: Return a warning about existing foreign key references and don't drop the database. - `false`: Drop the database and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Deletes a database.  # noqa: E501
+
+
+        Deletes the specified database. If you enable the `ifExists` parameter, the operation succeeds even if the database does not exist. Otherwise, a 404 failure is returned if the database does not exist. if the drop is unsuccessful.  # noqa: E501
 
-        Delete a database with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_database(name, if_exists, restrict, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
-        :param restrict: Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :param restrict: Whether to drop the database if foreign keys exist that reference any tables in the database. - `true`: Return a warning about existing foreign key references and don't drop the database. - `false`: Drop the database and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables.
         :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -2137,32 +2413,54 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_database_with_http_info(name, if_exists, restrict, **kwargs)  # noqa: E501
+        return self.delete_database_with_http_info(name, if_exists, restrict,
+                                                   **kwargs)  # noqa: E501
+
+    @validate_call
+    def delete_database_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            restrict:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to drop the database if foreign keys exist that reference any tables in the database. - `true`: Return a warning about existing foreign key references and don't drop the database. - `false`: Drop the database and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Deletes a database.  # noqa: E501
+
 
-    @validate_arguments
-    def delete_database_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs):  # noqa: E501
-        """Delete a database.  # noqa: E501
+        Deletes the specified database. If you enable the `ifExists` parameter, the operation succeeds even if the database does not exist. Otherwise, a 404 failure is returned if the database does not exist. if the drop is unsuccessful.  # noqa: E501
 
-        Delete a database with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_database_with_http_info(name, if_exists, restrict, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
-        :param restrict: Specifies whether the database should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :param restrict: Whether to drop the database if foreign keys exist that reference any tables in the database. - `true`: Return a warning about existing foreign key references and don't drop the database. - `false`: Drop the database and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables.
         :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -2182,52 +2480,42 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'if_exists',
-            'restrict'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'if_exists', 'restrict']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method delete_database" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method delete_database" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
+
         if _params.get('restrict') is not None:  # noqa: E501
             _query_params.append(('restrict', _params['restrict']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -2254,22 +2542,24 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{name}', 'DELETE',
+            '/api/v2/databases/{name}',
+            'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,20 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Database API
 
+    Snowflake Database API
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.database._generated.models.account_identifiers import AccountIdentifiers
 from snowflake.core.database._generated.models.database import Database
 from snowflake.core.database._generated.models.database_clone import DatabaseClone
 from snowflake.core.database._generated.models.error_response import ErrorResponse
@@ -33,8 +30,8 @@
     'DatabaseClone',
     'ErrorResponse',
     'PointOfTime',
     'PointOfTimeOffset',
     'PointOfTimeStatement',
     'PointOfTimeTimestamp',
     'SuccessResponse',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/account_identifiers.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/account_identifiers.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,39 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
 
+    Snowflake Database API
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import List
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, conlist, constr
+
+from pydantic import BaseModel, ConfigDict, Field
+
+from typing import Any, ClassVar, Dict, List
+
+from typing_extensions import Annotated
+
 
 class AccountIdentifiers(BaseModel):
-    accounts: conlist(constr(strict=True, min_length=1)) = Field(...)
-    __properties = ["accounts"]
 
+    accounts: List[Annotated[str, Field(min_length=1, strict=True)]]
+
+    __properties = ["accounts"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +44,60 @@
     @classmethod
     def from_json(cls, json_str: str) -> AccountIdentifiers:
         """Create an instance of AccountIdentifiers from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> AccountIdentifiers:
         """Create an instance of AccountIdentifiers from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return AccountIdentifiers.parse_obj(obj)
 
         _obj = AccountIdentifiers.parse_obj({
             "accounts": obj.get("accounts"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class AccountIdentifiersModel():
+
     def __init__(
         self,
         accounts: List[str],
         # optional properties
     ):
+
         self.accounts = accounts
+
     __properties = ["accounts"]
 
     def _to_model(self):
-        return AccountIdentifiers(
-            accounts=self.accounts,
-
-        )
+        return AccountIdentifiers(accounts=self.accounts, )
 
     @classmethod
     def _from_model(cls, model) -> AccountIdentifiersModel:
-        return AccountIdentifiersModel(
-            accounts=model.accounts,
-
-        )
+        return AccountIdentifiersModel(accounts=model.accounts, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> AccountIdentifiersModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/schema_clone.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,307 +1,336 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Optional
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
 
-class Database(BaseModel):
+from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
+
+class SchemaClone(BaseModel):
+
+    point_of_time: Optional[PointOfTime] = None
+
     created_on: Optional[datetime] = None
-    name: constr(strict=True) = Field(...)
+
+    name: Annotated[str, Field(strict=True)]
+
     is_default: Optional[StrictBool] = None
+
     is_current: Optional[StrictBool] = None
-    origin: Optional[StrictStr] = None
+
+    database_name: Optional[StrictStr] = None
+
     owner: Optional[StrictStr] = None
+
     comment: Optional[StrictStr] = None
+
     options: Optional[StrictStr] = None
+
     retention_time: Optional[StrictInt] = None
+
     dropped_on: Optional[datetime] = None
-    kind: Optional[StrictStr] = None
-    budget: Optional[StrictStr] = None
+
     owner_role_type: Optional[StrictStr] = None
+
+    budget: Optional[StrictStr] = None
+
     data_retention_time_in_days: Optional[StrictInt] = None
+
     default_ddl_collation: Optional[StrictStr] = None
+
     log_level: Optional[StrictStr] = None
+
+    pipe_execution_paused: Optional[StrictBool] = None
+
     max_data_extension_time_in_days: Optional[StrictInt] = None
+
     suspend_task_after_num_failures: Optional[StrictInt] = None
+
     trace_level: Optional[StrictStr] = None
+
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
+
     user_task_timeout_ms: Optional[StrictInt] = None
-    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "database_name",
+        "owner", "comment", "options", "retention_time", "dropped_on",
+        "owner_role_type", "budget", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level", "pipe_execution_paused",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> Database:
-        """Create an instance of Database from a JSON string"""
+    def from_json(cls, json_str: str) -> SchemaClone:
+        """Create an instance of SchemaClone from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "created_on",
-                            "is_default",
-                            "is_current",
-                            "origin",
-                            "owner",
-                            "options",
-                            "retention_time",
-                            "dropped_on",
-                            "kind",
-                            "budget",
-                            "owner_role_type",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "is_default",
+                           "is_current",
+                           "database_name",
+                           "owner",
+                           "options",
+                           "retention_time",
+                           "dropped_on",
+                           "owner_role_type",
+                           "budget",
+                       },
+                       exclude_none=True))
+
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Database:
-        """Create an instance of Database from a dict"""
+    def from_dict(cls, obj: dict) -> SchemaClone:
+        """Create an instance of SchemaClone from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
-            return Database.parse_obj(obj)
-
-        _obj = Database.parse_obj({
-            "created_on": obj.get("created_on"),
-
-            "name": obj.get("name"),
-
-            "is_default": obj.get("is_default"),
-
-            "is_current": obj.get("is_current"),
-
-            "origin": obj.get("origin"),
+            return SchemaClone.parse_obj(obj)
 
-            "owner": obj.get("owner"),
-
-            "comment": obj.get("comment"),
-
-            "options": obj.get("options"),
-
-            "retention_time": obj.get("retention_time"),
-
-            "dropped_on": obj.get("dropped_on"),
-
-            "kind": obj.get("kind"),
-
-            "budget": obj.get("budget"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
-            "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
-
-            "default_ddl_collation": obj.get("default_ddl_collation"),
-
-            "log_level": obj.get("log_level"),
-
-            "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
-
-            "suspend_task_after_num_failures": obj.get("suspend_task_after_num_failures"),
+        _obj = SchemaClone.parse_obj({
+            "point_of_time":
+            PointOfTime.from_dict(obj.get("point_of_time"))
+            if obj.get("point_of_time") is not None else None,
+            "created_on":
+            obj.get("created_on"),
+            "name":
+            obj.get("name"),
+            "is_default":
+            obj.get("is_default"),
+            "is_current":
+            obj.get("is_current"),
+            "database_name":
+            obj.get("database_name"),
+            "owner":
+            obj.get("owner"),
+            "comment":
+            obj.get("comment"),
+            "options":
+            obj.get("options"),
+            "retention_time":
+            obj.get("retention_time"),
+            "dropped_on":
+            obj.get("dropped_on"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
+            "budget":
+            obj.get("budget"),
+            "data_retention_time_in_days":
+            obj.get("data_retention_time_in_days"),
+            "default_ddl_collation":
+            obj.get("default_ddl_collation"),
+            "log_level":
+            obj.get("log_level"),
+            "pipe_execution_paused":
+            obj.get("pipe_execution_paused"),
+            "max_data_extension_time_in_days":
+            obj.get("max_data_extension_time_in_days"),
+            "suspend_task_after_num_failures":
+            obj.get("suspend_task_after_num_failures"),
+            "trace_level":
+            obj.get("trace_level"),
+            "user_task_managed_initial_warehouse_size":
+            obj.get("user_task_managed_initial_warehouse_size"),
+            "user_task_timeout_ms":
+            obj.get("user_task_timeout_ms"),
+        })
 
-            "trace_level": obj.get("trace_level"),
+        return _obj
 
-            "user_task_managed_initial_warehouse_size": obj.get("user_task_managed_initial_warehouse_size"),
 
-            "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
+from typing import Optional, List, Dict
 
-        })
-        return _obj
+from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
 
-from typing import Optional, List, Dict
+class SchemaCloneModel():
 
-class DatabaseModel():
     def __init__(
         self,
         name: str,
         # optional properties
+        point_of_time: Optional[PointOfTime] = None,
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
         is_current: Optional[bool] = None,
-        origin: Optional[str] = None,
+        database_name: Optional[str] = None,
         owner: Optional[str] = None,
         comment: Optional[str] = None,
         options: Optional[str] = None,
         retention_time: Optional[int] = None,
         dropped_on: Optional[datetime] = None,
-        kind: Optional[str] = None,
-        budget: Optional[str] = None,
         owner_role_type: Optional[str] = None,
+        budget: Optional[str] = None,
         data_retention_time_in_days: Optional[int] = None,
         default_ddl_collation: Optional[str] = None,
         log_level: Optional[str] = None,
+        pipe_execution_paused: Optional[bool] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
+
+        self.point_of_time = point_of_time
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
-        self.origin = origin
+        self.database_name = database_name
         self.owner = owner
         self.comment = comment
         self.options = options
         self.retention_time = retention_time
         self.dropped_on = dropped_on
-        self.kind = kind
-        self.budget = budget
         self.owner_role_type = owner_role_type
+        self.budget = budget
         self.data_retention_time_in_days = data_retention_time_in_days
         self.default_ddl_collation = default_ddl_collation
         self.log_level = log_level
+        self.pipe_execution_paused = pipe_execution_paused
         self.max_data_extension_time_in_days = max_data_extension_time_in_days
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
-    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
+
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "database_name",
+        "owner", "comment", "options", "retention_time", "dropped_on",
+        "owner_role_type", "budget", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level", "pipe_execution_paused",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
     def _to_model(self):
-        return Database(
+        return SchemaClone(
+            point_of_time=self.point_of_time._to_model()
+            if self.point_of_time is not None else None,
             created_on=self.created_on,
-
             name=self.name,
-
             is_default=self.is_default,
-
             is_current=self.is_current,
-
-            origin=self.origin,
-
+            database_name=self.database_name,
             owner=self.owner,
-
             comment=self.comment,
-
             options=self.options,
-
             retention_time=self.retention_time,
-
             dropped_on=self.dropped_on,
-
-            kind=self.kind,
-
-            budget=self.budget,
-
             owner_role_type=self.owner_role_type,
-
+            budget=self.budget,
             data_retention_time_in_days=self.data_retention_time_in_days,
-
             default_ddl_collation=self.default_ddl_collation,
-
             log_level=self.log_level,
-
-            max_data_extension_time_in_days=self.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=self.suspend_task_after_num_failures,
-
+            pipe_execution_paused=self.pipe_execution_paused,
+            max_data_extension_time_in_days=self.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=self.
+            suspend_task_after_num_failures,
             trace_level=self.trace_level,
-
-            user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=self.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=self.user_task_timeout_ms,
-
         )
 
     @classmethod
-    def _from_model(cls, model) -> DatabaseModel:
-        return DatabaseModel(
+    def _from_model(cls, model) -> SchemaCloneModel:
+        return SchemaCloneModel(
+            point_of_time=PointOfTimeModel._from_model(model.point_of_time)
+            if model.point_of_time is not None else None,
             created_on=model.created_on,
-
             name=model.name,
-
             is_default=model.is_default,
-
             is_current=model.is_current,
-
-            origin=model.origin,
-
+            database_name=model.database_name,
             owner=model.owner,
-
             comment=model.comment,
-
             options=model.options,
-
             retention_time=model.retention_time,
-
             dropped_on=model.dropped_on,
-
-            kind=model.kind,
-
-            budget=model.budget,
-
             owner_role_type=model.owner_role_type,
-
+            budget=model.budget,
             data_retention_time_in_days=model.data_retention_time_in_days,
-
             default_ddl_collation=model.default_ddl_collation,
-
             log_level=model.log_level,
-
-            max_data_extension_time_in_days=model.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=model.suspend_task_after_num_failures,
-
+            pipe_execution_paused=model.pipe_execution_paused,
+            max_data_extension_time_in_days=model.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=model.
+            suspend_task_after_num_failures,
             trace_level=model.trace_level,
-
-            user_task_managed_initial_warehouse_size=model.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=model.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=model.user_task_timeout_ms,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> DatabaseModel:
-        """Create an instance of Database from a dict"""
-        return cls._from_model(Database.from_dict(obj))
+    def from_dict(cls, obj: dict) -> SchemaCloneModel:
+        """Create an instance of SchemaClone from a dict"""
+        return cls._from_model(SchemaClone.from_dict(obj))
 
 
-Database._model_class = DatabaseModel
+SchemaClone._model_class = SchemaCloneModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/database_clone.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/database_clone.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,67 +1,103 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
 
+    Snowflake Database API
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Optional
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+
 from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
+
 class DatabaseClone(BaseModel):
+
     point_of_time: Optional[PointOfTime] = None
+
     created_on: Optional[datetime] = None
-    name: constr(strict=True) = Field(...)
+
+    name: Annotated[str, Field(strict=True)]
+
     is_default: Optional[StrictBool] = None
+
     is_current: Optional[StrictBool] = None
+
     origin: Optional[StrictStr] = None
+
     owner: Optional[StrictStr] = None
+
     comment: Optional[StrictStr] = None
+
     options: Optional[StrictStr] = None
+
     retention_time: Optional[StrictInt] = None
+
     dropped_on: Optional[datetime] = None
+
     kind: Optional[StrictStr] = None
+
     budget: Optional[StrictStr] = None
+
     owner_role_type: Optional[StrictStr] = None
+
     data_retention_time_in_days: Optional[StrictInt] = None
+
     default_ddl_collation: Optional[StrictStr] = None
+
     log_level: Optional[StrictStr] = None
+
     max_data_extension_time_in_days: Optional[StrictInt] = None
+
     suspend_task_after_num_failures: Optional[StrictInt] = None
+
     trace_level: Optional[StrictStr] = None
+
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
+
     user_task_timeout_ms: Optional[StrictInt] = None
-    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "origin", "owner",
+        "comment", "options", "retention_time", "dropped_on", "kind", "budget",
+        "owner_role_type", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -71,97 +107,106 @@
     @classmethod
     def from_json(cls, json_str: str) -> DatabaseClone:
         """Create an instance of DatabaseClone from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "created_on",
-                            "is_default",
-                            "is_current",
-                            "origin",
-                            "owner",
-                            "options",
-                            "retention_time",
-                            "dropped_on",
-                            "kind",
-                            "budget",
-                            "owner_role_type",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "is_default",
+                           "is_current",
+                           "origin",
+                           "owner",
+                           "options",
+                           "retention_time",
+                           "dropped_on",
+                           "kind",
+                           "budget",
+                           "owner_role_type",
+                       },
+                       exclude_none=True))
+
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> DatabaseClone:
         """Create an instance of DatabaseClone from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return DatabaseClone.parse_obj(obj)
 
         _obj = DatabaseClone.parse_obj({
-            "point_of_time": PointOfTime.from_dict(obj.get("point_of_time")) if obj.get("point_of_time") is not None else None,
-
-            "created_on": obj.get("created_on"),
-
-            "name": obj.get("name"),
-
-            "is_default": obj.get("is_default"),
-
-            "is_current": obj.get("is_current"),
-
-            "origin": obj.get("origin"),
-
-            "owner": obj.get("owner"),
-
-            "comment": obj.get("comment"),
-
-            "options": obj.get("options"),
-
-            "retention_time": obj.get("retention_time"),
-
-            "dropped_on": obj.get("dropped_on"),
-
-            "kind": obj.get("kind"),
-
-            "budget": obj.get("budget"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
-            "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
-
-            "default_ddl_collation": obj.get("default_ddl_collation"),
-
-            "log_level": obj.get("log_level"),
-
-            "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
-
-            "suspend_task_after_num_failures": obj.get("suspend_task_after_num_failures"),
-
-            "trace_level": obj.get("trace_level"),
-
-            "user_task_managed_initial_warehouse_size": obj.get("user_task_managed_initial_warehouse_size"),
-
-            "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
-
+            "point_of_time":
+            PointOfTime.from_dict(obj.get("point_of_time"))
+            if obj.get("point_of_time") is not None else None,
+            "created_on":
+            obj.get("created_on"),
+            "name":
+            obj.get("name"),
+            "is_default":
+            obj.get("is_default"),
+            "is_current":
+            obj.get("is_current"),
+            "origin":
+            obj.get("origin"),
+            "owner":
+            obj.get("owner"),
+            "comment":
+            obj.get("comment"),
+            "options":
+            obj.get("options"),
+            "retention_time":
+            obj.get("retention_time"),
+            "dropped_on":
+            obj.get("dropped_on"),
+            "kind":
+            obj.get("kind"),
+            "budget":
+            obj.get("budget"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
+            "data_retention_time_in_days":
+            obj.get("data_retention_time_in_days"),
+            "default_ddl_collation":
+            obj.get("default_ddl_collation"),
+            "log_level":
+            obj.get("log_level"),
+            "max_data_extension_time_in_days":
+            obj.get("max_data_extension_time_in_days"),
+            "suspend_task_after_num_failures":
+            obj.get("suspend_task_after_num_failures"),
+            "trace_level":
+            obj.get("trace_level"),
+            "user_task_managed_initial_warehouse_size":
+            obj.get("user_task_managed_initial_warehouse_size"),
+            "user_task_timeout_ms":
+            obj.get("user_task_timeout_ms"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
+
 class DatabaseCloneModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
         point_of_time: Optional[PointOfTime] = None,
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
@@ -180,14 +225,15 @@
         log_level: Optional[str] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
+
         self.point_of_time = point_of_time
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
         self.origin = origin
         self.owner = owner
@@ -202,111 +248,84 @@
         self.default_ddl_collation = default_ddl_collation
         self.log_level = log_level
         self.max_data_extension_time_in_days = max_data_extension_time_in_days
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
-    __properties = ["created_on", "name", "is_default", "is_current", "origin", "owner", "comment", "options", "retention_time", "dropped_on", "kind", "budget", "owner_role_type", "data_retention_time_in_days", "default_ddl_collation", "log_level", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
+
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "origin", "owner",
+        "comment", "options", "retention_time", "dropped_on", "kind", "budget",
+        "owner_role_type", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
     def _to_model(self):
         return DatabaseClone(
-            point_of_time=self.point_of_time._to_model() if self.point_of_time is not None else None,
-
+            point_of_time=self.point_of_time._to_model()
+            if self.point_of_time is not None else None,
             created_on=self.created_on,
-
             name=self.name,
-
             is_default=self.is_default,
-
             is_current=self.is_current,
-
             origin=self.origin,
-
             owner=self.owner,
-
             comment=self.comment,
-
             options=self.options,
-
             retention_time=self.retention_time,
-
             dropped_on=self.dropped_on,
-
             kind=self.kind,
-
             budget=self.budget,
-
             owner_role_type=self.owner_role_type,
-
             data_retention_time_in_days=self.data_retention_time_in_days,
-
             default_ddl_collation=self.default_ddl_collation,
-
             log_level=self.log_level,
-
-            max_data_extension_time_in_days=self.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=self.suspend_task_after_num_failures,
-
+            max_data_extension_time_in_days=self.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=self.
+            suspend_task_after_num_failures,
             trace_level=self.trace_level,
-
-            user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=self.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=self.user_task_timeout_ms,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> DatabaseCloneModel:
         return DatabaseCloneModel(
-            point_of_time=PointOfTimeModel._from_model(model.point_of_time) if model.point_of_time is not None else None,
-
+            point_of_time=PointOfTimeModel._from_model(model.point_of_time)
+            if model.point_of_time is not None else None,
             created_on=model.created_on,
-
             name=model.name,
-
             is_default=model.is_default,
-
             is_current=model.is_current,
-
             origin=model.origin,
-
             owner=model.owner,
-
             comment=model.comment,
-
             options=model.options,
-
             retention_time=model.retention_time,
-
             dropped_on=model.dropped_on,
-
             kind=model.kind,
-
             budget=model.budget,
-
             owner_role_type=model.owner_role_type,
-
             data_retention_time_in_days=model.data_retention_time_in_days,
-
             default_ddl_collation=model.default_ddl_collation,
-
             log_level=model.log_level,
-
-            max_data_extension_time_in_days=model.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=model.suspend_task_after_num_failures,
-
+            max_data_extension_time_in_days=model.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=model.
+            suspend_task_after_num_failures,
             trace_level=model.trace_level,
-
-            user_task_managed_initial_warehouse_size=model.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=model.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=model.user_task_timeout_ms,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/error_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Session API
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,138 +1,152 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Table API
+    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
-import snowflake.core.database._generated.models
-from snowflake.core.database._generated.models import *
 
+import snowflake.core.table._generated.models
+from snowflake.core.table._generated.models import *
 
-from typing import Optional, Union
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import BaseModel, Field, StrictStr
+
+from importlib import import_module
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional, Union
+
 
 class PointOfTime(BaseModel):
-    point_of_time_type: StrictStr = Field(...)
+
+    point_of_time_type: StrictStr
+
     reference: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     # JSON field name that stores the object type
-    __discriminator_property_name = 'point_of_time_type'
+    __discriminator_property_name: ClassVar[str] = 'point_of_time_type'
 
     # discriminator mappings
-    __discriminator_value_class_map = {
+    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
         'offset': 'PointOfTimeOffset',
         'statement': 'PointOfTimeStatement',
         'timestamp': 'PointOfTimeTimestamp'
     }
 
     @classmethod
-    def get_discriminator_value(cls, obj: dict) -> str:
+    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
         """Returns the discriminator value (object type) of the data"""
         discriminator_value = obj[cls.__discriminator_property_name]
         if discriminator_value:
             return cls.__discriminator_value_class_map.get(discriminator_value)
         else:
             return None
 
-
-    __discriminator_value_to_type = {
+    __discriminator_value_to_type: ClassVar[Dict[str, str]] = {
         'PointOfTimeOffset': 'offset',
         'PointOfTimeStatement': 'statement',
         'PointOfTimeTimestamp': 'timestamp',
     }
 
     @classmethod
     def get_child_model_discriminator_value(cls, child_model: str) -> str:
         return cls.__discriminator_value_to_type[child_model]
 
-
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
+    def from_json(
+        cls, json_str: str
+    ) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
         """Create an instance of PointOfTime from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
+    def from_dict(
+        cls, obj: dict
+    ) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
         """Create an instance of PointOfTime from a dict"""
+
         # look up the object type based on discriminator mapping
         object_type = cls.get_discriminator_value(obj)
         if object_type:
-            klass = getattr(snowflake.core.database._generated.models, object_type)
+            klass = getattr(snowflake.core.table._generated.models,
+                            object_type)
             return klass.from_dict(obj)
         else:
-            raise ValueError("PointOfTime failed to lookup discriminator value from " +
-                             json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
-                             ", mapping: " + json.dumps(cls.__discriminator_value_class_map))
+            raise ValueError(
+                "PointOfTime failed to lookup discriminator value from " +
+                json.dumps(obj) + ". Discriminator property name: " +
+                cls.__discriminator_property_name + ", mapping: " +
+                json.dumps(cls.__discriminator_value_class_map))
 
 
 from typing import Optional, List, Dict
 
+
 class PointOfTimeModel():
+
     def __init__(
         self,
         point_of_time_type: str,
         # optional properties
         reference: Optional[str] = None,
     ):
+
         self.point_of_time_type = point_of_time_type
         self.reference = reference
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
-        return PointOfTime(
-            
-            reference=self.reference,
-
-        )
+        return PointOfTime(reference=self.reference, )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeModel:
         return model.__class__._model_class._from_model(model)
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union(PointOfTimeOffsetModel, PointOfTimeStatementModel, PointOfTimeTimestampModel):
+    def from_dict(
+        cls, obj: dict
+    ) -> Union[PointOfTimeOffsetModel, PointOfTimeStatementModel,
+               PointOfTimeTimestampModel]:
         """Create an instance of PointOfTime from a dict"""
         return cls._from_model(PointOfTime.from_dict(obj))
 
 
 PointOfTime._model_class = PointOfTimeModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_offset.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time_offset.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
 
+    Snowflake Database API
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import StrictStr
+
 from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class PointOfTimeOffset(PointOfTime):
+
     offset: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeOffset:
         """Create an instance of PointOfTimeOffset from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeOffset')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeOffset')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeOffset:
         """Create an instance of PointOfTimeOffset from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeOffset.parse_obj(obj)
 
         _obj = PointOfTimeOffset.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "offset": obj.get("offset"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "offset":
+            obj.get("offset"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.database._generated.models.point_of_time import PointOfTime
 
+
 class PointOfTimeOffsetModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         offset: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.offset = offset
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeOffset(
-            
             reference=self.reference,
-
             offset=self.offset,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeOffsetModel:
         return PointOfTimeOffsetModel(
-            
             reference=model.reference,
-
             offset=model.offset,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_statement.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time_statement.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Table API
+    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import StrictStr
-from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.table._generated.models.point_of_time import PointOfTime
+
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class PointOfTimeStatement(PointOfTime):
+
     statement: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeStatement:
         """Create an instance of PointOfTimeStatement from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeStatement')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeStatement')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeStatement:
         """Create an instance of PointOfTimeStatement from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeStatement.parse_obj(obj)
 
         _obj = PointOfTimeStatement.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "statement": obj.get("statement"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "statement":
+            obj.get("statement"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.table._generated.models.point_of_time import PointOfTime
+
 
 class PointOfTimeStatementModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         statement: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.statement = statement
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeStatement(
-            
             reference=self.reference,
-
             statement=self.statement,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeStatementModel:
         return PointOfTimeStatementModel(
-            
             reference=model.reference,
-
             statement=model.statement,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
-
-    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import StrictStr
-from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class PointOfTimeTimestamp(PointOfTime):
+
     timestamp: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeTimestamp:
         """Create an instance of PointOfTimeTimestamp from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeTimestamp')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeTimestamp')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeTimestamp:
         """Create an instance of PointOfTimeTimestamp from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeTimestamp.parse_obj(obj)
 
         _obj = PointOfTimeTimestamp.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "timestamp": obj.get("timestamp"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "timestamp":
+            obj.get("timestamp"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+
 
 class PointOfTimeTimestampModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         timestamp: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.timestamp = timestamp
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeTimestamp(
-            
             reference=self.reference,
-
             timestamp=self.timestamp,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeTimestampModel:
         return PointOfTimeTimestampModel(
-            
             reference=model.reference,
-
             timestamp=model.timestamp,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/database/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/success_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Database API
 
+    Snowflake Database API
     The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.database._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_image_repository.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_image_repository.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,16 +1,17 @@
 from typing import TYPE_CHECKING, Iterator, Optional
 
+from pydantic import StrictStr
+
 from snowflake.core._common import (
     CreateMode,
     SchemaObjectCollectionParent,
     SchemaObjectReferenceMixin,
 )
 from snowflake.core._internal.telemetry import api_telemetry
-from snowflake.core.image_repository._generated.pydantic_compatibility import StrictStr
 
 
 if TYPE_CHECKING:
     from snowflake.core.schema import SchemaResource
 
 
 from snowflake.core.image_repository._generated import ImageRepositoryApi
@@ -106,7 +107,15 @@
 
     @api_telemetry
     def delete(self) -> None:
         """Delete the image repository from Snowflake."""
         self.collection._api.delete_image_repository(
             self.database.name, self.schema.name, self.name, async_req=False
         )
+
+    @api_telemetry
+    def list_images_in_repository(self) -> Iterator[str]:
+        """List images in the image repository from Snowflake."""
+        images = self.collection._api.list_images_in_repository(
+            self.database.name, self.schema.name, self.name, async_req=False
+        )
+        return iter([]) if images.images is None else iter(images.images)
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,31 +1,27 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Image Repository API
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform common actions on Image Repository resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
-__version__ = "1.0.0"
-
-# import apis into sdk package
-from snowflake.core.image_repository._generated.api.image_repository_api import ImageRepositoryApi
-
-# import ApiClient
-from snowflake.core.image_repository._generated.api_client import ApiClient
-from snowflake.core.image_repository._generated.configuration import Configuration
-# import models into sdk package
+# import models into model package
 from snowflake.core.image_repository._generated.models.error_response import ErrorResponse
 from snowflake.core.image_repository._generated.models.image_repository import ImageRepository
+from snowflake.core.image_repository._generated.models.list_images_in_repository200_response import ListImagesInRepository200Response
 from snowflake.core.image_repository._generated.models.success_response import SuccessResponse
+
+__all__ = [
+    'ErrorResponse',
+    'ImageRepository',
+    'ListImagesInRepository200Response',
+    'SuccessResponse',
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/api_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Warehouse API
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.image_repository._generated.configuration import Configuration
-import snowflake.core.image_repository._generated.models
-from snowflake.core.image_repository._generated import rest
-from snowflake.core.image_repository._generated.paging import PagedIter
+from snowflake.core.warehouse._generated.configuration import Configuration
+import snowflake.core.warehouse._generated.models
+from snowflake.core.warehouse._generated import rest
+from snowflake.core.warehouse._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,62 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.image_repository._generated.models, klass)
+                klass = getattr(snowflake.core.warehouse._generated.models,
+                                klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +520,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +671,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for image_repository. Updating image_repository '
-                        'objects is not supported yet; use create() for creating a image_repository.')
+                        'create_or_update is not yet supported for warehouse. Updating warehouse '
+                        'objects is not supported yet; use create() for creating a warehouse.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +700,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +743,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +787,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +824,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +848,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +875,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +941,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +959,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +975,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1010,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/function/_generated/api_response.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.image_repository._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Image Repository API
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform common actions on Image Repository resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.image_repository._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.image_repository._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Image Repository API",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake Image Repository API",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/function/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/rest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Image Repository API
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform common actions on Image Repository resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/api/image_repository_api.py` & `snowflake_core-0.8.1/src/snowflake/core/user/_generated/api/user_api.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,85 +1,80 @@
 # coding: utf-8
-
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake User API
+    The Snowflake User API is a REST API that you can use to access, update, and perform certain action on Users in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictStr, constr, validator
-
+from pydantic import Field, StrictBool, StrictInt, StrictStr, field_validator
 from typing import List, Optional
-
-from snowflake.core.image_repository._generated.models.image_repository import ImageRepository
-from snowflake.core.image_repository._generated.models.success_response import SuccessResponse
+from typing_extensions import Annotated
+from snowflake.core.user._generated.models.success_response import SuccessResponse
+from snowflake.core.user._generated.models.user import User
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.image_repository._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
 
-logger  = logging.getLogger(__name__)
+logger = logging.getLogger(__name__)
 
-class ImageRepositoryApi(object):
+
+class UserApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
     def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._resource_name = 'image_repository'
+        self._resource_name = 'user'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
         self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
             new_chosen_client is the client we want to choose under the current situation ( value of
             _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        from snowflake.core.image_repository._generated.api_client import ApiClient
+        from snowflake.core.user._generated.api_client import ApiClient
 
         # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
         def _get_rest_client():
             if is_running_inside_stored_procedure():
                 return self._sproc_client, ApiClientType.STORED_PROC
             else:
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('image_repository')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge('user')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -91,35 +86,43 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_image_repository(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], image_repository : ImageRepository, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create an image repository  # noqa: E501
+    @validate_call
+    def create_user(
+            self,
+            user: User,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a user  # noqa: E501
+
+
+        Create a user according to the parameters given  # noqa: E501
 
-        Create an image repository, with standard create modifiers as query parameters. See the ImageRepository component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_image_repository(database, var_schema, image_repository, create_mode, async_req=True)
+        >>> thread = api.create_user(user, create_mode, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param image_repository: (required)
-        :type image_repository: ImageRepository
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param user: (required)
+        :type user: User
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -129,34 +132,42 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_image_repository_with_http_info(database, var_schema, image_repository, create_mode, **kwargs)  # noqa: E501
+        return self.create_user_with_http_info(user, create_mode,
+                                               **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_user_with_http_info(
+            self,
+            user: User,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Create a user  # noqa: E501
 
-    @validate_arguments
-    def create_image_repository_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], image_repository : ImageRepository, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
-        """Create an image repository  # noqa: E501
 
-        Create an image repository, with standard create modifiers as query parameters. See the ImageRepository component definition for what is required to be provided in the request body.  # noqa: E501
+        Create a user according to the parameters given  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_image_repository_with_http_info(database, var_schema, image_repository, create_mode, async_req=True)
+        >>> thread = api.create_user_with_http_info(user, create_mode, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param image_repository: (required)
-        :type image_repository: ImageRepository
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param user: (required)
+        :type user: User
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -176,78 +187,62 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'image_repository',
-            'create_mode'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['user', 'create_mode']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_image_repository" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_user" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['image_repository']:
-            _body_params = _params['image_repository']
+
+        if _params['user']:
+            _body_params = _params['user']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -259,81 +254,85 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/image-repositories', 'POST',
+            '/api/v2/users',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_image_repository(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> ImageRepository:  # noqa: E501
-        """Fetch an image repository.  # noqa: E501
+    @validate_call
+    def fetch_user(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                   **kwargs) -> User:  # noqa: E501
+        """Fetch information about a user  # noqa: E501
+
+
+        Fetch user information using the result of the DESCRIBE command  # noqa: E501
 
-        Fetch an image repository using the SHOW command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_image_repository(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_user(name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: ImageRepository
+        :rtype: User
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_image_repository_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.fetch_user_with_http_info(name, **kwargs)  # noqa: E501
+
+    @validate_call
+    def fetch_user_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                  **kwargs):  # noqa: E501
+        """Fetch information about a user  # noqa: E501
 
-    @validate_arguments
-    def fetch_image_repository_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Fetch an image repository.  # noqa: E501
 
-        Fetch an image repository using the SHOW command output.  # noqa: E501
+        Fetch user information using the result of the DESCRIBE command  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_image_repository_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.fetch_user_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -348,54 +347,38 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(ImageRepository, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(User, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_image_repository" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_user" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -412,95 +395,165 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "ImageRepository",
+            '200': "User",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/image-repositories/{name}', 'GET',
+            '/api/v2/users/{name}',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def list_image_repositories(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs) -> Iterable[ImageRepository]:  # noqa: E501
-        """List image repositories  # noqa: E501
+    @validate_call
+    def list_users(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            from_name:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name."
+            )] = None,
+            **kwargs) -> Iterable[User]:  # noqa: E501
+        """List users in the system.  # noqa: E501
+
+
+        Lists the users in the system.  # noqa: E501
 
-        Lists the image repositories under the database and schema.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_image_repositories(database, var_schema, like, async_req=True)
+        >>> thread = api.list_users(like, starts_with, show_limit, from_name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :type starts_with: str
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
+        :type show_limit: int
+        :param from_name: Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :type from_name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Iterable[ImageRepository]
+        :rtype: Iterable[User]
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_image_repositories_with_http_info(database, var_schema, like, **kwargs)  # noqa: E501
+        return self.list_users_with_http_info(like, starts_with, show_limit,
+                                              from_name,
+                                              **kwargs)  # noqa: E501
+
+    @validate_call
+    def list_users_with_http_info(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            from_name:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """List users in the system.  # noqa: E501
 
-    @validate_arguments
-    def list_image_repositories_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs):  # noqa: E501
-        """List image repositories  # noqa: E501
 
-        Lists the image repositories under the database and schema.  # noqa: E501
+        Lists the users in the system.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_image_repositories_with_http_info(database, var_schema, like, async_req=True)
+        >>> thread = api.list_users_with_http_info(like, starts_with, show_limit, from_name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :type starts_with: str
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
+        :type show_limit: int
+        :param from_name: Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :type from_name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -514,60 +567,53 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Iterable[ImageRepository], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[User], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'like'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['like', 'starts_with', 'show_limit', 'from_name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method list_image_repositories" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method list_users" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
 
+        if _params.get('starts_with') is not None:  # noqa: E501
+            _query_params.append(('startsWith', _params['starts_with']))
+
+        if _params.get('show_limit') is not None:  # noqa: E501
+            _query_params.append(('showLimit', _params['show_limit']))
+
+        if _params.get('from_name') is not None:  # noqa: E501
+            _query_params.append(('fromName', _params['from_name']))
+
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
@@ -578,62 +624,73 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Iterable[ImageRepository]",
+            '200': "Iterable[User]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
-            '409': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/image-repositories', 'GET',
+            '/api/v2/users',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def delete_image_repository(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete an image repository  # noqa: E501
+    @validate_call
+    def delete_user(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete a user  # noqa: E501
+
+
+        Delete a user with the given name.  # noqa: E501
 
-        Delete an image repository with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_image_repository(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.delete_user(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -643,34 +700,45 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_image_repository_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
+        return self.delete_user_with_http_info(name, if_exists,
+                                               **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def delete_image_repository_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
-        """Delete an image repository  # noqa: E501
+    @validate_call
+    def delete_user_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Delete a user  # noqa: E501
+
+
+        Delete a user with the given name.  # noqa: E501
 
-        Delete an image repository with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_image_repository_with_http_info(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.delete_user_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -690,55 +758,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method delete_image_repository" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method delete_user" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -765,22 +817,24 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/image-repositories/{name}', 'DELETE',
+            '/api/v2/users/{name}',
+            'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/grant/_generated/models/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Grant API
+    The Snowflake Grant API is a REST API that you can use to show or manage privileges that have been provided to users and roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
-from snowflake.core.image_repository._generated.models.error_response import ErrorResponse
-from snowflake.core.image_repository._generated.models.image_repository import ImageRepository
-from snowflake.core.image_repository._generated.models.success_response import SuccessResponse
+from snowflake.core.grant._generated.models.error_response import ErrorResponse
+from snowflake.core.grant._generated.models.grant import Grant
+from snowflake.core.grant._generated.models.success_response import SuccessResponse
 
 __all__ = [
     'ErrorResponse',
-    'ImageRepository',
+    'Grant',
     'SuccessResponse',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/function/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Function API
+    The Snowflake Function API is a REST API that allows caller to create, execute and drop functions in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.image_repository._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/image_repository.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/image_repository.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,67 +1,88 @@
 # coding: utf-8
-
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Image Repository API
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform common actions on Image Repository resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Optional
 from typing import Union
-from snowflake.core.image_repository._generated.pydantic_compatibility import BaseModel, Field, StrictStr, constr, validator
+
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
 
 class ImageRepository(BaseModel):
-    name: constr(strict=True) = Field(...)
-    database_name: Optional[constr(strict=True)] = None
-    schema_name: Optional[constr(strict=True)] = None
+
+    name: Annotated[str, Field(strict=True)]
+
+    database_name: Optional[Annotated[str, Field(strict=True)]] = None
+
+    schema_name: Optional[Annotated[str, Field(strict=True)]] = None
+
     created_on: Optional[datetime] = None
+
     repository_url: Optional[StrictStr] = None
+
     owner: Optional[StrictStr] = None
+
     owner_role_type: Optional[StrictStr] = None
-    __properties = ["name", "database_name", "schema_name", "created_on", "repository_url", "owner", "owner_role_type"]
 
+    __properties = [
+        "name", "database_name", "schema_name", "created_on", "repository_url",
+        "owner", "owner_role_type"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('database_name')
+    @field_validator('database_name')
     def database_name_validate_regular_expression(cls, v):
+
         if v is None:
             return v
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('schema_name')
+    @field_validator('schema_name')
     def schema_name_validate_regular_expression(cls, v):
+
         if v is None:
             return v
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -71,110 +92,108 @@
     @classmethod
     def from_json(cls, json_str: str) -> ImageRepository:
         """Create an instance of ImageRepository from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "created_on",
-                            "repository_url",
-                            "owner",
-                            "owner_role_type",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "repository_url",
+                           "owner",
+                           "owner_role_type",
+                       },
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ImageRepository:
         """Create an instance of ImageRepository from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ImageRepository.parse_obj(obj)
 
         _obj = ImageRepository.parse_obj({
-            "name": obj.get("name"),
-
-            "database_name": obj.get("database_name"),
-
-            "schema_name": obj.get("schema_name"),
-
-            "created_on": obj.get("created_on"),
-
-            "repository_url": obj.get("repository_url"),
-
-            "owner": obj.get("owner"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
+            "name":
+            obj.get("name"),
+            "database_name":
+            obj.get("database_name"),
+            "schema_name":
+            obj.get("schema_name"),
+            "created_on":
+            obj.get("created_on"),
+            "repository_url":
+            obj.get("repository_url"),
+            "owner":
+            obj.get("owner"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ImageRepositoryModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
         database_name: Optional[str] = None,
         schema_name: Optional[str] = None,
         created_on: Optional[datetime] = None,
         repository_url: Optional[str] = None,
         owner: Optional[str] = None,
         owner_role_type: Optional[str] = None,
     ):
+
         self.name = name
         self.database_name = database_name
         self.schema_name = schema_name
         self.created_on = created_on
         self.repository_url = repository_url
         self.owner = owner
         self.owner_role_type = owner_role_type
-    __properties = ["name", "database_name", "schema_name", "created_on", "repository_url", "owner", "owner_role_type"]
+
+    __properties = [
+        "name", "database_name", "schema_name", "created_on", "repository_url",
+        "owner", "owner_role_type"
+    ]
 
     def _to_model(self):
         return ImageRepository(
             name=self.name,
-
             database_name=self.database_name,
-
             schema_name=self.schema_name,
-
             created_on=self.created_on,
-
             repository_url=self.repository_url,
-
             owner=self.owner,
-
             owner_role_type=self.owner_role_type,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ImageRepositoryModel:
         return ImageRepositoryModel(
             name=model.name,
-
             database_name=model.database_name,
-
             schema_name=model.schema_name,
-
             created_on=model.created_on,
-
             repository_url=model.repository_url,
-
             owner=model.owner,
-
             owner_role_type=model.owner_role_type,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/image_repository/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/success_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Image Repository API
-
-    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform certain actions on Image Repository resource in Snowflake.  # noqa: E501
 
+    Snowflake Image Repository API
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform common actions on Image Repository resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.image_repository._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_schema.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_schema.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,20 +1,23 @@
 from functools import cached_property
 from typing import TYPE_CHECKING, Iterator, Optional, Union
 
+from pydantic import StrictStr
+
 from snowflake.connector import SnowflakeConnection
 from snowflake.core.schema._generated.api_client import BridgeApiClient, StoredProcApiClient
-from snowflake.core.schema._generated.pydantic_compatibility import StrictStr
 from snowflake.snowpark import Session
 
 from .._common import Clone, CreateMode, ObjectCollection, ObjectReferenceMixin, PointOfTime
 from .._internal.telemetry import api_telemetry
 from ..cortex.search_service import CortexSearchServiceCollection
+from ..function import FunctionCollection
 from ..image_repository import ImageRepositoryCollection
 from ..service import ServiceCollection
+from ..stage import StageCollection
 from ..table import TableCollection
 from ..task import TaskCollection
 from ._generated.api.schema_api import SchemaApi
 from ._generated.models.model_schema import ModelSchemaModel as Schema
 from ._generated.models.point_of_time import PointOfTime as SchemaPointOfTime
 from ._generated.models.schema_clone import SchemaClone
 
@@ -50,14 +53,15 @@
     def create(
         self,
         schema: Schema,
         *,
         clone: Optional[Union[str, Clone]] = None,
         mode: CreateMode = CreateMode.error_if_exists,
         kind: str = "",
+        with_managed_access: Optional[bool] = None,
     ) -> "SchemaResource":
         """Create a schema in Snowflake.
 
         Args:
             schema: an instance of :class:`Schema`.
             mode: One of the following strings.
                 CreateMode.error_if_exists: Throw an :class:`snowflake.core.exceptions.ConflictError`
@@ -82,24 +86,24 @@
                 **schema._to_model().to_dict(),
             )
             self._api.clone_schema(
                 database=self.database.name,
                 name=real_clone.source,
                 schema_clone=req,
                 create_mode=StrictStr(real_mode),
-                with_managed_access=False,
+                with_managed_access=with_managed_access,
                 kind=kind,
                 async_req=False,
             )
         else:
             self._api.create_schema(
                 database=self.database.name,
                 model_schema=schema._to_model(),
                 create_mode=StrictStr(real_mode),
-                with_managed_access=False,
+                with_managed_access=with_managed_access,
                 kind=kind,
                 async_req=False,
             )
         return self[schema.name]
 
     @api_telemetry
     def iter(
@@ -143,20 +147,21 @@
         return self.collection.database
 
     @property
     def _api(self) -> SchemaApi:
         return self.collection._api
 
     @api_telemetry
-    def create_or_update(self, schema: Schema) -> "SchemaResource":
+    def create_or_update(self, schema: Schema, with_managed_access: Optional[bool] = None) -> "SchemaResource":
         """Create or update a schema in Snowflake."""
         self._api.create_or_alter_schema(
             self.database.name,
             schema.name,
             schema._to_model(),
+            with_managed_access=with_managed_access,
             async_req=False,
         )
         return self
 
     @api_telemetry
     def fetch(self) -> Schema:
         return Schema._from_model(self.collection._api.fetch_schema(
@@ -187,9 +192,18 @@
         return ImageRepositoryCollection(self)
 
     @cached_property
     def tables(self) -> TableCollection:
         return TableCollection(self)
 
     @cached_property
+    def stages(self) -> StageCollection:
+        return StageCollection(self)
+
+    @cached_property
     def cortex_search_services(self) -> CortexSearchServiceCollection:
         return CortexSearchServiceCollection(self)
+
+    @cached_property
+    def functions(self) -> FunctionCollection:
+        return FunctionCollection(self)
+
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.schema._generated.api.schema_api import SchemaApi
-
 # import ApiClient
 from snowflake.core.schema._generated.api_client import ApiClient
 from snowflake.core.schema._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.schema._generated.models.error_response import ErrorResponse
 from snowflake.core.schema._generated.models.model_schema import ModelSchema
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/stage/_generated/api_client.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Stage API
+    The Snowflake Stage API is a REST API that you can use to access, update, and perform certain actions on stage resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.schema._generated.configuration import Configuration
-import snowflake.core.schema._generated.models
-from snowflake.core.schema._generated import rest
-from snowflake.core.schema._generated.paging import PagedIter
+from snowflake.core.stage._generated.configuration import Configuration
+import snowflake.core.stage._generated.models
+from snowflake.core.stage._generated import rest
+from snowflake.core.stage._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,61 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.schema._generated.models, klass)
+                klass = getattr(snowflake.core.stage._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +519,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +670,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for schema. Updating schema '
-                        'objects is not supported yet; use create() for creating a schema.')
+                        'create_or_update is not yet supported for stage. Updating stage '
+                        'objects is not supported yet; use create() for creating a stage.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +699,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +742,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +786,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +823,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +847,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +874,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +940,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +958,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +974,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1009,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/grant/_generated/api_response.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.schema._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/configuration.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.schema._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.schema._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Schema API",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake Schema API",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/grant/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/rest.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Task API
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/api/schema_api.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/api/schema_api.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,47 +1,41 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
-
+from pydantic import Field, StrictBool, StrictInt, StrictStr, field_validator
 from typing import List, Optional
-
+from typing_extensions import Annotated
 from snowflake.core.schema._generated.models.model_schema import ModelSchema
 from snowflake.core.schema._generated.models.schema_clone import SchemaClone
 from snowflake.core.schema._generated.models.success_response import SuccessResponse
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.schema._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
+
+logger = logging.getLogger(__name__)
 
-logger  = logging.getLogger(__name__)
 
 class SchemaApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
@@ -72,15 +66,16 @@
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('schema')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge('schema')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -92,34 +87,69 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_or_alter_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], model_schema : ModelSchema, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) schema.  # noqa: E501
+    @validate_call
+    def create_or_alter_schema(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            model_schema: ModelSchema,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            with_managed_access:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Creates a new, or alters an existing, schema.  # noqa: E501
+
+
+        Creates a new, or alters an existing, schema. You must provide the full schema definition even when altering an existing schema.  # noqa: E501
 
-        Create a (or alter an existing) schema. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_schema(database, name, model_schema, async_req=True)
+        >>> thread = api.create_or_alter_schema(database, name, model_schema, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param model_schema: (required)
         :type model_schema: ModelSchema
+        :param kind: Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
+        :type kind: str
+        :param with_managed_access: Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`.
+        :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -128,33 +158,69 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_alter_schema_with_http_info(database, name, model_schema, **kwargs)  # noqa: E501
+        return self.create_or_alter_schema_with_http_info(
+            database, name, model_schema, kind, with_managed_access,
+            **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_or_alter_schema_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            model_schema: ModelSchema,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            with_managed_access:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Creates a new, or alters an existing, schema.  # noqa: E501
+
 
-    @validate_arguments
-    def create_or_alter_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], model_schema : ModelSchema, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) schema.  # noqa: E501
+        Creates a new, or alters an existing, schema. You must provide the full schema definition even when altering an existing schema.  # noqa: E501
 
-        Create a (or alter an existing) schema. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_schema_with_http_info(database, name, model_schema, async_req=True)
+        >>> thread = api.create_or_alter_schema_with_http_info(database, name, model_schema, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param model_schema: (required)
         :type model_schema: ModelSchema
+        :param kind: Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
+        :type kind: str
+        :param with_managed_access: Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`.
+        :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -174,74 +240,73 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'name',
-            'model_schema'
+            'database', 'name', 'model_schema', 'kind', 'with_managed_access'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_or_alter_schema" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_or_alter_schema" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
+        if _params.get('kind') is not None:  # noqa: E501
+            _query_params.append(('kind', _params['kind']))
+
+        if _params.get('with_managed_access') is not None:  # noqa: E501
+            _query_params.append(
+                ('with_managed_access', _params['with_managed_access']))
+
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['model_schema']:
             _body_params = _params['model_schema']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -252,50 +317,85 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{name}', 'PUT',
+            '/api/v2/databases/{database}/schemas/{name}',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], model_schema : ModelSchema, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a schema  # noqa: E501
+    @validate_call
+    def create_schema(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            model_schema: ModelSchema,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            with_managed_access:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Creates a schema.  # noqa: E501
+
+
+        Creates a schema, with modifiers as query parameters. You must provide the full schema definition when creating a schema.  # noqa: E501
 
-        Create a schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_schema(database, model_schema, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
         :param model_schema: (required)
         :type model_schema: ModelSchema
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :param with_managed_access: Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`.
         :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -305,36 +405,72 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_schema_with_http_info(database, model_schema, create_mode, kind, with_managed_access, **kwargs)  # noqa: E501
+        return self.create_schema_with_http_info(database, model_schema,
+                                                 create_mode, kind,
+                                                 with_managed_access,
+                                                 **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_schema_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            model_schema: ModelSchema,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            with_managed_access:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Creates a schema.  # noqa: E501
+
 
-    @validate_arguments
-    def create_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], model_schema : ModelSchema, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs):  # noqa: E501
-        """Create a schema  # noqa: E501
+        Creates a schema, with modifiers as query parameters. You must provide the full schema definition when creating a schema.  # noqa: E501
 
-        Create a schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_schema_with_http_info(database, model_schema, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
         :param model_schema: (required)
         :type model_schema: ModelSchema
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of schema to create. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :param with_managed_access: Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`.
         :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -355,80 +491,74 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'model_schema',
-            'create_mode',
-            'kind',
+            'database', 'model_schema', 'create_mode', 'kind',
             'with_managed_access'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_schema" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_schema" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
+
         if _params.get('kind') is not None:  # noqa: E501
             _query_params.append(('kind', _params['kind']))
+
         if _params.get('with_managed_access') is not None:  # noqa: E501
-            _query_params.append(('with_managed_access', _params['with_managed_access']))
+            _query_params.append(
+                ('with_managed_access', _params['with_managed_access']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['model_schema']:
             _body_params = _params['model_schema']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -440,52 +570,91 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas', 'POST',
+            '/api/v2/databases/{database}/schemas',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def clone_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], schema_clone : SchemaClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Clone a schema  # noqa: E501
+    @validate_call
+    def clone_schema(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            schema_clone: SchemaClone,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of schema to clone. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            with_managed_access:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Clones a schema.  # noqa: E501
+
+
+        Clones an existing schema, with modifiers as query parameters. You must provide the full schema definition when cloning an existing schema.  # noqa: E501
 
-        Clone an existing schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.clone_schema(database, name, schema_clone, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param schema_clone: (required)
         :type schema_clone: SchemaClone
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of schema to clone. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :param with_managed_access: Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`.
         :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -495,38 +664,78 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.clone_schema_with_http_info(database, name, schema_clone, create_mode, kind, with_managed_access, **kwargs)  # noqa: E501
+        return self.clone_schema_with_http_info(database, name, schema_clone,
+                                                create_mode, kind,
+                                                with_managed_access,
+                                                **kwargs)  # noqa: E501
+
+    @validate_call
+    def clone_schema_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            schema_clone: SchemaClone,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            kind:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Type of schema to clone. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string)."
+            )] = None,
+            with_managed_access:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Clones a schema.  # noqa: E501
+
 
-    @validate_arguments
-    def clone_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], schema_clone : SchemaClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, kind : Annotated[Optional[StrictStr], Field(description="Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.")] = None, with_managed_access : Annotated[Optional[StrictBool], Field(description="Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.")] = None, **kwargs):  # noqa: E501
-        """Clone a schema  # noqa: E501
+        Clones an existing schema, with modifiers as query parameters. You must provide the full schema definition when cloning an existing schema.  # noqa: E501
 
-        Clone an existing schema, with modifiers as query parameters. See the schema definition for what is required to be provided in the request body. (Cloning not currently supported)  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.clone_schema_with_http_info(database, name, schema_clone, create_mode, kind, with_managed_access, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param schema_clone: (required)
         :type schema_clone: SchemaClone
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param kind: Type of schema. At the time of writing this transient and permanent (represented by the empty string) are supported.
+        :param kind: Type of schema to clone. Currently, Snowflake supports only `transient` and `permanent` (also represented by the empty string).
         :type kind: str
-        :param with_managed_access: Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.
+        :param with_managed_access: Whether this schema is a managed access schemas that centralizes privilege management with the schema owner. Default: `false`.
         :type with_managed_access: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -547,83 +756,77 @@
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'name',
-            'schema_clone',
-            'create_mode',
-            'kind',
+            'database', 'name', 'schema_clone', 'create_mode', 'kind',
             'with_managed_access'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method clone_schema" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method clone_schema" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
+
         if _params.get('kind') is not None:  # noqa: E501
             _query_params.append(('kind', _params['kind']))
+
         if _params.get('with_managed_access') is not None:  # noqa: E501
-            _query_params.append(('with_managed_access', _params['with_managed_access']))
+            _query_params.append(
+                ('with_managed_access', _params['with_managed_access']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['schema_clone']:
             _body_params = _params['schema_clone']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -635,44 +838,57 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{name}:clone', 'POST',
+            '/api/v2/databases/{database}/schemas/{name}:clone',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> ModelSchema:  # noqa: E501
+    @validate_call
+    def fetch_schema(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], name: Annotated[
+            str,
+            Field(strict=True,
+                  description="Identifier (i.e. name) for the resource.")],
+                     **kwargs) -> ModelSchema:  # noqa: E501
         """fetch_schema  # noqa: E501
 
-        Fetch a schema.  # noqa: E501
+
+        Fetches a schema.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_schema(database, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -682,30 +898,42 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: ModelSchema
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_schema_with_http_info(database, name, **kwargs)  # noqa: E501
+        return self.fetch_schema_with_http_info(database, name,
+                                                **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def fetch_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def fetch_schema_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], name: Annotated[
+            str,
+            Field(strict=True,
+                  description="Identifier (i.e. name) for the resource.")],
+                                    **kwargs):  # noqa: E501
         """fetch_schema  # noqa: E501
 
-        Fetch a schema.  # noqa: E501
+
+        Fetches a schema.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_schema_with_http_info(database, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -725,46 +953,36 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(ModelSchema, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_schema" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_schema" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -794,52 +1012,100 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{name}', 'GET',
+            '/api/v2/databases/{database}/schemas/{name}',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def list_schemas(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Includes dropped schemas that have not yet been purged.")] = None, **kwargs) -> Iterable[ModelSchema]:  # noqa: E501
-        """List schemas  # noqa: E501
+    @validate_call
+    def list_schemas(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            from_name:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name."
+            )] = None,
+            history:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to include dropped schemas that have not yet been purged. Default: `false`."
+            )] = None,
+            **kwargs) -> Iterable[ModelSchema]:  # noqa: E501
+        """Lists schemas.  # noqa: E501
+
 
         Lists the accessible schemas.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_schemas(database, like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :param from_name: Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
         :type from_name: str
-        :param history: Includes dropped schemas that have not yet been purged.
+        :param history: Whether to include dropped schemas that have not yet been purged. Default: `false`.
         :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -849,38 +1115,86 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Iterable[ModelSchema]
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_schemas_with_http_info(database, like, starts_with, show_limit, from_name, history, **kwargs)  # noqa: E501
+        return self.list_schemas_with_http_info(database, like, starts_with,
+                                                show_limit, from_name, history,
+                                                **kwargs)  # noqa: E501
+
+    @validate_call
+    def list_schemas_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            from_name:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name."
+            )] = None,
+            history:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to include dropped schemas that have not yet been purged. Default: `false`."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Lists schemas.  # noqa: E501
 
-    @validate_arguments
-    def list_schemas_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Includes dropped schemas that have not yet been purged.")] = None, **kwargs):  # noqa: E501
-        """List schemas  # noqa: E501
 
         Lists the accessible schemas.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_schemas_with_http_info(database, like, starts_with, show_limit, from_name, history, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
+        :param from_name: Query parameter to enable fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
         :type from_name: str
-        :param history: Includes dropped schemas that have not yet been purged.
+        :param history: Whether to include dropped schemas that have not yet been purged. Default: `false`.
         :type history: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -901,60 +1215,53 @@
                  returns the request thread.
         :rtype: tuple(Iterable[ModelSchema], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'like',
-            'starts_with',
-            'show_limit',
-            'from_name',
+            'database', 'like', 'starts_with', 'show_limit', 'from_name',
             'history'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method list_schemas" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method list_schemas" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
+
         if _params.get('starts_with') is not None:  # noqa: E501
             _query_params.append(('startsWith', _params['starts_with']))
+
         if _params.get('show_limit') is not None:  # noqa: E501
             _query_params.append(('showLimit', _params['show_limit']))
+
         if _params.get('from_name') is not None:  # noqa: E501
             _query_params.append(('fromName', _params['from_name']))
+
         if _params.get('history') is not None:  # noqa: E501
             _query_params.append(('history', _params['history']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -981,48 +1288,79 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas', 'GET',
+            '/api/v2/databases/{database}/schemas',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def delete_schema(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a schema.  # noqa: E501
+    @validate_call
+    def delete_schema(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            restrict:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to drop the schema if foreign keys exist that reference any tables in the schema. - `true`: Return a warning about existing foreign key references and don't drop the schema. - `false`: Drop the schema and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables. Default: `false`."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Deletes a schema.  # noqa: E501
+
+
+        Deletes the specified schema. If you enable the `ifExists` parameter, the operation succeeds even if the schema does not exist. Otherwise, a 404 failure is returned if the schema does not exist. if the drop is unsuccessful.  # noqa: E501
 
-        Delete a schema with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_schema(database, name, if_exists, restrict, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
-        :param restrict: Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :param restrict: Whether to drop the schema if foreign keys exist that reference any tables in the schema. - `true`: Return a warning about existing foreign key references and don't drop the schema. - `false`: Drop the schema and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables. Default: `false`.
         :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1032,34 +1370,65 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_schema_with_http_info(database, name, if_exists, restrict, **kwargs)  # noqa: E501
+        return self.delete_schema_with_http_info(database, name, if_exists,
+                                                 restrict,
+                                                 **kwargs)  # noqa: E501
+
+    @validate_call
+    def delete_schema_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            restrict:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to drop the schema if foreign keys exist that reference any tables in the schema. - `true`: Return a warning about existing foreign key references and don't drop the schema. - `false`: Drop the schema and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables. Default: `false`."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Deletes a schema.  # noqa: E501
+
 
-    @validate_arguments
-    def delete_schema_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, restrict : Annotated[Optional[StrictBool], Field(description="Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.")] = None, **kwargs):  # noqa: E501
-        """Delete a schema.  # noqa: E501
+        Deletes the specified schema. If you enable the `ifExists` parameter, the operation succeeds even if the schema does not exist. Otherwise, a 404 failure is returned if the schema does not exist. if the drop is unsuccessful.  # noqa: E501
 
-        Delete a schema with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_schema_with_http_info(database, name, if_exists, restrict, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
-        :param restrict: Specifies whether the schema should not be droppped if there are existing foreign key references. Returns a warning instead.
+        :param restrict: Whether to drop the schema if foreign keys exist that reference any tables in the schema. - `true`: Return a warning about existing foreign key references and don't drop the schema. - `false`: Drop the schema and all objects in the database, including tables with primary or unique keys that are referenced by foreign keys in other tables. Default: `false`.
         :type restrict: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1079,55 +1448,45 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'name',
-            'if_exists',
-            'restrict'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'name', 'if_exists', 'restrict']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method delete_schema" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method delete_schema" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
+
         if _params.get('restrict') is not None:  # noqa: E501
             _query_params.append(('restrict', _params['restrict']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -1154,22 +1513,24 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{name}', 'DELETE',
+            '/api/v2/databases/{database}/schemas/{name}',
+            'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,20 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.schema._generated.models.error_response import ErrorResponse
 from snowflake.core.schema._generated.models.model_schema import ModelSchema
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 from snowflake.core.schema._generated.models.point_of_time_offset import PointOfTimeOffset
@@ -31,8 +28,8 @@
     'ModelSchema',
     'PointOfTime',
     'PointOfTimeOffset',
     'PointOfTimeStatement',
     'PointOfTimeTimestamp',
     'SchemaClone',
     'SuccessResponse',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/error_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/model_schema.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/model_schema.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,65 +1,99 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Optional
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
 
 class ModelSchema(BaseModel):
+
     created_on: Optional[datetime] = None
-    name: constr(strict=True) = Field(...)
+
+    name: Annotated[str, Field(strict=True)]
+
     is_default: Optional[StrictBool] = None
+
     is_current: Optional[StrictBool] = None
+
     database_name: Optional[StrictStr] = None
+
     owner: Optional[StrictStr] = None
+
     comment: Optional[StrictStr] = None
+
     options: Optional[StrictStr] = None
+
     retention_time: Optional[StrictInt] = None
+
     dropped_on: Optional[datetime] = None
+
     owner_role_type: Optional[StrictStr] = None
+
     budget: Optional[StrictStr] = None
+
     data_retention_time_in_days: Optional[StrictInt] = None
+
     default_ddl_collation: Optional[StrictStr] = None
+
     log_level: Optional[StrictStr] = None
+
     pipe_execution_paused: Optional[StrictBool] = None
+
     max_data_extension_time_in_days: Optional[StrictInt] = None
+
     suspend_task_after_num_failures: Optional[StrictInt] = None
+
     trace_level: Optional[StrictStr] = None
+
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
+
     user_task_timeout_ms: Optional[StrictInt] = None
-    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "database_name",
+        "owner", "comment", "options", "retention_time", "dropped_on",
+        "owner_role_type", "budget", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level", "pipe_execution_paused",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -69,93 +103,100 @@
     @classmethod
     def from_json(cls, json_str: str) -> ModelSchema:
         """Create an instance of ModelSchema from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "created_on",
-                            "is_default",
-                            "is_current",
-                            "database_name",
-                            "owner",
-                            "options",
-                            "retention_time",
-                            "dropped_on",
-                            "owner_role_type",
-                            "budget",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "is_default",
+                           "is_current",
+                           "database_name",
+                           "owner",
+                           "options",
+                           "retention_time",
+                           "dropped_on",
+                           "owner_role_type",
+                           "budget",
+                       },
+                       exclude_none=True))
+
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ModelSchema:
         """Create an instance of ModelSchema from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ModelSchema.parse_obj(obj)
 
         _obj = ModelSchema.parse_obj({
-            "created_on": obj.get("created_on"),
-
-            "name": obj.get("name"),
-
-            "is_default": obj.get("is_default"),
-
-            "is_current": obj.get("is_current"),
-
-            "database_name": obj.get("database_name"),
-
-            "owner": obj.get("owner"),
-
-            "comment": obj.get("comment"),
-
-            "options": obj.get("options"),
-
-            "retention_time": obj.get("retention_time"),
-
-            "dropped_on": obj.get("dropped_on"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
-            "budget": obj.get("budget"),
-
-            "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
-
-            "default_ddl_collation": obj.get("default_ddl_collation"),
-
-            "log_level": obj.get("log_level"),
-
-            "pipe_execution_paused": obj.get("pipe_execution_paused"),
-
-            "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
-
-            "suspend_task_after_num_failures": obj.get("suspend_task_after_num_failures"),
-
-            "trace_level": obj.get("trace_level"),
-
-            "user_task_managed_initial_warehouse_size": obj.get("user_task_managed_initial_warehouse_size"),
-
-            "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
-
+            "created_on":
+            obj.get("created_on"),
+            "name":
+            obj.get("name"),
+            "is_default":
+            obj.get("is_default"),
+            "is_current":
+            obj.get("is_current"),
+            "database_name":
+            obj.get("database_name"),
+            "owner":
+            obj.get("owner"),
+            "comment":
+            obj.get("comment"),
+            "options":
+            obj.get("options"),
+            "retention_time":
+            obj.get("retention_time"),
+            "dropped_on":
+            obj.get("dropped_on"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
+            "budget":
+            obj.get("budget"),
+            "data_retention_time_in_days":
+            obj.get("data_retention_time_in_days"),
+            "default_ddl_collation":
+            obj.get("default_ddl_collation"),
+            "log_level":
+            obj.get("log_level"),
+            "pipe_execution_paused":
+            obj.get("pipe_execution_paused"),
+            "max_data_extension_time_in_days":
+            obj.get("max_data_extension_time_in_days"),
+            "suspend_task_after_num_failures":
+            obj.get("suspend_task_after_num_failures"),
+            "trace_level":
+            obj.get("trace_level"),
+            "user_task_managed_initial_warehouse_size":
+            obj.get("user_task_managed_initial_warehouse_size"),
+            "user_task_timeout_ms":
+            obj.get("user_task_timeout_ms"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ModelSchemaModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
         is_current: Optional[bool] = None,
@@ -173,14 +214,15 @@
         pipe_execution_paused: Optional[bool] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
+
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
         self.database_name = database_name
         self.owner = owner
         self.comment = comment
@@ -194,107 +236,80 @@
         self.log_level = log_level
         self.pipe_execution_paused = pipe_execution_paused
         self.max_data_extension_time_in_days = max_data_extension_time_in_days
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
-    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
+
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "database_name",
+        "owner", "comment", "options", "retention_time", "dropped_on",
+        "owner_role_type", "budget", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level", "pipe_execution_paused",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
     def _to_model(self):
         return ModelSchema(
             created_on=self.created_on,
-
             name=self.name,
-
             is_default=self.is_default,
-
             is_current=self.is_current,
-
             database_name=self.database_name,
-
             owner=self.owner,
-
             comment=self.comment,
-
             options=self.options,
-
             retention_time=self.retention_time,
-
             dropped_on=self.dropped_on,
-
             owner_role_type=self.owner_role_type,
-
             budget=self.budget,
-
             data_retention_time_in_days=self.data_retention_time_in_days,
-
             default_ddl_collation=self.default_ddl_collation,
-
             log_level=self.log_level,
-
             pipe_execution_paused=self.pipe_execution_paused,
-
-            max_data_extension_time_in_days=self.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=self.suspend_task_after_num_failures,
-
+            max_data_extension_time_in_days=self.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=self.
+            suspend_task_after_num_failures,
             trace_level=self.trace_level,
-
-            user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=self.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=self.user_task_timeout_ms,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ModelSchemaModel:
         return ModelSchemaModel(
             created_on=model.created_on,
-
             name=model.name,
-
             is_default=model.is_default,
-
             is_current=model.is_current,
-
             database_name=model.database_name,
-
             owner=model.owner,
-
             comment=model.comment,
-
             options=model.options,
-
             retention_time=model.retention_time,
-
             dropped_on=model.dropped_on,
-
             owner_role_type=model.owner_role_type,
-
             budget=model.budget,
-
             data_retention_time_in_days=model.data_retention_time_in_days,
-
             default_ddl_collation=model.default_ddl_collation,
-
             log_level=model.log_level,
-
             pipe_execution_paused=model.pipe_execution_paused,
-
-            max_data_extension_time_in_days=model.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=model.suspend_task_after_num_failures,
-
+            max_data_extension_time_in_days=model.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=model.
+            suspend_task_after_num_failures,
             trace_level=model.trace_level,
-
-            user_task_managed_initial_warehouse_size=model.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=model.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=model.user_task_timeout_ms,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,138 +1,152 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
+
 import snowflake.core.schema._generated.models
 from snowflake.core.schema._generated.models import *
 
-
-from typing import Optional, Union
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, Field, StrictStr
+
+from importlib import import_module
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional, Union
+
 
 class PointOfTime(BaseModel):
-    point_of_time_type: StrictStr = Field(...)
+
+    point_of_time_type: StrictStr
+
     reference: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     # JSON field name that stores the object type
-    __discriminator_property_name = 'point_of_time_type'
+    __discriminator_property_name: ClassVar[str] = 'point_of_time_type'
 
     # discriminator mappings
-    __discriminator_value_class_map = {
+    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
         'offset': 'PointOfTimeOffset',
         'statement': 'PointOfTimeStatement',
         'timestamp': 'PointOfTimeTimestamp'
     }
 
     @classmethod
-    def get_discriminator_value(cls, obj: dict) -> str:
+    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
         """Returns the discriminator value (object type) of the data"""
         discriminator_value = obj[cls.__discriminator_property_name]
         if discriminator_value:
             return cls.__discriminator_value_class_map.get(discriminator_value)
         else:
             return None
 
-
-    __discriminator_value_to_type = {
+    __discriminator_value_to_type: ClassVar[Dict[str, str]] = {
         'PointOfTimeOffset': 'offset',
         'PointOfTimeStatement': 'statement',
         'PointOfTimeTimestamp': 'timestamp',
     }
 
     @classmethod
     def get_child_model_discriminator_value(cls, child_model: str) -> str:
         return cls.__discriminator_value_to_type[child_model]
 
-
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
+    def from_json(
+        cls, json_str: str
+    ) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
         """Create an instance of PointOfTime from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
+    def from_dict(
+        cls, obj: dict
+    ) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
         """Create an instance of PointOfTime from a dict"""
+
         # look up the object type based on discriminator mapping
         object_type = cls.get_discriminator_value(obj)
         if object_type:
-            klass = getattr(snowflake.core.schema._generated.models, object_type)
+            klass = getattr(snowflake.core.schema._generated.models,
+                            object_type)
             return klass.from_dict(obj)
         else:
-            raise ValueError("PointOfTime failed to lookup discriminator value from " +
-                             json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
-                             ", mapping: " + json.dumps(cls.__discriminator_value_class_map))
+            raise ValueError(
+                "PointOfTime failed to lookup discriminator value from " +
+                json.dumps(obj) + ". Discriminator property name: " +
+                cls.__discriminator_property_name + ", mapping: " +
+                json.dumps(cls.__discriminator_value_class_map))
 
 
 from typing import Optional, List, Dict
 
+
 class PointOfTimeModel():
+
     def __init__(
         self,
         point_of_time_type: str,
         # optional properties
         reference: Optional[str] = None,
     ):
+
         self.point_of_time_type = point_of_time_type
         self.reference = reference
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
-        return PointOfTime(
-            
-            reference=self.reference,
-
-        )
+        return PointOfTime(reference=self.reference, )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeModel:
         return model.__class__._model_class._from_model(model)
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union(PointOfTimeOffsetModel, PointOfTimeStatementModel, PointOfTimeTimestampModel):
+    def from_dict(
+        cls, obj: dict
+    ) -> Union[PointOfTimeOffsetModel, PointOfTimeStatementModel,
+               PointOfTimeTimestampModel]:
         """Create an instance of PointOfTime from a dict"""
         return cls._from_model(PointOfTime.from_dict(obj))
 
 
 PointOfTime._model_class = PointOfTimeModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_offset.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time_offset.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import StrictStr
+
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class PointOfTimeOffset(PointOfTime):
+
     offset: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeOffset:
         """Create an instance of PointOfTimeOffset from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeOffset')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeOffset')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeOffset:
         """Create an instance of PointOfTimeOffset from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeOffset.parse_obj(obj)
 
         _obj = PointOfTimeOffset.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "offset": obj.get("offset"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "offset":
+            obj.get("offset"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
+
 class PointOfTimeOffsetModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         offset: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.offset = offset
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeOffset(
-            
             reference=self.reference,
-
             offset=self.offset,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeOffsetModel:
         return PointOfTimeOffsetModel(
-            
             reference=model.reference,
-
             offset=model.offset,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_statement.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/models/point_of_time_statement.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import StrictStr
+
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class PointOfTimeStatement(PointOfTime):
+
     statement: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeStatement:
         """Create an instance of PointOfTimeStatement from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeStatement')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeStatement')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeStatement:
         """Create an instance of PointOfTimeStatement from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeStatement.parse_obj(obj)
 
         _obj = PointOfTimeStatement.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "statement": obj.get("statement"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "statement":
+            obj.get("statement"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
+
 class PointOfTimeStatementModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         statement: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.statement = statement
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeStatement(
-            
             reference=self.reference,
-
             statement=self.statement,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeStatementModel:
         return PointOfTimeStatementModel(
-            
             reference=model.reference,
-
             statement=model.statement,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/point_of_time_timestamp.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time_timestamp.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Database API
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import StrictStr
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class PointOfTimeTimestamp(PointOfTime):
+
     timestamp: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeTimestamp:
         """Create an instance of PointOfTimeTimestamp from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeTimestamp')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeTimestamp')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeTimestamp:
         """Create an instance of PointOfTimeTimestamp from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeTimestamp.parse_obj(obj)
 
         _obj = PointOfTimeTimestamp.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "timestamp": obj.get("timestamp"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "timestamp":
+            obj.get("timestamp"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
 
 class PointOfTimeTimestampModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         timestamp: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.timestamp = timestamp
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeTimestamp(
-            
             reference=self.reference,
-
             timestamp=self.timestamp,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeTimestampModel:
         return PointOfTimeTimestampModel(
-            
             reference=model.reference,
-
             timestamp=model.timestamp,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/schema_clone.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/database.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,317 +1,322 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Database API
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Optional
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
-class SchemaClone(BaseModel):
-    point_of_time: Optional[PointOfTime] = None
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
+
+class Database(BaseModel):
+
     created_on: Optional[datetime] = None
-    name: constr(strict=True) = Field(...)
+
+    name: Annotated[str, Field(strict=True)]
+
     is_default: Optional[StrictBool] = None
+
     is_current: Optional[StrictBool] = None
-    database_name: Optional[StrictStr] = None
+
+    origin: Optional[StrictStr] = None
+
     owner: Optional[StrictStr] = None
+
     comment: Optional[StrictStr] = None
+
     options: Optional[StrictStr] = None
+
     retention_time: Optional[StrictInt] = None
+
     dropped_on: Optional[datetime] = None
-    owner_role_type: Optional[StrictStr] = None
+
+    kind: Optional[StrictStr] = None
+
     budget: Optional[StrictStr] = None
+
+    owner_role_type: Optional[StrictStr] = None
+
     data_retention_time_in_days: Optional[StrictInt] = None
+
     default_ddl_collation: Optional[StrictStr] = None
+
     log_level: Optional[StrictStr] = None
-    pipe_execution_paused: Optional[StrictBool] = None
+
     max_data_extension_time_in_days: Optional[StrictInt] = None
+
     suspend_task_after_num_failures: Optional[StrictInt] = None
+
     trace_level: Optional[StrictStr] = None
+
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
+
     user_task_timeout_ms: Optional[StrictInt] = None
-    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "origin", "owner",
+        "comment", "options", "retention_time", "dropped_on", "kind", "budget",
+        "owner_role_type", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> SchemaClone:
-        """Create an instance of SchemaClone from a JSON string"""
+    def from_json(cls, json_str: str) -> Database:
+        """Create an instance of Database from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "created_on",
-                            "is_default",
-                            "is_current",
-                            "database_name",
-                            "owner",
-                            "options",
-                            "retention_time",
-                            "dropped_on",
-                            "owner_role_type",
-                            "budget",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "is_default",
+                           "is_current",
+                           "origin",
+                           "owner",
+                           "options",
+                           "retention_time",
+                           "dropped_on",
+                           "kind",
+                           "budget",
+                           "owner_role_type",
+                       },
+                       exclude_none=True))
+
         # set to None if dropped_on (nullable) is None
         if self.dropped_on is None:
             _dict['dropped_on'] = None
 
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> SchemaClone:
-        """Create an instance of SchemaClone from a dict"""
+    def from_dict(cls, obj: dict) -> Database:
+        """Create an instance of Database from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
-            return SchemaClone.parse_obj(obj)
-
-        _obj = SchemaClone.parse_obj({
-            "point_of_time": PointOfTime.from_dict(obj.get("point_of_time")) if obj.get("point_of_time") is not None else None,
-
-            "created_on": obj.get("created_on"),
-
-            "name": obj.get("name"),
-
-            "is_default": obj.get("is_default"),
-
-            "is_current": obj.get("is_current"),
-
-            "database_name": obj.get("database_name"),
-
-            "owner": obj.get("owner"),
-
-            "comment": obj.get("comment"),
-
-            "options": obj.get("options"),
-
-            "retention_time": obj.get("retention_time"),
-
-            "dropped_on": obj.get("dropped_on"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
-            "budget": obj.get("budget"),
-
-            "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
-
-            "default_ddl_collation": obj.get("default_ddl_collation"),
-
-            "log_level": obj.get("log_level"),
-
-            "pipe_execution_paused": obj.get("pipe_execution_paused"),
-
-            "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
-
-            "suspend_task_after_num_failures": obj.get("suspend_task_after_num_failures"),
-
-            "trace_level": obj.get("trace_level"),
-
-            "user_task_managed_initial_warehouse_size": obj.get("user_task_managed_initial_warehouse_size"),
-
-            "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
+            return Database.parse_obj(obj)
 
+        _obj = Database.parse_obj({
+            "created_on":
+            obj.get("created_on"),
+            "name":
+            obj.get("name"),
+            "is_default":
+            obj.get("is_default"),
+            "is_current":
+            obj.get("is_current"),
+            "origin":
+            obj.get("origin"),
+            "owner":
+            obj.get("owner"),
+            "comment":
+            obj.get("comment"),
+            "options":
+            obj.get("options"),
+            "retention_time":
+            obj.get("retention_time"),
+            "dropped_on":
+            obj.get("dropped_on"),
+            "kind":
+            obj.get("kind"),
+            "budget":
+            obj.get("budget"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
+            "data_retention_time_in_days":
+            obj.get("data_retention_time_in_days"),
+            "default_ddl_collation":
+            obj.get("default_ddl_collation"),
+            "log_level":
+            obj.get("log_level"),
+            "max_data_extension_time_in_days":
+            obj.get("max_data_extension_time_in_days"),
+            "suspend_task_after_num_failures":
+            obj.get("suspend_task_after_num_failures"),
+            "trace_level":
+            obj.get("trace_level"),
+            "user_task_managed_initial_warehouse_size":
+            obj.get("user_task_managed_initial_warehouse_size"),
+            "user_task_timeout_ms":
+            obj.get("user_task_timeout_ms"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.schema._generated.models.point_of_time import PointOfTime
 
-class SchemaCloneModel():
+
+class DatabaseModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
-        point_of_time: Optional[PointOfTime] = None,
         created_on: Optional[datetime] = None,
         is_default: Optional[bool] = None,
         is_current: Optional[bool] = None,
-        database_name: Optional[str] = None,
+        origin: Optional[str] = None,
         owner: Optional[str] = None,
         comment: Optional[str] = None,
         options: Optional[str] = None,
         retention_time: Optional[int] = None,
         dropped_on: Optional[datetime] = None,
-        owner_role_type: Optional[str] = None,
+        kind: Optional[str] = None,
         budget: Optional[str] = None,
+        owner_role_type: Optional[str] = None,
         data_retention_time_in_days: Optional[int] = None,
         default_ddl_collation: Optional[str] = None,
         log_level: Optional[str] = None,
-        pipe_execution_paused: Optional[bool] = None,
         max_data_extension_time_in_days: Optional[int] = None,
         suspend_task_after_num_failures: Optional[int] = None,
         trace_level: Optional[str] = None,
         user_task_managed_initial_warehouse_size: Optional[str] = None,
         user_task_timeout_ms: Optional[int] = None,
     ):
-        self.point_of_time = point_of_time
+
         self.created_on = created_on
         self.name = name
         self.is_default = is_default
         self.is_current = is_current
-        self.database_name = database_name
+        self.origin = origin
         self.owner = owner
         self.comment = comment
         self.options = options
         self.retention_time = retention_time
         self.dropped_on = dropped_on
-        self.owner_role_type = owner_role_type
+        self.kind = kind
         self.budget = budget
+        self.owner_role_type = owner_role_type
         self.data_retention_time_in_days = data_retention_time_in_days
         self.default_ddl_collation = default_ddl_collation
         self.log_level = log_level
-        self.pipe_execution_paused = pipe_execution_paused
         self.max_data_extension_time_in_days = max_data_extension_time_in_days
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         self.trace_level = trace_level
         self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
         self.user_task_timeout_ms = user_task_timeout_ms
-    __properties = ["created_on", "name", "is_default", "is_current", "database_name", "owner", "comment", "options", "retention_time", "dropped_on", "owner_role_type", "budget", "data_retention_time_in_days", "default_ddl_collation", "log_level", "pipe_execution_paused", "max_data_extension_time_in_days", "suspend_task_after_num_failures", "trace_level", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms"]
 
-    def _to_model(self):
-        return SchemaClone(
-            point_of_time=self.point_of_time._to_model() if self.point_of_time is not None else None,
+    __properties = [
+        "created_on", "name", "is_default", "is_current", "origin", "owner",
+        "comment", "options", "retention_time", "dropped_on", "kind", "budget",
+        "owner_role_type", "data_retention_time_in_days",
+        "default_ddl_collation", "log_level",
+        "max_data_extension_time_in_days", "suspend_task_after_num_failures",
+        "trace_level", "user_task_managed_initial_warehouse_size",
+        "user_task_timeout_ms"
+    ]
 
+    def _to_model(self):
+        return Database(
             created_on=self.created_on,
-
             name=self.name,
-
             is_default=self.is_default,
-
             is_current=self.is_current,
-
-            database_name=self.database_name,
-
+            origin=self.origin,
             owner=self.owner,
-
             comment=self.comment,
-
             options=self.options,
-
             retention_time=self.retention_time,
-
             dropped_on=self.dropped_on,
-
-            owner_role_type=self.owner_role_type,
-
+            kind=self.kind,
             budget=self.budget,
-
+            owner_role_type=self.owner_role_type,
             data_retention_time_in_days=self.data_retention_time_in_days,
-
             default_ddl_collation=self.default_ddl_collation,
-
             log_level=self.log_level,
-
-            pipe_execution_paused=self.pipe_execution_paused,
-
-            max_data_extension_time_in_days=self.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=self.suspend_task_after_num_failures,
-
+            max_data_extension_time_in_days=self.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=self.
+            suspend_task_after_num_failures,
             trace_level=self.trace_level,
-
-            user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=self.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=self.user_task_timeout_ms,
-
         )
 
     @classmethod
-    def _from_model(cls, model) -> SchemaCloneModel:
-        return SchemaCloneModel(
-            point_of_time=PointOfTimeModel._from_model(model.point_of_time) if model.point_of_time is not None else None,
-
+    def _from_model(cls, model) -> DatabaseModel:
+        return DatabaseModel(
             created_on=model.created_on,
-
             name=model.name,
-
             is_default=model.is_default,
-
             is_current=model.is_current,
-
-            database_name=model.database_name,
-
+            origin=model.origin,
             owner=model.owner,
-
             comment=model.comment,
-
             options=model.options,
-
             retention_time=model.retention_time,
-
             dropped_on=model.dropped_on,
-
-            owner_role_type=model.owner_role_type,
-
+            kind=model.kind,
             budget=model.budget,
-
+            owner_role_type=model.owner_role_type,
             data_retention_time_in_days=model.data_retention_time_in_days,
-
             default_ddl_collation=model.default_ddl_collation,
-
             log_level=model.log_level,
-
-            pipe_execution_paused=model.pipe_execution_paused,
-
-            max_data_extension_time_in_days=model.max_data_extension_time_in_days,
-
-            suspend_task_after_num_failures=model.suspend_task_after_num_failures,
-
+            max_data_extension_time_in_days=model.
+            max_data_extension_time_in_days,
+            suspend_task_after_num_failures=model.
+            suspend_task_after_num_failures,
             trace_level=model.trace_level,
-
-            user_task_managed_initial_warehouse_size=model.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=model.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=model.user_task_timeout_ms,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> SchemaCloneModel:
-        """Create an instance of SchemaClone from a dict"""
-        return cls._from_model(SchemaClone.from_dict(obj))
+    def from_dict(cls, obj: dict) -> DatabaseModel:
+        """Create an instance of Database from a dict"""
+        return cls._from_model(Database.from_dict(obj))
 
 
-SchemaClone._model_class = SchemaCloneModel
+Database._model_class = DatabaseModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/schema/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/role/_generated/models/success_response.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Schema API
-
-    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on Schema resource in Snowflake.  # noqa: E501
 
+    Snowflake Role API
+    The Snowflake Role API is a REST API that you can use to access, update, and perform certain action on Roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.schema._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/service/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_service.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_service.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 import json
 import re
 
 from textwrap import dedent
-from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Optional, Tuple, Union
+from typing import TYPE_CHECKING, Any, Dict, Iterable, Iterator, List, Optional, Tuple, Union
 
 import yaml
 
-from snowflake.core.service._generated.pydantic_compatibility import StrictInt, StrictStr
+from pydantic import StrictInt, StrictStr
 
 from .._common import (
     CreateMode,
     SchemaObjectCollectionParent,
     SchemaObjectReferenceMixin,
 )
 from .._internal.telemetry import api_telemetry
 
 
 if TYPE_CHECKING:
     from snowflake.core.schema import SchemaResource
 
-from snowflake.core.service._generated import ServiceApi
+from snowflake.core.service._generated import ServiceApi, ServiceEndpoint
 from snowflake.core.service._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.service._generated.models import Service, ServiceSpecInlineText, ServiceSpecStageFile
 
 
 class ServiceCollection(SchemaObjectCollectionParent["ServiceResource"]):
     """Represents the collection operations of the Snowpark Container Service resource."""
 
@@ -70,23 +70,22 @@
         Args:
             service: an instance of :class:`Service`.
             mode: One of the following strings.
 
                 CreateMode.error_if_exists: Throw an :class:`snowflake.core.exceptions.ConflictError`
                 if the service already exists in Snowflake. Equivalent to SQL ``create service <name> ...``.
 
-                CreateMode.or_replace: Replace if the service already exists in Snowflake. Equivalent to SQL
-                ``create or replace service <name> ...``.
-
                 CreateMode.if_not_exists: Do nothing if the service already exists in Snowflake. Equivalent to SQL
                 ``create service <name> if not exists...``
 
                 Default value is CreateMode.error_if_exists.
 
         """
+        if mode == CreateMode.or_replace:
+            raise ValueError(f"{mode} is not a valid value for this resource")
         real_mode = CreateMode[mode].value
         self._api.create_service(
             self.database.name,
             self.schema.name,
             service,
             StrictStr(real_mode),
             async_req=False,
@@ -127,14 +126,21 @@
     def resume(self) -> None:
         """Resumes the service."""
         self.collection._api.resume_service(
             self.database.name, self.schema.name, self.name, async_req=False
         )
 
     @api_telemetry
+    def get_endpoints(self) -> Iterable[ServiceEndpoint]:
+        """Show the endpoints corresponding to this service."""
+        return self.collection._api.show_service_endpoints(
+            self.database.name, self.schema.name, self.name, async_req=False
+        )
+
+    @api_telemetry
     def get_service_status(self, timeout: int = 0) -> List[Dict[str, Any]]:
         """Get the status of the service.
 
         Args:
             timeout: Number of seconds to wait for the service to reach a steady state (for example, READY)
               before returning the status. If the service does not reach steady state within the specified time,
               Snowflake returns the current state.
@@ -151,30 +157,32 @@
             async_req=False,
         )
         if status.systemget_service_status is None:
             return list()
         return json.loads(status.systemget_service_status)
 
     @api_telemetry
-    def get_service_logs(self, instance_id: str, container_name: str) -> str:
+    def get_service_logs(self, instance_id: str, container_name: str, num_lines: Optional[int] = None) -> str:
         """Get the service logs of the service.
 
         Args:
             instance_id: Service instance ID.
             container_name: Container name.
+            num_lines: (Optional) Number of the most recent log lines to retrieve.
 
         :meth:`get_service_status` returns the ``instance_id`` and ``container_name`` as a part of its results.
 
         """
         logs = self.collection._api.fetch_service_logs(
             self.database.name,
             self.schema.name,
             self.name,
             StrictInt(instance_id),
             StrictStr(container_name),
+            num_lines,
             async_req=False,
         )
         if logs.systemget_service_logs is None:
             return ""
         return logs.systemget_service_logs
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.service._generated.api.service_api import ServiceApi
-
 # import ApiClient
 from snowflake.core.service._generated.api_client import ApiClient
 from snowflake.core.service._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.service._generated.models.error_response import ErrorResponse
 from snowflake.core.service._generated.models.fetch_service_logs200_response import FetchServiceLogs200Response
 from snowflake.core.service._generated.models.fetch_service_status200_response import FetchServiceStatus200Response
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/function/_generated/api_client.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Services API
-
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Function API
+    The Snowflake Function API is a REST API that allows caller to create, execute and drop functions in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.service._generated.configuration import Configuration
-import snowflake.core.service._generated.models
-from snowflake.core.service._generated import rest
-from snowflake.core.service._generated.paging import PagedIter
+from snowflake.core.function._generated.configuration import Configuration
+import snowflake.core.function._generated.models
+from snowflake.core.function._generated import rest
+from snowflake.core.function._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,62 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.service._generated.models, klass)
+                klass = getattr(snowflake.core.function._generated.models,
+                                klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +520,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +671,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for service. Updating service '
-                        'objects is not supported yet; use create() for creating a service.')
+                        'create_or_update is not yet supported for function. Updating function '
+                        'objects is not supported yet; use create() for creating a function.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +700,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +743,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +787,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +824,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +848,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +875,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +941,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +959,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +975,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1010,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/api_response.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.service._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
-
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Database API
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.service._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.database._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Services API",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake Database API",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/stage/_generated/rest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
-
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Stage API
+    The Snowflake Stage API is a REST API that you can use to access, update, and perform certain actions on stage resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/api/service_api.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/api/service_api.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,49 +1,43 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
-
+from pydantic import Field, StrictBool, StrictInt, StrictStr, field_validator
 from typing import List, Optional
-
+from typing_extensions import Annotated
 from snowflake.core.service._generated.models.fetch_service_logs200_response import FetchServiceLogs200Response
 from snowflake.core.service._generated.models.fetch_service_status200_response import FetchServiceStatus200Response
 from snowflake.core.service._generated.models.service import Service
 from snowflake.core.service._generated.models.service_endpoint import ServiceEndpoint
 from snowflake.core.service._generated.models.success_response import SuccessResponse
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.service._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
+
+logger = logging.getLogger(__name__)
 
-logger  = logging.getLogger(__name__)
 
 class ServiceApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
@@ -74,15 +68,16 @@
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('service')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge('service')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -94,35 +89,63 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], service : Service, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def create_service(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            service: Service,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """Create a service  # noqa: E501
 
+
         Create a service, with standard create modifiers as query parameters. See the Service component definition for what is required to be provided in the request body.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_service(database, var_schema, service, create_mode, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
         :param service: (required)
         :type service: Service
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -132,34 +155,63 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_service_with_http_info(database, var_schema, service, create_mode, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def create_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], service : Service, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
+        return self.create_service_with_http_info(database, var_schema,
+                                                  service, create_mode,
+                                                  **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_service_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            service: Service,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs):  # noqa: E501
         """Create a service  # noqa: E501
 
+
         Create a service, with standard create modifiers as query parameters. See the Service component definition for what is required to be provided in the request body.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_service_with_http_info(database, var_schema, service, create_mode, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
         :param service: (required)
         :type service: Service
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -179,78 +231,68 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'service',
-            'create_mode'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'service', 'create_mode']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_service" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_service" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['service']:
             _body_params = _params['service']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -262,46 +304,65 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/services',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Service:  # noqa: E501
+    @validate_call
+    def fetch_service(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                      **kwargs) -> Service:  # noqa: E501
         """Fetch a service.  # noqa: E501
 
+
         Fetch a Service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_service(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -311,32 +372,50 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Service
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.fetch_service_with_http_info(database, var_schema, name,
+                                                 **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def fetch_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def fetch_service_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                     **kwargs):  # noqa: E501
         """Fetch a service.  # noqa: E501
 
+
         Fetch a Service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_service_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -356,49 +435,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(Service, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_service" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_service" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -428,46 +497,87 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}', 'GET',
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_service_logs(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], instance_id : Annotated[StrictInt, Field(..., description="ID of the service instance, starting with 0.")], container_name : Annotated[StrictStr, Field(..., description="Container name as specified in the service specification file.")], num_lines : Annotated[Optional[StrictInt], Field(description="Number of trailing log lines to retrieve.")] = None, **kwargs) -> FetchServiceLogs200Response:  # noqa: E501
+    @validate_call
+    def fetch_service_logs(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            instance_id: Annotated[
+                StrictInt,
+                Field(
+                    description="ID of the service instance, starting with 0."
+                )],
+            container_name:
+        Annotated[
+            StrictStr,
+            Field(
+                description=
+                "Container name as specified in the service specification file."
+            )],
+            num_lines: Annotated[
+                Optional[StrictInt],
+                Field(description="Number of trailing log lines to retrieve."
+                      )] = None,
+            **kwargs) -> FetchServiceLogs200Response:  # noqa: E501
         """Fetch the logs for a given service.  # noqa: E501
 
+
         Fetch the logs for a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_service_logs(database, var_schema, name, instance_id, container_name, num_lines, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param instance_id: ID of the service instance, starting with 0. (required)
         :type instance_id: int
         :param container_name: Container name as specified in the service specification file. (required)
         :type container_name: str
         :param num_lines: Number of trailing log lines to retrieve.
         :type num_lines: int
@@ -483,32 +593,75 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: FetchServiceLogs200Response
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_service_logs_with_http_info(database, var_schema, name, instance_id, container_name, num_lines, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def fetch_service_logs_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], instance_id : Annotated[StrictInt, Field(..., description="ID of the service instance, starting with 0.")], container_name : Annotated[StrictStr, Field(..., description="Container name as specified in the service specification file.")], num_lines : Annotated[Optional[StrictInt], Field(description="Number of trailing log lines to retrieve.")] = None, **kwargs):  # noqa: E501
+        return self.fetch_service_logs_with_http_info(database, var_schema,
+                                                      name, instance_id,
+                                                      container_name,
+                                                      num_lines,
+                                                      **kwargs)  # noqa: E501
+
+    @validate_call
+    def fetch_service_logs_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            instance_id: Annotated[
+                StrictInt,
+                Field(
+                    description="ID of the service instance, starting with 0."
+                )],
+            container_name:
+        Annotated[
+            StrictStr,
+            Field(
+                description=
+                "Container name as specified in the service specification file."
+            )],
+            num_lines: Annotated[
+                Optional[StrictInt],
+                Field(description="Number of trailing log lines to retrieve."
+                      )] = None,
+            **kwargs):  # noqa: E501
         """Fetch the logs for a given service.  # noqa: E501
 
+
         Fetch the logs for a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_service_logs_with_http_info(database, var_schema, name, instance_id, container_name, num_lines, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param instance_id: ID of the service instance, starting with 0. (required)
         :type instance_id: int
         :param container_name: Container name as specified in the service specification file. (required)
         :type container_name: str
         :param num_lines: Number of trailing log lines to retrieve.
         :type num_lines: int
@@ -535,60 +688,53 @@
                  returns the request thread.
         :rtype: tuple(FetchServiceLogs200Response, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'instance_id',
-            'container_name',
+            'database', 'var_schema', 'name', 'instance_id', 'container_name',
             'num_lines'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_service_logs" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_service_logs" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('instance_id') is not None:  # noqa: E501
             _query_params.append(('instanceId', _params['instance_id']))
+
         if _params.get('container_name') is not None:  # noqa: E501
             _query_params.append(('containerName', _params['container_name']))
+
         if _params.get('num_lines') is not None:  # noqa: E501
             _query_params.append(('numLines', _params['num_lines']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -615,46 +761,78 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/logs', 'GET',
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/logs',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_service_status(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], timeout : Annotated[Optional[StrictInt], Field(description="Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.")] = None, **kwargs) -> FetchServiceStatus200Response:  # noqa: E501
+    @validate_call
+    def fetch_service_status(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            timeout:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state."
+            )] = None,
+            **kwargs) -> FetchServiceStatus200Response:  # noqa: E501
         """Fetch the status for a given service.  # noqa: E501
 
+
         Fetch the status for a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_service_status(database, var_schema, name, timeout, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param timeout: Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.
         :type timeout: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -666,32 +844,63 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: FetchServiceStatus200Response
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_service_status_with_http_info(database, var_schema, name, timeout, **kwargs)  # noqa: E501
+        return self.fetch_service_status_with_http_info(
+            database, var_schema, name, timeout, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def fetch_service_status_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], timeout : Annotated[Optional[StrictInt], Field(description="Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def fetch_service_status_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            timeout:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state."
+            )] = None,
+            **kwargs):  # noqa: E501
         """Fetch the status for a given service.  # noqa: E501
 
+
         Fetch the status for a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.fetch_service_status_with_http_info(database, var_schema, name, timeout, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param timeout: Number of seconds to wait for the service to reach a steady state (for example, READY) before returning the status. If the service does not reach a steady state within the specified time, Snowflake returns the current state.
         :type timeout: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -713,55 +922,45 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(FetchServiceStatus200Response, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'timeout'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name', 'timeout']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_service_status" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_service_status" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('timeout') is not None:  # noqa: E501
             _query_params.append(('timeout', _params['timeout']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -788,50 +987,92 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/status', 'GET',
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/status',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def list_services(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs) -> Iterable[Service]:  # noqa: E501
+    @validate_call
+    def list_services(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            **kwargs) -> Iterable[Service]:  # noqa: E501
         """List services  # noqa: E501
 
+
         Lists the services under the database and schema.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_services(database, var_schema, like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -841,36 +1082,78 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Iterable[Service]
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_services_with_http_info(database, var_schema, like, starts_with, show_limit, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def list_services_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs):  # noqa: E501
+        return self.list_services_with_http_info(database, var_schema, like,
+                                                 starts_with, show_limit,
+                                                 **kwargs)  # noqa: E501
+
+    @validate_call
+    def list_services_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            **kwargs):  # noqa: E501
         """List services  # noqa: E501
 
+
         Lists the services under the database and schema.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_services_with_http_info(database, var_schema, like, starts_with, show_limit, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -891,57 +1174,49 @@
                  returns the request thread.
         :rtype: tuple(Iterable[Service], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'like',
-            'starts_with',
-            'show_limit'
+            'database', 'var_schema', 'like', 'starts_with', 'show_limit'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method list_services" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method list_services" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
+
         if _params.get('starts_with') is not None:  # noqa: E501
             _query_params.append(('startsWith', _params['starts_with']))
+
         if _params.get('show_limit') is not None:  # noqa: E501
             _query_params.append(('showLimit', _params['show_limit']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -968,46 +1243,65 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services', 'GET',
+            '/api/v2/databases/{database}/schemas/{schema}/services',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def resume_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def resume_service(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                       **kwargs) -> SuccessResponse:  # noqa: E501
         """Resume a service  # noqa: E501
 
+
         Resume a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.resume_service(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1017,32 +1311,50 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.resume_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.resume_service_with_http_info(database, var_schema, name,
+                                                  **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def resume_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def resume_service_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                      **kwargs):  # noqa: E501
         """Resume a service  # noqa: E501
 
+
         Resume a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.resume_service_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1062,49 +1374,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method resume_service" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method resume_service" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1134,45 +1436,64 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:resume', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:resume',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def show_service_endpoints(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Iterable[ServiceEndpoint]:  # noqa: E501
+    @validate_call
+    def show_service_endpoints(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                               **kwargs
+                               ) -> Iterable[ServiceEndpoint]:  # noqa: E501
         """List the endpoints in a service.  # noqa: E501
 
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.show_service_endpoints(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1182,31 +1503,48 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Iterable[ServiceEndpoint]
         """
         kwargs['_return_http_data_only'] = True
-        return self.show_service_endpoints_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.show_service_endpoints_with_http_info(
+            database, var_schema, name, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def show_service_endpoints_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def show_service_endpoints_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                              **kwargs):  # noqa: E501
         """List the endpoints in a service.  # noqa: E501
 
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.show_service_endpoints_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1226,49 +1564,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(Iterable[ServiceEndpoint], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method show_service_endpoints" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method show_service_endpoints" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1298,46 +1626,65 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/endpoints', 'GET',
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}/endpoints',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def suspend_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def suspend_service(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                        **kwargs) -> SuccessResponse:  # noqa: E501
         """Suspend a service  # noqa: E501
 
+
         Suspend a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.suspend_service(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1347,32 +1694,50 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_service_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.suspend_service_with_http_info(database, var_schema, name,
+                                                   **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def suspend_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def suspend_service_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                       **kwargs):  # noqa: E501
         """Suspend a service  # noqa: E501
 
+
         Suspend a service.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.suspend_service_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1392,49 +1757,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method suspend_service" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method suspend_service" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1464,48 +1819,80 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:suspend', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}:suspend',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def delete_service(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def delete_service(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """Delete a service  # noqa: E501
 
+
         Delete a service with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_service(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1515,34 +1902,66 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_service_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def delete_service_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+        return self.delete_service_with_http_info(database, var_schema, name,
+                                                  if_exists,
+                                                  **kwargs)  # noqa: E501
+
+    @validate_call
+    def delete_service_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
         """Delete a service  # noqa: E501
 
+
         Delete a service with the given name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.delete_service_with_http_info(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1562,55 +1981,45 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method delete_service" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method delete_service" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -1637,22 +2046,24 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/services/{name}', 'DELETE',
+            '/api/v2/databases/{database}/schemas/{schema}/services/{name}',
+            'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,23 +1,20 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.service._generated.models.error_response import ErrorResponse
 from snowflake.core.service._generated.models.fetch_service_logs200_response import FetchServiceLogs200Response
 from snowflake.core.service._generated.models.fetch_service_status200_response import FetchServiceStatus200Response
 from snowflake.core.service._generated.models.service import Service
@@ -33,8 +30,8 @@
     'FetchServiceStatus200Response',
     'Service',
     'ServiceEndpoint',
     'ServiceSpec',
     'ServiceSpecInlineText',
     'ServiceSpecStageFile',
     'SuccessResponse',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/grant/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
-
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Grant API
+    The Snowflake Grant API is a REST API that you can use to show or manage privileges that have been provided to users and roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/fetch_service_logs200_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,39 +1,39 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import BaseModel, Field, StrictStr
+
+from pydantic import BaseModel, ConfigDict, Field, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class FetchServiceLogs200Response(BaseModel):
-    systemget_service_logs: Optional[StrictStr] = Field(None, alias="system$get_service_logs")
-    __properties = ["system$get_service_logs"]
 
+    systemget_service_logs: Optional[StrictStr] = Field(
+        default=None, alias="system$get_service_logs")
+
+    __properties = ["system$get_service_logs"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +43,62 @@
     @classmethod
     def from_json(cls, json_str: str) -> FetchServiceLogs200Response:
         """Create an instance of FetchServiceLogs200Response from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> FetchServiceLogs200Response:
         """Create an instance of FetchServiceLogs200Response from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return FetchServiceLogs200Response.parse_obj(obj)
 
         _obj = FetchServiceLogs200Response.parse_obj({
-            "systemget_service_logs": obj.get("system$get_service_logs"),
-
+            "systemget_service_logs":
+            obj.get("system$get_service_logs"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class FetchServiceLogs200ResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         systemget_service_logs: Optional[str] = None,
     ):
+
         self.systemget_service_logs = systemget_service_logs
+
     __properties = ["system$get_service_logs"]
 
     def _to_model(self):
         return FetchServiceLogs200Response(
-            systemget_service_logs=self.systemget_service_logs,
-
-        )
+            systemget_service_logs=self.systemget_service_logs, )
 
     @classmethod
     def _from_model(cls, model) -> FetchServiceLogs200ResponseModel:
         return FetchServiceLogs200ResponseModel(
-            systemget_service_logs=model.systemget_service_logs,
-
-        )
+            systemget_service_logs=model.systemget_service_logs, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> FetchServiceLogs200ResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/fetch_service_status200_response.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,39 +1,39 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import BaseModel, Field, StrictStr
+
+from pydantic import BaseModel, ConfigDict, Field, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class FetchServiceStatus200Response(BaseModel):
-    systemget_service_status: Optional[StrictStr] = Field(None, alias="system$get_service_status")
-    __properties = ["system$get_service_status"]
 
+    systemget_service_status: Optional[StrictStr] = Field(
+        default=None, alias="system$get_service_status")
+
+    __properties = ["system$get_service_status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +43,62 @@
     @classmethod
     def from_json(cls, json_str: str) -> FetchServiceStatus200Response:
         """Create an instance of FetchServiceStatus200Response from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> FetchServiceStatus200Response:
         """Create an instance of FetchServiceStatus200Response from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return FetchServiceStatus200Response.parse_obj(obj)
 
         _obj = FetchServiceStatus200Response.parse_obj({
-            "systemget_service_status": obj.get("system$get_service_status"),
-
+            "systemget_service_status":
+            obj.get("system$get_service_status"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class FetchServiceStatus200ResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         systemget_service_status: Optional[str] = None,
     ):
+
         self.systemget_service_status = systemget_service_status
+
     __properties = ["system$get_service_status"]
 
     def _to_model(self):
         return FetchServiceStatus200Response(
-            systemget_service_status=self.systemget_service_status,
-
-        )
+            systemget_service_status=self.systemget_service_status, )
 
     @classmethod
     def _from_model(cls, model) -> FetchServiceStatus200ResponseModel:
         return FetchServiceStatus200ResponseModel(
-            systemget_service_status=model.systemget_service_status,
-
-        )
+            systemget_service_status=model.systemget_service_status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> FetchServiceStatus200ResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,86 +1,123 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import List, Optional
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist, constr, validator
+
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
+
 class Service(BaseModel):
-    name: constr(strict=True) = Field(...)
-    compute_pool: StrictStr = Field(...)
-    spec: ServiceSpec = Field(...)
-    external_access_integrations: Optional[conlist(StrictStr)] = None
+
+    name: Annotated[str, Field(strict=True)]
+
+    compute_pool: StrictStr
+
+    spec: ServiceSpec
+
+    external_access_integrations: Optional[List[StrictStr]] = None
+
     auto_resume: Optional[StrictBool] = None
+
     min_instances: Optional[StrictInt] = None
+
     max_instances: Optional[StrictInt] = None
-    query_warehouse: Optional[constr(strict=True)] = None
+
+    query_warehouse: Optional[Annotated[str, Field(strict=True)]] = None
+
     comment: Optional[StrictStr] = None
-    database_name: Optional[constr(strict=True)] = None
-    schema_name: Optional[constr(strict=True)] = None
+
+    database_name: Optional[Annotated[str, Field(strict=True)]] = None
+
+    schema_name: Optional[Annotated[str, Field(strict=True)]] = None
+
     owner: Optional[StrictStr] = None
+
     dns_name: Optional[StrictStr] = None
+
     created_on: Optional[datetime] = None
+
     updated_on: Optional[datetime] = None
+
     resumed_on: Optional[datetime] = None
+
     owner_role_type: Optional[StrictStr] = None
-    __properties = ["name", "compute_pool", "spec", "external_access_integrations", "auto_resume", "min_instances", "max_instances", "query_warehouse", "comment", "database_name", "schema_name", "owner", "dns_name", "created_on", "updated_on", "resumed_on", "owner_role_type"]
 
+    __properties = [
+        "name", "compute_pool", "spec", "external_access_integrations",
+        "auto_resume", "min_instances", "max_instances", "query_warehouse",
+        "comment", "database_name", "schema_name", "owner", "dns_name",
+        "created_on", "updated_on", "resumed_on", "owner_role_type"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('query_warehouse')
+    @field_validator('query_warehouse')
     def query_warehouse_validate_regular_expression(cls, v):
+
         if v is None:
             return v
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('database_name')
+    @field_validator('database_name')
     def database_name_validate_regular_expression(cls, v):
+
         if v is None:
             return v
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('schema_name')
+    @field_validator('schema_name')
     def schema_name_validate_regular_expression(cls, v):
+
         if v is None:
             return v
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -90,81 +127,91 @@
     @classmethod
     def from_json(cls, json_str: str) -> Service:
         """Create an instance of Service from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "owner",
-                            "dns_name",
-                            "created_on",
-                            "updated_on",
-                            "resumed_on",
-                            "owner_role_type",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "owner",
+                           "dns_name",
+                           "created_on",
+                           "updated_on",
+                           "resumed_on",
+                           "owner_role_type",
+                       },
+                       exclude_none=True))
+
         # override the default output from pydantic by calling `to_dict()` of spec
         if self.spec:
             _dict['spec'] = self.spec.to_dict()
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> Service:
         """Create an instance of Service from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return Service.parse_obj(obj)
 
         _obj = Service.parse_obj({
-            "name": obj.get("name"),
-
-            "compute_pool": obj.get("compute_pool"),
-
-            "spec": ServiceSpec.from_dict(obj.get("spec")) if obj.get("spec") is not None else None,
-
-            "external_access_integrations": obj.get("external_access_integrations"),
-
-            "auto_resume": obj.get("auto_resume"),
-
-            "min_instances": obj.get("min_instances"),
-
-            "max_instances": obj.get("max_instances"),
-
-            "query_warehouse": obj.get("query_warehouse"),
-
-            "comment": obj.get("comment"),
-
-            "database_name": obj.get("database_name"),
-
-            "schema_name": obj.get("schema_name"),
-
-            "owner": obj.get("owner"),
-
-            "dns_name": obj.get("dns_name"),
-
-            "created_on": obj.get("created_on"),
-
-            "updated_on": obj.get("updated_on"),
-
-            "resumed_on": obj.get("resumed_on"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
+            "name":
+            obj.get("name"),
+            "compute_pool":
+            obj.get("compute_pool"),
+            "spec":
+            ServiceSpec.from_dict(obj.get("spec"))
+            if obj.get("spec") is not None else None,
+            "external_access_integrations":
+            obj.get("external_access_integrations"),
+            "auto_resume":
+            obj.get("auto_resume"),
+            "min_instances":
+            obj.get("min_instances"),
+            "max_instances":
+            obj.get("max_instances"),
+            "query_warehouse":
+            obj.get("query_warehouse"),
+            "comment":
+            obj.get("comment"),
+            "database_name":
+            obj.get("database_name"),
+            "schema_name":
+            obj.get("schema_name"),
+            "owner":
+            obj.get("owner"),
+            "dns_name":
+            obj.get("dns_name"),
+            "created_on":
+            obj.get("created_on"),
+            "updated_on":
+            obj.get("updated_on"),
+            "resumed_on":
+            obj.get("resumed_on"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
+
 class ServiceModel():
+
     def __init__(
         self,
         name: str,
         compute_pool: str,
         spec: ServiceSpec,
         # optional properties
         external_access_integrations: Optional[List[str]] = None,
@@ -178,14 +225,15 @@
         owner: Optional[str] = None,
         dns_name: Optional[str] = None,
         created_on: Optional[datetime] = None,
         updated_on: Optional[datetime] = None,
         resumed_on: Optional[datetime] = None,
         owner_role_type: Optional[str] = None,
     ):
+
         self.name = name
         self.compute_pool = compute_pool
         self.spec = spec
         self.external_access_integrations = external_access_integrations
         self.auto_resume = auto_resume
         self.min_instances = min_instances
         self.max_instances = max_instances
@@ -195,91 +243,64 @@
         self.schema_name = schema_name
         self.owner = owner
         self.dns_name = dns_name
         self.created_on = created_on
         self.updated_on = updated_on
         self.resumed_on = resumed_on
         self.owner_role_type = owner_role_type
-    __properties = ["name", "compute_pool", "spec", "external_access_integrations", "auto_resume", "min_instances", "max_instances", "query_warehouse", "comment", "database_name", "schema_name", "owner", "dns_name", "created_on", "updated_on", "resumed_on", "owner_role_type"]
+
+    __properties = [
+        "name", "compute_pool", "spec", "external_access_integrations",
+        "auto_resume", "min_instances", "max_instances", "query_warehouse",
+        "comment", "database_name", "schema_name", "owner", "dns_name",
+        "created_on", "updated_on", "resumed_on", "owner_role_type"
+    ]
 
     def _to_model(self):
         return Service(
             name=self.name,
-
             compute_pool=self.compute_pool,
-
             spec=self.spec._to_model() if self.spec is not None else None,
-
             external_access_integrations=self.external_access_integrations,
-
             auto_resume=self.auto_resume,
-
             min_instances=self.min_instances,
-
             max_instances=self.max_instances,
-
             query_warehouse=self.query_warehouse,
-
             comment=self.comment,
-
             database_name=self.database_name,
-
             schema_name=self.schema_name,
-
             owner=self.owner,
-
             dns_name=self.dns_name,
-
             created_on=self.created_on,
-
             updated_on=self.updated_on,
-
             resumed_on=self.resumed_on,
-
             owner_role_type=self.owner_role_type,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ServiceModel:
         return ServiceModel(
             name=model.name,
-
             compute_pool=model.compute_pool,
-
-            spec=ServiceSpecModel._from_model(model.spec) if model.spec is not None else None,
-
+            spec=ServiceSpecModel._from_model(model.spec)
+            if model.spec is not None else None,
             external_access_integrations=model.external_access_integrations,
-
             auto_resume=model.auto_resume,
-
             min_instances=model.min_instances,
-
             max_instances=model.max_instances,
-
             query_warehouse=model.query_warehouse,
-
             comment=model.comment,
-
             database_name=model.database_name,
-
             schema_name=model.schema_name,
-
             owner=model.owner,
-
             dns_name=model.dns_name,
-
             created_on=model.created_on,
-
             updated_on=model.updated_on,
-
             resumed_on=model.resumed_on,
-
             owner_role_type=model.owner_role_type,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_endpoint.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_endpoint.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,43 +1,46 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import BaseModel, StrictBool, StrictInt, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictBool, StrictInt, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ServiceEndpoint(BaseModel):
+
     name: Optional[StrictStr] = None
+
     port: Optional[StrictInt] = None
+
     protocol: Optional[StrictStr] = None
+
     is_public: Optional[StrictBool] = None
+
     ingress_url: Optional[StrictStr] = None
-    __properties = ["name", "port", "protocol", "is_public", "ingress_url"]
 
+    __properties = ["name", "port", "protocol", "is_public", "ingress_url"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -47,90 +50,82 @@
     @classmethod
     def from_json(cls, json_str: str) -> ServiceEndpoint:
         """Create an instance of ServiceEndpoint from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ServiceEndpoint:
         """Create an instance of ServiceEndpoint from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ServiceEndpoint.parse_obj(obj)
 
         _obj = ServiceEndpoint.parse_obj({
             "name": obj.get("name"),
-
             "port": obj.get("port"),
-
             "protocol": obj.get("protocol"),
-
             "is_public": obj.get("is_public"),
-
             "ingress_url": obj.get("ingress_url"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ServiceEndpointModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         name: Optional[str] = None,
         port: Optional[int] = None,
         protocol: Optional[str] = None,
         is_public: Optional[bool] = None,
         ingress_url: Optional[str] = None,
     ):
+
         self.name = name
         self.port = port
         self.protocol = protocol
         self.is_public = is_public
         self.ingress_url = ingress_url
+
     __properties = ["name", "port", "protocol", "is_public", "ingress_url"]
 
     def _to_model(self):
         return ServiceEndpoint(
             name=self.name,
-
             port=self.port,
-
             protocol=self.protocol,
-
             is_public=self.is_public,
-
             ingress_url=self.ingress_url,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ServiceEndpointModel:
         return ServiceEndpointModel(
             name=model.name,
-
             port=model.port,
-
             protocol=model.protocol,
-
             is_public=model.is_public,
-
             ingress_url=model.ingress_url,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_spec.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,131 +1,144 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
+
 import snowflake.core.service._generated.models
 from snowflake.core.service._generated.models import *
 
-
-from typing import Optional, Union
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from importlib import import_module
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional, Union
+
 
 class ServiceSpec(BaseModel):
+
     spec_type: Optional[StrictStr] = None
-    __properties = ["spec_type"]
 
+    __properties = ["spec_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     # JSON field name that stores the object type
-    __discriminator_property_name = 'spec_type'
+    __discriminator_property_name: ClassVar[str] = 'spec_type'
 
     # discriminator mappings
-    __discriminator_value_class_map = {
+    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
         'from_file': 'ServiceSpecStageFile',
         'from_inline': 'ServiceSpecInlineText'
     }
 
     @classmethod
-    def get_discriminator_value(cls, obj: dict) -> str:
+    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
         """Returns the discriminator value (object type) of the data"""
         discriminator_value = obj[cls.__discriminator_property_name]
         if discriminator_value:
             return cls.__discriminator_value_class_map.get(discriminator_value)
         else:
             return None
 
-
-    __discriminator_value_to_type = {
+    __discriminator_value_to_type: ClassVar[Dict[str, str]] = {
         'ServiceSpecStageFile': 'from_file',
         'ServiceSpecInlineText': 'from_inline',
     }
 
     @classmethod
     def get_child_model_discriminator_value(cls, child_model: str) -> str:
         return cls.__discriminator_value_to_type[child_model]
 
-
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> Union[ServiceSpecInlineText, ServiceSpecStageFile]:
+    def from_json(
+            cls, json_str: str
+    ) -> Union[ServiceSpecInlineText, ServiceSpecStageFile]:
         """Create an instance of ServiceSpec from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union[ServiceSpecInlineText, ServiceSpecStageFile]:
+    def from_dict(
+            cls,
+            obj: dict) -> Union[ServiceSpecInlineText, ServiceSpecStageFile]:
         """Create an instance of ServiceSpec from a dict"""
+
         # look up the object type based on discriminator mapping
         object_type = cls.get_discriminator_value(obj)
         if object_type:
-            klass = getattr(snowflake.core.service._generated.models, object_type)
+            klass = getattr(snowflake.core.service._generated.models,
+                            object_type)
             return klass.from_dict(obj)
         else:
-            raise ValueError("ServiceSpec failed to lookup discriminator value from " +
-                             json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
-                             ", mapping: " + json.dumps(cls.__discriminator_value_class_map))
+            raise ValueError(
+                "ServiceSpec failed to lookup discriminator value from " +
+                json.dumps(obj) + ". Discriminator property name: " +
+                cls.__discriminator_property_name + ", mapping: " +
+                json.dumps(cls.__discriminator_value_class_map))
 
 
 from typing import Optional, List, Dict
 
+
 class ServiceSpecModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         spec_type: Optional[str] = None,
     ):
+
         self.spec_type = spec_type
+
     __properties = ["spec_type"]
 
     def _to_model(self):
-        return ServiceSpec(
-            
-        )
+        return ServiceSpec()
 
     @classmethod
     def _from_model(cls, model) -> ServiceSpecModel:
         return model.__class__._model_class._from_model(model)
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union(ServiceSpecInlineTextModel, ServiceSpecStageFileModel):
+    def from_dict(
+        cls, obj: dict
+    ) -> Union[ServiceSpecInlineTextModel, ServiceSpecStageFileModel]:
         """Create an instance of ServiceSpec from a dict"""
         return cls._from_model(ServiceSpec.from_dict(obj))
 
 
 ServiceSpec._model_class = ServiceSpecModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_inline_text.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_spec_inline_text.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import Field, StrictStr
+
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List
+
+
 class ServiceSpecInlineText(ServiceSpec):
-    spec_text: StrictStr = Field(...)
-    __properties = ["spec_type"]
 
+    spec_text: StrictStr
+
+    __properties = ["spec_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,67 +44,68 @@
     @classmethod
     def from_json(cls, json_str: str) -> ServiceSpecInlineText:
         """Create an instance of ServiceSpecInlineText from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['spec_type'] = ServiceSpec.get_child_model_discriminator_value('ServiceSpecInlineText')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict['spec_type'] = ServiceSpec.get_child_model_discriminator_value(
+            'ServiceSpecInlineText')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ServiceSpecInlineText:
         """Create an instance of ServiceSpecInlineText from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ServiceSpecInlineText.parse_obj(obj)
 
         _obj = ServiceSpecInlineText.parse_obj({
-            "spec_type": obj.get("spec_type"),
-
-            "spec_text": obj.get("spec_text"),
-
+            "spec_type":
+            obj.get("spec_type"),
+            "spec_text":
+            obj.get("spec_text"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
+
 class ServiceSpecInlineTextModel(ServiceSpec):
+
     def __init__(
         self,
         spec_text: str,
         # optional properties
     ):
-        super().__init__(
-        )
+        super().__init__()
         self.spec_text = spec_text
+
     __properties = ["spec_type"]
 
     def _to_model(self):
-        return ServiceSpecInlineText(
-            
-            spec_text=self.spec_text,
-
-        )
+        return ServiceSpecInlineText(spec_text=self.spec_text, )
 
     @classmethod
     def _from_model(cls, model) -> ServiceSpecInlineTextModel:
-        return ServiceSpecInlineTextModel(
-            
-            spec_text=model.spec_text,
-
-        )
+        return ServiceSpecInlineTextModel(spec_text=model.spec_text, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> ServiceSpecInlineTextModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/service_spec_stage_file.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/models/service_spec_stage_file.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,41 +1,42 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
 
+    Snowflake Services API
     The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import Field, StrictStr
+
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List
+
+
 class ServiceSpecStageFile(ServiceSpec):
-    stage: StrictStr = Field(...)
-    spec_file: StrictStr = Field(...)
-    __properties = ["spec_type"]
 
+    stage: StrictStr
+
+    spec_file: StrictStr
+
+    __properties = ["spec_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -45,74 +46,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ServiceSpecStageFile:
         """Create an instance of ServiceSpecStageFile from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['spec_type'] = ServiceSpec.get_child_model_discriminator_value('ServiceSpecStageFile')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict['spec_type'] = ServiceSpec.get_child_model_discriminator_value(
+            'ServiceSpecStageFile')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ServiceSpecStageFile:
         """Create an instance of ServiceSpecStageFile from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ServiceSpecStageFile.parse_obj(obj)
 
         _obj = ServiceSpecStageFile.parse_obj({
-            "spec_type": obj.get("spec_type"),
-
-            "stage": obj.get("stage"),
-
-            "spec_file": obj.get("spec_file"),
-
+            "spec_type":
+            obj.get("spec_type"),
+            "stage":
+            obj.get("stage"),
+            "spec_file":
+            obj.get("spec_file"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.service._generated.models.service_spec import ServiceSpec
 
+
 class ServiceSpecStageFileModel(ServiceSpec):
+
     def __init__(
         self,
         stage: str,
         spec_file: str,
         # optional properties
     ):
-        super().__init__(
-        )
+        super().__init__()
         self.stage = stage
         self.spec_file = spec_file
+
     __properties = ["spec_type"]
 
     def _to_model(self):
         return ServiceSpecStageFile(
-            
             stage=self.stage,
-
             spec_file=self.spec_file,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ServiceSpecStageFileModel:
         return ServiceSpecStageFileModel(
-            
             stage=model.stage,
-
             spec_file=model.spec_file,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/service/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/success_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Services API
-
-    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Task API
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.service._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_session.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_session.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 from typing import TYPE_CHECKING, Dict, Optional
 
+from pydantic import StrictStr
+
 from snowflake.core.session._generated.api import SessionApi
 from snowflake.core.session._generated.api_client import StoredProcApiClient
-from snowflake.core.session._generated.pydantic_compatibility import StrictStr
 
 
 if TYPE_CHECKING:
     from snowflake.core import Root
 
 
 class SnowAPISession:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/grant/_generated/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Session API
-
-    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
+    Snowflake Grant API
+    The Snowflake Grant API is a REST API that you can use to show or manage privileges that have been provided to users and roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
-from snowflake.core.session._generated.api.session_api import SessionApi
-
+from snowflake.core.grant._generated.api.grant_api import GrantApi
 # import ApiClient
-from snowflake.core.session._generated.api_client import ApiClient
-from snowflake.core.session._generated.configuration import Configuration
+from snowflake.core.grant._generated.api_client import ApiClient
+from snowflake.core.grant._generated.configuration import Configuration
 # import models into sdk package
-from snowflake.core.session._generated.models.error_response import ErrorResponse
-from snowflake.core.session._generated.models.parameter import Parameter
-from snowflake.core.session._generated.models.success_response import SuccessResponse
+from snowflake.core.grant._generated.models.error_response import ErrorResponse
+from snowflake.core.grant._generated.models.grant import Grant
+from snowflake.core.grant._generated.models.success_response import SuccessResponse
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/user/_generated/api_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Session API
-
-    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
+    Snowflake User API
+    The Snowflake User API is a REST API that you can use to access, update, and perform certain action on Users in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.session._generated.configuration import Configuration
-import snowflake.core.session._generated.models
-from snowflake.core.session._generated import rest
-from snowflake.core.session._generated.paging import PagedIter
+from snowflake.core.user._generated.configuration import Configuration
+import snowflake.core.user._generated.models
+from snowflake.core.user._generated import rest
+from snowflake.core.user._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,61 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.session._generated.models, klass)
+                klass = getattr(snowflake.core.user._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +519,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +670,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for session. Updating session '
-                        'objects is not supported yet; use create() for creating a session.')
+                        'create_or_update is not yet supported for user. Updating user '
+                        'objects is not supported yet; use create() for creating a user.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +699,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +742,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +786,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +823,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +847,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +874,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +940,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +958,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +974,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1009,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/role/_generated/api_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.session._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/grant/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Session API
-
-    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
+    Snowflake Grant API
+    The Snowflake Grant API is a REST API that you can use to show or manage privileges that have been provided to users and roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.session._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.grant._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Session API. Always refers to user's current, ongoing session.",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake REST Server",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/role/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/cortex/search_service/_generated/rest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Session API
-
-    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
-    The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Cortex Search REST API
+    OpenAPI 3.0 specification for the Cortex Search REST API  # noqa: E501
+    The version of the OpenAPI document: 0.1.0
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/models/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Session API
-
-    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
+    Snowflake Warehouse API
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
-from snowflake.core.session._generated.models.error_response import ErrorResponse
-from snowflake.core.session._generated.models.parameter import Parameter
-from snowflake.core.session._generated.models.success_response import SuccessResponse
+from snowflake.core.warehouse._generated.models.error_response import ErrorResponse
+from snowflake.core.warehouse._generated.models.success_response import SuccessResponse
+from snowflake.core.warehouse._generated.models.warehouse import Warehouse
 
 __all__ = [
     'ErrorResponse',
-    'Parameter',
     'SuccessResponse',
-]
+    'Warehouse',
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/create_session_request.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/create_session_request.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,35 +1,32 @@
 # coding: utf-8
-
 """
     Snowflake Session API
 
     The Snowflake Session API is a REST API that you can use to manage Snowflake sessions and session tokens.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
 from typing import Optional
 from typing import Union
 from snowflake.core.session._generated.pydantic_compatibility import BaseModel, Field, StrictStr
 
+
 class CreateSessionRequest(BaseModel):
     role_name: Optional[StrictStr] = Field(None, alias="roleName")
     __properties = ["roleName"]
 
-
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
@@ -41,59 +38,52 @@
     @classmethod
     def from_json(cls, json_str: str) -> CreateSessionRequest:
         """Create an instance of CreateSessionRequest from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = self.dict(by_alias=True, exclude={}, exclude_none=True)
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> CreateSessionRequest:
         """Create an instance of CreateSessionRequest from a dict"""
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return CreateSessionRequest.parse_obj(obj)
 
         _obj = CreateSessionRequest.parse_obj({
             "role_name": obj.get("roleName"),
-
         })
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class CreateSessionRequestModel():
+
     def __init__(
         self,
         # optional properties
         role_name: Optional[str] = None,
     ):
         self.role_name = role_name
+
     __properties = ["roleName"]
 
     def _to_model(self):
-        return CreateSessionRequest(
-            role_name=self.role_name,
-
-        )
+        return CreateSessionRequest(role_name=self.role_name, )
 
     @classmethod
     def _from_model(cls, model) -> CreateSessionRequestModel:
-        return CreateSessionRequestModel(
-            role_name=model.role_name,
-
-        )
+        return CreateSessionRequestModel(role_name=model.role_name, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> CreateSessionRequestModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/create_session_response.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/create_session_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,38 +1,40 @@
 # coding: utf-8
-
 """
     Snowflake Session API
 
     The Snowflake Session API is a REST API that you can use to manage Snowflake sessions and session tokens.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
 from typing import Optional
 from typing import Union
 from snowflake.core.session._generated.pydantic_compatibility import BaseModel, Field, StrictInt, StrictStr
 
+
 class CreateSessionResponse(BaseModel):
     token: Optional[StrictStr] = None
-    validity_in_seconds: Optional[StrictInt] = Field(None, alias="validityInSeconds")
+    validity_in_seconds: Optional[StrictInt] = Field(None,
+                                                     alias="validityInSeconds")
     master_token: Optional[StrictStr] = Field(None, alias="masterToken")
-    master_validity_in_seconds: Optional[StrictInt] = Field(None, alias="masterValidityInSeconds")
+    master_validity_in_seconds: Optional[StrictInt] = Field(
+        None, alias="masterValidityInSeconds")
     session_id: Optional[StrictInt] = Field(None, alias="sessionId")
-    __properties = ["token", "validityInSeconds", "masterToken", "masterValidityInSeconds", "sessionId"]
-
+    __properties = [
+        "token", "validityInSeconds", "masterToken", "masterValidityInSeconds",
+        "sessionId"
+    ]
 
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
@@ -47,93 +49,89 @@
         """Create an instance of CreateSessionResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         _dict = self.dict(by_alias=True,
                           exclude={
-                            "token",
-                            "validity_in_seconds",
-                            "master_token",
-                            "master_validity_in_seconds",
-                            "session_id",
+                              "token",
+                              "validity_in_seconds",
+                              "master_token",
+                              "master_validity_in_seconds",
+                              "session_id",
                           },
                           exclude_none=True)
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> CreateSessionResponse:
         """Create an instance of CreateSessionResponse from a dict"""
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return CreateSessionResponse.parse_obj(obj)
 
         _obj = CreateSessionResponse.parse_obj({
-            "token": obj.get("token"),
-
-            "validity_in_seconds": obj.get("validityInSeconds"),
-
-            "master_token": obj.get("masterToken"),
-
-            "master_validity_in_seconds": obj.get("masterValidityInSeconds"),
-
-            "session_id": obj.get("sessionId"),
-
+            "token":
+            obj.get("token"),
+            "validity_in_seconds":
+            obj.get("validityInSeconds"),
+            "master_token":
+            obj.get("masterToken"),
+            "master_validity_in_seconds":
+            obj.get("masterValidityInSeconds"),
+            "session_id":
+            obj.get("sessionId"),
         })
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class CreateSessionResponseModel():
+
     def __init__(
         self,
         # optional properties
         token: Optional[str] = None,
         validity_in_seconds: Optional[int] = None,
         master_token: Optional[str] = None,
         master_validity_in_seconds: Optional[int] = None,
         session_id: Optional[int] = None,
     ):
         self.token = token
         self.validity_in_seconds = validity_in_seconds
         self.master_token = master_token
         self.master_validity_in_seconds = master_validity_in_seconds
         self.session_id = session_id
-    __properties = ["token", "validityInSeconds", "masterToken", "masterValidityInSeconds", "sessionId"]
+
+    __properties = [
+        "token", "validityInSeconds", "masterToken", "masterValidityInSeconds",
+        "sessionId"
+    ]
 
     def _to_model(self):
         return CreateSessionResponse(
             token=self.token,
-
             validity_in_seconds=self.validity_in_seconds,
-
             master_token=self.master_token,
-
             master_validity_in_seconds=self.master_validity_in_seconds,
-
             session_id=self.session_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> CreateSessionResponseModel:
         return CreateSessionResponseModel(
             token=model.token,
-
             validity_in_seconds=model.validity_in_seconds,
-
             master_token=model.master_token,
-
             master_validity_in_seconds=model.master_validity_in_seconds,
-
             session_id=model.session_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/models/error_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Session API
-
-    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
 
+    Snowflake Warehouse API
+    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.session._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/parameter.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/parameter.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,44 +1,51 @@
 # coding: utf-8
-
 """
-    Snowflake Session API
 
+    Snowflake Session API
     The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.session._generated.pydantic_compatibility import BaseModel, Field, StrictStr
+
+from pydantic import BaseModel, ConfigDict, Field, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class Parameter(BaseModel):
-    name: StrictStr = Field(...)
+
+    name: StrictStr
+
     value: Optional[StrictStr] = None
-    default_value: Optional[StrictStr] = Field(None, alias="defaultValue")
-    data_type: Optional[StrictStr] = Field(None, alias="dataType")
+
+    default_value: Optional[StrictStr] = Field(default=None,
+                                               alias="defaultValue")
+
+    data_type: Optional[StrictStr] = Field(default=None, alias="dataType")
+
     level: Optional[StrictStr] = None
+
     description: Optional[StrictStr] = None
-    __properties = ["name", "value", "defaultValue", "dataType", "level", "description"]
 
+    __properties = [
+        "name", "value", "defaultValue", "dataType", "level", "description"
+    ]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -48,98 +55,90 @@
     @classmethod
     def from_json(cls, json_str: str) -> Parameter:
         """Create an instance of Parameter from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> Parameter:
         """Create an instance of Parameter from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return Parameter.parse_obj(obj)
 
         _obj = Parameter.parse_obj({
             "name": obj.get("name"),
-
             "value": obj.get("value"),
-
             "default_value": obj.get("defaultValue"),
-
             "data_type": obj.get("dataType"),
-
             "level": obj.get("level"),
-
             "description": obj.get("description"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ParameterModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
         value: Optional[str] = None,
         default_value: Optional[str] = None,
         data_type: Optional[str] = None,
         level: Optional[str] = None,
         description: Optional[str] = None,
     ):
+
         self.name = name
         self.value = value
         self.default_value = default_value
         self.data_type = data_type
         self.level = level
         self.description = description
-    __properties = ["name", "value", "defaultValue", "dataType", "level", "description"]
+
+    __properties = [
+        "name", "value", "defaultValue", "dataType", "level", "description"
+    ]
 
     def _to_model(self):
         return Parameter(
             name=self.name,
-
             value=self.value,
-
             default_value=self.default_value,
-
             data_type=self.data_type,
-
             level=self.level,
-
             description=self.description,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ParameterModel:
         return ParameterModel(
             name=model.name,
-
             value=model.value,
-
             default_value=model.default_value,
-
             data_type=model.data_type,
-
             level=model.level,
-
             description=model.description,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/success_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Session API
 
+    Snowflake Session API
     The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.session._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/session/_generated/models/token_request.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/models/token_request.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,35 +1,32 @@
 # coding: utf-8
-
 """
     Snowflake Session API
 
     The Snowflake Session API is a REST API that you can use to manage Snowflake sessions and session tokens.  # noqa: E501
 
     The version of the OpenAPI document: 0.0.1
     Contact: support@snowflake.com
     Generated by: https://openapi-generator.tech
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
 from typing import Optional
 from typing import Union
 from snowflake.core.session._generated.pydantic_compatibility import BaseModel, Field, StrictStr
 
+
 class TokenRequest(BaseModel):
     session_token: Optional[StrictStr] = Field(None, alias="sessionToken")
     __properties = ["sessionToken"]
 
-
     class Config:
         allow_population_by_field_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
@@ -41,59 +38,52 @@
     @classmethod
     def from_json(cls, json_str: str) -> TokenRequest:
         """Create an instance of TokenRequest from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = self.dict(by_alias=True, exclude={}, exclude_none=True)
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> TokenRequest:
         """Create an instance of TokenRequest from a dict"""
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return TokenRequest.parse_obj(obj)
 
         _obj = TokenRequest.parse_obj({
             "session_token": obj.get("sessionToken"),
-
         })
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class TokenRequestModel():
+
     def __init__(
         self,
         # optional properties
         session_token: Optional[str] = None,
     ):
         self.session_token = session_token
+
     __properties = ["sessionToken"]
 
     def _to_model(self):
-        return TokenRequest(
-            session_token=self.session_token,
-
-        )
+        return TokenRequest(session_token=self.session_token, )
 
     @classmethod
     def _from_model(cls, model) -> TokenRequestModel:
-        return TokenRequestModel(
-            session_token=model.session_token,
-
-        )
+        return TokenRequestModel(session_token=model.session_token, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> TokenRequestModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_table.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_table.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 from typing import TYPE_CHECKING, Iterator, Optional, Union
 
+from pydantic import StrictStr
+
 from snowflake.core._common import (
     Clone,
     CreateMode,
     PointOfTime,
     SchemaObjectCollectionParent,
     SchemaObjectReferenceMixin,
 )
-from snowflake.core.table._generated.pydantic_compatibility import StrictStr
 
 from .._internal.telemetry import api_telemetry
 from ._generated.api import TableApi
 from ._generated.api_client import BridgeApiClient, StoredProcApiClient
 from ._generated.models.point_of_time import PointOfTime as TablePointOfTime
 from ._generated.models.table import Table
 from ._generated.models.table_clone import TableClone
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.table._generated.api.table_api import TableApi
-
 # import ApiClient
 from snowflake.core.table._generated.api_client import ApiClient
 from snowflake.core.table._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.table._generated.models.constraint import Constraint
 from snowflake.core.table._generated.models.error_response import ErrorResponse
 from snowflake.core.table._generated.models.foreign_key import ForeignKey
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/api_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Table API
-
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Schema API
+    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.table._generated.configuration import Configuration
-import snowflake.core.table._generated.models
-from snowflake.core.table._generated import rest
-from snowflake.core.table._generated.paging import PagedIter
+from snowflake.core.schema._generated.configuration import Configuration
+import snowflake.core.schema._generated.models
+from snowflake.core.schema._generated import rest
+from snowflake.core.schema._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,61 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.table._generated.models, klass)
+                klass = getattr(snowflake.core.schema._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +519,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +670,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for table. Updating table '
-                        'objects is not supported yet; use create() for creating a table.')
+                        'create_or_update is not yet supported for schema. Updating schema '
+                        'objects is not supported yet; use create() for creating a schema.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +699,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +742,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +786,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +823,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +847,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +874,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +940,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +958,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +974,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1009,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/api_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.table._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/stage/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
-
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Stage API
+    The Snowflake Stage API is a REST API that you can use to access, update, and perform certain actions on stage resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.table._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.stage._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake REST Server",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake Stage API",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/schema/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/rest.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/api/table_api.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/api/task_api.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,86 +1,81 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
-
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Task API
+    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
-
+from pydantic import Field, StrictBool, StrictInt, StrictStr, field_validator
 from typing import List, Optional
-
-from snowflake.core.table._generated.models.success_response import SuccessResponse
-from snowflake.core.table._generated.models.table import Table
-from snowflake.core.table._generated.models.table_clone import TableClone
+from typing_extensions import Annotated
+from snowflake.core.task._generated.models.success_response import SuccessResponse
+from snowflake.core.task._generated.models.task import Task
+from snowflake.core.task._generated.models.task_run import TaskRun
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.table._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
 
-logger  = logging.getLogger(__name__)
+logger = logging.getLogger(__name__)
 
-class TableApi(object):
+
+class TaskApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
     def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._resource_name = 'table'
+        self._resource_name = 'task'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
         self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
             new_chosen_client is the client we want to choose under the current situation ( value of
             _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        from snowflake.core.table._generated.api_client import ApiClient
+        from snowflake.core.task._generated.api_client import ApiClient
 
         # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
         def _get_rest_client():
             if is_running_inside_stored_procedure():
                 return self._sproc_client, ApiClientType.STORED_PROC
             else:
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('table')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge('task')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -92,36 +87,55 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_or_alter_table(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], table : Table, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) table.  # noqa: E501
+    @validate_call
+    def create_or_alter_task(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                             task: Task,
+                             **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a (or alter an existing) task  # noqa: E501
+
+
+        Create a (or alter an existing) task. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
 
-        Create a (or alter an existing) table. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_table(database, var_schema, name, table, async_req=True)
+        >>> thread = api.create_or_alter_task(database, var_schema, name, task, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param table: (required)
-        :type table: Table
+        :param task: (required)
+        :type task: Task
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -130,35 +144,54 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_alter_table_with_http_info(database, var_schema, name, table, **kwargs)  # noqa: E501
+        return self.create_or_alter_task_with_http_info(
+            database, var_schema, name, task, **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_or_alter_task_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                            task: Task,
+                                            **kwargs):  # noqa: E501
+        """Create a (or alter an existing) task  # noqa: E501
 
-    @validate_arguments
-    def create_or_alter_table_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], table : Table, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) table.  # noqa: E501
 
-        Create a (or alter an existing) table. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        Create a (or alter an existing) task. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_table_with_http_info(database, var_schema, name, table, async_req=True)
+        >>> thread = api.create_or_alter_task_with_http_info(database, var_schema, name, task, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param table: (required)
-        :type table: Table
+        :param task: (required)
+        :type task: Task
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -177,50 +210,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'table'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name', 'task']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_or_alter_table" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_or_alter_task" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -228,83 +250,111 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['table']:
-            _body_params = _params['table']
+
+        if _params['task']:
+            _body_params = _params['task']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
-            '201': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}', 'PUT',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_table(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], table : Table, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a table (clone and undrop are separate subresources)  # noqa: E501
+    @validate_call
+    def create_task(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            task: Task,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Create a task  # noqa: E501
+
+
+        Create a task, with standard create modifiers as query parameters. See the Task component definition for what is required to be provided in the request body.  # noqa: E501
 
-        Create a table.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table(database, var_schema, table, create_mode, copy_grants, async_req=True)
-        >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param table: (required)
-        :type table: Table
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        >>> thread = api.create_task(database, var_schema, task, create_mode, async_req=True)
+        >>> result = thread.get()
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
+        :type database: str
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
+        :type var_schema: str
+        :param task: (required)
+        :type task: Task
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -313,37 +363,64 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_table_with_http_info(database, var_schema, table, create_mode, copy_grants, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def create_table_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], table : Table, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs):  # noqa: E501
-        """Create a table (clone and undrop are separate subresources)  # noqa: E501
+        return self.create_task_with_http_info(database, var_schema, task,
+                                               create_mode,
+                                               **kwargs)  # noqa: E501
+
+    @validate_call
+    def create_task_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            task: Task,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Create a task  # noqa: E501
+
+
+        Create a task, with standard create modifiers as query parameters. See the Task component definition for what is required to be provided in the request body.  # noqa: E501
 
-        Create a table.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_with_http_info(database, var_schema, table, create_mode, copy_grants, async_req=True)
-        >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param table: (required)
-        :type table: Table
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        >>> thread = api.create_task_with_http_info(database, var_schema, task, create_mode, async_req=True)
+        >>> result = thread.get()
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
+        :type database: str
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
+        :type var_schema: str
+        :param task: (required)
+        :type task: Task
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -362,141 +439,152 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'table',
-            'create_mode',
-            'copy_grants'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'task', 'create_mode']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_table" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_task" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('copy_grants') is not None:  # noqa: E501
-            _query_params.append(('copyGrants', _params['copy_grants']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['table']:
-            _body_params = _params['table']
+
+        if _params['task']:
+            _body_params = _params['task']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '201': "SuccessResponse",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '409': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_table_as_select(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], query : Annotated[StrictStr, Field(..., description="The SQL select query to run to set up the table values (and possibly columns).")], table : Table, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a table using the result of the specified select query  # noqa: E501
+    @validate_call
+    def execute_task(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            retry_last: Annotated[
+                Optional[StrictBool],
+                Field(description="Retry the last failed run of the DAG."
+                      )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Execute a task object.  # noqa: E501
+
+
+        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
 
-        Create a table as select.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_as_select(database, var_schema, name, query, table, create_mode, copy_grants, async_req=True)
+        >>> thread = api.execute_task(database, var_schema, name, retry_last, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param query: The SQL select query to run to set up the table values (and possibly columns). (required)
-        :type query: str
-        :param table: (required)
-        :type table: Table
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
+        :param retry_last: Retry the last failed run of the DAG.
+        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -505,41 +593,64 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_table_as_select_with_http_info(database, var_schema, name, query, table, create_mode, copy_grants, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def create_table_as_select_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], query : Annotated[StrictStr, Field(..., description="The SQL select query to run to set up the table values (and possibly columns).")], table : Table, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs):  # noqa: E501
-        """Create a table using the result of the specified select query  # noqa: E501
+        return self.execute_task_with_http_info(database, var_schema, name,
+                                                retry_last,
+                                                **kwargs)  # noqa: E501
+
+    @validate_call
+    def execute_task_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            retry_last: Annotated[
+                Optional[StrictBool],
+                Field(description="Retry the last failed run of the DAG."
+                      )] = None,
+            **kwargs):  # noqa: E501
+        """Execute a task object.  # noqa: E501
+
+
+        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
 
-        Create a table as select.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_as_select_with_http_info(database, var_schema, name, query, table, create_mode, copy_grants, async_req=True)
+        >>> thread = api.execute_task_with_http_info(database, var_schema, name, retry_last, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param query: The SQL select query to run to set up the table values (and possibly columns). (required)
-        :type query: str
-        :param table: (required)
-        :type table: Table
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
+        :param retry_last: Retry the last failed run of the DAG.
+        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -558,186 +669,185 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'query',
-            'table',
-            'create_mode',
-            'copy_grants'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name', 'retry_last']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_table_as_select" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method execute_task" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('copy_grants') is not None:  # noqa: E501
-            _query_params.append(('copyGrants', _params['copy_grants']))
-        if _params.get('query') is not None:  # noqa: E501
-            _query_params.append(('query', _params['query']))
+
+        if _params.get('retry_last') is not None:  # noqa: E501
+            _query_params.append(('retryLast', _params['retry_last']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['table']:
-            _body_params = _params['table']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
-
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '201': "SuccessResponse",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
-            '409': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:as_select', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:execute',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_table_like(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], new_table_name : Annotated[StrictStr, Field(..., description="The name of the table to be created.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a table like this existing one  # noqa: E501
+    @validate_call
+    def fetch_task(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                   **kwargs) -> Task:  # noqa: E501
+        """Fetch a task  # noqa: E501
+
+
+        Fetch a task using the describe command output.  # noqa: E501
 
-        Create a new table like the specified resource, but empty  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_like(database, var_schema, name, new_table_name, create_mode, copy_grants, async_req=True)
+        >>> thread = api.fetch_task(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param new_table_name: The name of the table to be created. (required)
-        :type new_table_name: str
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: Task
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_table_like_with_http_info(database, var_schema, name, new_table_name, create_mode, copy_grants, **kwargs)  # noqa: E501
+        return self.fetch_task_with_http_info(database, var_schema, name,
+                                              **kwargs)  # noqa: E501
+
+    @validate_call
+    def fetch_task_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                  **kwargs):  # noqa: E501
+        """Fetch a task  # noqa: E501
+
 
-    @validate_arguments
-    def create_table_like_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], new_table_name : Annotated[StrictStr, Field(..., description="The name of the table to be created.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs):  # noqa: E501
-        """Create a table like this existing one  # noqa: E501
+        Fetch a task using the describe command output.  # noqa: E501
 
-        Create a new table like the specified resource, but empty  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_like_with_http_info(database, var_schema, name, new_table_name, create_mode, copy_grants, async_req=True)
+        >>> thread = api.fetch_task_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param new_table_name: The name of the table to be created. (required)
-        :type new_table_name: str
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -751,68 +861,49 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Task, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'new_table_name',
-            'create_mode',
-            'copy_grants'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_table_like" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_task" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('copy_grants') is not None:  # noqa: E501
-            _query_params.append(('copyGrants', _params['copy_grants']))
-        if _params.get('new_table_name') is not None:  # noqa: E501
-            _query_params.append(('newTableName', _params['new_table_name']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -824,107 +915,163 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "Task",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:create_like', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_table_using_template(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], query : Annotated[StrictStr, Field(..., description="The SQL query that uses INFER_SCHEMA on staged files to set the column definitions for the new table.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a table using the templates specified in staged files  # noqa: E501
+    @validate_call
+    def fetch_task_dependents(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            recursive:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks."
+            )] = None,
+            **kwargs) -> Iterable[Task]:  # noqa: E501
+        """Fetch the dependent tasks of a task  # noqa: E501
+
+
+        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
 
-        Create a table using template.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_using_template(database, var_schema, name, query, create_mode, copy_grants, async_req=True)
+        >>> thread = api.fetch_task_dependents(database, var_schema, name, recursive, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param query: The SQL query that uses INFER_SCHEMA on staged files to set the column definitions for the new table. (required)
-        :type query: str
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
+        :param recursive: Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.
+        :type recursive: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: Iterable[Task]
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_table_using_template_with_http_info(database, var_schema, name, query, create_mode, copy_grants, **kwargs)  # noqa: E501
+        return self.fetch_task_dependents_with_http_info(
+            database, var_schema, name, recursive, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def create_table_using_template_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], query : Annotated[StrictStr, Field(..., description="The SQL query that uses INFER_SCHEMA on staged files to set the column definitions for the new table.")], create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs):  # noqa: E501
-        """Create a table using the templates specified in staged files  # noqa: E501
+    @validate_call
+    def fetch_task_dependents_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            recursive:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Fetch the dependent tasks of a task  # noqa: E501
+
+
+        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
 
-        Create a table using template.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_table_using_template_with_http_info(database, var_schema, name, query, create_mode, copy_grants, async_req=True)
+        >>> thread = api.fetch_task_dependents_with_http_info(database, var_schema, name, recursive, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param query: The SQL query that uses INFER_SCHEMA on staged files to set the column definitions for the new table. (required)
-        :type query: str
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
+        :param recursive: Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.
+        :type recursive: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -938,68 +1085,52 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[Task], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'query',
-            'create_mode',
-            'copy_grants'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name', 'recursive']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_table_using_template" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method fetch_task_dependents" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('copy_grants') is not None:  # noqa: E501
-            _query_params.append(('copyGrants', _params['copy_grants']))
-        if _params.get('query') is not None:  # noqa: E501
-            _query_params.append(('query', _params['query']))
+
+        if _params.get('recursive') is not None:  # noqa: E501
+            _query_params.append(('recursive', _params['recursive']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1011,108 +1142,183 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '201': "SuccessResponse",
+            '200': "Iterable[Task]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
-            '409': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:using_template', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/dependents',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def clone_table(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], table_clone : TableClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Clone table  # noqa: E501
+    @validate_call
+    def get_complete_graphs(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            result_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Number of results to return, at most. Default is 1000, valid range is 1 to 10000."
+            )] = None,
+            error_only:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to only return results for tasks runs that have failed. Default is false."
+            )] = None,
+            **kwargs) -> Iterable[TaskRun]:  # noqa: E501
+        """Get the graph runs that are completed for the task.  # noqa: E501
+
+
+        This function returns details for graph runs that are completed.  # noqa: E501
 
-        Create a new table by cloning from the specified resource  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.clone_table(database, var_schema, name, table_clone, create_mode, copy_grants, async_req=True)
+        >>> thread = api.get_complete_graphs(database, var_schema, name, result_limit, error_only, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param table_clone: (required)
-        :type table_clone: TableClone
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
+        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
+        :type result_limit: int
+        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
+        :type error_only: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: Iterable[TaskRun]
         """
         kwargs['_return_http_data_only'] = True
-        return self.clone_table_with_http_info(database, var_schema, name, table_clone, create_mode, copy_grants, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def clone_table_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], table_clone : TableClone, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, copy_grants : Annotated[Optional[StrictBool], Field(description="A query parameter enabled copy grants during the creation of the object.")] = None, **kwargs):  # noqa: E501
-        """Clone table  # noqa: E501
+        return self.get_complete_graphs_with_http_info(database, var_schema,
+                                                       name, result_limit,
+                                                       error_only,
+                                                       **kwargs)  # noqa: E501
+
+    @validate_call
+    def get_complete_graphs_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            result_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Number of results to return, at most. Default is 1000, valid range is 1 to 10000."
+            )] = None,
+            error_only:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Whether to only return results for tasks runs that have failed. Default is false."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Get the graph runs that are completed for the task.  # noqa: E501
+
+
+        This function returns details for graph runs that are completed.  # noqa: E501
 
-        Create a new table by cloning from the specified resource  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.clone_table_with_http_info(database, var_schema, name, table_clone, create_mode, copy_grants, async_req=True)
-        >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param table_clone: (required)
-        :type table_clone: TableClone
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
-        :param copy_grants: A query parameter enabled copy grants during the creation of the object.
-        :type copy_grants: bool
+        >>> thread = api.get_complete_graphs_with_http_info(database, var_schema, name, result_limit, error_only, async_req=True)
+        >>> result = thread.get()
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
+        :type database: str
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
+        :type var_schema: str
+        :param name: Identifier (i.e. name) for the resource. (required)
+        :type name: str
+        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
+        :type result_limit: int
+        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
+        :type error_only: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1126,175 +1332,214 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[TaskRun], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'table_clone',
-            'create_mode',
-            'copy_grants'
+            'database', 'var_schema', 'name', 'result_limit', 'error_only'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method clone_table" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_complete_graphs" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
-        if _params.get('copy_grants') is not None:  # noqa: E501
-            _query_params.append(('copyGrants', _params['copy_grants']))
+
+        if _params.get('result_limit') is not None:  # noqa: E501
+            _query_params.append(('resultLimit', _params['result_limit']))
+
+        if _params.get('error_only') is not None:  # noqa: E501
+            _query_params.append(('errorOnly', _params['error_only']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['table_clone']:
-            _body_params = _params['table_clone']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
-
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "Iterable[TaskRun]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:clone', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/complete_graphs',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_table(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Table:  # noqa: E501
-        """Fetch a table.  # noqa: E501
+    @validate_call
+    def get_current_graphs(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            result_limit: Optional[StrictInt] = None,
+            **kwargs) -> Iterable[TaskRun]:  # noqa: E501
+        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
+
+
+        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
 
-        Fetch a Table using the describe command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_table(database, var_schema, name, async_req=True)
+        >>> thread = api.get_current_graphs(database, var_schema, name, result_limit, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param result_limit:
+        :type result_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Table
+        :rtype: Iterable[TaskRun]
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_table_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.get_current_graphs_with_http_info(database, var_schema,
+                                                      name, result_limit,
+                                                      **kwargs)  # noqa: E501
+
+    @validate_call
+    def get_current_graphs_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            result_limit: Optional[StrictInt] = None,
+            **kwargs):  # noqa: E501
+        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
+
+
+        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
 
-    @validate_arguments
-    def fetch_table_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Fetch a table.  # noqa: E501
-
-        Fetch a Table using the describe command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_table_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.get_current_graphs_with_http_info(database, var_schema, name, result_limit, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
+        :param result_limit:
+        :type result_limit: int
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1308,60 +1553,53 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Table, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[TaskRun], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name', 'result_limit']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_table" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_current_graphs" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
+        if _params.get('result_limit') is not None:  # noqa: E501
+            _query_params.append(('resultLimit', _params['result_limit']))
+
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
@@ -1372,115 +1610,206 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Table",
+            '200': "Iterable[TaskRun]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}', 'GET',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/current_graphs',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def list_tables(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Optionally includes dropped tables that have not yet been purged.")] = None, deep : Annotated[Optional[StrictBool], Field(description="Optionally includes dependency information of the table.")] = None, **kwargs) -> Iterable[Table]:  # noqa: E501
-        """List tables  # noqa: E501
-
-        Lists the tables under the database and schema.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.list_tables(database, var_schema, like, starts_with, show_limit, from_name, history, deep, async_req=True)
-        >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+    @validate_call
+    def list_tasks(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            root_only:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter to filter the command output to return only root resources (resources with no predecessors)."
+            )] = None,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            **kwargs) -> Iterable[Task]:  # noqa: E501
+        """List tasks  # noqa: E501
+
+
+        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
+
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.list_tasks(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
+        >>> result = thread.get()
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
+        :type database: str
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
+        :type var_schema: str
+        :param root_only: Query parameter to filter the command output to return only root resources (resources with no predecessors).
+        :type root_only: bool
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
-        :type from_name: str
-        :param history: Optionally includes dropped tables that have not yet been purged.
-        :type history: bool
-        :param deep: Optionally includes dependency information of the table.
-        :type deep: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Iterable[Table]
+        :rtype: Iterable[Task]
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_tables_with_http_info(database, var_schema, like, starts_with, show_limit, from_name, history, deep, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def list_tables_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, from_name : Annotated[Optional[StrictStr], Field(description="A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.")] = None, history : Annotated[Optional[StrictBool], Field(description="Optionally includes dropped tables that have not yet been purged.")] = None, deep : Annotated[Optional[StrictBool], Field(description="Optionally includes dependency information of the table.")] = None, **kwargs):  # noqa: E501
-        """List tables  # noqa: E501
-
-        Lists the tables under the database and schema.  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.list_tables_with_http_info(database, var_schema, like, starts_with, show_limit, from_name, history, deep, async_req=True)
-        >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        return self.list_tasks_with_http_info(database, var_schema, root_only,
+                                              like, starts_with, show_limit,
+                                              **kwargs)  # noqa: E501
+
+    @validate_call
+    def list_tasks_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            root_only:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter to filter the command output to return only root resources (resources with no predecessors)."
+            )] = None,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            starts_with:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching."
+            )] = None,
+            show_limit:
+        Annotated[
+            Optional[StrictInt],
+            Field(
+                description=
+                "Query parameter to limit the maximum number of rows returned by a command."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """List tasks  # noqa: E501
+
+
+        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
+
+        This method makes a synchronous HTTP request by default. To make an
+        asynchronous HTTP request, please pass async_req=True
+
+        >>> thread = api.list_tasks_with_http_info(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
+        >>> result = thread.get()
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
+        :type database: str
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
+        :type var_schema: str
+        :param root_only: Query parameter to filter the command output to return only root resources (resources with no predecessors).
+        :type root_only: bool
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
+        :param starts_with: Query parameter to filter the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
         :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
+        :param show_limit: Query parameter to limit the maximum number of rows returned by a command.
         :type show_limit: int
-        :param from_name: A query parameter enables fetching rows only following the first row whose object name matches the specified string. Case-sensitive and does not have to be the full name.
-        :type from_name: str
-        :param history: Optionally includes dropped tables that have not yet been purged.
-        :type history: bool
-        :param deep: Optionally includes dependency information of the table.
-        :type deep: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1494,74 +1823,61 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Iterable[Table], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[Task], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
         _all_params = [
-            'database',
-            'var_schema',
-            'like',
-            'starts_with',
-            'show_limit',
-            'from_name',
-            'history',
-            'deep'
+            'database', 'var_schema', 'root_only', 'like', 'starts_with',
+            'show_limit'
         ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method list_tables" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method list_tasks" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
+
+        if _params.get('root_only') is not None:  # noqa: E501
+            _query_params.append(('rootOnly', _params['root_only']))
+
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
+
         if _params.get('starts_with') is not None:  # noqa: E501
             _query_params.append(('startsWith', _params['starts_with']))
+
         if _params.get('show_limit') is not None:  # noqa: E501
             _query_params.append(('showLimit', _params['show_limit']))
-        if _params.get('from_name') is not None:  # noqa: E501
-            _query_params.append(('fromName', _params['from_name']))
-        if _params.get('history') is not None:  # noqa: E501
-            _query_params.append(('history', _params['history']))
-        if _params.get('deep') is not None:  # noqa: E501
-            _query_params.append(('deep', _params['deep']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1573,235 +1889,81 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Iterable[Table]",
+            '200': "Iterable[Task]",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables', 'GET',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def resume_recluster(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Resume recluster of a table  # noqa: E501
+    @validate_call
+    def resume_task(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                    **kwargs) -> SuccessResponse:  # noqa: E501
+        """Resume a suspended task.  # noqa: E501
 
-        Resume recluster of a table  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_recluster(database, var_schema, name, if_exists, async_req=True)
-        >>> result = thread.get()
+        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
 
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: SuccessResponse
-        """
-        kwargs['_return_http_data_only'] = True
-        return self.resume_recluster_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def resume_recluster_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
-        """Resume recluster of a table  # noqa: E501
-
-        Resume recluster of a table  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_recluster_with_http_info(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.resume_task(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _return_http_data_only: response data without head status code
-                                       and headers
-        :type _return_http_data_only: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :param _request_auth: set to override the auth_settings for an a single
-                              request; this effectively ignores the authentication
-                              in the spec for a single request.
-        :type _request_auth: dict, optional
-        :type _content_type: string, optional: force content-type for the request
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
-        """
-
-        _params = locals()
-
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
-
-        # validate the arguments
-        for _key, _val in _params['kwargs'].items():
-            if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method resume_recluster" % _key
-                )
-            _params[_key] = _val
-        del _params['kwargs']
-
-        _collection_formats = {}
-
-        # process the path parameters
-        _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
-
-        # process the query parameters
-        _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
-
-        # process the header parameters
-        _header_params = dict(_params.get('_headers', {}))
-
-        # process the form parameters
-        _form_params = []
-        _files = {}
-
-        # process the body parameter
-        _body_params = None
-
-        # set the HTTP header `Accept`
-        _header_params['Accept'] = self.api_client.select_header_accept(
-            ['application/json'])  # noqa: E501
-
-        # authentication setting
-        _auth_settings = []  # noqa: E501
-
-        _response_types_map = {
-            '200': "SuccessResponse",
-            '400': "ErrorResponse",
-            '401': "ErrorResponse",
-            '403': "ErrorResponse",
-            '404': "ErrorResponse",
-            '405': "ErrorResponse",
-            '500': "ErrorResponse",
-            '503': "ErrorResponse",
-            '504': "ErrorResponse",
-        }
-
-        return self.api_client.call_api(
-            self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:resume_recluster', 'POST',
-            _path_params,
-            _query_params,
-            _header_params,
-            body=_body_params,
-            post_params=_form_params,
-            files=_files,
-            response_types_map=_response_types_map,
-            auth_settings=_auth_settings,
-            async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
-            _preload_content=_params.get('_preload_content', True),
-            _request_timeout=_params.get('_request_timeout'),
-            collection_formats=_collection_formats,
-            _request_auth=_params.get('_request_auth'))
-
-    @validate_arguments
-    def suspend_recluster(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Suspend recluster of a table  # noqa: E501
-
-        Suspend recluster of a table  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.suspend_recluster(database, var_schema, name, if_exists, async_req=True)
-        >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1810,212 +1972,51 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_recluster_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
+        return self.resume_task_with_http_info(database, var_schema, name,
+                                               **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def suspend_recluster_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
-        """Suspend recluster of a table  # noqa: E501
+    @validate_call
+    def resume_task_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                   **kwargs):  # noqa: E501
+        """Resume a suspended task.  # noqa: E501
 
-        Suspend recluster of a table  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_recluster_with_http_info(database, var_schema, name, if_exists, async_req=True)
-        >>> result = thread.get()
+        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
 
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _return_http_data_only: response data without head status code
-                                       and headers
-        :type _return_http_data_only: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :param _request_auth: set to override the auth_settings for an a single
-                              request; this effectively ignores the authentication
-                              in the spec for a single request.
-        :type _request_auth: dict, optional
-        :type _content_type: string, optional: force content-type for the request
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
-        """
-
-        _params = locals()
-
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
-
-        # validate the arguments
-        for _key, _val in _params['kwargs'].items():
-            if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method suspend_recluster" % _key
-                )
-            _params[_key] = _val
-        del _params['kwargs']
-
-        _collection_formats = {}
-
-        # process the path parameters
-        _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
-
-        # process the query parameters
-        _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
-
-        # process the header parameters
-        _header_params = dict(_params.get('_headers', {}))
-
-        # process the form parameters
-        _form_params = []
-        _files = {}
-
-        # process the body parameter
-        _body_params = None
-
-        # set the HTTP header `Accept`
-        _header_params['Accept'] = self.api_client.select_header_accept(
-            ['application/json'])  # noqa: E501
-
-        # authentication setting
-        _auth_settings = []  # noqa: E501
-
-        _response_types_map = {
-            '200': "SuccessResponse",
-            '400': "ErrorResponse",
-            '401': "ErrorResponse",
-            '403': "ErrorResponse",
-            '404': "ErrorResponse",
-            '405': "ErrorResponse",
-            '500': "ErrorResponse",
-            '503': "ErrorResponse",
-            '504': "ErrorResponse",
-        }
-
-        return self.api_client.call_api(
-            self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:suspend_recluster', 'POST',
-            _path_params,
-            _query_params,
-            _header_params,
-            body=_body_params,
-            post_params=_form_params,
-            files=_files,
-            response_types_map=_response_types_map,
-            auth_settings=_auth_settings,
-            async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
-            _preload_content=_params.get('_preload_content', True),
-            _request_timeout=_params.get('_request_timeout'),
-            collection_formats=_collection_formats,
-            _request_auth=_params.get('_request_auth'))
-
-    @validate_arguments
-    def swap_with(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], target_table_name : Annotated[StrictStr, Field(..., description="The fully-specified name of the target table to be swapped with.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Swap with another table  # noqa: E501
-
-        Swap with another table  # noqa: E501
-        This method makes a synchronous HTTP request by default. To make an
-        asynchronous HTTP request, please pass async_req=True
-
-        >>> thread = api.swap_with(database, var_schema, name, target_table_name, if_exists, async_req=True)
-        >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param target_table_name: The fully-specified name of the target table to be swapped with. (required)
-        :type target_table_name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
-        :param async_req: Whether to execute the request asynchronously.
-        :type async_req: bool, optional
-        :param _preload_content: if False, the urllib3.HTTPResponse object will
-                                 be returned without reading/decoding response
-                                 data. Default is True.
-        :type _preload_content: bool, optional
-        :param _request_timeout: timeout setting for this request. If one
-                                 number provided, it will be total request
-                                 timeout. It can also be a pair (tuple) of
-                                 (connection, read) timeouts.
-        :return: Returns the result object.
-                 If the method is called asynchronously,
-                 returns the request thread.
-        :rtype: SuccessResponse
-        """
-        kwargs['_return_http_data_only'] = True
-        return self.swap_with_with_http_info(database, var_schema, name, target_table_name, if_exists, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def swap_with_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], target_table_name : Annotated[StrictStr, Field(..., description="The fully-specified name of the target table to be swapped with.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
-        """Swap with another table  # noqa: E501
-
-        Swap with another table  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.swap_with_with_http_info(database, var_schema, name, target_table_name, if_exists, async_req=True)
+        >>> thread = api.resume_task_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param target_table_name: The fully-specified name of the target table to be swapped with. (required)
-        :type target_table_name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -2034,60 +2035,44 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'target_table_name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method swap_with" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method resume_task" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
-        if _params.get('target_table_name') is not None:  # noqa: E501
-            _query_params.append(('targetTableName', _params['target_table_name']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -2105,53 +2090,73 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:swapwith', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:resume',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def undrop_table(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
-        """Undrop a table  # noqa: E501
+    @validate_call
+    def suspend_task(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                     **kwargs) -> SuccessResponse:  # noqa: E501
+        """Suspends a running task.  # noqa: E501
+
+
+        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
 
-        Undrop specified table  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.undrop_table(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_task(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -2161,32 +2166,50 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.undrop_table_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.suspend_task_with_http_info(database, var_schema, name,
+                                                **kwargs)  # noqa: E501
+
+    @validate_call
+    def suspend_task_with_http_info(self, database: Annotated[
+        str,
+        Field(
+            strict=True,
+            description=
+            "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+        )], var_schema: Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )], name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+                                    **kwargs):  # noqa: E501
+        """Suspends a running task.  # noqa: E501
 
-    @validate_arguments
-    def undrop_table_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Undrop a table  # noqa: E501
 
-        Undrop specified table  # noqa: E501
+        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.undrop_table_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.suspend_task_with_http_info(database, var_schema, name, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -2206,49 +2229,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method undrop_table" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method suspend_task" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -2271,55 +2284,88 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}:undrop', 'POST',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:suspend',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def delete_table(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a table  # noqa: E501
+    @validate_call
+    def delete_task(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
+        """Delete a task  # noqa: E501
+
+
+        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
 
-        Delete a table with the given name.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_table(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.delete_task(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -2329,34 +2375,66 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_table_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
-
-    @validate_arguments
-    def delete_table_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
-        """Delete a table  # noqa: E501
+        return self.delete_task_with_http_info(database, var_schema, name,
+                                               if_exists,
+                                               **kwargs)  # noqa: E501
+
+    @validate_call
+    def delete_task_with_http_info(
+            self,
+            database:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases."
+            )],
+            var_schema:
+        Annotated[
+            str,
+            Field(
+                strict=True,
+                description=
+                "Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database."
+            )],
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Delete a task  # noqa: E501
+
+
+        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
 
-        Delete a table with the given name.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_table_with_http_info(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.delete_task_with_http_info(database, var_schema, name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
+        :param database: Identifier (i.e. name) for the database to which the resource belongs. You can use the `/api/v2/databases` GET request to get a list of available databases. (required)
         :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
+        :param var_schema: Identifier (i.e. name) for the schema to which the resource belongs. You can use the `/api/v2/databases/{database}/schemas` GET request to get a list of available schemas for the specified database. (required)
         :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -2376,55 +2454,45 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['database', 'var_schema', 'name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method delete_table" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method delete_task" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['database']:
             _path_params['database'] = _params['database']
+
         if _params['var_schema']:
             _path_params['schema'] = _params['var_schema']
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -2444,29 +2512,32 @@
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tables/{name}', 'DELETE',
+            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}',
+            'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,20 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.table._generated.models.constraint import Constraint
 from snowflake.core.table._generated.models.error_response import ErrorResponse
 from snowflake.core.table._generated.models.foreign_key import ForeignKey
 from snowflake.core.table._generated.models.point_of_time import PointOfTime
@@ -41,8 +38,8 @@
     'PointOfTimeTimestamp',
     'PrimaryKey',
     'SuccessResponse',
     'Table',
     'TableClone',
     'TableColumn',
     'UniqueKey',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/constraint.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/constraint.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,143 +1,154 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
+
 import snowflake.core.table._generated.models
 from snowflake.core.table._generated.models import *
 
-
-from typing import List, Optional, Union
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import BaseModel, StrictStr, conlist
+
+from importlib import import_module
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional, Union
+
 
 class Constraint(BaseModel):
+
     name: Optional[StrictStr] = None
-    column_names: Optional[conlist(StrictStr)] = None
+
+    column_names: Optional[List[StrictStr]] = None
+
     constraint_type: Optional[StrictStr] = None
-    __properties = ["name", "column_names", "constraint_type"]
 
+    __properties = ["name", "column_names", "constraint_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     # JSON field name that stores the object type
-    __discriminator_property_name = 'constraint_type'
+    __discriminator_property_name: ClassVar[str] = 'constraint_type'
 
     # discriminator mappings
-    __discriminator_value_class_map = {
+    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
         'FOREIGN KEY': 'ForeignKey',
         'PRIMARY KEY': 'PrimaryKey',
         'UNIQUE': 'UniqueKey'
     }
 
     @classmethod
-    def get_discriminator_value(cls, obj: dict) -> str:
+    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
         """Returns the discriminator value (object type) of the data"""
         discriminator_value = obj[cls.__discriminator_property_name]
         if discriminator_value:
             return cls.__discriminator_value_class_map.get(discriminator_value)
         else:
             return None
 
-
-    __discriminator_value_to_type = {
+    __discriminator_value_to_type: ClassVar[Dict[str, str]] = {
         'ForeignKey': 'FOREIGN KEY',
         'PrimaryKey': 'PRIMARY KEY',
         'UniqueKey': 'UNIQUE',
     }
 
     @classmethod
     def get_child_model_discriminator_value(cls, child_model: str) -> str:
         return cls.__discriminator_value_to_type[child_model]
 
-
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> Union[ForeignKey, PrimaryKey, UniqueKey]:
+    def from_json(cls,
+                  json_str: str) -> Union[ForeignKey, PrimaryKey, UniqueKey]:
         """Create an instance of Constraint from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> Union[ForeignKey, PrimaryKey, UniqueKey]:
         """Create an instance of Constraint from a dict"""
+
         # look up the object type based on discriminator mapping
         object_type = cls.get_discriminator_value(obj)
         if object_type:
-            klass = getattr(snowflake.core.table._generated.models, object_type)
+            klass = getattr(snowflake.core.table._generated.models,
+                            object_type)
             return klass.from_dict(obj)
         else:
-            raise ValueError("Constraint failed to lookup discriminator value from " +
-                             json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
-                             ", mapping: " + json.dumps(cls.__discriminator_value_class_map))
+            raise ValueError(
+                "Constraint failed to lookup discriminator value from " +
+                json.dumps(obj) + ". Discriminator property name: " +
+                cls.__discriminator_property_name + ", mapping: " +
+                json.dumps(cls.__discriminator_value_class_map))
 
 
 from typing import Optional, List, Dict
 
+
 class ConstraintModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         name: Optional[str] = None,
         column_names: Optional[List[str]] = None,
         constraint_type: Optional[str] = None,
     ):
+
         self.name = name
         self.column_names = column_names
         self.constraint_type = constraint_type
+
     __properties = ["name", "column_names", "constraint_type"]
 
     def _to_model(self):
         return Constraint(
             name=self.name,
-
             column_names=self.column_names,
-
-            
         )
 
     @classmethod
     def _from_model(cls, model) -> ConstraintModel:
         return model.__class__._model_class._from_model(model)
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union(ForeignKeyModel, PrimaryKeyModel, UniqueKeyModel):
+    def from_dict(
+            cls, obj: dict
+    ) -> Union[ForeignKeyModel, PrimaryKeyModel, UniqueKeyModel]:
         """Create an instance of Constraint from a dict"""
         return cls._from_model(Constraint.from_dict(obj))
 
 
 Constraint._model_class = ConstraintModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/error_response.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
-
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Database API
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/foreign_key.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/foreign_key.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,41 +1,42 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import List
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import Field, StrictStr, conlist
+
 from snowflake.core.table._generated.models.constraint import Constraint
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List
+
+
 class ForeignKey(Constraint):
-    referenced_table_name: StrictStr = Field(...)
-    referenced_column_names: conlist(StrictStr) = Field(...)
-    __properties = ["name", "column_names", "constraint_type"]
 
+    referenced_table_name: StrictStr
+
+    referenced_column_names: List[StrictStr]
+
+    __properties = ["name", "column_names", "constraint_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -45,90 +46,91 @@
     @classmethod
     def from_json(cls, json_str: str) -> ForeignKey:
         """Create an instance of ForeignKey from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['constraint_type'] = Constraint.get_child_model_discriminator_value('ForeignKey')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'constraint_type'] = Constraint.get_child_model_discriminator_value(
+                'ForeignKey')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ForeignKey:
         """Create an instance of ForeignKey from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ForeignKey.parse_obj(obj)
 
         _obj = ForeignKey.parse_obj({
-            "name": obj.get("name"),
-
-            "column_names": obj.get("column_names"),
-
-            "constraint_type": obj.get("constraint_type"),
-
-            "referenced_table_name": obj.get("referenced_table_name"),
-
-            "referenced_column_names": obj.get("referenced_column_names"),
-
+            "name":
+            obj.get("name"),
+            "column_names":
+            obj.get("column_names"),
+            "constraint_type":
+            obj.get("constraint_type"),
+            "referenced_table_name":
+            obj.get("referenced_table_name"),
+            "referenced_column_names":
+            obj.get("referenced_column_names"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.constraint import Constraint
 
+
 class ForeignKeyModel(Constraint):
+
     def __init__(
         self,
         referenced_table_name: str,
         referenced_column_names: List[str],
         # optional properties
         name: Optional[str] = None,
         column_names: Optional[List[str]] = None,
     ):
         super().__init__(
             name=name,
             column_names=column_names,
         )
         self.referenced_table_name = referenced_table_name
         self.referenced_column_names = referenced_column_names
+
     __properties = ["name", "column_names", "constraint_type"]
 
     def _to_model(self):
         return ForeignKey(
             name=self.name,
-
             column_names=self.column_names,
-
-            
             referenced_table_name=self.referenced_table_name,
-
             referenced_column_names=self.referenced_column_names,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ForeignKeyModel:
         return ForeignKeyModel(
             name=model.name,
-
             column_names=model.column_names,
-
-            
             referenced_table_name=model.referenced_table_name,
-
             referenced_column_names=model.referenced_column_names,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,138 +1,152 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
-
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Database API
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
-import snowflake.core.table._generated.models
-from snowflake.core.table._generated.models import *
 
+import snowflake.core.database._generated.models
+from snowflake.core.database._generated.models import *
 
-from typing import Optional, Union
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import BaseModel, Field, StrictStr
+
+from importlib import import_module
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional, Union
+
 
 class PointOfTime(BaseModel):
-    point_of_time_type: StrictStr = Field(...)
+
+    point_of_time_type: StrictStr
+
     reference: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     # JSON field name that stores the object type
-    __discriminator_property_name = 'point_of_time_type'
+    __discriminator_property_name: ClassVar[str] = 'point_of_time_type'
 
     # discriminator mappings
-    __discriminator_value_class_map = {
+    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
         'offset': 'PointOfTimeOffset',
         'statement': 'PointOfTimeStatement',
         'timestamp': 'PointOfTimeTimestamp'
     }
 
     @classmethod
-    def get_discriminator_value(cls, obj: dict) -> str:
+    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
         """Returns the discriminator value (object type) of the data"""
         discriminator_value = obj[cls.__discriminator_property_name]
         if discriminator_value:
             return cls.__discriminator_value_class_map.get(discriminator_value)
         else:
             return None
 
-
-    __discriminator_value_to_type = {
+    __discriminator_value_to_type: ClassVar[Dict[str, str]] = {
         'PointOfTimeOffset': 'offset',
         'PointOfTimeStatement': 'statement',
         'PointOfTimeTimestamp': 'timestamp',
     }
 
     @classmethod
     def get_child_model_discriminator_value(cls, child_model: str) -> str:
         return cls.__discriminator_value_to_type[child_model]
 
-
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
 
     @classmethod
-    def from_json(cls, json_str: str) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
+    def from_json(
+        cls, json_str: str
+    ) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
         """Create an instance of PointOfTime from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
+    def from_dict(
+        cls, obj: dict
+    ) -> Union[PointOfTimeOffset, PointOfTimeStatement, PointOfTimeTimestamp]:
         """Create an instance of PointOfTime from a dict"""
+
         # look up the object type based on discriminator mapping
         object_type = cls.get_discriminator_value(obj)
         if object_type:
-            klass = getattr(snowflake.core.table._generated.models, object_type)
+            klass = getattr(snowflake.core.database._generated.models,
+                            object_type)
             return klass.from_dict(obj)
         else:
-            raise ValueError("PointOfTime failed to lookup discriminator value from " +
-                             json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
-                             ", mapping: " + json.dumps(cls.__discriminator_value_class_map))
+            raise ValueError(
+                "PointOfTime failed to lookup discriminator value from " +
+                json.dumps(obj) + ". Discriminator property name: " +
+                cls.__discriminator_property_name + ", mapping: " +
+                json.dumps(cls.__discriminator_value_class_map))
 
 
 from typing import Optional, List, Dict
 
+
 class PointOfTimeModel():
+
     def __init__(
         self,
         point_of_time_type: str,
         # optional properties
         reference: Optional[str] = None,
     ):
+
         self.point_of_time_type = point_of_time_type
         self.reference = reference
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
-        return PointOfTime(
-            
-            reference=self.reference,
-
-        )
+        return PointOfTime(reference=self.reference, )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeModel:
         return model.__class__._model_class._from_model(model)
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union(PointOfTimeOffsetModel, PointOfTimeStatementModel, PointOfTimeTimestampModel):
+    def from_dict(
+        cls, obj: dict
+    ) -> Union[PointOfTimeOffsetModel, PointOfTimeStatementModel,
+               PointOfTimeTimestampModel]:
         """Create an instance of PointOfTime from a dict"""
         return cls._from_model(PointOfTime.from_dict(obj))
 
 
 PointOfTime._model_class = PointOfTimeModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_offset.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time_offset.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import StrictStr
+
 from snowflake.core.table._generated.models.point_of_time import PointOfTime
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class PointOfTimeOffset(PointOfTime):
+
     offset: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeOffset:
         """Create an instance of PointOfTimeOffset from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeOffset')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeOffset')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeOffset:
         """Create an instance of PointOfTimeOffset from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeOffset.parse_obj(obj)
 
         _obj = PointOfTimeOffset.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "offset": obj.get("offset"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "offset":
+            obj.get("offset"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.point_of_time import PointOfTime
 
+
 class PointOfTimeOffsetModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         offset: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.offset = offset
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeOffset(
-            
             reference=self.reference,
-
             offset=self.offset,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeOffsetModel:
         return PointOfTimeOffsetModel(
-            
             reference=model.reference,
-
             offset=model.offset,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_statement.py` & `snowflake_core-0.8.1/src/snowflake/core/database/_generated/models/point_of_time_statement.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
-
-    The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
 
+    Snowflake Database API
+    The Snowflake Database API is a REST API that you can use to access, update, and perform certain actions on Database resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import StrictStr
-from snowflake.core.table._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class PointOfTimeStatement(PointOfTime):
+
     statement: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeStatement:
         """Create an instance of PointOfTimeStatement from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeStatement')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeStatement')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeStatement:
         """Create an instance of PointOfTimeStatement from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeStatement.parse_obj(obj)
 
         _obj = PointOfTimeStatement.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "statement": obj.get("statement"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "statement":
+            obj.get("statement"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
-from snowflake.core.table._generated.models.point_of_time import PointOfTime
+
+from snowflake.core.database._generated.models.point_of_time import PointOfTime
+
 
 class PointOfTimeStatementModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         statement: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.statement = statement
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeStatement(
-            
             reference=self.reference,
-
             statement=self.statement,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeStatementModel:
         return PointOfTimeStatementModel(
-            
             reference=model.reference,
-
             statement=model.statement,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/point_of_time_timestamp.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/point_of_time_timestamp.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import StrictStr
+
 from snowflake.core.table._generated.models.point_of_time import PointOfTime
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class PointOfTimeTimestamp(PointOfTime):
+
     timestamp: Optional[StrictStr] = None
-    __properties = ["point_of_time_type", "reference"]
 
+    __properties = ["point_of_time_type", "reference"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,74 +44,76 @@
     @classmethod
     def from_json(cls, json_str: str) -> PointOfTimeTimestamp:
         """Create an instance of PointOfTimeTimestamp from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['point_of_time_type'] = PointOfTime.get_child_model_discriminator_value('PointOfTimeTimestamp')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'point_of_time_type'] = PointOfTime.get_child_model_discriminator_value(
+                'PointOfTimeTimestamp')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PointOfTimeTimestamp:
         """Create an instance of PointOfTimeTimestamp from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PointOfTimeTimestamp.parse_obj(obj)
 
         _obj = PointOfTimeTimestamp.parse_obj({
-            "point_of_time_type": obj.get("point_of_time_type"),
-
-            "reference": obj.get("reference"),
-
-            "timestamp": obj.get("timestamp"),
-
+            "point_of_time_type":
+            obj.get("point_of_time_type"),
+            "reference":
+            obj.get("reference"),
+            "timestamp":
+            obj.get("timestamp"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.point_of_time import PointOfTime
 
+
 class PointOfTimeTimestampModel(PointOfTime):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         reference: Optional[str] = None,
         timestamp: Optional[str] = None,
     ):
-        super().__init__(
-            reference=reference,
-        )
+        super().__init__(reference=reference, )
         self.timestamp = timestamp
+
     __properties = ["point_of_time_type", "reference"]
 
     def _to_model(self):
         return PointOfTimeTimestamp(
-            
             reference=self.reference,
-
             timestamp=self.timestamp,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> PointOfTimeTimestampModel:
         return PointOfTimeTimestampModel(
-            
             reference=model.reference,
-
             timestamp=model.timestamp,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/primary_key.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/primary_key.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-
 from typing import Union
 
 from snowflake.core.table._generated.models.constraint import Constraint
 
+from pydantic import ConfigDict
+
+from typing import Any, ClassVar, Dict, List
+
+
 class PrimaryKey(Constraint):
-    __properties = ["name", "column_names", "constraint_type"]
 
+    __properties = ["name", "column_names", "constraint_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,74 +42,78 @@
     @classmethod
     def from_json(cls, json_str: str) -> PrimaryKey:
         """Create an instance of PrimaryKey from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['constraint_type'] = Constraint.get_child_model_discriminator_value('PrimaryKey')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'constraint_type'] = Constraint.get_child_model_discriminator_value(
+                'PrimaryKey')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> PrimaryKey:
         """Create an instance of PrimaryKey from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return PrimaryKey.parse_obj(obj)
 
         _obj = PrimaryKey.parse_obj({
-            "name": obj.get("name"),
-
-            "column_names": obj.get("column_names"),
-
-            "constraint_type": obj.get("constraint_type"),
-
+            "name":
+            obj.get("name"),
+            "column_names":
+            obj.get("column_names"),
+            "constraint_type":
+            obj.get("constraint_type"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.constraint import Constraint
 
+
 class PrimaryKeyModel(Constraint):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         name: Optional[str] = None,
         column_names: Optional[List[str]] = None,
     ):
         super().__init__(
             name=name,
             column_names=column_names,
         )
+
     __properties = ["name", "column_names", "constraint_type"]
 
     def _to_model(self):
         return PrimaryKey(
             name=self.name,
-
             column_names=self.column_names,
-
-            
         )
 
     @classmethod
     def _from_model(cls, model) -> PrimaryKeyModel:
         return PrimaryKeyModel(
             name=model.name,
-
             column_names=model.column_names,
-
-            
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/success_response.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/table.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,64 +1,98 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import List, Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist
+
 from snowflake.core.table._generated.models.constraint import Constraint
+
 from snowflake.core.table._generated.models.table_column import TableColumn
 
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, StrictBool, StrictInt, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class Table(BaseModel):
-    name: StrictStr = Field(...)
+
+    name: StrictStr
+
     kind: Optional[StrictStr] = None
-    cluster_by: Optional[conlist(StrictStr)] = None
+
+    cluster_by: Optional[List[StrictStr]] = None
+
     enable_schema_evolution: Optional[StrictBool] = None
+
     change_tracking: Optional[StrictBool] = None
+
     data_retention_time_in_days: Optional[StrictInt] = None
+
     max_data_extension_time_in_days: Optional[StrictInt] = None
+
     default_ddl_collation: Optional[StrictStr] = None
-    columns: Optional[conlist(TableColumn)] = None
-    constraints: Optional[conlist(Constraint)] = None
+
+    columns: Optional[List[TableColumn]] = None
+
+    constraints: Optional[List[Constraint]] = None
+
     comment: Optional[StrictStr] = None
+
     created_on: Optional[datetime] = None
+
     database_name: Optional[StrictStr] = None
+
     schema_name: Optional[StrictStr] = None
+
     rows: Optional[StrictInt] = None
+
     bytes: Optional[StrictInt] = None
+
     owner: Optional[StrictStr] = None
+
     dropped_on: Optional[datetime] = None
+
     automatic_clustering: Optional[StrictBool] = None
+
     search_optimization: Optional[StrictBool] = None
+
     search_optimization_progress: Optional[StrictInt] = None
+
     search_optimization_bytes: Optional[StrictInt] = None
+
     owner_role_type: Optional[StrictStr] = None
+
     budget: Optional[StrictStr] = None
-    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type", "budget"]
 
+    __properties = [
+        "name", "kind", "cluster_by", "enable_schema_evolution",
+        "change_tracking", "data_retention_time_in_days",
+        "max_data_extension_time_in_days", "default_ddl_collation", "columns",
+        "constraints", "comment", "created_on", "database_name", "schema_name",
+        "rows", "bytes", "owner", "dropped_on", "automatic_clustering",
+        "search_optimization", "search_optimization_progress",
+        "search_optimization_bytes", "owner_role_type", "budget"
+    ]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -68,101 +102,127 @@
     @classmethod
     def from_json(cls, json_str: str) -> Table:
         """Create an instance of Table from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "database_name",
+                           "schema_name",
+                           "rows",
+                           "bytes",
+                           "owner",
+                           "dropped_on",
+                           "automatic_clustering",
+                           "search_optimization",
+                           "search_optimization_progress",
+                           "search_optimization_bytes",
+                           "owner_role_type",
+                           "budget",
+                       },
+                       exclude_none=True))
+
         # override the default output from pydantic by calling `to_dict()` of each item in columns (list)
         _items = []
         if self.columns:
             for _item in self.columns:
                 if _item:
                     _items.append(_item.to_dict())
             _dict['columns'] = _items
+
         # override the default output from pydantic by calling `to_dict()` of each item in constraints (list)
         _items = []
         if self.constraints:
             for _item in self.constraints:
                 if _item:
                     _items.append(_item.to_dict())
             _dict['constraints'] = _items
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> Table:
         """Create an instance of Table from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return Table.parse_obj(obj)
 
         _obj = Table.parse_obj({
-            "name": obj.get("name"),
-
-            "kind": obj.get("kind"),
-
-            "cluster_by": obj.get("cluster_by"),
-
-            "enable_schema_evolution": obj.get("enable_schema_evolution"),
-
-            "change_tracking": obj.get("change_tracking"),
-
-            "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
-
-            "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
-
-            "default_ddl_collation": obj.get("default_ddl_collation"),
-
-            "columns": [TableColumn.from_dict(_item) for _item in obj.get("columns")] if obj.get("columns") is not None else None,
-
-            "constraints": [Constraint.from_dict(_item) for _item in obj.get("constraints")] if obj.get("constraints") is not None else None,
-
-            "comment": obj.get("comment"),
-
-            "created_on": obj.get("created_on"),
-
-            "database_name": obj.get("database_name"),
-
-            "schema_name": obj.get("schema_name"),
-
-            "rows": obj.get("rows"),
-
-            "bytes": obj.get("bytes"),
-
-            "owner": obj.get("owner"),
-
-            "dropped_on": obj.get("dropped_on"),
-
-            "automatic_clustering": obj.get("automatic_clustering"),
-
-            "search_optimization": obj.get("search_optimization"),
-
-            "search_optimization_progress": obj.get("search_optimization_progress"),
-
-            "search_optimization_bytes": obj.get("search_optimization_bytes"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
-            "budget": obj.get("budget"),
-
+            "name":
+            obj.get("name"),
+            "kind":
+            obj.get("kind"),
+            "cluster_by":
+            obj.get("cluster_by"),
+            "enable_schema_evolution":
+            obj.get("enable_schema_evolution"),
+            "change_tracking":
+            obj.get("change_tracking"),
+            "data_retention_time_in_days":
+            obj.get("data_retention_time_in_days"),
+            "max_data_extension_time_in_days":
+            obj.get("max_data_extension_time_in_days"),
+            "default_ddl_collation":
+            obj.get("default_ddl_collation"),
+            "columns":
+            [TableColumn.from_dict(_item) for _item in obj.get("columns")]
+            if obj.get("columns") is not None else None,
+            "constraints":
+            [Constraint.from_dict(_item) for _item in obj.get("constraints")]
+            if obj.get("constraints") is not None else None,
+            "comment":
+            obj.get("comment"),
+            "created_on":
+            obj.get("created_on"),
+            "database_name":
+            obj.get("database_name"),
+            "schema_name":
+            obj.get("schema_name"),
+            "rows":
+            obj.get("rows"),
+            "bytes":
+            obj.get("bytes"),
+            "owner":
+            obj.get("owner"),
+            "dropped_on":
+            obj.get("dropped_on"),
+            "automatic_clustering":
+            obj.get("automatic_clustering"),
+            "search_optimization":
+            obj.get("search_optimization"),
+            "search_optimization_progress":
+            obj.get("search_optimization_progress"),
+            "search_optimization_bytes":
+            obj.get("search_optimization_bytes"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
+            "budget":
+            obj.get("budget"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.constraint import Constraint
+
 from snowflake.core.table._generated.models.table_column import TableColumn
 
+
 class TableModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
         kind: Optional[str] = None,
         cluster_by: Optional[List[str]] = None,
         enable_schema_evolution: Optional[bool] = None,
@@ -183,14 +243,15 @@
         automatic_clustering: Optional[bool] = None,
         search_optimization: Optional[bool] = None,
         search_optimization_progress: Optional[int] = None,
         search_optimization_bytes: Optional[int] = None,
         owner_role_type: Optional[str] = None,
         budget: Optional[str] = None,
     ):
+
         self.name = name
         self.kind = kind
         self.cluster_by = cluster_by
         self.enable_schema_evolution = enable_schema_evolution
         self.change_tracking = change_tracking
         self.data_retention_time_in_days = data_retention_time_in_days
         self.max_data_extension_time_in_days = max_data_extension_time_in_days
@@ -207,119 +268,87 @@
         self.dropped_on = dropped_on
         self.automatic_clustering = automatic_clustering
         self.search_optimization = search_optimization
         self.search_optimization_progress = search_optimization_progress
         self.search_optimization_bytes = search_optimization_bytes
         self.owner_role_type = owner_role_type
         self.budget = budget
-    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type", "budget"]
+
+    __properties = [
+        "name", "kind", "cluster_by", "enable_schema_evolution",
+        "change_tracking", "data_retention_time_in_days",
+        "max_data_extension_time_in_days", "default_ddl_collation", "columns",
+        "constraints", "comment", "created_on", "database_name", "schema_name",
+        "rows", "bytes", "owner", "dropped_on", "automatic_clustering",
+        "search_optimization", "search_optimization_progress",
+        "search_optimization_bytes", "owner_role_type", "budget"
+    ]
 
     def _to_model(self):
         return Table(
             name=self.name,
-
             kind=self.kind,
-
             cluster_by=self.cluster_by,
-
             enable_schema_evolution=self.enable_schema_evolution,
-
             change_tracking=self.change_tracking,
-
             data_retention_time_in_days=self.data_retention_time_in_days,
-
-            max_data_extension_time_in_days=self.max_data_extension_time_in_days,
-
+            max_data_extension_time_in_days=self.
+            max_data_extension_time_in_days,
             default_ddl_collation=self.default_ddl_collation,
-
-            columns=[x._to_model() for x in self.columns] if self.columns is not None else None,
-
-            constraints=[x._to_model() for x in self.constraints] if self.constraints is not None else None,
-
+            columns=[x._to_model() for x in self.columns]
+            if self.columns is not None else None,
+            constraints=[x._to_model() for x in self.constraints]
+            if self.constraints is not None else None,
             comment=self.comment,
-
             created_on=self.created_on,
-
             database_name=self.database_name,
-
             schema_name=self.schema_name,
-
             rows=self.rows,
-
             bytes=self.bytes,
-
             owner=self.owner,
-
             dropped_on=self.dropped_on,
-
             automatic_clustering=self.automatic_clustering,
-
             search_optimization=self.search_optimization,
-
             search_optimization_progress=self.search_optimization_progress,
-
             search_optimization_bytes=self.search_optimization_bytes,
-
             owner_role_type=self.owner_role_type,
-
             budget=self.budget,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> TableModel:
         return TableModel(
             name=model.name,
-
             kind=model.kind,
-
             cluster_by=model.cluster_by,
-
             enable_schema_evolution=model.enable_schema_evolution,
-
             change_tracking=model.change_tracking,
-
             data_retention_time_in_days=model.data_retention_time_in_days,
-
-            max_data_extension_time_in_days=model.max_data_extension_time_in_days,
-
+            max_data_extension_time_in_days=model.
+            max_data_extension_time_in_days,
             default_ddl_collation=model.default_ddl_collation,
-
-            columns=[TableColumnModel._from_model(x) for x in model.columns] if model.columns is not None else None,
-
-            constraints=[ConstraintModel._from_model(x) for x in model.constraints] if model.constraints is not None else None,
-
+            columns=[TableColumnModel._from_model(x) for x in model.columns]
+            if model.columns is not None else None,
+            constraints=[
+                ConstraintModel._from_model(x) for x in model.constraints
+            ] if model.constraints is not None else None,
             comment=model.comment,
-
             created_on=model.created_on,
-
             database_name=model.database_name,
-
             schema_name=model.schema_name,
-
             rows=model.rows,
-
             bytes=model.bytes,
-
             owner=model.owner,
-
             dropped_on=model.dropped_on,
-
             automatic_clustering=model.automatic_clustering,
-
             search_optimization=model.search_optimization,
-
             search_optimization_progress=model.search_optimization_progress,
-
             search_optimization_bytes=model.search_optimization_bytes,
-
             owner_role_type=model.owner_role_type,
-
             budget=model.budget,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table_clone.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/table_clone.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,66 +1,102 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import List, Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist
+
 from snowflake.core.table._generated.models.constraint import Constraint
+
 from snowflake.core.table._generated.models.point_of_time import PointOfTime
+
 from snowflake.core.table._generated.models.table_column import TableColumn
 
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, StrictBool, StrictInt, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class TableClone(BaseModel):
+
     point_of_time: Optional[PointOfTime] = None
-    name: StrictStr = Field(...)
+
+    name: StrictStr
+
     kind: Optional[StrictStr] = None
-    cluster_by: Optional[conlist(StrictStr)] = None
+
+    cluster_by: Optional[List[StrictStr]] = None
+
     enable_schema_evolution: Optional[StrictBool] = None
+
     change_tracking: Optional[StrictBool] = None
+
     data_retention_time_in_days: Optional[StrictInt] = None
+
     max_data_extension_time_in_days: Optional[StrictInt] = None
+
     default_ddl_collation: Optional[StrictStr] = None
-    columns: Optional[conlist(TableColumn)] = None
-    constraints: Optional[conlist(Constraint)] = None
+
+    columns: Optional[List[TableColumn]] = None
+
+    constraints: Optional[List[Constraint]] = None
+
     comment: Optional[StrictStr] = None
+
     created_on: Optional[datetime] = None
+
     database_name: Optional[StrictStr] = None
+
     schema_name: Optional[StrictStr] = None
+
     rows: Optional[StrictInt] = None
+
     bytes: Optional[StrictInt] = None
+
     owner: Optional[StrictStr] = None
+
     dropped_on: Optional[datetime] = None
+
     automatic_clustering: Optional[StrictBool] = None
+
     search_optimization: Optional[StrictBool] = None
+
     search_optimization_progress: Optional[StrictInt] = None
+
     search_optimization_bytes: Optional[StrictInt] = None
+
     owner_role_type: Optional[StrictStr] = None
+
     budget: Optional[StrictStr] = None
-    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type", "budget"]
 
+    __properties = [
+        "name", "kind", "cluster_by", "enable_schema_evolution",
+        "change_tracking", "data_retention_time_in_days",
+        "max_data_extension_time_in_days", "default_ddl_collation", "columns",
+        "constraints", "comment", "created_on", "database_name", "schema_name",
+        "rows", "bytes", "owner", "dropped_on", "automatic_clustering",
+        "search_optimization", "search_optimization_progress",
+        "search_optimization_bytes", "owner_role_type", "budget"
+    ]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -70,104 +106,132 @@
     @classmethod
     def from_json(cls, json_str: str) -> TableClone:
         """Create an instance of TableClone from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "database_name",
+                           "schema_name",
+                           "rows",
+                           "bytes",
+                           "owner",
+                           "dropped_on",
+                           "automatic_clustering",
+                           "search_optimization",
+                           "search_optimization_progress",
+                           "search_optimization_bytes",
+                           "owner_role_type",
+                           "budget",
+                       },
+                       exclude_none=True))
+
         # override the default output from pydantic by calling `to_dict()` of each item in columns (list)
         _items = []
         if self.columns:
             for _item in self.columns:
                 if _item:
                     _items.append(_item.to_dict())
             _dict['columns'] = _items
+
         # override the default output from pydantic by calling `to_dict()` of each item in constraints (list)
         _items = []
         if self.constraints:
             for _item in self.constraints:
                 if _item:
                     _items.append(_item.to_dict())
             _dict['constraints'] = _items
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> TableClone:
         """Create an instance of TableClone from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return TableClone.parse_obj(obj)
 
         _obj = TableClone.parse_obj({
-            "point_of_time": PointOfTime.from_dict(obj.get("point_of_time")) if obj.get("point_of_time") is not None else None,
-
-            "name": obj.get("name"),
-
-            "kind": obj.get("kind"),
-
-            "cluster_by": obj.get("cluster_by"),
-
-            "enable_schema_evolution": obj.get("enable_schema_evolution"),
-
-            "change_tracking": obj.get("change_tracking"),
-
-            "data_retention_time_in_days": obj.get("data_retention_time_in_days"),
-
-            "max_data_extension_time_in_days": obj.get("max_data_extension_time_in_days"),
-
-            "default_ddl_collation": obj.get("default_ddl_collation"),
-
-            "columns": [TableColumn.from_dict(_item) for _item in obj.get("columns")] if obj.get("columns") is not None else None,
-
-            "constraints": [Constraint.from_dict(_item) for _item in obj.get("constraints")] if obj.get("constraints") is not None else None,
-
-            "comment": obj.get("comment"),
-
-            "created_on": obj.get("created_on"),
-
-            "database_name": obj.get("database_name"),
-
-            "schema_name": obj.get("schema_name"),
-
-            "rows": obj.get("rows"),
-
-            "bytes": obj.get("bytes"),
-
-            "owner": obj.get("owner"),
-
-            "dropped_on": obj.get("dropped_on"),
-
-            "automatic_clustering": obj.get("automatic_clustering"),
-
-            "search_optimization": obj.get("search_optimization"),
-
-            "search_optimization_progress": obj.get("search_optimization_progress"),
-
-            "search_optimization_bytes": obj.get("search_optimization_bytes"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
-            "budget": obj.get("budget"),
-
+            "point_of_time":
+            PointOfTime.from_dict(obj.get("point_of_time"))
+            if obj.get("point_of_time") is not None else None,
+            "name":
+            obj.get("name"),
+            "kind":
+            obj.get("kind"),
+            "cluster_by":
+            obj.get("cluster_by"),
+            "enable_schema_evolution":
+            obj.get("enable_schema_evolution"),
+            "change_tracking":
+            obj.get("change_tracking"),
+            "data_retention_time_in_days":
+            obj.get("data_retention_time_in_days"),
+            "max_data_extension_time_in_days":
+            obj.get("max_data_extension_time_in_days"),
+            "default_ddl_collation":
+            obj.get("default_ddl_collation"),
+            "columns":
+            [TableColumn.from_dict(_item) for _item in obj.get("columns")]
+            if obj.get("columns") is not None else None,
+            "constraints":
+            [Constraint.from_dict(_item) for _item in obj.get("constraints")]
+            if obj.get("constraints") is not None else None,
+            "comment":
+            obj.get("comment"),
+            "created_on":
+            obj.get("created_on"),
+            "database_name":
+            obj.get("database_name"),
+            "schema_name":
+            obj.get("schema_name"),
+            "rows":
+            obj.get("rows"),
+            "bytes":
+            obj.get("bytes"),
+            "owner":
+            obj.get("owner"),
+            "dropped_on":
+            obj.get("dropped_on"),
+            "automatic_clustering":
+            obj.get("automatic_clustering"),
+            "search_optimization":
+            obj.get("search_optimization"),
+            "search_optimization_progress":
+            obj.get("search_optimization_progress"),
+            "search_optimization_bytes":
+            obj.get("search_optimization_bytes"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
+            "budget":
+            obj.get("budget"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.constraint import Constraint
+
 from snowflake.core.table._generated.models.point_of_time import PointOfTime
+
 from snowflake.core.table._generated.models.table_column import TableColumn
 
+
 class TableCloneModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
         point_of_time: Optional[PointOfTime] = None,
         kind: Optional[str] = None,
         cluster_by: Optional[List[str]] = None,
@@ -189,14 +253,15 @@
         automatic_clustering: Optional[bool] = None,
         search_optimization: Optional[bool] = None,
         search_optimization_progress: Optional[int] = None,
         search_optimization_bytes: Optional[int] = None,
         owner_role_type: Optional[str] = None,
         budget: Optional[str] = None,
     ):
+
         self.point_of_time = point_of_time
         self.name = name
         self.kind = kind
         self.cluster_by = cluster_by
         self.enable_schema_evolution = enable_schema_evolution
         self.change_tracking = change_tracking
         self.data_retention_time_in_days = data_retention_time_in_days
@@ -214,123 +279,91 @@
         self.dropped_on = dropped_on
         self.automatic_clustering = automatic_clustering
         self.search_optimization = search_optimization
         self.search_optimization_progress = search_optimization_progress
         self.search_optimization_bytes = search_optimization_bytes
         self.owner_role_type = owner_role_type
         self.budget = budget
-    __properties = ["name", "kind", "cluster_by", "enable_schema_evolution", "change_tracking", "data_retention_time_in_days", "max_data_extension_time_in_days", "default_ddl_collation", "columns", "constraints", "comment", "created_on", "database_name", "schema_name", "rows", "bytes", "owner", "dropped_on", "automatic_clustering", "search_optimization", "search_optimization_progress", "search_optimization_bytes", "owner_role_type", "budget"]
+
+    __properties = [
+        "name", "kind", "cluster_by", "enable_schema_evolution",
+        "change_tracking", "data_retention_time_in_days",
+        "max_data_extension_time_in_days", "default_ddl_collation", "columns",
+        "constraints", "comment", "created_on", "database_name", "schema_name",
+        "rows", "bytes", "owner", "dropped_on", "automatic_clustering",
+        "search_optimization", "search_optimization_progress",
+        "search_optimization_bytes", "owner_role_type", "budget"
+    ]
 
     def _to_model(self):
         return TableClone(
-            point_of_time=self.point_of_time._to_model() if self.point_of_time is not None else None,
-
+            point_of_time=self.point_of_time._to_model()
+            if self.point_of_time is not None else None,
             name=self.name,
-
             kind=self.kind,
-
             cluster_by=self.cluster_by,
-
             enable_schema_evolution=self.enable_schema_evolution,
-
             change_tracking=self.change_tracking,
-
             data_retention_time_in_days=self.data_retention_time_in_days,
-
-            max_data_extension_time_in_days=self.max_data_extension_time_in_days,
-
+            max_data_extension_time_in_days=self.
+            max_data_extension_time_in_days,
             default_ddl_collation=self.default_ddl_collation,
-
-            columns=[x._to_model() for x in self.columns] if self.columns is not None else None,
-
-            constraints=[x._to_model() for x in self.constraints] if self.constraints is not None else None,
-
+            columns=[x._to_model() for x in self.columns]
+            if self.columns is not None else None,
+            constraints=[x._to_model() for x in self.constraints]
+            if self.constraints is not None else None,
             comment=self.comment,
-
             created_on=self.created_on,
-
             database_name=self.database_name,
-
             schema_name=self.schema_name,
-
             rows=self.rows,
-
             bytes=self.bytes,
-
             owner=self.owner,
-
             dropped_on=self.dropped_on,
-
             automatic_clustering=self.automatic_clustering,
-
             search_optimization=self.search_optimization,
-
             search_optimization_progress=self.search_optimization_progress,
-
             search_optimization_bytes=self.search_optimization_bytes,
-
             owner_role_type=self.owner_role_type,
-
             budget=self.budget,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> TableCloneModel:
         return TableCloneModel(
-            point_of_time=PointOfTimeModel._from_model(model.point_of_time) if model.point_of_time is not None else None,
-
+            point_of_time=PointOfTimeModel._from_model(model.point_of_time)
+            if model.point_of_time is not None else None,
             name=model.name,
-
             kind=model.kind,
-
             cluster_by=model.cluster_by,
-
             enable_schema_evolution=model.enable_schema_evolution,
-
             change_tracking=model.change_tracking,
-
             data_retention_time_in_days=model.data_retention_time_in_days,
-
-            max_data_extension_time_in_days=model.max_data_extension_time_in_days,
-
+            max_data_extension_time_in_days=model.
+            max_data_extension_time_in_days,
             default_ddl_collation=model.default_ddl_collation,
-
-            columns=[TableColumnModel._from_model(x) for x in model.columns] if model.columns is not None else None,
-
-            constraints=[ConstraintModel._from_model(x) for x in model.constraints] if model.constraints is not None else None,
-
+            columns=[TableColumnModel._from_model(x) for x in model.columns]
+            if model.columns is not None else None,
+            constraints=[
+                ConstraintModel._from_model(x) for x in model.constraints
+            ] if model.constraints is not None else None,
             comment=model.comment,
-
             created_on=model.created_on,
-
             database_name=model.database_name,
-
             schema_name=model.schema_name,
-
             rows=model.rows,
-
             bytes=model.bytes,
-
             owner=model.owner,
-
             dropped_on=model.dropped_on,
-
             automatic_clustering=model.automatic_clustering,
-
             search_optimization=model.search_optimization,
-
             search_optimization_progress=model.search_optimization_progress,
-
             search_optimization_bytes=model.search_optimization_bytes,
-
             owner_role_type=model.owner_role_type,
-
             budget=model.budget,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/table_column.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/table_column.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,49 +1,62 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import List, Optional
 from typing import Union
-from snowflake.core.table._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist
+
 from snowflake.core.table._generated.models.constraint import Constraint
 
+from pydantic import BaseModel, ConfigDict, StrictBool, StrictInt, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+
 class TableColumn(BaseModel):
-    name: StrictStr = Field(...)
-    datatype: StrictStr = Field(...)
+
+    name: StrictStr
+
+    datatype: StrictStr
+
     nullable: Optional[StrictBool] = True
+
     collate: Optional[StrictStr] = None
+
     default: Optional[StrictStr] = None
+
     autoincrement: Optional[StrictBool] = None
+
     autoincrement_start: Optional[StrictInt] = None
+
     autoincrement_increment: Optional[StrictInt] = None
-    constraints: Optional[conlist(Constraint)] = None
+
+    constraints: Optional[List[Constraint]] = None
+
     comment: Optional[StrictStr] = None
-    __properties = ["name", "datatype", "nullable", "collate", "default", "autoincrement", "autoincrement_start", "autoincrement_increment", "constraints", "comment"]
 
+    __properties = [
+        "name", "datatype", "nullable", "collate", "default", "autoincrement",
+        "autoincrement_start", "autoincrement_increment", "constraints",
+        "comment"
+    ]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -53,138 +66,136 @@
     @classmethod
     def from_json(cls, json_str: str) -> TableColumn:
         """Create an instance of TableColumn from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         # override the default output from pydantic by calling `to_dict()` of each item in constraints (list)
         _items = []
         if self.constraints:
             for _item in self.constraints:
                 if _item:
                     _items.append(_item.to_dict())
             _dict['constraints'] = _items
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> TableColumn:
         """Create an instance of TableColumn from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return TableColumn.parse_obj(obj)
 
         _obj = TableColumn.parse_obj({
-            "name": obj.get("name"),
-
-            "datatype": obj.get("datatype"),
-
-            "nullable": obj.get("nullable") if obj.get("nullable") is not None else True,
-
-            "collate": obj.get("collate"),
-
-            "default": obj.get("default"),
-
-            "autoincrement": obj.get("autoincrement"),
-
-            "autoincrement_start": obj.get("autoincrement_start"),
-
-            "autoincrement_increment": obj.get("autoincrement_increment"),
-
-            "constraints": [Constraint.from_dict(_item) for _item in obj.get("constraints")] if obj.get("constraints") is not None else None,
-
-            "comment": obj.get("comment"),
-
+            "name":
+            obj.get("name"),
+            "datatype":
+            obj.get("datatype"),
+            "nullable":
+            obj.get("nullable") if obj.get("nullable") is not None else True,
+            "collate":
+            obj.get("collate"),
+            "default":
+            obj.get("default"),
+            "autoincrement":
+            obj.get("autoincrement"),
+            "autoincrement_start":
+            obj.get("autoincrement_start"),
+            "autoincrement_increment":
+            obj.get("autoincrement_increment"),
+            "constraints":
+            [Constraint.from_dict(_item) for _item in obj.get("constraints")]
+            if obj.get("constraints") is not None else None,
+            "comment":
+            obj.get("comment"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.constraint import Constraint
 
+
 class TableColumnModel():
+
     def __init__(
         self,
         name: str,
         datatype: str,
         # optional properties
         nullable: Optional[bool] = True,
         collate: Optional[str] = None,
         default: Optional[str] = None,
         autoincrement: Optional[bool] = None,
         autoincrement_start: Optional[int] = None,
         autoincrement_increment: Optional[int] = None,
         constraints: Optional[List[Constraint]] = None,
         comment: Optional[str] = None,
     ):
+
         self.name = name
         self.datatype = datatype
         self.nullable = nullable
         self.collate = collate
         self.default = default
         self.autoincrement = autoincrement
         self.autoincrement_start = autoincrement_start
         self.autoincrement_increment = autoincrement_increment
         self.constraints = constraints
         self.comment = comment
-    __properties = ["name", "datatype", "nullable", "collate", "default", "autoincrement", "autoincrement_start", "autoincrement_increment", "constraints", "comment"]
+
+    __properties = [
+        "name", "datatype", "nullable", "collate", "default", "autoincrement",
+        "autoincrement_start", "autoincrement_increment", "constraints",
+        "comment"
+    ]
 
     def _to_model(self):
         return TableColumn(
             name=self.name,
-
             datatype=self.datatype,
-
             nullable=self.nullable,
-
             collate=self.collate,
-
             default=self.default,
-
             autoincrement=self.autoincrement,
-
             autoincrement_start=self.autoincrement_start,
-
             autoincrement_increment=self.autoincrement_increment,
-
-            constraints=[x._to_model() for x in self.constraints] if self.constraints is not None else None,
-
+            constraints=[x._to_model() for x in self.constraints]
+            if self.constraints is not None else None,
             comment=self.comment,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> TableColumnModel:
         return TableColumnModel(
             name=model.name,
-
             datatype=model.datatype,
-
             nullable=model.nullable,
-
             collate=model.collate,
-
             default=model.default,
-
             autoincrement=model.autoincrement,
-
             autoincrement_start=model.autoincrement_start,
-
             autoincrement_increment=model.autoincrement_increment,
-
-            constraints=[ConstraintModel._from_model(x) for x in model.constraints] if model.constraints is not None else None,
-
+            constraints=[
+                ConstraintModel._from_model(x) for x in model.constraints
+            ] if model.constraints is not None else None,
             comment=model.comment,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/table/_generated/models/unique_key.py` & `snowflake_core-0.8.1/src/snowflake/core/table/_generated/models/unique_key.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Table API
 
+    Snowflake Table API
     The Snowflake Table API is a REST API that you can use to access, update, and perform certain actions on Tables resource in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-
 from typing import Union
 
 from snowflake.core.table._generated.models.constraint import Constraint
 
+from pydantic import ConfigDict
+
+from typing import Any, ClassVar, Dict, List
+
+
 class UniqueKey(Constraint):
-    __properties = ["name", "column_names", "constraint_type"]
 
+    __properties = ["name", "column_names", "constraint_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,74 +42,78 @@
     @classmethod
     def from_json(cls, json_str: str) -> UniqueKey:
         """Create an instance of UniqueKey from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['constraint_type'] = Constraint.get_child_model_discriminator_value('UniqueKey')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'constraint_type'] = Constraint.get_child_model_discriminator_value(
+                'UniqueKey')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> UniqueKey:
         """Create an instance of UniqueKey from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return UniqueKey.parse_obj(obj)
 
         _obj = UniqueKey.parse_obj({
-            "name": obj.get("name"),
-
-            "column_names": obj.get("column_names"),
-
-            "constraint_type": obj.get("constraint_type"),
-
+            "name":
+            obj.get("name"),
+            "column_names":
+            obj.get("column_names"),
+            "constraint_type":
+            obj.get("constraint_type"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.table._generated.models.constraint import Constraint
 
+
 class UniqueKeyModel(Constraint):
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         name: Optional[str] = None,
         column_names: Optional[List[str]] = None,
     ):
         super().__init__(
             name=name,
             column_names=column_names,
         )
+
     __properties = ["name", "column_names", "constraint_type"]
 
     def _to_model(self):
         return UniqueKey(
             name=self.name,
-
             column_names=self.column_names,
-
-            
         )
 
     @classmethod
     def _from_model(cls, model) -> UniqueKeyModel:
         return UniqueKeyModel(
             name=model.name,
-
             column_names=model.column_names,
-
-            
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/task/__init__.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_task.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_task.py`

 * *Files 0% similar despite different names*

```diff
@@ -15,14 +15,16 @@
     List,
     NamedTuple,
     Optional,
     Tuple,
     Union,
 )
 
+from pydantic import StrictStr
+
 from snowflake.core._common import (
     CreateMode,
     SchemaObjectCollectionParent,
     SchemaObjectReferenceMixin,
 )
 from snowflake.core._internal.telemetry import api_telemetry
 from snowflake.core.task._generated import (
@@ -32,15 +34,14 @@
     TaskRun,
     TaskSchedule,
 )
 from snowflake.core.task._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.task._generated.models import (
     Task as TaskModel,
 )
-from snowflake.core.task._generated.pydantic_compatibility import StrictStr
 from snowflake.snowpark._internal.udf_utils import generate_call_python_sp_sql
 from snowflake.snowpark._internal.utils import is_in_stored_procedure
 from snowflake.snowpark.stored_procedure import StoredProcedure
 from snowflake.snowpark.types import DataType
 
 
 if TYPE_CHECKING:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/context.py` & `snowflake_core-0.8.1/src/snowflake/core/task/context.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/dagv1.py` & `snowflake_core-0.8.1/src/snowflake/core/task/dagv1.py`

 * *Files 1% similar despite different names*

```diff
@@ -123,15 +123,15 @@
 def _convert_func_to_task(
     other: Union[
         "DAGTask", Iterable[
             Union["DAGTask", Callable[[Session], Optional[str]]]
         ], Callable[[Session], Optional[str]]
     ]
 ) -> Union["DAGTask", Iterable["DAGTask"]]:
-    tasks: Union["DAGTask", Iterable["DAGTask"]]
+    tasks: Union[DAGTask, Iterable[DAGTask]]
     if callable(other):
         tasks = DAGTask(other.__name__, other)
     elif isinstance(other, DAGTask):
         tasks = other
     elif isinstance(other, Iterable):
         tasks = [DAGTask(t.__name__, t) if callable(t) else t for t in other]
     else:
@@ -227,17 +227,17 @@
         self.user_task_timeout_ms = user_task_timeout_ms
         #: Refer to :attr:`snowflake.core.task.Task.suspend_task_after_num_failures`.
         self.suspend_task_after_num_failures = suspend_task_after_num_failures
         #: Refer to :attr:`snowflake.core.task.Task.config`.
         self.config = config
         #: Refer to :attr:`snowflake.core.task.Task.session_parameters`.
         self.session_parameters = session_parameters
-        self._tasks: Dict[str, "DAGTask"] = dict()
+        self._tasks: Dict[str, DAGTask] = dict()
         self._task_list: Optional[
-            List["DAGTask"]
+            List[DAGTask]
         ] = None  # as a cache for property tasks
 
         #: The default stage location where this task graph's tasks code will be stored
         #: if creating the tasks from Python functions.
         self.stage_location = stage_location
         #: The default imports for all tasks of this task graph if creating the tasks from Python functions.
         self.imports = imports
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Task API
 
+    Snowflake Task API
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.task._generated.api.task_api import TaskApi
-
 # import ApiClient
 from snowflake.core.task._generated.api_client import ApiClient
 from snowflake.core.task._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.task._generated.models.cron_schedule import CronSchedule
 from snowflake.core.task._generated.models.error_response import ErrorResponse
 from snowflake.core.task._generated.models.minutes_schedule import MinutesSchedule
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/api_client.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Task API
-
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
+    Snowflake Session API
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.task._generated.configuration import Configuration
-import snowflake.core.task._generated.models
-from snowflake.core.task._generated import rest
-from snowflake.core.task._generated.paging import PagedIter
+from snowflake.core.session._generated.configuration import Configuration
+import snowflake.core.session._generated.models
+from snowflake.core.session._generated import rest
+from snowflake.core.session._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,62 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.task._generated.models, klass)
+                klass = getattr(snowflake.core.session._generated.models,
+                                klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +520,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +671,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for task. Updating task '
-                        'objects is not supported yet; use create() for creating a task.')
+                        'create_or_update is not yet supported for session. Updating session '
+                        'objects is not supported yet; use create() for creating a session.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +700,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +743,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +787,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +824,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +848,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +875,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +941,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +959,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +975,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1010,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/api_response.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.task._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/function/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
-
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
+    Snowflake Function API
+    The Snowflake Function API is a REST API that allows caller to create, execute and drop functions in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.task._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.function._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,18 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Task API",
-            }
-        ]
+        return [{
+            'url': "https://org-account.snowflakecomputing.com",
+            'description': "Snowflake REST Server",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +370,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/service/_generated/rest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
-
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
+    Snowflake Services API
+    The Snowflake Services API is a REST API that you can use to access, update, and perform certain actions on Services resource in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/api/task_api.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/api/session_api.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,86 +1,84 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
-
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
+    Snowflake Session API
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictInt, StrictStr, constr, validator
-
+from pydantic import Field, StrictStr
 from typing import List, Optional
-
-from snowflake.core.task._generated.models.success_response import SuccessResponse
-from snowflake.core.task._generated.models.task import Task
-from snowflake.core.task._generated.models.task_run import TaskRun
+from typing_extensions import Annotated
+from snowflake.core.session._generated.models.current_secondary_roles import CurrentSecondaryRoles
+from snowflake.core.session._generated.models.default_result import DefaultResult
+from snowflake.core.session._generated.models.named_default import NamedDefault
+from snowflake.core.session._generated.models.parameter import Parameter
+from snowflake.core.session._generated.models.secondary_roles import SecondaryRoles
+from snowflake.core.session._generated.models.success_response import SuccessResponse
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.task._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
 
-logger  = logging.getLogger(__name__)
+logger = logging.getLogger(__name__)
 
-class TaskApi(object):
+
+class SessionApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
 
     def __init__(self, root, resource_class, bridge_client, sproc_client):
         self._root = root
-        self._resource_name = 'task'
+        self._resource_name = 'session'
         self._resource_class = resource_class
         self._bridge_client = bridge_client
         self._sproc_client = sproc_client
         self._chosen_client_type = ApiClientType.NONE
 
     @property
     def api_client(self):
         """
             chosen_client is the client we chose , either bridge or rest
             new_chosen_client is the client we want to choose under the current situation ( value of
             _supports_rest_api + _can_use_rest_api, and the server-controlled flag )
             We will log the change if we want to choose another client instead of the current one
         """
-        from snowflake.core.task._generated.api_client import ApiClient
+        from snowflake.core.session._generated.api_client import ApiClient
 
         # Small helper function for figuring out the correct 'REST' client to use if in stored proc or not
         def _get_rest_client():
             if is_running_inside_stored_procedure():
                 return self._sproc_client, ApiClientType.STORED_PROC
             else:
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('task')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge('session')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -92,73 +90,63 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_or_alter_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], task : Task, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a (or alter an existing) task  # noqa: E501
+    @validate_call
+    def get_current_secondary_roles(
+            self, **kwargs) -> CurrentSecondaryRoles:  # noqa: E501
+        """Get current session's default role  # noqa: E501
+
+
+        Get current session's default role  # noqa: E501
 
-        Create a (or alter an existing) task. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_task(database, var_schema, name, task, async_req=True)
+        >>> thread = api.get_current_secondary_roles(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param task: (required)
-        :type task: Task
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: CurrentSecondaryRoles
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_alter_task_with_http_info(database, var_schema, name, task, **kwargs)  # noqa: E501
+        return self.get_current_secondary_roles_with_http_info(
+            **kwargs)  # noqa: E501
+
+    @validate_call
+    def get_current_secondary_roles_with_http_info(self,
+                                                   **kwargs):  # noqa: E501
+        """Get current session's default role  # noqa: E501
 
-    @validate_arguments
-    def create_or_alter_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], task : Task, **kwargs):  # noqa: E501
-        """Create a (or alter an existing) task  # noqa: E501
 
-        Create a (or alter an existing) task. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+        Get current session's default role  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_or_alter_task_with_http_info(database, var_schema, name, task, async_req=True)
+        >>> thread = api.get_current_secondary_roles_with_http_info(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param task: (required)
-        :type task: Task
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -172,174 +160,135 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(CurrentSecondaryRoles, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'task'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = []
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_or_alter_task" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_current_secondary_roles" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['task']:
-            _body_params = _params['task']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
-
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "CurrentSecondaryRoles",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'PUT',
+            '/api/v2/session/secondary-roles',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], task : Task, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Create a task  # noqa: E501
+    @validate_call
+    def get_default_database(self, **kwargs) -> DefaultResult:  # noqa: E501
+        """Get current session's default database  # noqa: E501
+
+
+        Get current session's default database  # noqa: E501
 
-        Create a task, with standard create modifiers as query parameters. See the Task component definition for what is required to be provided in the request body.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_task(database, var_schema, task, create_mode, async_req=True)
+        >>> thread = api.get_default_database(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param task: (required)
-        :type task: Task
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: DefaultResult
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_task_with_http_info(database, var_schema, task, create_mode, **kwargs)  # noqa: E501
+        return self.get_default_database_with_http_info(**kwargs)  # noqa: E501
+
+    @validate_call
+    def get_default_database_with_http_info(self, **kwargs):  # noqa: E501
+        """Get current session's default database  # noqa: E501
 
-    @validate_arguments
-    def create_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], task : Task, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
-        """Create a task  # noqa: E501
 
-        Create a task, with standard create modifiers as query parameters. See the Task component definition for what is required to be provided in the request body.  # noqa: E501
+        Get current session's default database  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.create_task_with_http_info(database, var_schema, task, create_mode, async_req=True)
+        >>> thread = api.get_default_database_with_http_info(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param task: (required)
-        :type task: Task
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
-        :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -353,175 +302,134 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(DefaultResult, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'task',
-            'create_mode'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = []
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_task" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_default_database" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
-        if _params.get('create_mode') is not None:  # noqa: E501
-            _query_params.append(('createMode', _params['create_mode']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
-        if _params['task']:
-            _body_params = _params['task']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
-        # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
-        if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
-
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "DefaultResult",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks', 'POST',
+            '/api/v2/session/default-database',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def execute_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], retry_last : Annotated[Optional[StrictBool], Field(description="Retry the last failed run of the DAG.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Execute a task object.  # noqa: E501
+    @validate_call
+    def get_default_role(self, **kwargs) -> DefaultResult:  # noqa: E501
+        """Get current session's default role  # noqa: E501
+
+
+        Get current session's default role  # noqa: E501
 
-        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.execute_task(database, var_schema, name, retry_last, async_req=True)
+        >>> thread = api.get_default_role(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param retry_last: Retry the last failed run of the DAG.
-        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: SuccessResponse
+        :rtype: DefaultResult
         """
         kwargs['_return_http_data_only'] = True
-        return self.execute_task_with_http_info(database, var_schema, name, retry_last, **kwargs)  # noqa: E501
+        return self.get_default_role_with_http_info(**kwargs)  # noqa: E501
 
-    @validate_arguments
-    def execute_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], retry_last : Annotated[Optional[StrictBool], Field(description="Retry the last failed run of the DAG.")] = None, **kwargs):  # noqa: E501
-        """Execute a task object.  # noqa: E501
+    @validate_call
+    def get_default_role_with_http_info(self, **kwargs):  # noqa: E501
+        """Get current session's default role  # noqa: E501
+
+
+        Get current session's default role  # noqa: E501
 
-        Execute a task -- this is equivalent to EXECUTE IMMEDIATE.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.execute_task_with_http_info(database, var_schema, name, retry_last, async_req=True)
+        >>> thread = api.get_default_role_with_http_info(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param retry_last: Retry the last failed run of the DAG.
-        :type retry_last: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -535,62 +443,40 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(DefaultResult, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'retry_last'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = []
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method execute_task" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_default_role" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('retry_last') is not None:  # noqa: E501
-            _query_params.append(('retryLast', _params['retry_last']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -602,96 +488,89 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "SuccessResponse",
+            '200': "DefaultResult",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:execute', 'POST',
+            '/api/v2/session/default-role',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Task:  # noqa: E501
-        """Fetch a task  # noqa: E501
+    @validate_call
+    def get_default_schema(self, **kwargs) -> DefaultResult:  # noqa: E501
+        """Get current session's default schema  # noqa: E501
+
+
+        Get current session's default schema  # noqa: E501
 
-        Fetch a task using the describe command output.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task(database, var_schema, name, async_req=True)
+        >>> thread = api.get_default_schema(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Task
+        :rtype: DefaultResult
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.get_default_schema_with_http_info(**kwargs)  # noqa: E501
+
+    @validate_call
+    def get_default_schema_with_http_info(self, **kwargs):  # noqa: E501
+        """Get current session's default schema  # noqa: E501
 
-    @validate_arguments
-    def fetch_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Fetch a task  # noqa: E501
 
-        Fetch a task using the describe command output.  # noqa: E501
+        Get current session's default schema  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.get_default_schema_with_http_info(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -705,56 +584,37 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Task, status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(DefaultResult, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = []
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_task" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_default_schema" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
@@ -769,100 +629,90 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Task",
+            '200': "DefaultResult",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'GET',
+            '/api/v2/session/default-schema',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def fetch_task_dependents(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], recursive : Annotated[Optional[StrictBool], Field(description="Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.")] = None, **kwargs) -> Iterable[Task]:  # noqa: E501
-        """Fetch the dependent tasks of a task  # noqa: E501
+    @validate_call
+    def get_default_warehouse(self, **kwargs) -> DefaultResult:  # noqa: E501
+        """Get current session's default warehouse  # noqa: E501
+
+
+        Get current session's default warehouse  # noqa: E501
 
-        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task_dependents(database, var_schema, name, recursive, async_req=True)
+        >>> thread = api.get_default_warehouse(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param recursive: Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.
-        :type recursive: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Iterable[Task]
+        :rtype: DefaultResult
         """
         kwargs['_return_http_data_only'] = True
-        return self.fetch_task_dependents_with_http_info(database, var_schema, name, recursive, **kwargs)  # noqa: E501
+        return self.get_default_warehouse_with_http_info(**
+                                                         kwargs)  # noqa: E501
+
+    @validate_call
+    def get_default_warehouse_with_http_info(self, **kwargs):  # noqa: E501
+        """Get current session's default warehouse  # noqa: E501
 
-    @validate_arguments
-    def fetch_task_dependents_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], recursive : Annotated[Optional[StrictBool], Field(description="Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.")] = None, **kwargs):  # noqa: E501
-        """Fetch the dependent tasks of a task  # noqa: E501
 
-        This operation returns a list of the dependent tasks of the task with identifier {name}.  # noqa: E501
+        Get current session's default warehouse  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.fetch_task_dependents_with_http_info(database, var_schema, name, recursive, async_req=True)
+        >>> thread = api.get_default_warehouse_with_http_info(async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param recursive: Specifies whether to limit the output to include only direct child tasks or to include all recursive child tasks.
-        :type recursive: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -876,62 +726,40 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Iterable[Task], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(DefaultResult, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'recursive'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = []
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method fetch_task_dependents" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_default_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('recursive') is not None:  # noqa: E501
-            _query_params.append(('recursive', _params['recursive']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -943,104 +771,111 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Iterable[Task]",
+            '200': "DefaultResult",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/dependents', 'GET',
+            '/api/v2/session/default-warehouse',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def get_complete_graphs(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Annotated[Optional[StrictInt], Field(description="Number of results to return, at most. Default is 1000, valid range is 1 to 10000.")] = None, error_only : Annotated[Optional[StrictBool], Field(description="Whether to only return results for tasks runs that have failed. Default is false.")] = None, **kwargs) -> Iterable[TaskRun]:  # noqa: E501
-        """Get the graph runs that are completed for the task.  # noqa: E501
+    @validate_call
+    def get_parameters(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            **kwargs) -> Iterable[Parameter]:  # noqa: E501
+        """Gets the effective parameter values for the user's current session.  # noqa: E501
+
+
+        Gets the effective parameter values for the user's current session.  # noqa: E501
 
-        This function returns details for graph runs that are completed.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_complete_graphs(database, var_schema, name, result_limit, error_only, async_req=True)
+        >>> thread = api.get_parameters(like, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
-        :type result_limit: int
-        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
-        :type error_only: bool
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
+        :type like: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Iterable[TaskRun]
+        :rtype: Iterable[Parameter]
         """
         kwargs['_return_http_data_only'] = True
-        return self.get_complete_graphs_with_http_info(database, var_schema, name, result_limit, error_only, **kwargs)  # noqa: E501
+        return self.get_parameters_with_http_info(like, **kwargs)  # noqa: E501
+
+    @validate_call
+    def get_parameters_with_http_info(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            **kwargs):  # noqa: E501
+        """Gets the effective parameter values for the user's current session.  # noqa: E501
 
-    @validate_arguments
-    def get_complete_graphs_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Annotated[Optional[StrictInt], Field(description="Number of results to return, at most. Default is 1000, valid range is 1 to 10000.")] = None, error_only : Annotated[Optional[StrictBool], Field(description="Whether to only return results for tasks runs that have failed. Default is false.")] = None, **kwargs):  # noqa: E501
-        """Get the graph runs that are completed for the task.  # noqa: E501
 
-        This function returns details for graph runs that are completed.  # noqa: E501
+        Gets the effective parameter values for the user's current session.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_complete_graphs_with_http_info(database, var_schema, name, result_limit, error_only, async_req=True)
+        >>> thread = api.get_parameters_with_http_info(like, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param result_limit: Number of results to return, at most. Default is 1000, valid range is 1 to 10000.
-        :type result_limit: int
-        :param error_only: Whether to only return results for tasks runs that have failed. Default is false.
-        :type error_only: bool
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
+        :type like: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1054,65 +889,43 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Iterable[TaskRun], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(Iterable[Parameter], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'result_limit',
-            'error_only'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['like']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method get_complete_graphs" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method get_parameters" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('result_limit') is not None:  # noqa: E501
-            _query_params.append(('resultLimit', _params['result_limit']))
-        if _params.get('error_only') is not None:  # noqa: E501
-            _query_params.append(('errorOnly', _params['error_only']))
+
+        if _params.get('like') is not None:  # noqa: E501
+            _query_params.append(('like', _params['like']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
@@ -1124,100 +937,97 @@
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Iterable[TaskRun]",
+            '200': "Iterable[Parameter]",
+            '202': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/complete_graphs', 'GET',
+            '/api/v2/session/parameters/effective',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def get_current_graphs(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Optional[StrictInt] = None, **kwargs) -> Iterable[TaskRun]:  # noqa: E501
-        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
+    @validate_call
+    def set_default_database(self, named_default: NamedDefault,
+                             **kwargs) -> SuccessResponse:  # noqa: E501
+        """Set current session's default database  # noqa: E501
+
+
+        Set current session's default database  # noqa: E501
 
-        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_current_graphs(database, var_schema, name, result_limit, async_req=True)
+        >>> thread = api.set_default_database(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param result_limit:
-        :type result_limit: int
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Iterable[TaskRun]
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.get_current_graphs_with_http_info(database, var_schema, name, result_limit, **kwargs)  # noqa: E501
+        return self.set_default_database_with_http_info(
+            named_default, **kwargs)  # noqa: E501
+
+    @validate_call
+    def set_default_database_with_http_info(self, named_default: NamedDefault,
+                                            **kwargs):  # noqa: E501
+        """Set current session's default database  # noqa: E501
+
 
-    @validate_arguments
-    def get_current_graphs_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], result_limit : Optional[StrictInt] = None, **kwargs):  # noqa: E501
-        """Get the graph runs that are executing or scheduled for the task for the next 8 days.  # noqa: E501
+        Set current session's default database  # noqa: E501
 
-        This function returns details for graph runs that are currently executing or are next scheduled to run within the next 8 days.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.get_current_graphs_with_http_info(database, var_schema, name, result_limit, async_req=True)
+        >>> thread = api.set_default_database_with_http_info(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param result_limit:
-        :type result_limit: int
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1231,175 +1041,151 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Iterable[TaskRun], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'result_limit'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['named_default']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method get_current_graphs" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method set_default_database" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('result_limit') is not None:  # noqa: E501
-            _query_params.append(('resultLimit', _params['result_limit']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
 
+        if _params['named_default']:
+            _body_params = _params['named_default']
+
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
+        if _content_types_list:
+            _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Iterable[TaskRun]",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}/current_graphs', 'GET',
+            '/api/v2/session/default-database',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def list_tasks(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], root_only : Annotated[Optional[StrictBool], Field(description="A query parameter that filters the command output to return only root resources (resources with no predecessors).")] = None, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs) -> Iterable[Task]:  # noqa: E501
-        """List tasks  # noqa: E501
+    @validate_call
+    def set_default_role(self, named_default: NamedDefault,
+                         **kwargs) -> SuccessResponse:  # noqa: E501
+        """Set current session's default role  # noqa: E501
+
+
+        Set current session's default role  # noqa: E501
 
-        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_tasks(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
+        >>> thread = api.set_default_role(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param root_only: A query parameter that filters the command output to return only root resources (resources with no predecessors).
-        :type root_only: bool
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
-        :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
-        :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
-        :type show_limit: int
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: Iterable[Task]
+        :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_tasks_with_http_info(database, var_schema, root_only, like, starts_with, show_limit, **kwargs)  # noqa: E501
+        return self.set_default_role_with_http_info(named_default,
+                                                    **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def list_tasks_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], root_only : Annotated[Optional[StrictBool], Field(description="A query parameter that filters the command output to return only root resources (resources with no predecessors).")] = None, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, starts_with : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.")] = None, show_limit : Annotated[Optional[StrictInt], Field(description="A query parameter that limits the maximum number of rows returned by a command.")] = None, **kwargs):  # noqa: E501
-        """List tasks  # noqa: E501
+    @validate_call
+    def set_default_role_with_http_info(self, named_default: NamedDefault,
+                                        **kwargs):  # noqa: E501
+        """Set current session's default role  # noqa: E501
+
+
+        Set current session's default role  # noqa: E501
 
-        Lists tasks under the database and schema, with show options as query parameters.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.list_tasks_with_http_info(database, var_schema, root_only, like, starts_with, show_limit, async_req=True)
+        >>> thread = api.set_default_role_with_http_info(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param root_only: A query parameter that filters the command output to return only root resources (resources with no predecessors).
-        :type root_only: bool
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
-        :type like: str
-        :param starts_with: A query parameter that filters the command output based on the string of characters that appear at the beginning of the object name. Uses case-sensitive pattern matching.
-        :type starts_with: str
-        :param show_limit: A query parameter that limits the maximum number of rows returned by a command.
-        :type show_limit: int
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1413,135 +1199,117 @@
                               request; this effectively ignores the authentication
                               in the spec for a single request.
         :type _request_auth: dict, optional
         :type _content_type: string, optional: force content-type for the request
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
-        :rtype: tuple(Iterable[Task], status_code(int), headers(HTTPHeaderDict))
+        :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'root_only',
-            'like',
-            'starts_with',
-            'show_limit'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['named_default']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method list_tasks" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method set_default_role" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
 
         # process the query parameters
         _query_params = []
-        if _params.get('root_only') is not None:  # noqa: E501
-            _query_params.append(('rootOnly', _params['root_only']))
-        if _params.get('like') is not None:  # noqa: E501
-            _query_params.append(('like', _params['like']))
-        if _params.get('starts_with') is not None:  # noqa: E501
-            _query_params.append(('startsWith', _params['starts_with']))
-        if _params.get('show_limit') is not None:  # noqa: E501
-            _query_params.append(('showLimit', _params['show_limit']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
 
+        if _params['named_default']:
+            _body_params = _params['named_default']
+
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
+        if _content_types_list:
+            _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
-            '200': "Iterable[Task]",
+            '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
             '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks', 'GET',
+            '/api/v2/session/default-role',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def resume_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
-        """Resume a suspended task.  # noqa: E501
+    @validate_call
+    def set_default_schema(self, named_default: NamedDefault,
+                           **kwargs) -> SuccessResponse:  # noqa: E501
+        """Set current session's default schema  # noqa: E501
+
+
+        Set current session's default schema  # noqa: E501
 
-        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_task(database, var_schema, name, async_req=True)
+        >>> thread = api.set_default_schema(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1550,33 +1318,32 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.resume_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.set_default_schema_with_http_info(named_default,
+                                                      **kwargs)  # noqa: E501
+
+    @validate_call
+    def set_default_schema_with_http_info(self, named_default: NamedDefault,
+                                          **kwargs):  # noqa: E501
+        """Set current session's default schema  # noqa: E501
+
 
-    @validate_arguments
-    def resume_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Resume a suspended task.  # noqa: E501
+        Set current session's default schema  # noqa: E501
 
-        Resumes a suspended task object. This is equivalento an ALTER TASK ... RESUME.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.resume_task_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.set_default_schema_with_http_info(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1595,120 +1362,112 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['named_default']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method resume_task" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method set_default_schema" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
 
+        if _params['named_default']:
+            _body_params = _params['named_default']
+
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
+        if _content_types_list:
+            _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:resume', 'POST',
+            '/api/v2/session/default-schema',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def suspend_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
-        """Suspends a running task.  # noqa: E501
+    @validate_call
+    def set_default_warehouse(self, named_default: NamedDefault,
+                              **kwargs) -> SuccessResponse:  # noqa: E501
+        """Set current session's default warehouse  # noqa: E501
+
+
+        Set current session's default warehouse  # noqa: E501
 
-        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_task(database, var_schema, name, async_req=True)
+        >>> thread = api.set_default_warehouse(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1717,33 +1476,32 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_task_with_http_info(database, var_schema, name, **kwargs)  # noqa: E501
+        return self.set_default_warehouse_with_http_info(
+            named_default, **kwargs)  # noqa: E501
+
+    @validate_call
+    def set_default_warehouse_with_http_info(self, named_default: NamedDefault,
+                                             **kwargs):  # noqa: E501
+        """Set current session's default warehouse  # noqa: E501
 
-    @validate_arguments
-    def suspend_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
-        """Suspends a running task.  # noqa: E501
 
-        Suspends a running task. This is equivalent to an ALTER TASK ... SUSPEND.  # noqa: E501
+        Set current session's default warehouse  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.suspend_task_with_http_info(database, var_schema, name, async_req=True)
+        >>> thread = api.set_default_warehouse_with_http_info(named_default, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
+        :param named_default: (required)
+        :type named_default: NamedDefault
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1762,122 +1520,112 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['named_default']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method suspend_task" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method set_default_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
 
+        if _params['named_default']:
+            _body_params = _params['named_default']
+
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
+        if _content_types_list:
+            _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}:suspend', 'POST',
+            '/api/v2/session/default-warehouse',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def delete_task(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
-        """Delete a task  # noqa: E501
+    @validate_call
+    def use_secondary_role(self, secondary_roles: SecondaryRoles,
+                           **kwargs) -> SuccessResponse:  # noqa: E501
+        """Set or unset current session's secondary role usage  # noqa: E501
+
+
+        Enable or disable current session's secondary role usage  # noqa: E501
 
-        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_task(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.use_secondary_role(secondary_roles, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
+        :param secondary_roles: (required)
+        :type secondary_roles: SecondaryRoles
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
         :param _request_timeout: timeout setting for this request. If one
@@ -1886,35 +1634,33 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.delete_task_with_http_info(database, var_schema, name, if_exists, **kwargs)  # noqa: E501
+        return self.use_secondary_role_with_http_info(secondary_roles,
+                                                      **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def delete_task_with_http_info(self, database : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the database which the resource belongs to.")], var_schema : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the schema which the resource belongs to.")], name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
-        """Delete a task  # noqa: E501
+    @validate_call
+    def use_secondary_role_with_http_info(self,
+                                          secondary_roles: SecondaryRoles,
+                                          **kwargs):  # noqa: E501
+        """Set or unset current session's secondary role usage  # noqa: E501
+
+
+        Enable or disable current session's secondary role usage  # noqa: E501
 
-        Delete a task with the task name. If ifExists is used, the operation will succeed even if the object does not exist. Otherwise, there will be a failure if the drop is unsuccessful.  # noqa: E501
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
-        >>> thread = api.delete_task_with_http_info(database, var_schema, name, if_exists, async_req=True)
+        >>> thread = api.use_secondary_role_with_http_info(secondary_roles, async_req=True)
         >>> result = thread.get()
-
-        :param database: String that specifies the identifier (i.e. name) for the database which the resource belongs to. (required)
-        :type database: str
-        :param var_schema: String that specifies the identifier (i.e. name) for the schema which the resource belongs to. (required)
-        :type var_schema: str
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
-        :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
-        :type if_exists: bool
+        :param secondary_roles: (required)
+        :type secondary_roles: SecondaryRoles
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -1933,98 +1679,89 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'database',
-            'var_schema',
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['secondary_roles']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method delete_task" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method use_secondary_role" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
-        if _params['database']:
-            _path_params['database'] = _params['database']
-        if _params['var_schema']:
-            _path_params['schema'] = _params['var_schema']
-        if _params['name']:
-            _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
-        if _params.get('if_exists') is not None:  # noqa: E501
-            _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
 
+        if _params['secondary_roles']:
+            _body_params = _params['secondary_roles']
+
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
+        # set the HTTP header `Content-Type`
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
+        if _content_types_list:
+            _header_params['Content-Type'] = _content_types_list
+
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
             '401': "ErrorResponse",
             '403': "ErrorResponse",
             '404': "ErrorResponse",
             '405': "ErrorResponse",
+            '409': "ErrorResponse",
             '429': "ErrorResponse",
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/databases/{database}/schemas/{schema}/tasks/{name}', 'DELETE',
+            '/api/v2/session/secondary-roles',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,23 +1,20 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Task API
 
+    Snowflake Task API
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
 from snowflake.core.task._generated.models.cron_schedule import CronSchedule
 from snowflake.core.task._generated.models.error_response import ErrorResponse
 from snowflake.core.task._generated.models.minutes_schedule import MinutesSchedule
 from snowflake.core.task._generated.models.success_response import SuccessResponse
@@ -29,8 +26,8 @@
     'CronSchedule',
     'ErrorResponse',
     'MinutesSchedule',
     'SuccessResponse',
     'Task',
     'TaskRun',
     'TaskSchedule',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/cron_schedule.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/cron_schedule.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,41 +1,42 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
 
+    Snowflake Task API
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-
 from typing import Union
-from snowflake.core.task._generated.pydantic_compatibility import Field, StrictStr
+
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
+from pydantic import ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List
+
+
 class CronSchedule(TaskSchedule):
-    cron_expr: StrictStr = Field(...)
-    timezone: StrictStr = Field(...)
-    __properties = ["schedule_type"]
 
+    cron_expr: StrictStr
+
+    timezone: StrictStr
+
+    __properties = ["schedule_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -45,74 +46,75 @@
     @classmethod
     def from_json(cls, json_str: str) -> CronSchedule:
         """Create an instance of CronSchedule from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['schedule_type'] = TaskSchedule.get_child_model_discriminator_value('CronSchedule')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'schedule_type'] = TaskSchedule.get_child_model_discriminator_value(
+                'CronSchedule')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> CronSchedule:
         """Create an instance of CronSchedule from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return CronSchedule.parse_obj(obj)
 
         _obj = CronSchedule.parse_obj({
             "schedule_type": obj.get("schedule_type"),
-
             "cron_expr": obj.get("cron_expr"),
-
             "timezone": obj.get("timezone"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
+
 class CronScheduleModel(TaskSchedule):
+
     def __init__(
         self,
         cron_expr: str,
         timezone: str,
         # optional properties
     ):
-        super().__init__(
-        )
+        super().__init__()
         self.cron_expr = cron_expr
         self.timezone = timezone
+
     __properties = ["schedule_type"]
 
     def _to_model(self):
         return CronSchedule(
-            
             cron_expr=self.cron_expr,
-
             timezone=self.timezone,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> CronScheduleModel:
         return CronScheduleModel(
-            
             cron_expr=model.cron_expr,
-
             timezone=model.timezone,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/user/_generated/models/error_response.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
-
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
+    Snowflake User API
+    The Snowflake User API is a REST API that you can use to access, update, and perform certain action on Users in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.task._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/minutes_schedule.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/minutes_schedule.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
 
+    Snowflake Task API
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-
 from typing import Union
-from snowflake.core.task._generated.pydantic_compatibility import Field, StrictInt
+
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
+from pydantic import ConfigDict, StrictInt
+
+from typing import Any, ClassVar, Dict, List
+
+
 class MinutesSchedule(TaskSchedule):
-    minutes: StrictInt = Field(...)
-    __properties = ["schedule_type"]
 
+    minutes: StrictInt
+
+    __properties = ["schedule_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -44,67 +44,69 @@
     @classmethod
     def from_json(cls, json_str: str) -> MinutesSchedule:
         """Create an instance of MinutesSchedule from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
-        _dict['schedule_type'] = TaskSchedule.get_child_model_discriminator_value('MinutesSchedule')
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
+        _dict[
+            'schedule_type'] = TaskSchedule.get_child_model_discriminator_value(
+                'MinutesSchedule')
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> MinutesSchedule:
         """Create an instance of MinutesSchedule from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return MinutesSchedule.parse_obj(obj)
 
         _obj = MinutesSchedule.parse_obj({
-            "schedule_type": obj.get("schedule_type"),
-
-            "minutes": obj.get("minutes"),
-
+            "schedule_type":
+            obj.get("schedule_type"),
+            "minutes":
+            obj.get("minutes"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
+
 class MinutesScheduleModel(TaskSchedule):
+
     def __init__(
         self,
         minutes: int,
         # optional properties
     ):
-        super().__init__(
-        )
+        super().__init__()
         self.minutes = minutes
+
     __properties = ["schedule_type"]
 
     def _to_model(self):
-        return MinutesSchedule(
-            
-            minutes=self.minutes,
-
-        )
+        return MinutesSchedule(minutes=self.minutes, )
 
     @classmethod
     def _from_model(cls, model) -> MinutesScheduleModel:
-        return MinutesScheduleModel(
-            
-            minutes=model.minutes,
-
-        )
+        return MinutesScheduleModel(minutes=model.minutes, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> MinutesScheduleModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/user/_generated/models/success_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
-
-    The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
 
+    Snowflake User API
+    The Snowflake User API is a REST API that you can use to access, update, and perform certain action on Users in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.task._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/task.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,85 +1,125 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
 
+    Snowflake Task API
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Any, Dict, List, Optional
 from typing import Union
-from snowflake.core.task._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, conlist, constr, validator
+
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
+
 class Task(BaseModel):
-    name: constr(strict=True) = Field(...)
-    warehouse: Optional[constr(strict=True)] = None
+
+    name: Annotated[str, Field(strict=True)]
+
+    warehouse: Optional[Annotated[str, Field(strict=True)]] = None
+
     schedule: Optional[TaskSchedule] = None
+
     comment: Optional[StrictStr] = None
+
     config: Optional[Dict[str, Any]] = None
+
     session_parameters: Optional[Dict[str, Any]] = None
-    definition: StrictStr = Field(...)
-    predecessors: Optional[conlist(StrictStr)] = None
+
+    definition: StrictStr
+
+    predecessors: Optional[List[StrictStr]] = None
+
     user_task_managed_initial_warehouse_size: Optional[StrictStr] = None
+
     user_task_timeout_ms: Optional[StrictInt] = None
+
     suspend_task_after_num_failures: Optional[StrictInt] = None
+
     condition: Optional[StrictStr] = None
+
     allow_overlapping_execution: Optional[StrictBool] = None
+
     error_integration: Optional[StrictStr] = None
+
     created_on: Optional[datetime] = None
+
     id: Optional[StrictStr] = None
+
     owner: Optional[StrictStr] = None
+
     owner_role_type: Optional[StrictStr] = None
+
     state: Optional[StrictStr] = None
+
     last_committed_on: Optional[datetime] = None
+
     last_suspended_on: Optional[datetime] = None
+
     database_name: Optional[StrictStr] = None
+
     schema_name: Optional[StrictStr] = None
-    __properties = ["name", "warehouse", "schedule", "comment", "config", "session_parameters", "definition", "predecessors", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms", "suspend_task_after_num_failures", "condition", "allow_overlapping_execution", "error_integration", "created_on", "id", "owner", "owner_role_type", "state", "last_committed_on", "last_suspended_on", "database_name", "schema_name"]
 
+    __properties = [
+        "name", "warehouse", "schedule", "comment", "config",
+        "session_parameters", "definition", "predecessors",
+        "user_task_managed_initial_warehouse_size", "user_task_timeout_ms",
+        "suspend_task_after_num_failures", "condition",
+        "allow_overlapping_execution", "error_integration", "created_on", "id",
+        "owner", "owner_role_type", "state", "last_committed_on",
+        "last_suspended_on", "database_name", "schema_name"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('warehouse')
+    @field_validator('warehouse')
     def warehouse_validate_regular_expression(cls, v):
+
         if v is None:
             return v
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('state')
+    @field_validator('state')
     def state_validate_enum(cls, v):
+
         if v is None:
             return v
-
         if v not in ('started', 'suspended'):
-            raise ValueError("must validate the enum values ('started', 'suspended')")
+            raise ValueError("must validate the enum values ()")
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -89,96 +129,106 @@
     @classmethod
     def from_json(cls, json_str: str) -> Task:
         """Create an instance of Task from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "created_on",
-                            "id",
-                            "owner",
-                            "owner_role_type",
-                            "state",
-                            "last_committed_on",
-                            "last_suspended_on",
-                            "database_name",
-                            "schema_name",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "created_on",
+                           "id",
+                           "owner",
+                           "owner_role_type",
+                           "state",
+                           "last_committed_on",
+                           "last_suspended_on",
+                           "database_name",
+                           "schema_name",
+                       },
+                       exclude_none=True))
+
         # override the default output from pydantic by calling `to_dict()` of schedule
         if self.schedule:
             _dict['schedule'] = self.schedule.to_dict()
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> Task:
         """Create an instance of Task from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return Task.parse_obj(obj)
 
         _obj = Task.parse_obj({
-            "name": obj.get("name"),
-
-            "warehouse": obj.get("warehouse"),
-
-            "schedule": TaskSchedule.from_dict(obj.get("schedule")) if obj.get("schedule") is not None else None,
-
-            "comment": obj.get("comment"),
-
-            "config": obj.get("config"),
-
-            "session_parameters": obj.get("session_parameters"),
-
-            "definition": obj.get("definition"),
-
-            "predecessors": obj.get("predecessors"),
-
-            "user_task_managed_initial_warehouse_size": obj.get("user_task_managed_initial_warehouse_size"),
-
-            "user_task_timeout_ms": obj.get("user_task_timeout_ms"),
-
-            "suspend_task_after_num_failures": obj.get("suspend_task_after_num_failures"),
-
-            "condition": obj.get("condition"),
-
-            "allow_overlapping_execution": obj.get("allow_overlapping_execution"),
-
-            "error_integration": obj.get("error_integration"),
-
-            "created_on": obj.get("created_on"),
-
-            "id": obj.get("id"),
-
-            "owner": obj.get("owner"),
-
-            "owner_role_type": obj.get("owner_role_type"),
-
-            "state": obj.get("state"),
-
-            "last_committed_on": obj.get("last_committed_on"),
-
-            "last_suspended_on": obj.get("last_suspended_on"),
-
-            "database_name": obj.get("database_name"),
-
-            "schema_name": obj.get("schema_name"),
-
+            "name":
+            obj.get("name"),
+            "warehouse":
+            obj.get("warehouse"),
+            "schedule":
+            TaskSchedule.from_dict(obj.get("schedule"))
+            if obj.get("schedule") is not None else None,
+            "comment":
+            obj.get("comment"),
+            "config":
+            obj.get("config"),
+            "session_parameters":
+            obj.get("session_parameters"),
+            "definition":
+            obj.get("definition"),
+            "predecessors":
+            obj.get("predecessors"),
+            "user_task_managed_initial_warehouse_size":
+            obj.get("user_task_managed_initial_warehouse_size"),
+            "user_task_timeout_ms":
+            obj.get("user_task_timeout_ms"),
+            "suspend_task_after_num_failures":
+            obj.get("suspend_task_after_num_failures"),
+            "condition":
+            obj.get("condition"),
+            "allow_overlapping_execution":
+            obj.get("allow_overlapping_execution"),
+            "error_integration":
+            obj.get("error_integration"),
+            "created_on":
+            obj.get("created_on"),
+            "id":
+            obj.get("id"),
+            "owner":
+            obj.get("owner"),
+            "owner_role_type":
+            obj.get("owner_role_type"),
+            "state":
+            obj.get("state"),
+            "last_committed_on":
+            obj.get("last_committed_on"),
+            "last_suspended_on":
+            obj.get("last_suspended_on"),
+            "database_name":
+            obj.get("database_name"),
+            "schema_name":
+            obj.get("schema_name"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
+
 from snowflake.core.task._generated.models.task_schedule import TaskSchedule
 
+
 class TaskModel():
+
     def __init__(
         self,
         name: str,
         definition: str,
         # optional properties
         warehouse: Optional[str] = None,
         schedule: Optional[TaskSchedule] = None,
@@ -198,14 +248,15 @@
         owner_role_type: Optional[str] = None,
         state: Optional[str] = None,
         last_committed_on: Optional[datetime] = None,
         last_suspended_on: Optional[datetime] = None,
         database_name: Optional[str] = None,
         schema_name: Optional[str] = None,
     ):
+
         self.name = name
         self.warehouse = warehouse
         self.schedule = schedule
         self.comment = comment
         self.config = config
         self.session_parameters = session_parameters
         self.definition = definition
@@ -221,115 +272,84 @@
         self.owner = owner
         self.owner_role_type = owner_role_type
         self.state = state
         self.last_committed_on = last_committed_on
         self.last_suspended_on = last_suspended_on
         self.database_name = database_name
         self.schema_name = schema_name
-    __properties = ["name", "warehouse", "schedule", "comment", "config", "session_parameters", "definition", "predecessors", "user_task_managed_initial_warehouse_size", "user_task_timeout_ms", "suspend_task_after_num_failures", "condition", "allow_overlapping_execution", "error_integration", "created_on", "id", "owner", "owner_role_type", "state", "last_committed_on", "last_suspended_on", "database_name", "schema_name"]
+
+    __properties = [
+        "name", "warehouse", "schedule", "comment", "config",
+        "session_parameters", "definition", "predecessors",
+        "user_task_managed_initial_warehouse_size", "user_task_timeout_ms",
+        "suspend_task_after_num_failures", "condition",
+        "allow_overlapping_execution", "error_integration", "created_on", "id",
+        "owner", "owner_role_type", "state", "last_committed_on",
+        "last_suspended_on", "database_name", "schema_name"
+    ]
 
     def _to_model(self):
         return Task(
             name=self.name,
-
             warehouse=self.warehouse,
-
-            schedule=self.schedule._to_model() if self.schedule is not None else None,
-
+            schedule=self.schedule._to_model()
+            if self.schedule is not None else None,
             comment=self.comment,
-
             config=self.config,
-
             session_parameters=self.session_parameters,
-
             definition=self.definition,
-
             predecessors=self.predecessors,
-
-            user_task_managed_initial_warehouse_size=self.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=self.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=self.user_task_timeout_ms,
-
-            suspend_task_after_num_failures=self.suspend_task_after_num_failures,
-
+            suspend_task_after_num_failures=self.
+            suspend_task_after_num_failures,
             condition=self.condition,
-
             allow_overlapping_execution=self.allow_overlapping_execution,
-
             error_integration=self.error_integration,
-
             created_on=self.created_on,
-
             id=self.id,
-
             owner=self.owner,
-
             owner_role_type=self.owner_role_type,
-
             state=self.state,
-
             last_committed_on=self.last_committed_on,
-
             last_suspended_on=self.last_suspended_on,
-
             database_name=self.database_name,
-
             schema_name=self.schema_name,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> TaskModel:
         return TaskModel(
             name=model.name,
-
             warehouse=model.warehouse,
-
-            schedule=TaskScheduleModel._from_model(model.schedule) if model.schedule is not None else None,
-
+            schedule=TaskScheduleModel._from_model(model.schedule)
+            if model.schedule is not None else None,
             comment=model.comment,
-
             config=model.config,
-
             session_parameters=model.session_parameters,
-
             definition=model.definition,
-
             predecessors=model.predecessors,
-
-            user_task_managed_initial_warehouse_size=model.user_task_managed_initial_warehouse_size,
-
+            user_task_managed_initial_warehouse_size=model.
+            user_task_managed_initial_warehouse_size,
             user_task_timeout_ms=model.user_task_timeout_ms,
-
-            suspend_task_after_num_failures=model.suspend_task_after_num_failures,
-
+            suspend_task_after_num_failures=model.
+            suspend_task_after_num_failures,
             condition=model.condition,
-
             allow_overlapping_execution=model.allow_overlapping_execution,
-
             error_integration=model.error_integration,
-
             created_on=model.created_on,
-
             id=model.id,
-
             owner=model.owner,
-
             owner_role_type=model.owner_role_type,
-
             state=model.state,
-
             last_committed_on=model.last_committed_on,
-
             last_suspended_on=model.last_suspended_on,
-
             database_name=model.database_name,
-
             schema_name=model.schema_name,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_run.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/task_run.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,58 +1,79 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
 
+    Snowflake Task API
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Optional
 from typing import Union
-from snowflake.core.task._generated.pydantic_compatibility import BaseModel, Field, StrictInt, StrictStr, validator
+
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class TaskRun(BaseModel):
-    root_task_name: StrictStr = Field(...)
-    database_name: StrictStr = Field(...)
-    schema_name: StrictStr = Field(...)
-    state: StrictStr = Field(...)
+
+    root_task_name: StrictStr
+
+    database_name: StrictStr
+
+    schema_name: StrictStr
+
+    state: StrictStr
+
     first_error_task_name: Optional[StrictStr] = None
+
     first_error_code: Optional[StrictInt] = None
+
     first_error_message: Optional[StrictStr] = None
-    scheduled_time: datetime = Field(...)
+
+    scheduled_time: datetime
+
     query_start_time: Optional[datetime] = None
-    next_scheduled_time: datetime = Field(...)
+
+    next_scheduled_time: datetime
+
     completed_time: Optional[datetime] = None
-    root_task_id: StrictStr = Field(...)
-    graph_version: StrictInt = Field(...)
-    run_id: StrictInt = Field(...)
-    __properties = ["root_task_name", "database_name", "schema_name", "state", "first_error_task_name", "first_error_code", "first_error_message", "scheduled_time", "query_start_time", "next_scheduled_time", "completed_time", "root_task_id", "graph_version", "run_id"]
 
+    root_task_id: StrictStr
+
+    graph_version: StrictInt
+
+    run_id: StrictInt
 
-    @validator('state')
+    __properties = [
+        "root_task_name", "database_name", "schema_name", "state",
+        "first_error_task_name", "first_error_code", "first_error_message",
+        "scheduled_time", "query_start_time", "next_scheduled_time",
+        "completed_time", "root_task_id", "graph_version", "run_id"
+    ]
+
+    @field_validator('state')
     def state_validate_enum(cls, v):
-        if v not in ('SCHEDULED', 'EXECUTING', 'SUCCEEDED', 'FAILED', 'CANCELLED', 'SKIPPED'):
-            raise ValueError("must validate the enum values ('SCHEDULED', 'EXECUTING', 'SUCCEEDED', 'FAILED', 'CANCELLED', 'SKIPPED')")
+
+        if v not in ('SCHEDULED', 'EXECUTING', 'SUCCEEDED', 'FAILED',
+                     'CANCELLED', 'SKIPPED'):
+            raise ValueError("must validate the enum values ()")
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -62,79 +83,86 @@
     @classmethod
     def from_json(cls, json_str: str) -> TaskRun:
         """Create an instance of TaskRun from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "root_task_name",
-                            "database_name",
-                            "schema_name",
-                            "state",
-                            "first_error_task_name",
-                            "first_error_code",
-                            "first_error_message",
-                            "scheduled_time",
-                            "query_start_time",
-                            "next_scheduled_time",
-                            "completed_time",
-                            "root_task_id",
-                            "graph_version",
-                            "run_id",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "root_task_name",
+                           "database_name",
+                           "schema_name",
+                           "state",
+                           "first_error_task_name",
+                           "first_error_code",
+                           "first_error_message",
+                           "scheduled_time",
+                           "query_start_time",
+                           "next_scheduled_time",
+                           "completed_time",
+                           "root_task_id",
+                           "graph_version",
+                           "run_id",
+                       },
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> TaskRun:
         """Create an instance of TaskRun from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return TaskRun.parse_obj(obj)
 
         _obj = TaskRun.parse_obj({
-            "root_task_name": obj.get("root_task_name"),
-
-            "database_name": obj.get("database_name"),
-
-            "schema_name": obj.get("schema_name"),
-
-            "state": obj.get("state"),
-
-            "first_error_task_name": obj.get("first_error_task_name"),
-
-            "first_error_code": obj.get("first_error_code"),
-
-            "first_error_message": obj.get("first_error_message"),
-
-            "scheduled_time": obj.get("scheduled_time"),
-
-            "query_start_time": obj.get("query_start_time"),
-
-            "next_scheduled_time": obj.get("next_scheduled_time"),
-
-            "completed_time": obj.get("completed_time"),
-
-            "root_task_id": obj.get("root_task_id"),
-
-            "graph_version": obj.get("graph_version"),
-
-            "run_id": obj.get("run_id"),
-
+            "root_task_name":
+            obj.get("root_task_name"),
+            "database_name":
+            obj.get("database_name"),
+            "schema_name":
+            obj.get("schema_name"),
+            "state":
+            obj.get("state"),
+            "first_error_task_name":
+            obj.get("first_error_task_name"),
+            "first_error_code":
+            obj.get("first_error_code"),
+            "first_error_message":
+            obj.get("first_error_message"),
+            "scheduled_time":
+            obj.get("scheduled_time"),
+            "query_start_time":
+            obj.get("query_start_time"),
+            "next_scheduled_time":
+            obj.get("next_scheduled_time"),
+            "completed_time":
+            obj.get("completed_time"),
+            "root_task_id":
+            obj.get("root_task_id"),
+            "graph_version":
+            obj.get("graph_version"),
+            "run_id":
+            obj.get("run_id"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class TaskRunModel():
+
     def __init__(
         self,
         root_task_name: str,
         database_name: str,
         schema_name: str,
         state: str,
         scheduled_time: datetime,
@@ -145,93 +173,72 @@
         # optional properties
         first_error_task_name: Optional[str] = None,
         first_error_code: Optional[int] = None,
         first_error_message: Optional[str] = None,
         query_start_time: Optional[datetime] = None,
         completed_time: Optional[datetime] = None,
     ):
+
         self.root_task_name = root_task_name
         self.database_name = database_name
         self.schema_name = schema_name
         self.state = state
         self.first_error_task_name = first_error_task_name
         self.first_error_code = first_error_code
         self.first_error_message = first_error_message
         self.scheduled_time = scheduled_time
         self.query_start_time = query_start_time
         self.next_scheduled_time = next_scheduled_time
         self.completed_time = completed_time
         self.root_task_id = root_task_id
         self.graph_version = graph_version
         self.run_id = run_id
-    __properties = ["root_task_name", "database_name", "schema_name", "state", "first_error_task_name", "first_error_code", "first_error_message", "scheduled_time", "query_start_time", "next_scheduled_time", "completed_time", "root_task_id", "graph_version", "run_id"]
+
+    __properties = [
+        "root_task_name", "database_name", "schema_name", "state",
+        "first_error_task_name", "first_error_code", "first_error_message",
+        "scheduled_time", "query_start_time", "next_scheduled_time",
+        "completed_time", "root_task_id", "graph_version", "run_id"
+    ]
 
     def _to_model(self):
         return TaskRun(
             root_task_name=self.root_task_name,
-
             database_name=self.database_name,
-
             schema_name=self.schema_name,
-
             state=self.state,
-
             first_error_task_name=self.first_error_task_name,
-
             first_error_code=self.first_error_code,
-
             first_error_message=self.first_error_message,
-
             scheduled_time=self.scheduled_time,
-
             query_start_time=self.query_start_time,
-
             next_scheduled_time=self.next_scheduled_time,
-
             completed_time=self.completed_time,
-
             root_task_id=self.root_task_id,
-
             graph_version=self.graph_version,
-
             run_id=self.run_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> TaskRunModel:
         return TaskRunModel(
             root_task_name=model.root_task_name,
-
             database_name=model.database_name,
-
             schema_name=model.schema_name,
-
             state=model.state,
-
             first_error_task_name=model.first_error_task_name,
-
             first_error_code=model.first_error_code,
-
             first_error_message=model.first_error_message,
-
             scheduled_time=model.scheduled_time,
-
             query_start_time=model.query_start_time,
-
             next_scheduled_time=model.next_scheduled_time,
-
             completed_time=model.completed_time,
-
             root_task_id=model.root_task_id,
-
             graph_version=model.graph_version,
-
             run_id=model.run_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/task/_generated/models/task_schedule.py` & `snowflake_core-0.8.1/src/snowflake/core/task/_generated/models/task_schedule.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,72 +1,72 @@
 # coding: utf-8
-
 """
-    Snowflake Task API
 
+    Snowflake Task API
     The Snowflake Task API is a REST API that you can use to access, update, and perform certain actions on task resources in a Snowflake database.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
+
 import snowflake.core.task._generated.models
 from snowflake.core.task._generated.models import *
 
-
-from typing import Optional, Union
 from typing import Union
-from snowflake.core.task._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from importlib import import_module
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional, Union
+
 
 class TaskSchedule(BaseModel):
+
     schedule_type: Optional[StrictStr] = None
-    __properties = ["schedule_type"]
 
+    __properties = ["schedule_type"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     # JSON field name that stores the object type
-    __discriminator_property_name = 'schedule_type'
+    __discriminator_property_name: ClassVar[str] = 'schedule_type'
 
     # discriminator mappings
-    __discriminator_value_class_map = {
+    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
         'CRON_TYPE': 'CronSchedule',
         'MINUTES_TYPE': 'MinutesSchedule'
     }
 
     @classmethod
-    def get_discriminator_value(cls, obj: dict) -> str:
+    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
         """Returns the discriminator value (object type) of the data"""
         discriminator_value = obj[cls.__discriminator_property_name]
         if discriminator_value:
             return cls.__discriminator_value_class_map.get(discriminator_value)
         else:
             return None
 
-
-    __discriminator_value_to_type = {
+    __discriminator_value_to_type: ClassVar[Dict[str, str]] = {
         'CronSchedule': 'CRON_TYPE',
         'MinutesSchedule': 'MINUTES_TYPE',
     }
 
     @classmethod
     def get_child_model_discriminator_value(cls, child_model: str) -> str:
         return cls.__discriminator_value_to_type[child_model]
 
-
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
         """Returns the JSON representation of the model using alias"""
         return json.dumps(self.to_dict())
@@ -74,58 +74,65 @@
     @classmethod
     def from_json(cls, json_str: str) -> Union[CronSchedule, MinutesSchedule]:
         """Create an instance of TaskSchedule from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> Union[CronSchedule, MinutesSchedule]:
         """Create an instance of TaskSchedule from a dict"""
+
         # look up the object type based on discriminator mapping
         object_type = cls.get_discriminator_value(obj)
         if object_type:
             klass = getattr(snowflake.core.task._generated.models, object_type)
             return klass.from_dict(obj)
         else:
-            raise ValueError("TaskSchedule failed to lookup discriminator value from " +
-                             json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
-                             ", mapping: " + json.dumps(cls.__discriminator_value_class_map))
+            raise ValueError(
+                "TaskSchedule failed to lookup discriminator value from " +
+                json.dumps(obj) + ". Discriminator property name: " +
+                cls.__discriminator_property_name + ", mapping: " +
+                json.dumps(cls.__discriminator_value_class_map))
 
 
 from typing import Optional, List, Dict
 
+
 class TaskScheduleModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         schedule_type: Optional[str] = None,
     ):
+
         self.schedule_type = schedule_type
+
     __properties = ["schedule_type"]
 
     def _to_model(self):
-        return TaskSchedule(
-            
-        )
+        return TaskSchedule()
 
     @classmethod
     def _from_model(cls, model) -> TaskScheduleModel:
         return model.__class__._model_class._from_model(model)
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
-    def from_dict(cls, obj: dict) -> Union(CronScheduleModel, MinutesScheduleModel):
+    def from_dict(cls,
+                  obj: dict) -> Union[CronScheduleModel, MinutesScheduleModel]:
         """Create an instance of TaskSchedule from a dict"""
         return cls._from_model(TaskSchedule.from_dict(obj))
 
 
 TaskSchedule._model_class = TaskScheduleModel
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_warehouse.py` & `snowflake_core-0.8.1/src/snowflake/core/warehouse/_warehouse.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 from typing import TYPE_CHECKING, Iterator, Optional
 
+from pydantic import StrictStr
+
 from snowflake.core._common import AccountObjectCollectionParent, CreateMode, ObjectReferenceMixin
 from snowflake.core._internal.telemetry import api_telemetry
 from snowflake.core.warehouse._generated.api import WarehouseApi
 from snowflake.core.warehouse._generated.api_client import BridgeApiClient, StoredProcApiClient
 from snowflake.core.warehouse._generated.models.warehouse import WarehouseModel as Warehouse
-from snowflake.core.warehouse._generated.pydantic_compatibility import StrictStr
 
 
 if TYPE_CHECKING:
     from snowflake.core import Root
 
 
 class WarehouseCollection(AccountObjectCollectionParent["WarehouseResource"]):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 # coding: utf-8
 
 # flake8: noqa
-
 """
-    Snowflake Warehouse API
 
+    Snowflake Warehouse API
     The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 __version__ = "1.0.0"
 
 # import apis into sdk package
 from snowflake.core.warehouse._generated.api.warehouse_api import WarehouseApi
-
 # import ApiClient
 from snowflake.core.warehouse._generated.api_client import ApiClient
 from snowflake.core.warehouse._generated.configuration import Configuration
 # import models into sdk package
 from snowflake.core.warehouse._generated.models.error_response import ErrorResponse
 from snowflake.core.warehouse._generated.models.success_response import SuccessResponse
 from snowflake.core.warehouse._generated.models.warehouse import Warehouse
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api_client.py` & `snowflake_core-0.8.1/src/snowflake/core/role/_generated/api_client.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,16 +1,14 @@
 # coding: utf-8
 """
-    Snowflake Warehouse API
-
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
+    Snowflake Role API
+    The Snowflake Role API is a REST API that you can use to access, update, and perform certain action on Roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
 from __future__ import absolute_import
 
 import atexit
@@ -25,18 +23,18 @@
 import re
 import tempfile
 
 from urllib.parse import quote
 
 from functools import partial
 
-from snowflake.core.warehouse._generated.configuration import Configuration
-import snowflake.core.warehouse._generated.models
-from snowflake.core.warehouse._generated import rest
-from snowflake.core.warehouse._generated.paging import PagedIter
+from snowflake.core.role._generated.configuration import Configuration
+import snowflake.core.role._generated.models
+from snowflake.core.role._generated import rest
+from snowflake.core.role._generated.paging import PagedIter
 from snowflake.core.exceptions import _APIValueError, APIError, InvalidResponseError, LongRunningQueryTimeout
 from snowflake.core.version import __version__ as VERSION
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
 
@@ -61,64 +59,67 @@
     :param pool_threads: The number of threads to use for async requests
         to the API. More threads means more concurrent API requests.
     """
 
     PRIMITIVE_TYPES = (float, bool, bytes, str, int)
     NATIVE_TYPES_MAPPING = {
         'int': int,
-        'long': int, # TODO remove as only py3 is supported?
+        'long': int,  # TODO remove as only py3 is supported?
         'float': float,
         'str': str,
         'bool': bool,
         'date': datetime.date,
         'datetime': datetime.datetime,
         'object': object,
     }
-    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0 # default 10 minutes for long running queries
+    DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING = 600.0  # default 10 minutes for long running queries
     _pool = None
 
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
         # use default configuraiton if none is provided
         if configuration is None:
             configuration = Configuration.get_default()
         self.configuration = configuration
-        if (
-            hasattr(root, "_connection")
-            and root._connection is not None
-            and hasattr(root._connection, "_rest")
-            and root._connection._rest is not None
-            and hasattr(root._connection._rest, "_protocol")
-            and hasattr(root._connection._rest, "_host")
-            and hasattr(root._connection._rest, "_port")
-        ):
+        if (hasattr(root, "_connection") and root._connection is not None
+                and hasattr(root._connection, "_rest")
+                and root._connection._rest is not None
+                and hasattr(root._connection._rest, "_protocol")
+                and hasattr(root._connection._rest, "_host")
+                and hasattr(root._connection._rest, "_port")):
             self.configuration.host = (
-                f"{root._connection._rest._protocol}://"
-                + root._connection._rest._host
-                + f":{root._connection._rest._port}"
-            )
+                f"{root._connection._rest._protocol}://" +
+                root._connection._rest._host +
+                f":{root._connection._rest._port}")
         self.pool_threads = pool_threads
 
         self.rest_client = rest.RESTClientObject(root, configuration)
         self.default_headers = {}
         if header_name is not None:
             self.default_headers[header_name] = header_value
         self.cookie = cookie
         # Set default User-Agent.
         self.user_agent = 'python_api/' + VERSION + ''
         self.client_side_validation = configuration.client_side_validation
-        self._enable_long_running_polling = getattr(root, "_enable_long_running_polling", False)
+        self._enable_long_running_polling = getattr(
+            root, "_enable_long_running_polling", False)
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, traceback):
         self.close()
 
     def close(self):
+
         if self._pool:
             self._pool.close()
             self._pool.join()
             self._pool = None
             if hasattr(atexit, 'unregister'):
                 atexit.unregister(self.close)
 
@@ -140,15 +141,14 @@
     @user_agent.setter
     def user_agent(self, value):
         self.default_headers['User-Agent'] = value
 
     def set_default_header(self, header_name, header_value):
         self.default_headers[header_name] = header_value
 
-
     _default = None
 
     @classmethod
     def get_default(cls, root: "Root"):
         """Return new instance of ApiClient.
 
         This method returns newly created, based on default constructor,
@@ -167,59 +167,72 @@
 
         It stores default ApiClient.
 
         :param default: object of ApiClient.
         """
         cls._default = default
 
-    def __call_api(
-            self, root, resource_path, method, path_params=None,
-            query_params=None, header_params=None, body=None, post_params=None,
-            files=None, response_types_map=None, auth_settings=None,
-            _return_http_data_only=None, collection_formats=None,
-            _preload_content=True, _request_timeout=None, _host=None,
-            _request_auth=None):
+    def __call_api(self,
+                   root,
+                   resource_path,
+                   method,
+                   path_params=None,
+                   query_params=None,
+                   header_params=None,
+                   body=None,
+                   post_params=None,
+                   files=None,
+                   response_types_map=None,
+                   auth_settings=None,
+                   _return_http_data_only=None,
+                   collection_formats=None,
+                   _preload_content=True,
+                   _request_timeout=None,
+                   _host=None,
+                   _request_auth=None):
 
         config = self.configuration
 
         # header parameters
         header_params = header_params or {}
         header_params.update(self.default_headers)
         if self.cookie:
             header_params['Cookie'] = self.cookie
         if header_params:
             header_params = self.sanitize_for_serialization(header_params)
-            header_params = dict(self.parameters_to_tuples(header_params,
-                                                           collection_formats))
+            header_params = dict(
+                self.parameters_to_tuples(header_params, collection_formats))
 
         # path parameters
         if path_params:
             path_params = self.sanitize_for_serialization(path_params)
             path_params = self.parameters_to_tuples(path_params,
                                                     collection_formats)
             for k, v in path_params:
                 # specified safe chars, encode everything
                 resource_path = resource_path.replace(
                     '{%s}' % k,
-                    quote(str(v), safe=config.safe_chars_for_path_param)
-                )
+                    quote(str(v), safe=config.safe_chars_for_path_param))
 
         # post parameters
         if post_params or files:
             post_params = post_params if post_params else []
             post_params = self.sanitize_for_serialization(post_params)
             post_params = self.parameters_to_tuples(post_params,
                                                     collection_formats)
             post_params.extend(self.files_parameters(files))
 
         # auth setting
-        self.update_params_for_auth(
-            header_params, query_params, auth_settings,
-            resource_path, method, body,
-            request_auth=_request_auth)
+        self.update_params_for_auth(header_params,
+                                    query_params,
+                                    auth_settings,
+                                    resource_path,
+                                    method,
+                                    body,
+                                    request_auth=_request_auth)
 
         # body
         if body:
             body = self.sanitize_for_serialization(body)
 
         # request url
         if _host is None:
@@ -239,18 +252,18 @@
             # perform request and return response, maybe with retry
             response_data = self.request_with_retry(
                 root,
                 method,
                 url,
                 query_params=query_params,
                 headers=header_params,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
-                _request_timeout=_request_timeout
-            )
+                _request_timeout=_request_timeout)
         except APIError as e:
             if e.body:
                 e.body = e.body.decode('utf-8')
             raise e
 
         self.last_response = response_data
 
@@ -277,15 +290,16 @@
                 # regular, non-large results use case
                 return_data = self.deserialize(response_data, response_type)
             else:
                 # This should be the normal way in which we figure out where to get the results from,
                 # as well as how many chunks there are to get. Due to a bug, we use the alternate logic
                 # (in the "else" clause) to infer the URL from the UUID
                 if "Link" in response_data.getheaders():
-                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(response_data.getheaders()["Link"])
+                    results_path, num_chunks = self.get_path_and_chunk_count_from_header(
+                        response_data.getheaders()["Link"])
                 else:
                     handler_id = large_results_resp['result_handler']
                     results_path = '/api/v2/results/' + handler_id
 
                     # If there is no "Link" header, there is just one chunk
                     num_chunks = 1
 
@@ -298,18 +312,21 @@
                         root,
                         "GET",
                         chunk_url,
                         headers=header_params,
                         _preload_content=True,
                         _request_timeout=_request_timeout)
 
-                    return self.deserialize(chunk_response_data, deserialize_type)
+                    return self.deserialize(chunk_response_data,
+                                            deserialize_type)
 
                 if 'Iterable' in response_type:
-                    return PagedIter(partial(_fetch_next_chunk, deserialize_type=response_type), num_chunks)
+                    return PagedIter(
+                        partial(_fetch_next_chunk,
+                                deserialize_type=response_type), num_chunks)
                 else:
                     # At most, we should only need to fetch one chunk if it's a point lookup,
                     # i.e., one row return
                     return_data = _fetch_next_chunk(0, response_type)
         else:
             return_data = None
 
@@ -334,34 +351,37 @@
         :return: The serialized form of data.
         """
         if obj is None:
             return None
         elif isinstance(obj, self.PRIMITIVE_TYPES):
             return obj
         elif isinstance(obj, list):
-            return [self.sanitize_for_serialization(sub_obj)
-                    for sub_obj in obj]
+            return [
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj
+            ]
         elif isinstance(obj, tuple):
-            return tuple(self.sanitize_for_serialization(sub_obj)
-                         for sub_obj in obj)
+            return tuple(
+                self.sanitize_for_serialization(sub_obj) for sub_obj in obj)
         elif isinstance(obj, (datetime.datetime, datetime.date)):
             return obj.isoformat()
 
         if isinstance(obj, dict):
             obj_dict = obj
         else:
             # Convert model obj to dict except
             # attributes `openapi_types`, `attribute_map`
             # and attributes which value is not None.
             # Convert attribute name to json key in
             # model definition for request.
             obj_dict = obj.to_dict()
 
-        return {key: self.sanitize_for_serialization(val)
-                for key, val in obj_dict.items()}
+        return {
+            key: self.sanitize_for_serialization(val)
+            for key, val in obj_dict.items()
+        }
 
     def deserialize(self, response, response_type):
         """Deserializes response into an object.
 
         :param response: RESTResponse object to be deserialized.
         :param response_type: class literal for
             deserialized object, or string of class name.
@@ -391,46 +411,61 @@
         """
         if data is None:
             return None
 
         if type(klass) == str:
             if klass.startswith('Iterable['):
                 sub_kls = re.match(r'Iterable\[(.*)]', klass).group(1)
-                return [self.__deserialize(sub_data, sub_kls)
-                        for sub_data in data]
+                return [
+                    self.__deserialize(sub_data, sub_kls) for sub_data in data
+                ]
 
             if klass.startswith('Dict['):
                 sub_kls = re.match(r'Dict\[([^,]*), (.*)]', klass).group(2)
-                return {k: self.__deserialize(v, sub_kls)
-                        for k, v in data.items()}
+                return {
+                    k: self.__deserialize(v, sub_kls)
+                    for k, v in data.items()
+                }
 
             # convert str to class
             if klass in self.NATIVE_TYPES_MAPPING:
                 klass = self.NATIVE_TYPES_MAPPING[klass]
             else:
-                klass = getattr(snowflake.core.warehouse._generated.models, klass)
+                klass = getattr(snowflake.core.role._generated.models, klass)
 
         if klass in self.PRIMITIVE_TYPES:
             return self.__deserialize_primitive(data, klass)
         elif klass == object:
             return self.__deserialize_object(data)
         elif klass == datetime.date:
             return self.__deserialize_date(data)
         elif klass == datetime.datetime:
             return self.__deserialize_datetime(data)
         else:
             return self.__deserialize_model(data, klass)
 
-    def call_api(self, root, resource_path, method,
-                 path_params=None, query_params=None, header_params=None,
-                 body=None, post_params=None, files=None,
-                 response_types_map=None, auth_settings=None,
-                 async_req=None, _return_http_data_only=None,
-                 collection_formats=None,_preload_content=True,
-                  _request_timeout=None, _host=None, _request_auth=None):
+    def call_api(self,
+                 root,
+                 resource_path,
+                 method,
+                 path_params=None,
+                 query_params=None,
+                 header_params=None,
+                 body=None,
+                 post_params=None,
+                 files=None,
+                 response_types_map=None,
+                 auth_settings=None,
+                 async_req=None,
+                 _return_http_data_only=None,
+                 collection_formats=None,
+                 _preload_content=True,
+                 _request_timeout=None,
+                 _host=None,
+                 _request_auth=None):
         """Makes the HTTP request (synchronous) and returns deserialized data.
 
         To make an async_req request, set the async_req parameter.
 
         :param resource_path: Path to method endpoint.
         :param method: Method to call.
         :param path_params: Path parameters in the url.
@@ -484,96 +519,108 @@
                 collection_formats,
                 _preload_content,
                 _request_timeout,
                 _host,
                 _request_auth,
             )
 
-        return self.pool.apply_async(
-            self.__call_api,
-            (
-                root,
-                resource_path,
-                method,
-                path_params,
-                query_params,
-                header_params,
-                body,
-                post_params,
-                files,
-                response_types_map,
-                auth_settings,
-                _return_http_data_only,
-                collection_formats,
-                _preload_content,
-                _request_timeout,
-                _host,
-                _request_auth,
-            )
-        )
-
-
-    def request_with_retry(
-                self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
-                _request_timeout=None):
+        return self.pool.apply_async(self.__call_api, (
+            root,
+            resource_path,
+            method,
+            path_params,
+            query_params,
+            header_params,
+            body,
+            post_params,
+            files,
+            response_types_map,
+            auth_settings,
+            _return_http_data_only,
+            collection_formats,
+            _preload_content,
+            _request_timeout,
+            _host,
+            _request_auth,
+        ))
+
+    def request_with_retry(self,
+                           root,
+                           method,
+                           url,
+                           query_params=None,
+                           headers=None,
+                           post_params=None,
+                           body=None,
+                           _preload_content=True,
+                           _request_timeout=None):
         """
             Response time by default one hour
         """
         enter_timing = time.time()
-        response_data = self.request(
-                root,
-                method,
-                url,
-                query_params=query_params,
-                headers=headers,
-                post_params=post_params, body=body,
-                _preload_content=_preload_content,
-                _request_timeout=_request_timeout)
+        response_data = self.request(root,
+                                     method,
+                                     url,
+                                     query_params=query_params,
+                                     headers=headers,
+                                     post_params=post_params,
+                                     body=body,
+                                     _preload_content=_preload_content,
+                                     _request_timeout=_request_timeout)
 
         if response_data.status != 202 or not self._enable_long_running_polling:
             return response_data
 
         result_endpoint = response_data.getheader('Location')
         if result_endpoint is None:
-            raise InvalidResponseError("Long Running Queries result endpoint is missing")
+            raise InvalidResponseError(
+                "Long Running Queries result endpoint is missing")
 
         if _request_timeout is None:
             _request_timeout = self.DEFAULT_TIMEOUT_SECONDS_LONG_RUNNING
         wait_for_results_timeout = enter_timing + _request_timeout
 
-        exponential_wait_time = 1 # wait time increases exponentially, 30% more everytime
+        exponential_wait_time = 1  # wait time increases exponentially, 30% more everytime
         while True:
             time_remaining = wait_for_results_timeout - time.time()
             if time_remaining <= 0:
                 break
             wait_time = min(exponential_wait_time, time_remaining)
+
             time.sleep(wait_time)
+
             response_data = self.request(
                 root,
                 'GET',
                 self.configuration.host + result_endpoint,
                 query_params=query_params,
                 headers=headers,
-                post_params=post_params, body=body,
+                post_params=post_params,
+                body=body,
                 _preload_content=_preload_content,
                 _request_timeout=max(time_remaining - wait_time, 1)
                 # request_timeout can never be zero
             )
 
             if response_data.status != 202:
                 return response_data
 
             exponential_wait_time *= 1.3
 
         raise LongRunningQueryTimeout("Long running queries timeout")
 
-
-    def request(self, root, method, url, query_params=None, headers=None,
-                post_params=None, body=None, _preload_content=True,
+    def request(self,
+                root,
+                method,
+                url,
+                query_params=None,
+                headers=None,
+                post_params=None,
+                body=None,
+                _preload_content=True,
                 _request_timeout=None):
         """Makes the HTTP request using RESTClient."""
         if method == "GET":
             return self.rest_client.get_request(
                 root,
                 url,
                 query_params=query_params,
@@ -623,16 +670,17 @@
                     body=body,
                 )
             except APIError as error:
                 # Raise a more helpful user error if CoA is not supported for this resource;
                 # this is represented as either 405 or 501 on the server.
                 if error.status in (405, 501):
                     raise NotImplementedError(
-                        'create_or_update is not yet supported for warehouse. Updating warehouse '
-                        'objects is not supported yet; use create() for creating a warehouse.')
+                        'create_or_update is not yet supported for role. Updating role '
+                        'objects is not supported yet; use create() for creating a role.'
+                    )
                 raise
 
         elif method == "PATCH":
             return self.rest_client.patch_request(
                 root,
                 url,
                 query_params=query_params,
@@ -651,28 +699,28 @@
                 _preload_content=_preload_content,
                 _request_timeout=_request_timeout,
                 body=body,
             )
         else:
             raise _APIValueError(
                 "http method must be `GET`, `HEAD`, `OPTIONS`,"
-                " `POST`, `PATCH`, `PUT` or `DELETE`."
-            )
+                " `POST`, `PATCH`, `PUT` or `DELETE`.")
 
     def parameters_to_tuples(self, params, collection_formats):
         """Get parameters as list of tuples, formatting collections.
 
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: Parameters as list of tuples, collections formatted
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if k in collection_formats:
                 collection_format = collection_formats[k]
                 if collection_format == 'multi':
                     new_params.extend((k, value) for value in v)
                 else:
                     if collection_format == 'ssv':
                         delimiter = ' '
@@ -694,15 +742,16 @@
         :param params: Parameters as dict or list of two-tuples
         :param dict collection_formats: Parameter collection formats
         :return: URL query string (e.g. a=Hello%20World&b=123)
         """
         new_params = []
         if collection_formats is None:
             collection_formats = {}
-        for k, v in params.items() if isinstance(params, dict) else params:  # noqa: E501
+        for k, v in params.items() if isinstance(
+                params, dict) else params:  # noqa: E501
             if isinstance(v, (int, float)):
                 v = str(v)
             if isinstance(v, bool):
                 v = str(v).lower()
 
             if k in collection_formats:
                 collection_format = collection_formats[k]
@@ -737,16 +786,16 @@
                 if not v:
                     continue
                 file_names = v if type(v) is list else [v]
                 for n in file_names:
                     with open(n, 'rb') as f:
                         filename = os.path.basename(f.name)
                         filedata = f.read()
-                        mimetype = (mimetypes.guess_type(filename)[0] or
-                                    'application/octet-stream')
+                        mimetype = (mimetypes.guess_type(filename)[0]
+                                    or 'application/octet-stream')
                         params.append(
                             tuple([k, tuple([filename, filedata, mimetype])]))
 
         return params
 
     def select_header_accept(self, accepts):
         """Returns `Accept` based on an array of accepts provided.
@@ -774,16 +823,21 @@
 
         for content_type in content_types:
             if re.search('json', content_type, re.IGNORECASE):
                 return content_type
 
         return content_types[0]
 
-    def update_params_for_auth(self, headers, queries, auth_settings,
-                               resource_path, method, body,
+    def update_params_for_auth(self,
+                               headers,
+                               queries,
+                               auth_settings,
+                               resource_path,
+                               method,
+                               body,
                                request_auth=None):
         """Updates header and query params based on authentication setting.
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :param auth_settings: Authentication setting identifiers list.
         :resource_path: A string representation of the HTTP request resource path.
@@ -793,28 +847,25 @@
         :param request_auth: if set, the provided settings will
                              override the token in the configuration.
         """
         if not auth_settings:
             return
 
         if request_auth:
-            self._apply_auth_params(headers, queries,
-                                    resource_path, method, body,
-                                    request_auth)
+            self._apply_auth_params(headers, queries, resource_path, method,
+                                    body, request_auth)
             return
 
         for auth in auth_settings:
             auth_setting = self.configuration.auth_settings().get(auth)
             if auth_setting:
-                self._apply_auth_params(headers, queries,
-                                        resource_path, method, body,
-                                        auth_setting)
+                self._apply_auth_params(headers, queries, resource_path,
+                                        method, body, auth_setting)
 
-    def _apply_auth_params(self, headers, queries,
-                           resource_path, method, body,
+    def _apply_auth_params(self, headers, queries, resource_path, method, body,
                            auth_setting):
         """Updates the request parameters based on a single auth_setting
 
         :param headers: Header parameters dict to be updated.
         :param queries: Query parameters tuple list to be updated.
         :resource_path: A string representation of the HTTP request resource path.
         :method: A string representation of the HTTP request method.
@@ -823,20 +874,20 @@
         :param auth_setting: auth settings for the endpoint
         """
         if auth_setting['in'] == 'cookie':
             headers['Cookie'] = auth_setting['value']
         elif auth_setting['in'] == 'header':
             if auth_setting['type'] != 'http-signature':
                 headers[auth_setting['key']] = auth_setting['value']
+
         elif auth_setting['in'] == 'query':
             queries.append((auth_setting['key'], auth_setting['value']))
         else:
             raise _APIValueError(
-                'Authentication token must be in `query` or `header`'
-            )
+                'Authentication token must be in `query` or `header`')
 
     def __deserialize_file(self, response):
         """Deserializes body to file
 
         Saves response body into a file in a temporary folder,
         using the filename from the `Content-Disposition` header if provided.
 
@@ -889,16 +940,15 @@
         try:
             return parse(string).date()
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
-                reason="Failed to parse `{0}` as date object".format(string)
-            )
+                reason="Failed to parse `{0}` as date object".format(string))
 
     def __deserialize_datetime(self, string):
         """Deserializes string to datetime.
 
         The string should be in iso8601 datetime format.
 
         :param string: str.
@@ -908,18 +958,15 @@
             return parse(string)
         except ImportError:
             return string
         except ValueError:
             raise rest.APIError(
                 status=0,
                 reason=(
-                    "Failed to parse `{0}` as datetime object"
-                    .format(string)
-                )
-            )
+                    "Failed to parse `{0}` as datetime object".format(string)))
 
     def __deserialize_model(self, data, klass):
         """Deserializes list or dict to model.
 
         :param data: dict, list.
         :param klass: class literal.
         :return: model object.
@@ -927,26 +974,25 @@
 
         return klass.from_dict(data)
 
     @staticmethod
     def large_results(response):
         try:
             result = json.loads(response.data)
-            if ("result_handler" in result
-                    and "message" in result and
-                    'Large result set. Use provided Link' in result['message']):
+            if ("result_handler" in result and "message" in result
+                    and 'Large result set. Use provided Link'
+                    in result['message']):
                 return result
             else:
                 return None
         except ValueError:
             pass
 
         return None
 
-
     @staticmethod
     def get_path_and_chunk_count_from_header(links_str):
         links_list = links_str.split(",")
 
         def parse_links(s):
             import re
             # Use regex to extract necessary parts
@@ -963,33 +1009,51 @@
             # 3. rel="([^"]*)" matches 'rel="'
             pattern = r'<(.*?)\?page=(\d+)>; rel="([^"]*)"'
 
             # Search using the regular expression
             match = re.search(pattern, s)
             if match:
                 parse_result = dict()
-                parse_result['url'], parse_result['page_number'], parse_result['rel_value'] = match.groups()
+                parse_result['url'], parse_result['page_number'], parse_result[
+                    'rel_value'] = match.groups()
                 return parse_result
 
             return None
 
         parsed_links = [parse_links(link) for link in links_list]
 
         # Find the last one
-        last_link = list(filter(lambda link: link['rel_value'].lower() == 'last', parsed_links)).pop()
+        last_link = list(
+            filter(lambda link: link['rel_value'].lower() == 'last',
+                   parsed_links)).pop()
 
         # Return the URL; the number of chunks is the chunk index of the last page plus one
         return last_link['url'], int(last_link['page_number']) + 1
 
 
 class BridgeApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1, snowflake_connection=None):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1,
+                 snowflake_connection=None):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.BridgeClientObject(snowflake_connection)
 
 
 class StoredProcApiClient(ApiClient):
-    def __init__(self, root: "Root", configuration=None, header_name=None, header_value=None,
-                 cookie=None, pool_threads=1):
-        ApiClient.__init__(self, root, configuration, header_name, header_value, cookie, pool_threads)
+
+    def __init__(self,
+                 root: "Root",
+                 configuration=None,
+                 header_name=None,
+                 header_value=None,
+                 cookie=None,
+                 pool_threads=1):
+        ApiClient.__init__(self, root, configuration, header_name,
+                           header_value, cookie, pool_threads)
         self.rest_client = rest.StoredProcClientObject()
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api_response.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/api_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 """API response object."""
 
 from __future__ import annotations
 from typing import Any, Dict, Optional
-from snowflake.core.warehouse._generated.pydantic_compatibility import Field, StrictInt, StrictStr
+from pydantic import Field, StrictInt, StrictStr
+
 
 class ApiResponse:
     """
     API response object
     """
 
-    status_code: Optional[StrictInt] = Field(None, description="HTTP status code")
-    headers: Optional[Dict[StrictStr, StrictStr]] = Field(None, description="HTTP headers")
-    data: Optional[Any] = Field(None, description="Deserialized data given the data type")
-    raw_data: Optional[Any] = Field(None, description="Raw data (HTTP response body)")
+    status_code: Optional[StrictInt] = Field(None,
+                                             description="HTTP status code")
+    headers: Optional[Dict[StrictStr,
+                           StrictStr]] = Field(None,
+                                               description="HTTP headers")
+    data: Optional[Any] = Field(
+        None, description="Deserialized data given the data type")
+    raw_data: Optional[Any] = Field(
+        None, description="Raw data (HTTP response body)")
 
     def __init__(self,
                  status_code=None,
                  headers=None,
                  data=None,
                  raw_data=None) -> None:
         self.status_code = status_code
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/configuration.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,40 +1,37 @@
 # coding: utf-8
-
 """
-    Snowflake Warehouse API
-
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
+    Snowflake Session API
+    The Snowflake Session API is a REST API that you can use to query your current session properties.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import copy
 import logging
+
 import multiprocessing
+
 import sys
 import urllib3
 
 import http.client as httplib
 from snowflake.core.exceptions import _APIValueError
 
-
 JSON_SCHEMA_VALIDATION_KEYWORDS = {
-    'multipleOf', 'maximum', 'exclusiveMaximum',
-    'minimum', 'exclusiveMinimum', 'maxLength',
-    'minLength', 'pattern', 'maxItems', 'minItems'
+    'multipleOf', 'maximum', 'exclusiveMaximum', 'minimum', 'exclusiveMinimum',
+    'maxLength', 'minLength', 'pattern', 'maxItems', 'minItems'
 }
 
+
 class Configuration(object):
     """NOTE: This class is auto generated by OpenAPI Generator
 
     Ref: https://openapi-generator.tech
     Do not edit the class manually.
 
     :param host: Base url.
@@ -44,38 +41,46 @@
       The dict value is the API key secret.
     :param api_key_prefix: Dict to store API prefix (e.g. Bearer).
       The dict key is the name of the security scheme in the OAS specification.
       The dict value is an API key prefix when generating the auth data.
     :param username: Username for HTTP basic authentication.
     :param password: Password for HTTP basic authentication.
     :param access_token: Access token.
+
     :param server_index: Index to servers configuration.
     :param server_variables: Mapping with string values to replace variables in
       templated server configuration. The validation of enums is performed for
       variables with defined enum values before.
     :param server_operation_index: Mapping from operation ID to an index to server
       configuration.
     :param server_operation_variables: Mapping from operation ID to a mapping with
       string values to replace variables in templated server configuration.
       The validation of enums is performed for variables with defined enum values before.
     :param ssl_ca_cert: str - the path to a file of concatenated CA certificates
       in PEM format.
 
+
     """
 
     _default = None
 
-    def __init__(self, host=None,
-                 api_key=None, api_key_prefix=None,
-                 username=None, password=None,
-                 access_token=None,
-                 server_index=None, server_variables=None,
-                 server_operation_index=None, server_operation_variables=None,
-                 ssl_ca_cert=None,
-                 ):
+    def __init__(
+        self,
+        host=None,
+        api_key=None,
+        api_key_prefix=None,
+        username=None,
+        password=None,
+        access_token=None,
+        server_index=None,
+        server_variables=None,
+        server_operation_index=None,
+        server_operation_variables=None,
+        ssl_ca_cert=None,
+    ):
         """Constructor
         """
         self._base_path = "https://org-account.snowflakecomputing.com" if host is None else host
         """Default Base url
         """
         self.server_index = 0 if server_index is None and host is None else server_index
         self.server_operation_index = server_operation_index or {}
@@ -107,18 +112,20 @@
         """
         self.password = password
         """Password for HTTP basic authentication
         """
         self.access_token = access_token
         """Access token
         """
+
         self.logger = {}
         """Logging Settings
         """
-        self.logger["package_logger"] = logging.getLogger("snowflake.core.warehouse._generated")
+        self.logger["package_logger"] = logging.getLogger(
+            "snowflake.core.session._generated")
         self.logger["urllib3_logger"] = logging.getLogger("urllib3")
         self.logger_format = '%(asctime)s %(levelname)s %(message)s'
         """Log format
         """
         self.logger_stream_handler = None
         """Log stream handler
         """
@@ -284,15 +291,17 @@
 
         :param identifier: The identifier of apiKey.
         :param alias: The alternative identifier of apiKey.
         :return: The token for api key authentication.
         """
         if self.refresh_api_key_hook is not None:
             self.refresh_api_key_hook(self)
-        key = self.api_key.get(identifier, self.api_key.get(alias) if alias is not None else None)
+        key = self.api_key.get(
+            identifier,
+            self.api_key.get(alias) if alias is not None else None)
         if key:
             prefix = self.api_key_prefix.get(identifier)
             if prefix:
                 return "%s %s" % (prefix, key)
             else:
                 return key
 
@@ -303,24 +312,24 @@
         """
         username = ""
         if self.username is not None:
             username = self.username
         password = ""
         if self.password is not None:
             password = self.password
-        return urllib3.util.make_headers(
-            basic_auth=username + ':' + password
-        ).get('authorization')
+        return urllib3.util.make_headers(basic_auth=username + ':' +
+                                         password).get('authorization')
 
     def auth_settings(self):
         """Gets Auth Settings dict for api client.
 
         :return: The Auth Settings information dict.
         """
         auth = {}
+
         return auth
 
     def to_debug_report(self):
         """Gets the essential information for debugging.
 
         :return: The report for debugging.
         """
@@ -332,20 +341,20 @@
                format(env=sys.platform, pyversion=sys.version)
 
     def get_host_settings(self):
         """Gets an array of host settings
 
         :return: An array of host settings
         """
-        return [
-            {
-                'url': "https://org-account.snowflakecomputing.com",
-                'description': "Snowflake Warehouse API",
-            }
-        ]
+        return [{
+            'url':
+            "https://org-account.snowflakecomputing.com",
+            'description':
+            "Snowflake Session API. Always refers to user's current, ongoing session.",
+        }]
 
     def get_host_from_settings(self, index, variables=None, servers=None):
         """Gets host URL based on the index and variables
         :param index: array index of the host settings
         :param variables: hash of variable and the corresponding value
         :param servers: an array of host settings or None
         :return: URL based on host settings
@@ -363,32 +372,33 @@
                 "Invalid index {0} when selecting the host settings. "
                 "Must be less than {1}".format(index, len(servers)))
 
         url = server['url']
 
         # go through variables and replace placeholders
         for variable_name, variable in server.get('variables', {}).items():
-            used_value = variables.get(
-                variable_name, variable['default_value'])
+            used_value = variables.get(variable_name,
+                                       variable['default_value'])
 
             if 'enum_values' in variable \
                     and used_value not in variable['enum_values']:
                 raise ValueError(
                     "The variable `{0}` in the host URL has invalid value "
-                    "{1}. Must be {2}.".format(
-                        variable_name, variables[variable_name],
-                        variable['enum_values']))
+                    "{1}. Must be {2}.".format(variable_name,
+                                               variables[variable_name],
+                                               variable['enum_values']))
 
             url = url.replace("{" + variable_name + "}", used_value)
 
         return url
 
     @property
     def host(self):
         """Return generated host."""
-        return self.get_host_from_settings(self.server_index, variables=self.server_variables)
+        return self.get_host_from_settings(self.server_index,
+                                           variables=self.server_variables)
 
     @host.setter
     def host(self, value):
         """Fix base path."""
         self._base_path = value
         self.server_index = None
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/paging.py` & `snowflake_core-0.8.1/src/snowflake/core/session/_generated/paging.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 from typing import Callable, Generic, Iterable, Iterator, Optional, TypeVar, Union, overload
 from functools import partial
 from public import public
 
 T = TypeVar("T")
 S = TypeVar("S")
 
+
 @public
 class PagedIter(Iterable[T], Generic[T]):
     """A page-by-page iterator.
 
     Data fetched from the server is iterated over page by page, yielding items one by
     one.
 
@@ -35,17 +36,17 @@
         ...
 
     @overload
     def __init__(self, data: Iterable[S], map_: Callable[[S], T]) -> None:
         ...
 
     def __init__(
-            self,
-            page_fetch_closure_,
-            number_of_chunks_=1,
+        self,
+        page_fetch_closure_,
+        number_of_chunks_=1,
     ) -> None:
         self._page_fetch_closure = page_fetch_closure_
         self._number_of_chunks = number_of_chunks_
         self._iter = iter(self)
 
     def __iter__(self) -> Iterator[T]:
         for chunk in range(self._number_of_chunks):
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/rest.py` & `snowflake_core-0.8.1/src/snowflake/core/function/_generated/rest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,41 +1,31 @@
 # coding: utf-8
-
 """
-    Snowflake Warehouse API
-
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
+    Snowflake Function API
+    The Snowflake Function API is a REST API that allows caller to create, execute and drop functions in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import json
 import logging
 import re
 import typing
 import urllib3
 
-
 from snowflake.core._http_requests import create_connection_pool
-from snowflake.core.exceptions import (
-    APIError,
-    UnauthorizedError,
-    ForbiddenError,
-    NotFoundError,
-    ConflictError,
-    ServerError,
-    _APIValueError
-)
+from snowflake.core.exceptions import (APIError, UnauthorizedError,
+                                       ForbiddenError, NotFoundError,
+                                       ConflictError, ServerError,
+                                       _APIValueError)
 from snowflake.connector import SnowflakeConnection
 from snowflake.core._internal.bridge.snow_bridge import SnowBridge
 from snowflake.core.rest import RESTResponse
 
 if typing.TYPE_CHECKING:
     from snowflake.core._root import Root
 
@@ -82,83 +72,89 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
 
         if post_params and body:
             raise _APIValueError(
-                "body parameter cannot be used with post_params parameter."
-            )
+                "body parameter cannot be used with post_params parameter.")
 
         post_params = post_params or {}
         headers = headers or {}
         # url already contains the URL query string
         # so reset query_params to empty dict
         query_params = {}
 
         timeout = None
         if _request_timeout:
-            if isinstance(_request_timeout, (int,float)):  # noqa: E501,F821
+            if isinstance(_request_timeout, (int, float)):  # noqa: E501,F821
                 timeout = urllib3.Timeout(total=_request_timeout)
-            elif (isinstance(_request_timeout, tuple) and
-                  len(_request_timeout) == 2):
-                timeout = urllib3.Timeout(
-                    connect=_request_timeout[0], read=_request_timeout[1])
+            elif (isinstance(_request_timeout, tuple)
+                  and len(_request_timeout) == 2):
+                timeout = urllib3.Timeout(connect=_request_timeout[0],
+                                          read=_request_timeout[1])
 
         try:
             # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
             if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
 
                 # no content type provided or payload is json
-                if not headers.get('Content-Type') or re.search('json', headers['Content-Type'], re.IGNORECASE):
+                if not headers.get('Content-Type') or re.search(
+                        'json', headers['Content-Type'], re.IGNORECASE):
                     request_body = None
                     if body is not None:
                         request_body = json.dumps(body)
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
-                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
+                elif headers[
+                        'Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=False,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 elif headers['Content-Type'] == 'multipart/form-data':
                     # must del headers['Content-Type'], or the correct
                     # Content-Type which generated by urllib3 will be
                     # overwritten.
                     del headers['Content-Type']
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         fields=post_params,
                         encode_multipart=True,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 # Pass a `string` parameter directly in the body to support
                 # other content types than Json when `body` argument is
                 # provided in serialized form
                 elif isinstance(body, str) or isinstance(body, bytes):
                     request_body = body
                     r = self.pool_manager.request(
                         root,
-                        method, url,
+                        method,
+                        url,
                         body=request_body,
                         preload_content=_preload_content,
                         timeout=timeout,
                         headers=headers)
                 else:
                     # Cannot generate the request from given parameters
                     msg = """Cannot prepare a request message for provided
@@ -240,71 +236,105 @@
             url,
             headers=headers,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             query_params=query_params,
         )
 
-    def options_request(self, root, url, headers=None, query_params=None, post_params=None,
-                body=None, _preload_content=True, _request_timeout=None):
+    def options_request(self,
+                        root,
+                        url,
+                        headers=None,
+                        query_params=None,
+                        post_params=None,
+                        body=None,
+                        _preload_content=True,
+                        _request_timeout=None):
         return self.request(
             root,
             "OPTIONS",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def delete_request(self, root, url, headers=None, query_params=None, body=None,
-               _preload_content=True, _request_timeout=None):
+    def delete_request(self,
+                       root,
+                       url,
+                       headers=None,
+                       query_params=None,
+                       body=None,
+                       _preload_content=True,
+                       _request_timeout=None):
         return self.request(
             root,
             "DELETE",
             url,
             headers=headers,
             query_params=query_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def post_request(self, root, url, headers=None, query_params=None, post_params=None,
-             body=None, _preload_content=True, _request_timeout=None):
+    def post_request(self,
+                     root,
+                     url,
+                     headers=None,
+                     query_params=None,
+                     post_params=None,
+                     body=None,
+                     _preload_content=True,
+                     _request_timeout=None):
         return self.request(
             root,
             "POST",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def put_request(self, root, url, headers=None, query_params=None, post_params=None,
-            body=None, _preload_content=True, _request_timeout=None):
+    def put_request(self,
+                    root,
+                    url,
+                    headers=None,
+                    query_params=None,
+                    post_params=None,
+                    body=None,
+                    _preload_content=True,
+                    _request_timeout=None):
         return self.request(
             root,
             "PUT",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
             _preload_content=_preload_content,
             _request_timeout=_request_timeout,
             body=body,
         )
 
-    def patch_request(self, root, url, headers=None, query_params=None, post_params=None,
-              body=None, _preload_content=True, _request_timeout=None):
+    def patch_request(self,
+                      root,
+                      url,
+                      headers=None,
+                      query_params=None,
+                      post_params=None,
+                      body=None,
+                      _preload_content=True,
+                      _request_timeout=None):
         return self.request(
             root,
             "PATCH",
             url,
             headers=headers,
             query_params=query_params,
             post_params=post_params,
@@ -346,18 +376,20 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         r = self.bridge.request(method, url, query_params, headers, body,
-                                   post_params, _preload_content, _request_timeout)
+                                post_params, _preload_content,
+                                _request_timeout)
 
         if _preload_content:
             r = RESTResponse(r)
 
             # log response body
             logger.debug("response body: %s", r.data)
 
@@ -561,25 +593,28 @@
                                  data. Default is True.
         :param _request_timeout: timeout setting for this request. If one
                                  number provided, it will be total request
                                  timeout. It can also be a pair (tuple) of
                                  (connection, read) timeouts.
         """
         method = method.upper()
-        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
-                          'PATCH', 'OPTIONS']
+        assert method in [
+            'GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS'
+        ]
         import _snowflake
         parsed_url = urllib3.util.parse_url(url)
-        response_dict = _snowflake.send_snow_api_request(method, parsed_url.path, dict(query_params), headers, body,
-                                                         post_params, _request_timeout)
+        response_dict = _snowflake.send_snow_api_request(
+            method, parsed_url.path, dict(query_params), headers, body,
+            post_params, _request_timeout)
         json_content = json.loads(response_dict["content"])
         if "data" in json_content:
             r = urllib3.HTTPResponse(body=json.dumps(json_content["data"]))
         else:
-            r = urllib3.HTTPResponse(body=json.dumps(json_content).encode("utf-8"))
+            r = urllib3.HTTPResponse(
+                body=json.dumps(json_content).encode("utf-8"))
         r.status = response_dict["status"]
         if _preload_content:
             r = RESTResponse(r)
             # log response body
             logger.debug("response body: %s", r.data)
 
         if not 200 <= r.status <= 299:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/api/warehouse_api.py` & `snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/api/warehouse_api.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,46 +1,40 @@
 # coding: utf-8
-
 """
-    Snowflake Warehouse API
 
+    Snowflake Warehouse API
     The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 import logging
-
-from typing_extensions import Annotated
-from pydantic import Field, StrictBool, StrictStr, constr, validator
-
+from pydantic import Field, StrictBool, StrictStr, field_validator
 from typing import List, Optional
-
+from typing_extensions import Annotated
 from snowflake.core.warehouse._generated.models.success_response import SuccessResponse
 from snowflake.core.warehouse._generated.models.warehouse import Warehouse
 from typing import Iterable
 
+from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
+from typing import Any, Dict, List, Optional, Tuple, Union
+from typing_extensions import Annotated
 
-from snowflake.core.warehouse._generated.pydantic_compatibility import StrictBool, StrictInt, StrictStr, constr, validate_arguments, ValidationError, validator
 from snowflake.core._internal.snowapi_parameters import SnowApiParameters
 from snowflake.core._internal.utils import ApiClientType, is_running_inside_stored_procedure
 
 from snowflake.core.exceptions import (  # noqa: F401
-    _APITypeError,
-    _APIValueError
-)
+    _APITypeError, _APIValueError)
+
+logger = logging.getLogger(__name__)
 
-logger  = logging.getLogger(__name__)
 
 class WarehouseApi(object):
     """NOTE: This class is auto generated by OpenAPI Generator
     Ref: https://openapi-generator.tech
 
     Do not edit the class manually.
     """
@@ -71,15 +65,16 @@
                 return ApiClient.get_default(self._root), ApiClientType.REST
 
         use_bridge_override = False
 
         # We can force use of the bridge if the server dictates it so
         # But, don't check it for non-resources; _resource_class is not set for non-resources.
         if self._resource_class is not None:
-            use_bridge_override = self._root.effective_parameters(refresh = False).resource_should_use_client_bridge('warehouse')
+            use_bridge_override = self._root.effective_parameters(
+                refresh=False).resource_should_use_client_bridge('warehouse')
 
         # if the _resource_class is None (such as Session, which is not a resource), then it is implied
         # that we use REST (or the stored_proc client)
         if self._resource_class is None:
             chosen_client, new_chosen_client = _get_rest_client()
         elif use_bridge_override:
             # Bridge override is in effect. Use the client bridge.
@@ -91,29 +86,36 @@
         # If all else fails, use the BRIDGE (if there is no REST support for this resource)
         else:
             chosen_client = self._bridge_client
             new_chosen_client = ApiClientType.BRIDGE
 
         if new_chosen_client != self._chosen_client_type:
             self._chosen_client_type = new_chosen_client
-            logger.info("Going to use client-%s for this resource", new_chosen_client.name)
+            logger.info("Going to use client-%s for this resource",
+                        new_chosen_client.name)
         return chosen_client
 
-    @validate_arguments
-    def create_or_alter_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def create_or_alter_warehouse(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                  warehouse: Warehouse,
+                                  **kwargs) -> SuccessResponse:  # noqa: E501
         """Create a (or alter an existing) warehouse.  # noqa: E501
 
+
         Create a (or alter an existing) warehouse. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_or_alter_warehouse(name, warehouse, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param warehouse: (required)
         :type warehouse: Warehouse
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
@@ -125,28 +127,35 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_or_alter_warehouse_with_http_info(name, warehouse, **kwargs)  # noqa: E501
+        return self.create_or_alter_warehouse_with_http_info(
+            name, warehouse, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def create_or_alter_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, **kwargs):  # noqa: E501
+    @validate_call
+    def create_or_alter_warehouse_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                                 warehouse: Warehouse,
+                                                 **kwargs):  # noqa: E501
         """Create a (or alter an existing) warehouse.  # noqa: E501
 
+
         Create a (or alter an existing) warehouse. Even if the operation is just an alter, the full property set must be provided.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_or_alter_warehouse_with_http_info(name, warehouse, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param warehouse: (required)
         :type warehouse: Warehouse
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
@@ -168,44 +177,34 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'warehouse'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'warehouse']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_or_alter_warehouse" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_or_alter_warehouse" %
+                                    _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -213,27 +212,28 @@
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['warehouse']:
             _body_params = _params['warehouse']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -247,44 +247,57 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}', 'PUT',
+            '/api/v2/warehouses/{name}',
+            'PUT',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def create_warehouses(self, warehouse : Warehouse, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def create_warehouses(
+            self,
+            warehouse: Warehouse,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """Create or replace warehouse  # noqa: E501
 
+
         Create a virtual warehouse. Equivalent to CREATE WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_warehouses(warehouse, create_mode, async_req=True)
         >>> result = thread.get()
-
         :param warehouse: (required)
         :type warehouse: Warehouse
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -294,30 +307,42 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.create_warehouses_with_http_info(warehouse, create_mode, **kwargs)  # noqa: E501
+        return self.create_warehouses_with_http_info(warehouse, create_mode,
+                                                     **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def create_warehouses_with_http_info(self, warehouse : Warehouse, create_mode : Annotated[Optional[StrictStr], Field(description="A query parameter allowing support for different modes of resource creation.")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def create_warehouses_with_http_info(
+            self,
+            warehouse: Warehouse,
+            create_mode:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource."
+            )] = None,
+            **kwargs):  # noqa: E501
         """Create or replace warehouse  # noqa: E501
 
+
         Create a virtual warehouse. Equivalent to CREATE WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.create_warehouses_with_http_info(warehouse, create_mode, async_req=True)
         >>> result = thread.get()
-
         :param warehouse: (required)
         :type warehouse: Warehouse
-        :param create_mode: A query parameter allowing support for different modes of resource creation.
+        :param create_mode: Query parameter allowing support for different modes of resource creation. Possible values include: - `errorIfExists`: Throws an error if you try to create a resource that already exists. - `orReplace`: Automatically replaces the existing resource with the current one. - `ifNotExists`: Creates a new resource when an alter is requested for a non-existent resource.
         :type create_mode: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -337,72 +362,62 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'warehouse',
-            'create_mode'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['warehouse', 'create_mode']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method create_warehouses" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method create_warehouses" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
 
         # process the query parameters
         _query_params = []
+
         if _params.get('create_mode') is not None:  # noqa: E501
             _query_params.append(('createMode', _params['create_mode']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['warehouse']:
             _body_params = _params['warehouse']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -415,44 +430,60 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses', 'POST',
+            '/api/v2/warehouses',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def abort_all_queries_on_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def abort_all_queries_on_warehouse(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """abort all queries  # noqa: E501
 
+
         Aborts all the queries currently running or queued on the warehouse.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.abort_all_queries_on_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -462,30 +493,45 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.abort_all_queries_on_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
+        return self.abort_all_queries_on_warehouse_with_http_info(
+            name, if_exists, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def abort_all_queries_on_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def abort_all_queries_on_warehouse_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
         """abort all queries  # noqa: E501
 
+
         Aborts all the queries currently running or queued on the warehouse.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.abort_all_queries_on_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -505,49 +551,40 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
                 raise _APITypeError(
                     "Got an unexpected keyword argument '%s'"
-                    " to method abort_all_queries_on_warehouse" % _key
-                )
+                    " to method abort_all_queries_on_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -577,42 +614,49 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}:abort', 'POST',
+            '/api/v2/warehouses/{name}:abort',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def describe_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> Warehouse:  # noqa: E501
+    @validate_call
+    def describe_warehouse(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                           **kwargs) -> Warehouse:  # noqa: E501
         """Describe warehouse  # noqa: E501
 
+
         Describes the warehouse, show information of the chosen warehouse. Equivalent to DESCRIBE WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.describe_warehouse(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -622,28 +666,34 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Warehouse
         """
         kwargs['_return_http_data_only'] = True
-        return self.describe_warehouse_with_http_info(name, **kwargs)  # noqa: E501
+        return self.describe_warehouse_with_http_info(name,
+                                                      **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def describe_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def describe_warehouse_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                          **kwargs):  # noqa: E501
         """Describe warehouse  # noqa: E501
 
+
         Describes the warehouse, show information of the chosen warehouse. Equivalent to DESCRIBE WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.describe_warehouse_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -663,43 +713,33 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(Warehouse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method describe_warehouse" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method describe_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -732,44 +772,60 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}', 'GET',
+            '/api/v2/warehouses/{name}',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def drop_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def drop_warehouse(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """Drop warehouse  # noqa: E501
 
+
         Removes the specified virtual warehouse from the system. Equivalent to DROP WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.drop_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -779,30 +835,45 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.drop_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
+        return self.drop_warehouse_with_http_info(name, if_exists,
+                                                  **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def drop_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def drop_warehouse_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
         """Drop warehouse  # noqa: E501
 
+
         Removes the specified virtual warehouse from the system. Equivalent to DROP WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.drop_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -822,49 +893,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method drop_warehouse" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method drop_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -894,42 +955,54 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}', 'DELETE',
+            '/api/v2/warehouses/{name}',
+            'DELETE',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def list_warehouses(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs) -> Iterable[Warehouse]:  # noqa: E501
+    @validate_call
+    def list_warehouses(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            **kwargs) -> Iterable[Warehouse]:  # noqa: E501
         """List warehouse  # noqa: E501
 
+
         Show a list of warehouse filtered by pattern. Equivalent to SHOW WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_warehouses(like, async_req=True)
         >>> result = thread.get()
-
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -939,28 +1012,39 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: Iterable[Warehouse]
         """
         kwargs['_return_http_data_only'] = True
-        return self.list_warehouses_with_http_info(like, **kwargs)  # noqa: E501
+        return self.list_warehouses_with_http_info(like,
+                                                   **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def list_warehouses_with_http_info(self, like : Annotated[Optional[StrictStr], Field(description="A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def list_warehouses_with_http_info(
+            self,
+            like:
+        Annotated[
+            Optional[StrictStr],
+            Field(
+                description=
+                "Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters."
+            )] = None,
+            **kwargs):  # noqa: E501
         """List warehouse  # noqa: E501
 
+
         Show a list of warehouse filtered by pattern. Equivalent to SHOW WAREHOUSE in SQL.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.list_warehouses_with_http_info(like, async_req=True)
         >>> result = thread.get()
-
-        :param like: A query parameter that filters the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters
+        :param like: Query parameter to filter the command output by resource name. Uses case-insensitive pattern matching, with support for SQL wildcard characters.
         :type like: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -980,46 +1064,36 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(Iterable[Warehouse], status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'like'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['like']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method list_warehouses" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method list_warehouses" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
 
         # process the query parameters
         _query_params = []
+
         if _params.get('like') is not None:  # noqa: E501
             _query_params.append(('like', _params['like']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -1049,46 +1123,63 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses', 'GET',
+            '/api/v2/warehouses',
+            'GET',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def rename_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def rename_warehouse(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            warehouse: Warehouse,
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """update and rename warehouse  # noqa: E501
 
+
         Specifies a new identifier for the warehouse; must be unique for current account.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.rename_warehouse(name, warehouse, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param warehouse: (required)
         :type warehouse: Warehouse
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1098,32 +1189,48 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.rename_warehouse_with_http_info(name, warehouse, if_exists, **kwargs)  # noqa: E501
+        return self.rename_warehouse_with_http_info(name, warehouse, if_exists,
+                                                    **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def rename_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], warehouse : Warehouse, if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def rename_warehouse_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            warehouse: Warehouse,
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
         """update and rename warehouse  # noqa: E501
 
+
         Specifies a new identifier for the warehouse; must be unique for current account.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.rename_warehouse_with_http_info(name, warehouse, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param warehouse: (required)
         :type warehouse: Warehouse
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1143,75 +1250,65 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'warehouse',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'warehouse', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method rename_warehouse" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method rename_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
         _form_params = []
         _files = {}
 
         # process the body parameter
         _body_params = None
+
         if _params['warehouse']:
             _body_params = _params['warehouse']
 
         # set the HTTP header `Accept`
         _header_params['Accept'] = self.api_client.select_header_accept(
             ['application/json'])  # noqa: E501
 
         # set the HTTP header `Content-Type`
-        _content_types_list = _params.get('_content_type',
-            self.api_client.select_header_content_type(
-                ['application/json']))
+        _content_types_list = _params.get(
+            '_content_type',
+            self.api_client.select_header_content_type(['application/json']))
         if _content_types_list:
-                _header_params['Content-Type'] = _content_types_list
+            _header_params['Content-Type'] = _content_types_list
 
         # authentication setting
         _auth_settings = []  # noqa: E501
 
         _response_types_map = {
             '200': "SuccessResponse",
             '400': "ErrorResponse",
@@ -1225,44 +1322,60 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}:rename', 'POST',
+            '/api/v2/warehouses/{name}:rename',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def resume_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def resume_warehouse(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """resume warehouse  # noqa: E501
 
+
         Bring current warehouse to a usable ‘Running’ state by provisioning compute resources if current warehouse is suspended.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.resume_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1272,30 +1385,45 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.resume_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
+        return self.resume_warehouse_with_http_info(name, if_exists,
+                                                    **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def resume_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def resume_warehouse_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
         """resume warehouse  # noqa: E501
 
+
         Bring current warehouse to a usable ‘Running’ state by provisioning compute resources if current warehouse is suspended.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.resume_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1315,49 +1443,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method resume_warehouse" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method resume_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -1387,44 +1505,60 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}:resume', 'POST',
+            '/api/v2/warehouses/{name}:resume',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def suspend_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def suspend_warehouse(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs) -> SuccessResponse:  # noqa: E501
         """suspend warehouse  # noqa: E501
 
+
         Remove all compute nodes from a warehouse and put the warehouse into a ‘Suspended’ state if current warehouse is not suspended.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.suspend_warehouse(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1434,30 +1568,45 @@
                                  (connection, read) timeouts.
         :return: Returns the result object.
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
-        return self.suspend_warehouse_with_http_info(name, if_exists, **kwargs)  # noqa: E501
+        return self.suspend_warehouse_with_http_info(name, if_exists,
+                                                     **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def suspend_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], if_exists : Annotated[Optional[StrictBool], Field(description="A query parameter determining if the endpoint will not throw an error if the resource does not exist.")] = None, **kwargs):  # noqa: E501
+    @validate_call
+    def suspend_warehouse_with_http_info(
+            self,
+            name: Annotated[
+                str,
+                Field(strict=True,
+                      description="Identifier (i.e. name) for the resource.")],
+            if_exists:
+        Annotated[
+            Optional[StrictBool],
+            Field(
+                description=
+                "Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist."
+            )] = None,
+            **kwargs):  # noqa: E501
         """suspend warehouse  # noqa: E501
 
+
         Remove all compute nodes from a warehouse and put the warehouse into a ‘Suspended’ state if current warehouse is not suspended.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.suspend_warehouse_with_http_info(name, if_exists, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
-        :param if_exists: A query parameter determining if the endpoint will not throw an error if the resource does not exist.
+        :param if_exists: Query parameter that specifies how to handle the request for a resource that does not exist: - `true`: The endpoint does not throw an error if the resource does not exist. It returns a 200 success response, but does not take any action on the resource. - `false`: The endpoint throws an error if the resource doesn't exist.
         :type if_exists: bool
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1477,49 +1626,39 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name',
-            'if_exists'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name', 'if_exists']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method suspend_warehouse" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method suspend_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
+
         if _params.get('if_exists') is not None:  # noqa: E501
             _query_params.append(('ifExists', _params['if_exists']))
 
         # process the header parameters
         _header_params = dict(_params.get('_headers', {}))
 
         # process the form parameters
@@ -1549,42 +1688,49 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}:suspend', 'POST',
+            '/api/v2/warehouses/{name}:suspend',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
 
-    @validate_arguments
-    def use_warehouse(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs) -> SuccessResponse:  # noqa: E501
+    @validate_call
+    def use_warehouse(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                      **kwargs) -> SuccessResponse:  # noqa: E501
         """use current warehouse for session  # noqa: E501
 
+
         Specifies the active/current warehouse for the session.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.use_warehouse(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
                                  be returned without reading/decoding response
                                  data. Default is True.
         :type _preload_content: bool, optional
@@ -1596,26 +1742,31 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: SuccessResponse
         """
         kwargs['_return_http_data_only'] = True
         return self.use_warehouse_with_http_info(name, **kwargs)  # noqa: E501
 
-    @validate_arguments
-    def use_warehouse_with_http_info(self, name : Annotated[constr(strict=True), Field(..., description="String that specifies the identifier (i.e. name) for the resource.")], **kwargs):  # noqa: E501
+    @validate_call
+    def use_warehouse_with_http_info(self, name: Annotated[
+        str,
+        Field(strict=True,
+              description="Identifier (i.e. name) for the resource.")],
+                                     **kwargs):  # noqa: E501
         """use current warehouse for session  # noqa: E501
 
+
         Specifies the active/current warehouse for the session.  # noqa: E501
+
         This method makes a synchronous HTTP request by default. To make an
         asynchronous HTTP request, please pass async_req=True
 
         >>> thread = api.use_warehouse_with_http_info(name, async_req=True)
         >>> result = thread.get()
-
-        :param name: String that specifies the identifier (i.e. name) for the resource. (required)
+        :param name: Identifier (i.e. name) for the resource. (required)
         :type name: str
         :param async_req: Whether to execute the request asynchronously.
         :type async_req: bool, optional
         :param _return_http_data_only: response data without head status code
                                        and headers
         :type _return_http_data_only: bool, optional
         :param _preload_content: if False, the urllib3.HTTPResponse object will
@@ -1635,43 +1786,33 @@
                  If the method is called asynchronously,
                  returns the request thread.
         :rtype: tuple(SuccessResponse, status_code(int), headers(HTTPHeaderDict))
         """
 
         _params = locals()
 
-        _all_params = [
-            'name'
-        ]
-        _all_params.extend(
-            [
-                'async_req',
-                '_return_http_data_only',
-                '_preload_content',
-                '_request_timeout',
-                '_request_auth',
-                '_content_type',
-                '_headers'
-            ]
-        )
+        _all_params = ['name']
+        _all_params.extend([
+            'async_req', '_return_http_data_only', '_preload_content',
+            '_request_timeout', '_request_auth', '_content_type', '_headers'
+        ])
 
         # validate the arguments
         for _key, _val in _params['kwargs'].items():
             if _key not in _all_params:
-                raise _APITypeError(
-                    "Got an unexpected keyword argument '%s'"
-                    " to method use_warehouse" % _key
-                )
+                raise _APITypeError("Got an unexpected keyword argument '%s'"
+                                    " to method use_warehouse" % _key)
             _params[_key] = _val
         del _params['kwargs']
 
         _collection_formats = {}
 
         # process the path parameters
         _path_params = {}
+
         if _params['name']:
             _path_params['name'] = _params['name']
 
         # process the query parameters
         _query_params = []
 
         # process the header parameters
@@ -1704,22 +1845,24 @@
             '500': "ErrorResponse",
             '503': "ErrorResponse",
             '504': "ErrorResponse",
         }
 
         return self.api_client.call_api(
             self._root,
-            '/api/v2/warehouses/{name}:use', 'POST',
+            '/api/v2/warehouses/{name}:use',
+            'POST',
             _path_params,
             _query_params,
             _header_params,
             body=_body_params,
             post_params=_form_params,
             files=_files,
             response_types_map=_response_types_map,
             auth_settings=_auth_settings,
             async_req=_params.get('async_req'),
-            _return_http_data_only=_params.get('_return_http_data_only'),  # noqa: E501
+            _return_http_data_only=_params.get(
+                '_return_http_data_only'),  # noqa: E501
             _preload_content=_params.get('_preload_content', True),
             _request_timeout=_params.get('_request_timeout'),
             collection_formats=_collection_formats,
             _request_auth=_params.get('_request_auth'))
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/__init__.py` & `snowflake_core-0.8.1/src/snowflake/core/role/_generated/models/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 # coding: utf-8
 
 # flake8: noqa
 """
-    Snowflake Warehouse API
-
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
+    Snowflake Role API
+    The Snowflake Role API is a REST API that you can use to access, update, and perform certain action on Roles in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import absolute_import
 
 # import models into model package
-from snowflake.core.warehouse._generated.models.error_response import ErrorResponse
-from snowflake.core.warehouse._generated.models.success_response import SuccessResponse
-from snowflake.core.warehouse._generated.models.warehouse import Warehouse
+from snowflake.core.role._generated.models.error_response import ErrorResponse
+from snowflake.core.role._generated.models.role import Role
+from snowflake.core.role._generated.models.success_response import SuccessResponse
 
 __all__ = [
     'ErrorResponse',
+    'Role',
     'SuccessResponse',
-    'Warehouse',
-]
+]
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/error_response.py` & `snowflake_core-0.8.1/src/snowflake/core/image_repository/_generated/models/error_response.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,42 +1,44 @@
 # coding: utf-8
-
 """
-    Snowflake Warehouse API
-
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
+    Snowflake Image Repository API
+    The Snowflake Image Repository API is a REST API that you can use to access, update, and perform common actions on Image Repository resource in Snowflake.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.warehouse._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class ErrorResponse(BaseModel):
+
     message: Optional[StrictStr] = None
+
     code: Optional[StrictStr] = None
+
     error_code: Optional[StrictStr] = None
+
     request_id: Optional[StrictStr] = None
-    __properties = ["message", "code", "error_code", "request_id"]
 
+    __properties = ["message", "code", "error_code", "request_id"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -46,82 +48,77 @@
     @classmethod
     def from_json(cls, json_str: str) -> ErrorResponse:
         """Create an instance of ErrorResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> ErrorResponse:
         """Create an instance of ErrorResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return ErrorResponse.parse_obj(obj)
 
         _obj = ErrorResponse.parse_obj({
             "message": obj.get("message"),
-
             "code": obj.get("code"),
-
             "error_code": obj.get("error_code"),
-
             "request_id": obj.get("request_id"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class ErrorResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         message: Optional[str] = None,
         code: Optional[str] = None,
         error_code: Optional[str] = None,
         request_id: Optional[str] = None,
     ):
+
         self.message = message
         self.code = code
         self.error_code = error_code
         self.request_id = request_id
+
     __properties = ["message", "code", "error_code", "request_id"]
 
     def _to_model(self):
         return ErrorResponse(
             message=self.message,
-
             code=self.code,
-
             error_code=self.error_code,
-
             request_id=self.request_id,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> ErrorResponseModel:
         return ErrorResponseModel(
             message=model.message,
-
             code=model.code,
-
             error_code=model.error_code,
-
             request_id=model.request_id,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/success_response.py` & `snowflake_core-0.8.1/src/snowflake/core/stage/_generated/models/success_response.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,39 +1,38 @@
 # coding: utf-8
-
 """
-    Snowflake Warehouse API
-
-    The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
 
+    Snowflake Stage API
+    The Snowflake Stage API is a REST API that you can use to access, update, and perform certain actions on stage resources in a Snowflake database.  # noqa: E501
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-
-from typing import Optional
 from typing import Union
-from snowflake.core.warehouse._generated.pydantic_compatibility import BaseModel, StrictStr
+
+from pydantic import BaseModel, ConfigDict, StrictStr
+
+from typing import Any, ClassVar, Dict, List, Optional
+
 
 class SuccessResponse(BaseModel):
+
     status: Optional[StrictStr] = None
-    __properties = ["status"]
 
+    __properties = ["status"]
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -43,59 +42,59 @@
     @classmethod
     def from_json(cls, json_str: str) -> SuccessResponse:
         """Create an instance of SuccessResponse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={},
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponse:
         """Create an instance of SuccessResponse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return SuccessResponse.parse_obj(obj)
 
         _obj = SuccessResponse.parse_obj({
             "status": obj.get("status"),
-
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class SuccessResponseModel():
+
     def __init__(
-        self,
-        # optional properties
+        self,  # optional properties
         status: Optional[str] = None,
     ):
+
         self.status = status
+
     __properties = ["status"]
 
     def _to_model(self):
-        return SuccessResponse(
-            status=self.status,
-
-        )
+        return SuccessResponse(status=self.status, )
 
     @classmethod
     def _from_model(cls, model) -> SuccessResponseModel:
-        return SuccessResponseModel(
-            status=model.status,
-
-        )
+        return SuccessResponseModel(status=model.status, )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
     def from_dict(cls, obj: dict) -> SuccessResponseModel:
```

### Comparing `snowflake_core-0.8.0/src/snowflake/core/warehouse/_generated/models/warehouse.py` & `snowflake_core-0.8.1/src/snowflake/core/warehouse/_generated/models/warehouse.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,124 +1,179 @@
 # coding: utf-8
-
 """
-    Snowflake Warehouse API
 
+    Snowflake Warehouse API
     The Snowflake Warehouse API is a REST API that you can use to access, customize and manage virtual warehouse in a Snowflake account.  # noqa: E501
-
     The version of the OpenAPI document: 0.0.1
-    Contact: support@snowflake.com
-    Generated by: https://openapi-generator.tech
+    Contact: support@snowflake.comGenerated by: https://openapi-generator.tech
 
     Do not edit this file manually.
 """
 
-
 from __future__ import annotations
 import pprint
 import re  # noqa: F401
 import json
 
-from datetime import datetime
-from typing import Dict, Optional
 from typing import Union
-from snowflake.core.warehouse._generated.pydantic_compatibility import BaseModel, Field, StrictBool, StrictInt, StrictStr, constr, validator
+
+from datetime import datetime
+
+from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
+
+from typing import Any, ClassVar, Dict, List, Optional
+
+from typing_extensions import Annotated
+
 
 class Warehouse(BaseModel):
-    name: constr(strict=True) = Field(...)
+
+    name: Annotated[str, Field(strict=True)]
+
     warehouse_type: Optional[StrictStr] = None
+
     warehouse_size: Optional[StrictStr] = None
+
     wait_for_completion: Optional[StrictStr] = None
+
     max_cluster_count: Optional[StrictInt] = None
+
     min_cluster_count: Optional[StrictInt] = None
+
     scaling_policy: Optional[StrictStr] = None
+
     auto_suspend: Optional[StrictInt] = None
+
     auto_resume: Optional[StrictStr] = None
+
     initially_suspended: Optional[StrictStr] = None
-    resource_monitor: Optional[constr(strict=True)] = None
+
+    resource_monitor: Optional[Annotated[str, Field(strict=True)]] = None
+
     comment: Optional[StrictStr] = None
+
     enable_query_acceleration: Optional[StrictStr] = None
+
     query_acceleration_max_scale_factor: Optional[StrictInt] = None
+
     max_concurrency_level: Optional[StrictInt] = None
+
     statement_queued_timeout_in_seconds: Optional[StrictInt] = None
+
     statement_timeout_in_seconds: Optional[StrictInt] = None
+
     tags: Optional[Dict[str, StrictStr]] = None
+
     type: Optional[StrictStr] = None
+
     size: Optional[StrictStr] = None
+
     state: Optional[StrictStr] = None
+
     started_clusters: Optional[StrictInt] = None
+
     running: Optional[StrictInt] = None
+
     queued: Optional[StrictInt] = None
+
     is_default: Optional[StrictBool] = None
+
     is_current: Optional[StrictBool] = None
+
     available: Optional[StrictStr] = None
+
     provisioning: Optional[StrictStr] = None
+
     quiescing: Optional[StrictStr] = None
+
     other: Optional[StrictStr] = None
+
     created_on: Optional[datetime] = None
+
     resumed_on: Optional[datetime] = None
+
     updated_on: Optional[datetime] = None
+
     owner: Optional[StrictStr] = None
+
     budget: Optional[StrictStr] = None
+
     kind: Optional[StrictStr] = None
-    __properties = ["name", "warehouse_type", "warehouse_size", "wait_for_completion", "max_cluster_count", "min_cluster_count", "scaling_policy", "auto_suspend", "auto_resume", "initially_suspended", "resource_monitor", "comment", "enable_query_acceleration", "query_acceleration_max_scale_factor", "max_concurrency_level", "statement_queued_timeout_in_seconds", "statement_timeout_in_seconds", "tags", "type", "size", "state", "started_clusters", "running", "queued", "is_default", "is_current", "available", "provisioning", "quiescing", "other", "created_on", "resumed_on", "updated_on", "owner", "budget", "kind"]
 
+    __properties = [
+        "name", "warehouse_type", "warehouse_size", "wait_for_completion",
+        "max_cluster_count", "min_cluster_count", "scaling_policy",
+        "auto_suspend", "auto_resume", "initially_suspended",
+        "resource_monitor", "comment", "enable_query_acceleration",
+        "query_acceleration_max_scale_factor", "max_concurrency_level",
+        "statement_queued_timeout_in_seconds", "statement_timeout_in_seconds",
+        "tags", "type", "size", "state", "started_clusters", "running",
+        "queued", "is_default", "is_current", "available", "provisioning",
+        "quiescing", "other", "created_on", "resumed_on", "updated_on",
+        "owner", "budget", "kind"
+    ]
 
-    @validator('name')
+    @field_validator('name')
     def name_validate_regular_expression(cls, v):
+
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('wait_for_completion')
+    @field_validator('wait_for_completion')
     def wait_for_completion_validate_enum(cls, v):
+
         if v is None:
             return v
-
         if v not in ('true', 'false'):
-            raise ValueError("must validate the enum values ('true', 'false')")
+            raise ValueError("must validate the enum values ()")
         return v
 
-    @validator('auto_resume')
+    @field_validator('auto_resume')
     def auto_resume_validate_enum(cls, v):
+
         if v is None:
             return v
-
         if v not in ('true', 'false'):
-            raise ValueError("must validate the enum values ('true', 'false')")
+            raise ValueError("must validate the enum values ()")
         return v
 
-    @validator('initially_suspended')
+    @field_validator('initially_suspended')
     def initially_suspended_validate_enum(cls, v):
+
         if v is None:
             return v
-
         if v not in ('true', 'false'):
-            raise ValueError("must validate the enum values ('true', 'false')")
+            raise ValueError("must validate the enum values ()")
         return v
 
-    @validator('resource_monitor')
+    @field_validator('resource_monitor')
     def resource_monitor_validate_regular_expression(cls, v):
+
         if v is None:
             return v
         if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
-            raise ValueError(r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/""")
+            raise ValueError(
+                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
+            )
         return v
 
-    @validator('enable_query_acceleration')
+    @field_validator('enable_query_acceleration')
     def enable_query_acceleration_validate_enum(cls, v):
+
         if v is None:
             return v
-
         if v not in ('true', 'false'):
-            raise ValueError("must validate the enum values ('true', 'false')")
+            raise ValueError("must validate the enum values ()")
         return v
 
     class Config:
-        allow_population_by_field_name = True
+        populate_by_name = True
         validate_assignment = True
 
     def to_str(self) -> str:
         """Returns the string representation of the model using alias"""
         return pprint.pformat(self.dict(by_alias=True))
 
     def to_json(self) -> str:
@@ -128,125 +183,132 @@
     @classmethod
     def from_json(cls, json_str: str) -> Warehouse:
         """Create an instance of Warehouse from a JSON string"""
         return cls.from_dict(json.loads(json_str))
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
-        _dict = self.dict(by_alias=True,
-                          exclude={
-                            "state",
-                            "started_clusters",
-                            "running",
-                            "queued",
-                            "is_default",
-                            "is_current",
-                            "available",
-                            "provisioning",
-                            "quiescing",
-                            "other",
-                            "created_on",
-                            "resumed_on",
-                            "updated_on",
-                            "owner",
-                            "budget",
-                            "kind",
-                          },
-                          exclude_none=True)
+        _dict = dict(
+            self._iter(to_dict=True,
+                       by_alias=True,
+                       exclude={
+                           "state",
+                           "started_clusters",
+                           "running",
+                           "queued",
+                           "is_default",
+                           "is_current",
+                           "available",
+                           "provisioning",
+                           "quiescing",
+                           "other",
+                           "created_on",
+                           "resumed_on",
+                           "updated_on",
+                           "owner",
+                           "budget",
+                           "kind",
+                       },
+                       exclude_none=True))
+
         return _dict
 
     @classmethod
     def from_dict(cls, obj: dict) -> Warehouse:
         """Create an instance of Warehouse from a dict"""
+
         if obj is None:
             return None
 
         if type(obj) is not dict:
             return Warehouse.parse_obj(obj)
 
         _obj = Warehouse.parse_obj({
-            "name": obj.get("name"),
-
-            "warehouse_type": obj.get("warehouse_type"),
-
-            "warehouse_size": obj.get("warehouse_size"),
-
-            "wait_for_completion": obj.get("wait_for_completion"),
-
-            "max_cluster_count": obj.get("max_cluster_count"),
-
-            "min_cluster_count": obj.get("min_cluster_count"),
-
-            "scaling_policy": obj.get("scaling_policy"),
-
-            "auto_suspend": obj.get("auto_suspend"),
-
-            "auto_resume": obj.get("auto_resume"),
-
-            "initially_suspended": obj.get("initially_suspended"),
-
-            "resource_monitor": obj.get("resource_monitor"),
-
-            "comment": obj.get("comment"),
-
-            "enable_query_acceleration": obj.get("enable_query_acceleration"),
-
-            "query_acceleration_max_scale_factor": obj.get("query_acceleration_max_scale_factor"),
-
-            "max_concurrency_level": obj.get("max_concurrency_level"),
-
-            "statement_queued_timeout_in_seconds": obj.get("statement_queued_timeout_in_seconds"),
-
-            "statement_timeout_in_seconds": obj.get("statement_timeout_in_seconds"),
-
-            "tags": obj.get("tags"),
-
-            "type": obj.get("type"),
-
-            "size": obj.get("size"),
-
-            "state": obj.get("state"),
-
-            "started_clusters": obj.get("started_clusters"),
-
-            "running": obj.get("running"),
-
-            "queued": obj.get("queued"),
-
-            "is_default": obj.get("is_default"),
-
-            "is_current": obj.get("is_current"),
-
-            "available": obj.get("available"),
-
-            "provisioning": obj.get("provisioning"),
-
-            "quiescing": obj.get("quiescing"),
-
-            "other": obj.get("other"),
-
-            "created_on": obj.get("created_on"),
-
-            "resumed_on": obj.get("resumed_on"),
-
-            "updated_on": obj.get("updated_on"),
-
-            "owner": obj.get("owner"),
-
-            "budget": obj.get("budget"),
-
-            "kind": obj.get("kind"),
-
+            "name":
+            obj.get("name"),
+            "warehouse_type":
+            obj.get("warehouse_type"),
+            "warehouse_size":
+            obj.get("warehouse_size"),
+            "wait_for_completion":
+            obj.get("wait_for_completion"),
+            "max_cluster_count":
+            obj.get("max_cluster_count"),
+            "min_cluster_count":
+            obj.get("min_cluster_count"),
+            "scaling_policy":
+            obj.get("scaling_policy"),
+            "auto_suspend":
+            obj.get("auto_suspend"),
+            "auto_resume":
+            obj.get("auto_resume"),
+            "initially_suspended":
+            obj.get("initially_suspended"),
+            "resource_monitor":
+            obj.get("resource_monitor"),
+            "comment":
+            obj.get("comment"),
+            "enable_query_acceleration":
+            obj.get("enable_query_acceleration"),
+            "query_acceleration_max_scale_factor":
+            obj.get("query_acceleration_max_scale_factor"),
+            "max_concurrency_level":
+            obj.get("max_concurrency_level"),
+            "statement_queued_timeout_in_seconds":
+            obj.get("statement_queued_timeout_in_seconds"),
+            "statement_timeout_in_seconds":
+            obj.get("statement_timeout_in_seconds"),
+            "tags":
+            obj.get("tags"),
+            "type":
+            obj.get("type"),
+            "size":
+            obj.get("size"),
+            "state":
+            obj.get("state"),
+            "started_clusters":
+            obj.get("started_clusters"),
+            "running":
+            obj.get("running"),
+            "queued":
+            obj.get("queued"),
+            "is_default":
+            obj.get("is_default"),
+            "is_current":
+            obj.get("is_current"),
+            "available":
+            obj.get("available"),
+            "provisioning":
+            obj.get("provisioning"),
+            "quiescing":
+            obj.get("quiescing"),
+            "other":
+            obj.get("other"),
+            "created_on":
+            obj.get("created_on"),
+            "resumed_on":
+            obj.get("resumed_on"),
+            "updated_on":
+            obj.get("updated_on"),
+            "owner":
+            obj.get("owner"),
+            "budget":
+            obj.get("budget"),
+            "kind":
+            obj.get("kind"),
         })
+
         return _obj
 
 
 from typing import Optional, List, Dict
 
+
 class WarehouseModel():
+
     def __init__(
         self,
         name: str,
         # optional properties
         warehouse_type: Optional[str] = None,
         warehouse_size: Optional[str] = None,
         wait_for_completion: Optional[str] = None,
@@ -279,14 +341,15 @@
         created_on: Optional[datetime] = None,
         resumed_on: Optional[datetime] = None,
         updated_on: Optional[datetime] = None,
         owner: Optional[str] = None,
         budget: Optional[str] = None,
         kind: Optional[str] = None,
     ):
+
         self.name = name
         self.warehouse_type = warehouse_type
         self.warehouse_size = warehouse_size
         self.wait_for_completion = wait_for_completion
         self.max_cluster_count = max_cluster_count
         self.min_cluster_count = min_cluster_count
         self.scaling_policy = scaling_policy
@@ -315,167 +378,111 @@
         self.other = other
         self.created_on = created_on
         self.resumed_on = resumed_on
         self.updated_on = updated_on
         self.owner = owner
         self.budget = budget
         self.kind = kind
-    __properties = ["name", "warehouse_type", "warehouse_size", "wait_for_completion", "max_cluster_count", "min_cluster_count", "scaling_policy", "auto_suspend", "auto_resume", "initially_suspended", "resource_monitor", "comment", "enable_query_acceleration", "query_acceleration_max_scale_factor", "max_concurrency_level", "statement_queued_timeout_in_seconds", "statement_timeout_in_seconds", "tags", "type", "size", "state", "started_clusters", "running", "queued", "is_default", "is_current", "available", "provisioning", "quiescing", "other", "created_on", "resumed_on", "updated_on", "owner", "budget", "kind"]
+
+    __properties = [
+        "name", "warehouse_type", "warehouse_size", "wait_for_completion",
+        "max_cluster_count", "min_cluster_count", "scaling_policy",
+        "auto_suspend", "auto_resume", "initially_suspended",
+        "resource_monitor", "comment", "enable_query_acceleration",
+        "query_acceleration_max_scale_factor", "max_concurrency_level",
+        "statement_queued_timeout_in_seconds", "statement_timeout_in_seconds",
+        "tags", "type", "size", "state", "started_clusters", "running",
+        "queued", "is_default", "is_current", "available", "provisioning",
+        "quiescing", "other", "created_on", "resumed_on", "updated_on",
+        "owner", "budget", "kind"
+    ]
 
     def _to_model(self):
         return Warehouse(
             name=self.name,
-
             warehouse_type=self.warehouse_type,
-
             warehouse_size=self.warehouse_size,
-
             wait_for_completion=self.wait_for_completion,
-
             max_cluster_count=self.max_cluster_count,
-
             min_cluster_count=self.min_cluster_count,
-
             scaling_policy=self.scaling_policy,
-
             auto_suspend=self.auto_suspend,
-
             auto_resume=self.auto_resume,
-
             initially_suspended=self.initially_suspended,
-
             resource_monitor=self.resource_monitor,
-
             comment=self.comment,
-
             enable_query_acceleration=self.enable_query_acceleration,
-
-            query_acceleration_max_scale_factor=self.query_acceleration_max_scale_factor,
-
+            query_acceleration_max_scale_factor=self.
+            query_acceleration_max_scale_factor,
             max_concurrency_level=self.max_concurrency_level,
-
-            statement_queued_timeout_in_seconds=self.statement_queued_timeout_in_seconds,
-
+            statement_queued_timeout_in_seconds=self.
+            statement_queued_timeout_in_seconds,
             statement_timeout_in_seconds=self.statement_timeout_in_seconds,
-
             tags=self.tags,
-
             type=self.type,
-
             size=self.size,
-
             state=self.state,
-
             started_clusters=self.started_clusters,
-
             running=self.running,
-
             queued=self.queued,
-
             is_default=self.is_default,
-
             is_current=self.is_current,
-
             available=self.available,
-
             provisioning=self.provisioning,
-
             quiescing=self.quiescing,
-
             other=self.other,
-
             created_on=self.created_on,
-
             resumed_on=self.resumed_on,
-
             updated_on=self.updated_on,
-
             owner=self.owner,
-
             budget=self.budget,
-
             kind=self.kind,
-
         )
 
     @classmethod
     def _from_model(cls, model) -> WarehouseModel:
         return WarehouseModel(
             name=model.name,
-
             warehouse_type=model.warehouse_type,
-
             warehouse_size=model.warehouse_size,
-
             wait_for_completion=model.wait_for_completion,
-
             max_cluster_count=model.max_cluster_count,
-
             min_cluster_count=model.min_cluster_count,
-
             scaling_policy=model.scaling_policy,
-
             auto_suspend=model.auto_suspend,
-
             auto_resume=model.auto_resume,
-
             initially_suspended=model.initially_suspended,
-
             resource_monitor=model.resource_monitor,
-
             comment=model.comment,
-
             enable_query_acceleration=model.enable_query_acceleration,
-
-            query_acceleration_max_scale_factor=model.query_acceleration_max_scale_factor,
-
+            query_acceleration_max_scale_factor=model.
+            query_acceleration_max_scale_factor,
             max_concurrency_level=model.max_concurrency_level,
-
-            statement_queued_timeout_in_seconds=model.statement_queued_timeout_in_seconds,
-
+            statement_queued_timeout_in_seconds=model.
+            statement_queued_timeout_in_seconds,
             statement_timeout_in_seconds=model.statement_timeout_in_seconds,
-
             tags=model.tags,
-
             type=model.type,
-
             size=model.size,
-
             state=model.state,
-
             started_clusters=model.started_clusters,
-
             running=model.running,
-
             queued=model.queued,
-
             is_default=model.is_default,
-
             is_current=model.is_current,
-
             available=model.available,
-
             provisioning=model.provisioning,
-
             quiescing=model.quiescing,
-
             other=model.other,
-
             created_on=model.created_on,
-
             resumed_on=model.resumed_on,
-
             updated_on=model.updated_on,
-
             owner=model.owner,
-
             budget=model.budget,
-
             kind=model.kind,
-
         )
 
     def to_dict(self):
         """Returns the dictionary representation of the model using alias"""
         return self._to_model().to_dict()
 
     @classmethod
```

### Comparing `snowflake_core-0.8.0/tests/utils.py` & `snowflake_core-0.8.1/tests/utils.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/conftest.py` & `snowflake_core-0.8.1/tests/integ/conftest.py`

 * *Files 10% similar despite different names*

```diff
@@ -21,40 +21,45 @@
 )
 from snowflake.core.cortex.search_service import CortexSearchServiceCollection
 from snowflake.core.database import (
     Database,
     DatabaseCollection,
     DatabaseResource,
 )
+from snowflake.core.function import FunctionCollection
+from snowflake.core.grant._grants import Grants
 from snowflake.core.image_repository import (
     ImageRepository,
     ImageRepositoryCollection,
 )
+from snowflake.core.role import RoleCollection
 from snowflake.core.schema import (
     Schema,
     SchemaCollection,
     SchemaResource,
 )
 from snowflake.core.service import (
     Service,
     ServiceCollection,
     ServiceResource,
     ServiceSpecInlineText,
     ServiceSpecStageFile,
 )
+from snowflake.core.user import UserCollection
 from snowflake.core.warehouse import WarehouseCollection
 from snowflake.snowpark import Session
 
 from .utils import random_string
 
 
 RUNNING_ON_GHA = os.getenv("GITHUB_ACTIONS") == "true"
 RUNNING_ON_JENKINS = "JENKINS_URL" in os.environ
 TEST_SCHEMA = "GH_JOB_{}".format(str(uuid.uuid4()).replace("-", "_"))
 
+
 @pytest.fixture(scope="session")
 def running_on_public_ci() -> bool:
     return RUNNING_ON_GHA
 
 
 @pytest.fixture(scope="session")
 def running_on_private_ci():
@@ -71,14 +76,15 @@
     'password': 'test',
     'database': 'testdb',
     'schema': 'public',
 }
 """
     )
 
+
 def pytest_runtest_setup(item):
     # Skip online tests when not running on GHA
     # TODO: make the naming of this marker consistent with the other skip_xzy markers
     envnames = [mark.args[0] for mark in item.iter_markers(name="env")]
     if envnames:
         if "online" in envnames:
             if not RUNNING_ON_GHA:
@@ -86,15 +92,14 @@
     # Skip any test not marked for Jenkins when running on Jenkins
     if RUNNING_ON_JENKINS:
         jenkins_marker = list(item.iter_markers(name="jenkins"))
         if not jenkins_marker:
             pytest.skip("this test is not supposed to run on Jenkins")
 
 
-
 @pytest.fixture(scope="session")
 def db_parameters() -> Dict[str, str]:
     # If its running on our public CI, replace the schema
     # If its running on our public CI, replace the schema
     #
     # For legacy purposes, look to see if there's a parameters.py file and if
     # so, use its credentials.  To use the newer ~/.snowflake/config.toml file
@@ -105,16 +110,15 @@
         CONNECTION_PARAMETERS = None
         from snowflake.connector.config_manager import CONFIG_MANAGER
 
     # 2023-06-23(warsaw): By default, we read out of the [connections.snowflake] section in the config.toml file, but by
     # setting the environment variable SNOWFLAKE_DEFAULT_CONNECTION_NAME you can read out of a different section.
     # For example SNOWFLAKE_DEFAULT_CONNECTION_NAME='test' reads out of [connections.test]
 
-
-    level0, level1 = ('connections', CONFIG_MANAGER['default_connection_name'])
+    level0, level1 = ("connections", CONFIG_MANAGER["default_connection_name"])
 
     if CONNECTION_PARAMETERS is None:
         config = CONFIG_MANAGER[level0][level1]
     else:
         config = CONNECTION_PARAMETERS
 
     config["schema"] = TEST_SCHEMA
@@ -126,25 +130,15 @@
 # db_parameters in the traceback, and that **will** leak the password.  pytest
 # doesn't seem to have any way to suppress the password, and I've tried lots
 # of things to get that to work, to no avail.
 
 
 @pytest.fixture(scope="session")
 def connection(db_parameters):
-    _keys = [
-        "user",
-        "password",
-        "host",
-        "port",
-        "database",
-        "account",
-        "protocol",
-        "role",
-        "warehouse",
-    ]
+    _keys = ["user", "password", "host", "port", "database", "account", "protocol", "role", "warehouse"]
     with snowflake.connector.connect(
         # This works around SNOW-998521, by forcing JSON results
         **{k: db_parameters[k] for k in _keys if k in db_parameters}
     ) as con:
         yield con
 
 
@@ -185,23 +179,42 @@
 
 @pytest.fixture(scope="session")
 def services(schema) -> ServiceCollection:
     return schema.services
 
 
 @pytest.fixture(scope="session")
+def functions(schema) -> FunctionCollection:
+    return schema.functions
+
+
+@pytest.fixture(scope="session")
 def databases(root, db_parameters) -> DatabaseCollection:
     return root.databases
 
 
 @pytest.fixture(scope="session")
 def schemas(database) -> SchemaCollection:
     return database.schemas
 
 
+@pytest.fixture(scope="module")
+def roles(root) -> RoleCollection:
+    return root.roles
+
+
+@pytest.fixture(scope="module")
+def users(root) -> UserCollection:
+    return root.users
+
+@pytest.fixture(scope="module")
+def grants(root) -> Grants:
+    return root.grants
+
+
 @pytest.fixture(scope="session")
 def cortex_search_services(schema) -> CortexSearchServiceCollection:
     return schema.cortex_search_services
 
 
 @pytest.fixture(scope="session", autouse=True)
 def test_schema(connection) -> Generator[str, None, None]:
@@ -229,19 +242,15 @@
     image_repositories[test_ir.name].delete()
 
 
 @pytest.fixture
 def temp_cp(compute_pools) -> Generator[ComputePool, None, None]:
     cp_name = random_string(5, "test_cp_")
     test_cp = ComputePool(
-        name=cp_name,
-        instance_family="STANDARD_1",
-        min_nodes=1,
-        max_nodes=1,
-        comment="created by temp_cp",
+        name=cp_name, instance_family="CPU_X64_XS", min_nodes=1, max_nodes=1, comment="created by temp_cp"
     )
     compute_pools.create(test_cp)
     yield test_cp
     compute_pools[test_cp.name].delete()
 
 
 @pytest.fixture
@@ -274,17 +283,15 @@
     )
     s = services.create(test_s)
     yield test_s
     s.delete()
 
 
 @pytest.fixture
-def temp_service_from_spec_inline(
-    root, services, session, imagerepo
-) -> Iterator[ServiceResource]:
+def temp_service_from_spec_inline(root, services, session, imagerepo) -> Iterator[ServiceResource]:
     s_name = random_string(5, "test_service_")
     inline_spec = dedent(
         f"""
         spec:
           containers:
           - name: hello-world
             image: {imagerepo}/hello-world:latest
@@ -308,50 +315,38 @@
     """Reset the current database and schema after a test is complete.
 
     These 2 resources go hand-in-hand, so they should be backed up together.
     This fixture should be used when a database, or schema is created,
     or used in a test.
     """
     with connection.cursor() as cursor:
-        database_name = cursor.execute(
-            "SELECT /* backup_database_schema */ CURRENT_DATABASE()"
-        ).fetchone()[0]
-        schema_name = cursor.execute(
-            "SELECT /* backup_database_schema */ CURRENT_SCHEMA()"
-        ).fetchone()[0]
+        database_name = cursor.execute("SELECT /* backup_database_schema */ CURRENT_DATABASE()").fetchone()[0]
+        schema_name = cursor.execute("SELECT /* backup_database_schema */ CURRENT_SCHEMA()").fetchone()[0]
         try:
             yield
         finally:
             if schema_name is not None:
-                cursor.execute(
-                    f"USE SCHEMA /* backup_database_schema */ {database_name}.{schema_name}"
-                )
+                cursor.execute(f"USE SCHEMA /* backup_database_schema */ {database_name}.{schema_name}")
             elif database_name is not None:
-                cursor.execute(
-                    f"USE DATABASE /* backup_database_schema */ {database_name}"
-                )
+                cursor.execute(f"USE DATABASE /* backup_database_schema */ {database_name}")
 
 
 @pytest.fixture
 def backup_warehouse(connection):
     """Reset the current warehouse after a test is complete.
 
     This fixture should be used when a warehouse is created, or used in a test.
     """
     with connection.cursor() as cursor:
-        warehouse_name = cursor.execute(
-            "SELECT /* backup_warehouse */ CURRENT_WAREHOUSE()"
-        ).fetchone()[0]
+        warehouse_name = cursor.execute("SELECT /* backup_warehouse */ CURRENT_WAREHOUSE()").fetchone()[0]
         try:
             yield
         finally:
             if warehouse_name is not None:
-                cursor.execute(
-                    f"USE WAREHOUSE /* backup_warehouse */ {warehouse_name};"
-                )
+                cursor.execute(f"USE WAREHOUSE /* backup_warehouse */ {warehouse_name};")
 
 
 @pytest.fixture
 @pytest.mark.usefixtures("backup_database_schema")
 def temp_db(databases: DatabaseCollection) -> Iterator[DatabaseResource]:
     # create temp database
     db_name = random_string(5, "test_database_")
@@ -361,47 +356,87 @@
         yield db
     finally:
         db.delete()
 
 
 @pytest.fixture
 @pytest.mark.usefixtures("backup_database_schema")
+def temp_db_case_sensitive(databases: DatabaseCollection) -> Iterator[DatabaseResource]:
+    # create temp database
+    db_name = random_string(5, "test_database_case_sensitive_")
+    db_name_case_sensitive = '"' + db_name + '"'
+    test_db = Database(name=db_name_case_sensitive, comment="created by temp_case_sensitive_db")
+    db = databases.create(test_db)
+    try:
+        yield db
+    finally:
+        db.delete()
+
+
+@pytest.fixture
+@pytest.mark.usefixtures("backup_database_schema")
 def temp_schema(schemas) -> Iterator[SchemaResource]:
     schema_name = random_string(5, "test_schema_")
     test_schema = Schema(
         name=schema_name,
         comment="created by temp_schema",
     )
     sc = schemas.create(test_schema)
     try:
         yield sc
     finally:
         sc.delete()
 
 
+@pytest.fixture
+@pytest.mark.usefixtures("backup_database_schema")
+def temp_schema_case_sensitive(schemas) -> Iterator[SchemaResource]:
+    schema_name = random_string(5, "test_schema_case_sensitive_")
+    schema_name_case_sensitive = '"' + schema_name + '"'
+    test_schema = Schema(
+        name=schema_name_case_sensitive,
+        comment="created by temp_schema_case_sensitive",
+    )
+    sc = schemas.create(test_schema)
+    try:
+        yield sc
+    finally:
+        sc.delete()
+
+
 @pytest.fixture(params=[False, True], ids=("bridge", "rest"))
 def use_rest(request, root):
     if "skip_bridge" in request.keywords and not request.param:
         pytest.skip("Skipping test over the client bridge.")
     if "skip_rest" in request.keywords and request.param:
         pytest.skip("Skipping test over REST.")
 
     orig_setting = root._can_use_rest_api
     root._can_use_rest_api = request.param
     try:
         yield
     finally:
         root._can_use_rest_api = orig_setting
 
+@pytest.fixture
+def force_rest(root):
+    orig_setting = root._can_use_rest_api
+    root._can_use_rest_api = True
+    try:
+        yield
+    finally:
+        root._can_use_rest_api = orig_setting
 
 # this is temporary
 @pytest.fixture(params=[False, True], ids=("bridge", "rest"))
 def setup_rest_api_parameters_for_table(session, root, request):
     if "skip_rest" in request.keywords and request.param:
         pytest.skip("Skipping test over REST.")
+    if "skip_bridge" in request.keywords and not request.param:
+        pytest.skip("Skipping test over the client bridge.")
 
     orig_setting = root._can_use_rest_api
     root._can_use_rest_api = request.param
     if request.param:
         session.sql("alter session set enable_snow_api_for_table = 'enable'").collect()
     else:
         session.sql("alter session set enable_snow_api_for_table = 'disable'").collect()
@@ -414,62 +449,51 @@
 
 # TODO: SNOW-1297234 Organize NamedTuples in stack
 class Tuple_database(NamedTuple):
     name: str
     param: str
 
 
-AUTO_database = Tuple_database(
-    name="TESTDB_PYTHON_AUTO", param="DATA_RETENTION_TIME_IN_DAYS=1"
-)
+AUTO_database = Tuple_database(name="TESTDB_PYTHON_AUTO", param="DATA_RETENTION_TIME_IN_DAYS=1")
 
 
 class Tuple_schema(NamedTuple):
     name: str
     db: str
 
 
 AUTO_schema = Tuple_schema(name=TEST_SCHEMA, db="TESTDB_PYTHON_AUTO")
 
 
 @pytest.fixture(scope="session", autouse=True)
 def setup_basic(connection):
     with connection.cursor() as cursor:
         # Like backup_database_schema, but scope of this fixture is session
-        database_name = cursor.execute(
-            "SELECT /* setup_basic */ CURRENT_DATABASE()"
-        ).fetchone()[0]
-        schema_name = cursor.execute(
-            "SELECT /* setup_basic */ CURRENT_SCHEMA()"
-        ).fetchone()[0]
+        database_name = cursor.execute("SELECT /* setup_basic */ CURRENT_DATABASE()").fetchone()[0]
+        schema_name = cursor.execute("SELECT /* setup_basic */ CURRENT_SCHEMA()").fetchone()[0]
 
         # Database
         cursor.execute(
-            "CREATE DATABASE IF NOT EXISTS /* setup_basic */ "
-            f"{AUTO_database.name} {AUTO_database.param}",
+            "CREATE DATABASE IF NOT EXISTS /* setup_basic */ " f"{AUTO_database.name} {AUTO_database.param}",
         )
 
         # Schema
         cursor.execute(f"USE DATABASE {AUTO_schema.db}")
         cursor.execute(f"CREATE SCHEMA IF NOT EXISTS {AUTO_schema.name}")
 
         cursor.execute("USE DATABASE TESTDB_PYTHON_AUTO")
         cursor.execute(f"USE SCHEMA {TEST_SCHEMA}")
 
         try:
             yield
         finally:
             if schema_name is not None:
-                cursor.execute(
-                    f"USE SCHEMA /* backup_database_schema */ {database_name}.{schema_name}"
-                )
+                cursor.execute(f"USE SCHEMA /* backup_database_schema */ {database_name}.{schema_name}")
             elif database_name is not None:
-                cursor.execute(
-                    f"USE DATABASE /* backup_database_schema */ {database_name}"
-                )
+                cursor.execute(f"USE DATABASE /* backup_database_schema */ {database_name}")
 
 
 @pytest.fixture
 def imagerepo() -> str:
     # When adding an inlined image repository YAML file, don't hard code the path to the test image
     # repository.  Instead, use this fixture and f-string this value in for the `{imagrepo}` substitution.
     # This way, there's only one thing to change across the entire test suite.
```

### Comparing `snowflake_core-0.8.0/tests/integ/setup_manually.py` & `snowflake_core-0.8.1/tests/integ/setup_manually.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/test_cortex_search_service.py` & `snowflake_core-0.8.1/tests/integ/test_cortex_search_service.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/utils.py` & `snowflake_core-0.8.1/tests/integ/utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -17,18 +17,17 @@
         f"scheduled_time_range_start=>dateadd('hour',-1,current_timestamp()),"
         f"result_limit => 10,task_name=>'{name}'))"
     )
     return session.sql(query).collect()
 
 
 def string_skip_space_and_cases(s):
-    return s.replace(' ','').upper()
+    return s.replace(" ", "").upper()
 
 
 def array_equal_comparison(arr1, arr2):
     if not arr1 and not arr2:
         return True
     if not arr1 or not arr2:
         return False
 
-    return [string_skip_space_and_cases(i) for i in arr1] \
-        == [string_skip_space_and_cases(i) for i in arr2]
+    return [string_skip_space_and_cases(i) for i in arr1] == [string_skip_space_and_cases(i) for i in arr2]
```

### Comparing `snowflake_core-0.8.0/tests/integ/task/conftest.py` & `snowflake_core-0.8.1/tests/integ/task/conftest.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_create_or_update_task.py` & `snowflake_core-0.8.1/tests/integ/task/test_create_or_update_task.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_create_task.py` & `snowflake_core-0.8.1/tests/integ/task/test_create_task.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_drop_task.py` & `snowflake_core-0.8.1/tests/integ/task/test_drop_task.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_execute_task.py` & `snowflake_core-0.8.1/tests/integ/task/test_execute_task.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_load_task.py` & `snowflake_core-0.8.1/tests/integ/task/test_load_task.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_python_function.py` & `snowflake_core-0.8.1/tests/integ/task/test_python_function.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_show_task.py` & `snowflake_core-0.8.1/tests/integ/task/test_show_task.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/test_task_parameters.py` & `snowflake_core-0.8.1/tests/integ/task/test_task_parameters.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/integ/task/dag/test_dag.py` & `snowflake_core-0.8.1/tests/integ/task/dag/test_dag.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/conftest.py` & `snowflake_core-0.8.1/tests/unit/conftest.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/test_common.py` & `snowflake_core-0.8.1/tests/unit/test_common.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/test_database.py` & `snowflake_core-0.8.1/tests/unit/test_database.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/test_schema.py` & `snowflake_core-0.8.1/tests/unit/test_schema.py`

 * *Files 13% similar despite different names*

```diff
@@ -54,19 +54,18 @@
                 trace_level="always",
             ),
             kind="transient",
         )
     mocked_request.assert_called_once_with(
         fake_root,
         "POST",
-        "http://localhost:80/api/v2/databases/my_db/schemas?createMode=errorIfExists&kind=transient&with_managed_access=False",
+        "http://localhost:80/api/v2/databases/my_db/schemas?createMode=errorIfExists&kind=transient",
         query_params=[
             ("createMode", "errorIfExists"),
             ("kind", "transient"),
-            ("with_managed_access", False),
         ],
         headers={
             "Accept": "application/json",
             "Content-Type": "application/json",
             "User-Agent": SNOWPY_USER_AGENT_VAL,
         },
         post_params=[],
```

### Comparing `snowflake_core-0.8.0/tests/unit/test_table.py` & `snowflake_core-0.8.1/tests/unit/test_table.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/api/general_api_test.py` & `snowflake_core-0.8.1/tests/unit/api/general_api_test.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/bridge/test_database.py` & `snowflake_core-0.8.1/tests/unit/bridge/test_database.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/bridge/test_executor.py` & `snowflake_core-0.8.1/tests/unit/bridge/test_executor.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/bridge/test_rest_errors.py` & `snowflake_core-0.8.1/tests/unit/bridge/test_rest_errors.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/bridge/test_schema.py` & `snowflake_core-0.8.1/tests/unit/bridge/test_schema.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/resources/test_computepool_resource.py` & `snowflake_core-0.8.1/tests/unit/resources/test_computepool_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/resources/test_service.py` & `snowflake_core-0.8.1/tests/unit/resources/test_service.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/resources/test_task_resource.py` & `snowflake_core-0.8.1/tests/unit/resources/test_task_resource.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/task/test_dagv1.py` & `snowflake_core-0.8.1/tests/unit/task/test_dagv1.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/task/test_task_context.py` & `snowflake_core-0.8.1/tests/unit/task/test_task_context.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/tests/unit/task/test_task_reference.py` & `snowflake_core-0.8.1/tests/unit/task/test_task_reference.py`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/.gitignore` & `snowflake_core-0.8.1/.gitignore`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/LICENSE` & `snowflake_core-0.8.1/LICENSE`

 * *Files identical despite different names*

### Comparing `snowflake_core-0.8.0/pyproject.toml` & `snowflake_core-0.8.1/pyproject.toml`

 * *Files 2% similar despite different names*

```diff
@@ -32,15 +32,15 @@
     'Topic :: Software Development :: Libraries',
     'Topic :: Software Development :: Libraries :: Application Frameworks',
     'Topic :: Software Development :: Libraries :: Python Modules',
     'Topic :: Scientific/Engineering :: Information Analysis',
 ]
 dependencies = [
     'atpublic>=4',
-    'pydantic>=1.10.7',
+    'pydantic>=2',
     'python-dateutil>=2.8.2',
     'snowflake-snowpark-python>=1.5.0,<2.0.0',
     'urllib3',
 ]
 dynamic = ['version']
 
 # [project.urls]
```

### Comparing `snowflake_core-0.8.0/PKG-INFO` & `snowflake_core-0.8.1/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.3
 Name: snowflake.core
-Version: 0.8.0
+Version: 0.8.1
 Summary: Snowflake Python API for Resource Management
 Author-email: "Snowflake, Inc." <snowflake-python-libraries-dl@snowflake.com>
 License: Apache-2.0
 License-File: LICENSE
 Keywords: Snowflake,analytics,cloud,database,db,warehouse
 Classifier: Development Status :: 4 - Beta
 Classifier: Environment :: Console
@@ -21,15 +21,15 @@
 Classifier: Topic :: Scientific/Engineering :: Information Analysis
 Classifier: Topic :: Software Development
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Requires-Python: <3.12,>=3.8
 Requires-Dist: atpublic>=4
-Requires-Dist: pydantic>=1.10.7
+Requires-Dist: pydantic>=2
 Requires-Dist: python-dateutil>=2.8.2
 Requires-Dist: snowflake-snowpark-python<2.0.0,>=1.5.0
 Requires-Dist: urllib3
 Description-Content-Type: text/markdown
 
 `snowflake.core` is the subpackage providing Python access to Snowflake entity metadata.
```

