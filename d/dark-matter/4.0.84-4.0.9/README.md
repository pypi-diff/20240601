# Comparing `tmp/dark-matter-4.0.84.tar.gz` & `tmp/dark-matter-4.0.9.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dark-matter-4.0.84.tar", last modified: Sat Jun  1 07:06:35 2024, max compression
+gzip compressed data, was "dark-matter-4.0.9.tar", last modified: Sun Oct  3 19:42:47 2021, max compression
```

## Comparing `dark-matter-4.0.84.tar` & `dark-matter-4.0.9.tar`

### file list

```diff
@@ -1,223 +1,206 @@
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.838489 dark-matter-4.0.84/
--rw-r--r--   0 terry      (501) staff       (20)     1115 2015-05-01 08:27:42.000000 dark-matter-4.0.84/LICENSE
--rw-r--r--   0 terry      (501) staff       (20)     1235 2024-06-01 07:06:35.838285 dark-matter-4.0.84/PKG-INFO
--rw-rw-r--   0 terry      (501) staff       (20)     2322 2022-06-24 14:26:41.000000 dark-matter-4.0.84/README.md
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.812998 dark-matter-4.0.84/bin/
--rwxrwxr-x   0 terry      (501) staff       (20)     1683 2023-09-03 20:11:46.000000 dark-matter-4.0.84/bin/aa-info.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1350 2023-09-03 13:30:10.000000 dark-matter-4.0.84/bin/aa-to-dna.py
--rwxrwxr-x   0 terry      (501) staff       (20)      497 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/aa-to-properties.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1193 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/adaptor-distances.py
--rwxrwxr-x   0 terry      (501) staff       (20)    17669 2024-05-06 20:55:39.000000 dark-matter-4.0.84/bin/alignment-panel-civ.py
--rwxrwxr-x   0 terry      (501) staff       (20)      722 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/alignments-per-read.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1343 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/bit-score-to-e-value.py
--rwxrwxr-x   0 terry      (501) staff       (20)      338 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/cat-json-blast-records.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3209 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/check-fasta-json-blast-consistency.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1911 2023-09-03 13:30:30.000000 dark-matter-4.0.84/bin/codon-distance.py
--rwxrwxr-x   0 terry      (501) staff       (20)     7872 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/compare-consensuses.py
--rwxrwxr-x   0 terry      (501) staff       (20)     8748 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/compare-sequences.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1295 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/convert-blast-xml-to-json.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1680 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/convert-diamond-to-json.py
--rwxrwxr-x   0 terry      (501) staff       (20)     4954 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/convert-diamond-to-sam.py
--rwxr-xr-x   0 terry      (501) staff       (20)      528 2015-05-01 08:27:43.000000 dark-matter-4.0.84/bin/convert-sam-to-fastq.sh
--rwxrwxr-x   0 terry      (501) staff       (20)     1344 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/create-newick-relabeling-output.py
--rwxrwxr-x   0 terry      (501) staff       (20)       72 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/dark-matter-version.py
--rwxrwxr-x   0 terry      (501) staff       (20)      464 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/describe-protein-database.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1781 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/dna-to-aa.py
--rwxrwxr-x   0 terry      (501) staff       (20)     5393 2021-08-17 14:54:38.000000 dark-matter-4.0.84/bin/download-genbank.sh
--rwxrwxr-x   0 terry      (501) staff       (20)      602 2022-06-24 14:26:41.000000 dark-matter-4.0.84/bin/download-refseq-viral-fasta.sh
--rwxrwxr-x   0 terry      (501) staff       (20)      766 2023-07-17 13:23:29.000000 dark-matter-4.0.84/bin/download-refseq-viral-gbff.sh
--rwxrwxr-x   0 terry      (501) staff       (20)     1337 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/e-value-to-bit-score.py
--rwxrwxr-x   0 terry      (501) staff       (20)     5717 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/extract-ORFs.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3016 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-base-indices.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1437 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-count-chars.py
--rwxrwxr-x   0 terry      (501) staff       (20)      542 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-count.py
--rwxrwxr-x   0 terry      (501) staff       (20)     5559 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-coverage.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3765 2021-08-17 14:54:05.000000 dark-matter-4.0.84/bin/fasta-diff.sh
--rwxrwxr-x   0 terry      (501) staff       (20)     6366 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-find.py
--rwxrwxr-x   0 terry      (501) staff       (20)    32673 2024-03-17 18:58:09.000000 dark-matter-4.0.84/bin/fasta-identity-table.py
--rwxrwxr-x   0 terry      (501) staff       (20)      479 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-ids.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1368 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-join.py
--rwxrwxr-x   0 terry      (501) staff       (20)      499 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-lengths.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3772 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-match-offsets.py
--rwxrwxr-x   0 terry      (501) staff       (20)      445 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-sequences.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1658 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-sort.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3840 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-split-by-id.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3680 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-split.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1652 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-subset.py
--rwxrwxr-x   0 terry      (501) staff       (20)      403 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-subtraction.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1845 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-to-phylip.py
--rwxrwxr-x   0 terry      (501) staff       (20)      488 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-translate.py
--rwxrwxr-x   0 terry      (501) staff       (20)     5417 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/fasta-variable-sites.py
--rwxrwxr-x   0 terry      (501) staff       (20)      720 2023-08-29 15:49:19.000000 dark-matter-4.0.84/bin/fastq-set-quality.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3183 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/filter-fasta-by-complexity.py
--rwxrwxr-x   0 terry      (501) staff       (20)     4350 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/filter-fasta-by-taxonomy.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3821 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/filter-fasta.py
--rwxrwxr-x   0 terry      (501) staff       (20)     6515 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/filter-hits-to-fasta.py
--rwxrwxr-x   0 terry      (501) staff       (20)     9135 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/filter-reads-alignments.py
--rwxrwxr-x   0 terry      (501) staff       (20)     4885 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/filter-sam.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3122 2024-04-22 14:36:36.000000 dark-matter-4.0.84/bin/format-fasta.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2787 2024-03-12 05:12:26.000000 dark-matter-4.0.84/bin/genbank-grep.py
--rwxrwxr-x   0 terry      (501) staff       (20)     9231 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/genome-protein-summary.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2214 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/get-features.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2274 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/get-hosts.py
--rwxrwxr-x   0 terry      (501) staff       (20)     4560 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/get-reads.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2957 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/get-taxonomy.py
--rwxrwxr-x   0 terry      (501) staff       (20)      647 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/graph-evalues.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1779 2024-05-23 23:27:04.000000 dark-matter-4.0.84/bin/ids.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1555 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/local-align.py
--rwxrwxr-x   0 terry      (501) staff       (20)    10590 2024-04-02 12:11:31.000000 dark-matter-4.0.84/bin/make-consensus.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2531 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/make-fasta-database.py
--rwxrwxr-x   0 terry      (501) staff       (20)    10418 2024-03-12 05:12:26.000000 dark-matter-4.0.84/bin/make-protein-database.py
--rwxrwxr-x   0 terry      (501) staff       (20)      918 2024-04-01 20:06:20.000000 dark-matter-4.0.84/bin/ncbi-fetch-id.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1705 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/newick-to-ascii.py
--rwxrwxr-x   0 terry      (501) staff       (20)    20621 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/noninteractive-alignment-panel.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1413 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/parse-genbank-flat-file.py
--rwxrwxr-x   0 terry      (501) staff       (20)    11042 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/plot-references-by-inter-read-distance.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1032 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/position-summary.py
--rwxrwxr-x   0 terry      (501) staff       (20)      862 2021-08-17 14:54:05.000000 dark-matter-4.0.84/bin/pre-commit.sh
--rwxrwxr-x   0 terry      (501) staff       (20)      918 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/print-read-lengths.py
--rwxrwxr-x   0 terry      (501) staff       (20)    12568 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/proteins-to-pathogens-civ.py
--rwxrwxr-x   0 terry      (501) staff       (20)    12307 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/proteins-to-pathogens.py
--rwxrwxr-x   0 terry      (501) staff       (20)      576 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/randomize-fasta.py
--rwxrwxr-x   0 terry      (501) staff       (20)      718 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/read-blast-json.py
--rwxrwxr-x   0 terry      (501) staff       (20)      649 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/read-blast-xml.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2785 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/reference-read-scores-to-JSON.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2555 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/relabel-newick-tree.py
--rwxrwxr-x   0 terry      (501) staff       (20)    15271 2024-03-28 13:36:00.000000 dark-matter-4.0.84/bin/run-bowtie2.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3567 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/run-bwa.py
--rwxrwxr-x   0 terry      (501) staff       (20)     9568 2024-03-28 15:54:37.000000 dark-matter-4.0.84/bin/sam-coverage-depth.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2668 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/sam-coverage.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2862 2024-04-02 16:28:12.000000 dark-matter-4.0.84/bin/sam-reference-read-counts.py
--rwxrwxr-x   0 terry      (501) staff       (20)      404 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/sam-references.py
--rwxrwxr-x   0 terry      (501) staff       (20)     3430 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/sam-to-fasta-alignment.py
--rwxrwxr-x   0 terry      (501) staff       (20)      236 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/sff-to-fastq.py
--rwxrwxr-x   0 terry      (501) staff       (20)     7850 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/simple-consensus.py
--rwxrwxr-x   0 terry      (501) staff       (20)     6305 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/split-fasta-by-adaptors.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2401 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/subset-protein-database.py
--rwxrwxr-x   0 terry      (501) staff       (20)     2916 2023-09-03 13:30:49.000000 dark-matter-4.0.84/bin/summarize-fasta-bases.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1005 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/summarize-reads.py
--rwxrwxr-x   0 terry      (501) staff       (20)      221 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/translate.py
--rwxrwxr-x   0 terry      (501) staff       (20)     1712 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/trim-primers.py
--rwxrwxr-x   0 terry      (501) staff       (20)      508 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/trim-reads.py
--rwxrwxr-x   0 terry      (501) staff       (20)     9607 2023-07-24 14:01:45.000000 dark-matter-4.0.84/bin/write-htcondor-job-spec.py
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.824938 dark-matter-4.0.84/dark/
--rw-rw-r--   0 terry      (501) staff       (20)      358 2024-06-01 07:00:51.000000 dark-matter-4.0.84/dark/__init__.py
--rw-rw-r--   0 terry      (501) staff       (20)    14684 2023-09-03 20:00:32.000000 dark-matter-4.0.84/dark/aa.py
--rw-rw-r--   0 terry      (501) staff       (20)    26020 2024-02-24 20:03:30.000000 dark-matter-4.0.84/dark/aaVars.py
--rw-rw-r--   0 terry      (501) staff       (20)    10097 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/aligners.py
--rw-rw-r--   0 terry      (501) staff       (20)    20652 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/alignments.py
--rw-rw-r--   0 terry      (501) staff       (20)     1506 2024-01-20 09:23:50.000000 dark-matter-4.0.84/dark/analyze_reads.py
--rw-rw-r--   0 terry      (501) staff       (20)      846 2024-01-20 09:23:50.000000 dark-matter-4.0.84/dark/baseimage.py
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.826434 dark-matter-4.0.84/dark/blast/
--rw-r--r--   0 terry      (501) staff       (20)        0 2015-05-01 08:27:43.000000 dark-matter-4.0.84/dark/blast/__init__.py
--rw-rw-r--   0 terry      (501) staff       (20)    11389 2024-04-27 16:38:08.000000 dark-matter-4.0.84/dark/blast/alignments.py
--rw-rw-r--   0 terry      (501) staff       (20)    12637 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/blast/conversion.py
--rw-rw-r--   0 terry      (501) staff       (20)     1021 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/blast/hacks.py
--rw-rw-r--   0 terry      (501) staff       (20)     7674 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/blast/hsp.py
--rw-rw-r--   0 terry      (501) staff       (20)     1841 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/blast/params.py
--rw-rw-r--   0 terry      (501) staff       (20)     1057 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/blast/records.py
--rw-rw-r--   0 terry      (501) staff       (20)     2195 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/blast/score.py
--rw-rw-r--   0 terry      (501) staff       (20)    13314 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/bowtie2.py
--rw-rw-r--   0 terry      (501) staff       (20)     5650 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/btop.py
--rw-rw-r--   0 terry      (501) staff       (20)     9831 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/cigar.py
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.827293 dark-matter-4.0.84/dark/civ/
--rw-rw-r--   0 terry      (501) staff       (20)        0 2021-08-17 14:54:38.000000 dark-matter-4.0.84/dark/civ/__init__.py
--rw-rw-r--   0 terry      (501) staff       (20)    21983 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/civ/graphics.py
--rw-rw-r--   0 terry      (501) staff       (20)     6782 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/civ/html.py
--rw-rw-r--   0 terry      (501) staff       (20)   101648 2024-06-01 07:00:51.000000 dark-matter-4.0.84/dark/civ/proteins.py
--rw-rw-r--   0 terry      (501) staff       (20)     1475 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/codonDistance.py
--rw-rw-r--   0 terry      (501) staff       (20)     3819 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/colors.py
--rw-rw-r--   0 terry      (501) staff       (20)    32161 2023-07-17 15:32:55.000000 dark-matter-4.0.84/dark/consensus-with-debugging.py
--rw-rw-r--   0 terry      (501) staff       (20)    29167 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/consensus.py
--rw-rw-r--   0 terry      (501) staff       (20)      299 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/database.py
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.828580 dark-matter-4.0.84/dark/diamond/
--rw-r--r--   0 terry      (501) staff       (20)        0 2016-10-24 09:27:12.000000 dark-matter-4.0.84/dark/diamond/__init__.py
--rw-rw-r--   0 terry      (501) staff       (20)     8983 2024-04-27 16:38:36.000000 dark-matter-4.0.84/dark/diamond/alignments.py
--rw-rw-r--   0 terry      (501) staff       (20)    19314 2024-05-31 07:28:43.000000 dark-matter-4.0.84/dark/diamond/conversion.py
--rw-rw-r--   0 terry      (501) staff       (20)     9124 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/diamond/hsp.py
--rw-rw-r--   0 terry      (501) staff       (20)     3410 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/diamond/run.py
--rw-rw-r--   0 terry      (501) staff       (20)    16338 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/diamond/sam.py
--rw-rw-r--   0 terry      (501) staff       (20)     1824 2024-05-23 20:24:36.000000 dark-matter-4.0.84/dark/dimension.py
--rw-rw-r--   0 terry      (501) staff       (20)     1497 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/distance.py
--rw-rw-r--   0 terry      (501) staff       (20)    26920 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/dna.py
--rw-rw-r--   0 terry      (501) staff       (20)      994 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/entrez.py
--rw-rw-r--   0 terry      (501) staff       (20)      397 2021-08-17 14:54:38.000000 dark-matter-4.0.84/dark/errors.py
--rw-rw-r--   0 terry      (501) staff       (20)    16930 2024-06-01 07:00:51.000000 dark-matter-4.0.84/dark/fasta.py
--rw-rw-r--   0 terry      (501) staff       (20)     3871 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/fasta_ss.py
--rw-rw-r--   0 terry      (501) staff       (20)     1473 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/fastq.py
--rw-rw-r--   0 terry      (501) staff       (20)    12190 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/features.py
--rw-rw-r--   0 terry      (501) staff       (20)    25172 2024-04-22 14:36:36.000000 dark-matter-4.0.84/dark/filter.py
--rw-rw-r--   0 terry      (501) staff       (20)     2121 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/fpcache.py
--rw-rw-r--   0 terry      (501) staff       (20)    16657 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/genbank.py
--rw-rw-r--   0 terry      (501) staff       (20)     9623 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/genomes.py
--rw-rw-r--   0 terry      (501) staff       (20)    37556 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/graphics.py
--rw-rw-r--   0 terry      (501) staff       (20)     7191 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/hsp.py
--rw-rw-r--   0 terry      (501) staff       (20)    12123 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/html.py
--rw-rw-r--   0 terry      (501) staff       (20)     4039 2024-05-23 23:27:04.000000 dark-matter-4.0.84/dark/idutils.py
--rw-rw-r--   0 terry      (501) staff       (20)     6017 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/intervals.py
--rw-rw-r--   0 terry      (501) staff       (20)     1188 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/ipynb.py
--rw-rw-r--   0 terry      (501) staff       (20)    15243 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/local_align.py
--rw-rw-r--   0 terry      (501) staff       (20)    17331 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/mutations.py
--rw-rw-r--   0 terry      (501) staff       (20)      540 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/ncbidb.py
--rw-rw-r--   0 terry      (501) staff       (20)     2990 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/orfs.py
--rw-rw-r--   0 terry      (501) staff       (20)     4637 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/process.py
--rw-rw-r--   0 terry      (501) staff       (20)     1148 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/progress.py
--rw-rw-r--   0 terry      (501) staff       (20)    45709 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/proteins.py
--rw-rw-r--   0 terry      (501) staff       (20)    78593 2024-04-22 14:36:36.000000 dark-matter-4.0.84/dark/reads.py
--rw-rw-r--   0 terry      (501) staff       (20)    58490 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/sam.py
--rw-rw-r--   0 terry      (501) staff       (20)     1873 2024-01-20 09:23:50.000000 dark-matter-4.0.84/dark/score.py
--rw-rw-r--   0 terry      (501) staff       (20)     2940 2023-07-24 14:01:45.000000 dark-matter-4.0.84/dark/sequence.py
--rw-rw-r--   0 terry      (501) staff       (20)     1160 2024-04-22 14:36:36.000000 dark-matter-4.0.84/dark/simplify.py
--rw-rw-r--   0 terry      (501) staff       (20)      697 2024-06-01 07:00:51.000000 dark-matter-4.0.84/dark/sqlite3.py
--rwxrwxr-x   0 terry      (501) staff       (20)     4354 2024-01-20 09:23:50.000000 dark-matter-4.0.84/dark/summarize.py
--rw-rw-r--   0 terry      (501) staff       (20)    25083 2024-06-01 07:00:51.000000 dark-matter-4.0.84/dark/taxonomy.py
--rw-rw-r--   0 terry      (501) staff       (20)    20481 2024-04-02 16:28:12.000000 dark-matter-4.0.84/dark/titles.py
--rw-rw-r--   0 terry      (501) staff       (20)    11073 2024-05-06 20:55:39.000000 dark-matter-4.0.84/dark/utils.py
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.829164 dark-matter-4.0.84/dark_matter.egg-info/
--rw-r--r--   0 terry      (501) staff       (20)     1235 2024-06-01 07:06:35.000000 dark-matter-4.0.84/dark_matter.egg-info/PKG-INFO
--rw-rw-r--   0 terry      (501) staff       (20)     4660 2024-06-01 07:06:35.000000 dark-matter-4.0.84/dark_matter.egg-info/SOURCES.txt
--rw-rw-r--   0 terry      (501) staff       (20)        1 2024-06-01 07:06:35.000000 dark-matter-4.0.84/dark_matter.egg-info/dependency_links.txt
--rw-rw-r--   0 terry      (501) staff       (20)      263 2024-06-01 07:06:35.000000 dark-matter-4.0.84/dark_matter.egg-info/requires.txt
--rw-rw-r--   0 terry      (501) staff       (20)        5 2024-06-01 07:06:35.000000 dark-matter-4.0.84/dark_matter.egg-info/top_level.txt
--rw-rw-r--   0 terry      (501) staff       (20)       38 2024-06-01 07:06:35.838529 dark-matter-4.0.84/setup.cfg
--rw-rw-r--   0 terry      (501) staff       (20)     5132 2024-05-23 23:27:04.000000 dark-matter-4.0.84/setup.py
-drwxrwxr-x   0 terry      (501) staff       (20)        0 2024-06-01 07:06:35.837838 dark-matter-4.0.84/test/
--rw-rw-r--   0 terry      (501) staff       (20)    41381 2024-04-27 16:39:26.000000 dark-matter-4.0.84/test/test_aa.py
--rw-rw-r--   0 terry      (501) staff       (20)    17062 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_aligners.py
--rw-rw-r--   0 terry      (501) staff       (20)     7240 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_alignments.py
--rw-rw-r--   0 terry      (501) staff       (20)     4507 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_analyze_reads.py
--rw-rw-r--   0 terry      (501) staff       (20)    18678 2024-04-02 16:28:12.000000 dark-matter-4.0.84/test/test_bowtie2.py
--rw-rw-r--   0 terry      (501) staff       (20)    10313 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_btop.py
--rw-rw-r--   0 terry      (501) staff       (20)    15671 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_cigar.py
--rw-rw-r--   0 terry      (501) staff       (20)     1524 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_codonDistance.py
--rw-rw-r--   0 terry      (501) staff       (20)     5973 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_colors.py
--rw-rw-r--   0 terry      (501) staff       (20)    48052 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_consensus.py
--rw-rw-r--   0 terry      (501) staff       (20)     5735 2024-05-23 20:24:36.000000 dark-matter-4.0.84/test/test_dimension.py
--rw-rw-r--   0 terry      (501) staff       (20)      711 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_distance.py
--rw-rw-r--   0 terry      (501) staff       (20)    67958 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_dna.py
--rw-rw-r--   0 terry      (501) staff       (20)    41561 2024-04-02 16:28:12.000000 dark-matter-4.0.84/test/test_fasta.py
--rw-rw-r--   0 terry      (501) staff       (20)     6288 2024-04-02 16:28:12.000000 dark-matter-4.0.84/test/test_fasta_ss.py
--rw-rw-r--   0 terry      (501) staff       (20)     4442 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_fastq.py
--rw-rw-r--   0 terry      (501) staff       (20)    21611 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_features.py
--rw-rw-r--   0 terry      (501) staff       (20)    19245 2024-04-22 14:36:36.000000 dark-matter-4.0.84/test/test_filter.py
--rw-rw-r--   0 terry      (501) staff       (20)    18170 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_genbank.py
--rw-rw-r--   0 terry      (501) staff       (20)     8670 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_genomes.py
--rw-rw-r--   0 terry      (501) staff       (20)     1334 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_graphics.py
--rw-rw-r--   0 terry      (501) staff       (20)     6147 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_hsp.py
--rw-rw-r--   0 terry      (501) staff       (20)     3003 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_html.py
--rw-rw-r--   0 terry      (501) staff       (20)     4657 2024-05-23 23:27:04.000000 dark-matter-4.0.84/test/test_idutils.py
--rw-rw-r--   0 terry      (501) staff       (20)    20880 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_intervals.py
--rw-rw-r--   0 terry      (501) staff       (20)    11430 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_local_align.py
--rw-rw-r--   0 terry      (501) staff       (20)     4652 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_mutations.py
--rw-rw-r--   0 terry      (501) staff       (20)     1292 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_orfs.py
--rw-rw-r--   0 terry      (501) staff       (20)     2737 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_process.py
--rw-rw-r--   0 terry      (501) staff       (20)    50554 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_proteins.py
--rw-rw-r--   0 terry      (501) staff       (20)   151374 2024-03-12 10:16:59.000000 dark-matter-4.0.84/test/test_reads.py
--rw-rw-r--   0 terry      (501) staff       (20)    79113 2024-04-02 16:28:12.000000 dark-matter-4.0.84/test/test_sam.py
--rw-r--r--   0 terry      (501) staff       (20)     1685 2015-05-01 08:27:43.000000 dark-matter-4.0.84/test/test_score.py
--rw-rw-r--   0 terry      (501) staff       (20)     5190 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_sequence.py
--rw-rw-r--   0 terry      (501) staff       (20)     1932 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_simplify.py
--rw-rw-r--   0 terry      (501) staff       (20)     9506 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_summarize.py
--rw-rw-r--   0 terry      (501) staff       (20)    19227 2024-03-12 05:12:26.000000 dark-matter-4.0.84/test/test_taxonomy.py
--rw-rw-r--   0 terry      (501) staff       (20)    43907 2023-07-24 14:01:45.000000 dark-matter-4.0.84/test/test_titles.py
--rw-rw-r--   0 terry      (501) staff       (20)    19857 2024-05-06 20:55:39.000000 dark-matter-4.0.84/test/test_utils.py
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.614698 dark-matter-4.0.9/
+-rw-rw-r--   0 terry      (501) staff       (20)      763 2021-10-03 19:42:47.614442 dark-matter-4.0.9/PKG-INFO
+-rw-rw-r--   0 terry      (501) staff       (20)     2244 2021-08-17 14:54:46.000000 dark-matter-4.0.9/README.md
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.586204 dark-matter-4.0.9/bin/
+-rwxrwxr-x   0 terry      (501) staff       (20)     1170 2021-08-17 14:54:46.000000 dark-matter-4.0.9/bin/aa-info.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     1370 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/aa-to-dna.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      528 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/aa-to-properties.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1204 2016-09-07 14:55:30.000000 dark-matter-4.0.9/bin/adaptor-distances.py
+-rwxrwxr-x   0 terry      (501) staff       (20)    16440 2021-08-17 14:54:53.000000 dark-matter-4.0.9/bin/alignment-panel-civ.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      753 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/alignments-per-read.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1273 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/bit-score-to-e-value.py
+-rwxrwxr-x   0 terry      (501) staff       (20)      377 2021-08-17 14:54:46.000000 dark-matter-4.0.9/bin/cat-json-blast-records.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     2968 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/check-fasta-json-blast-consistency.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     1388 2021-08-17 14:54:53.000000 dark-matter-4.0.9/bin/codon-distance.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     7658 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/compare-consensuses.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     7064 2021-08-17 14:54:50.000000 dark-matter-4.0.9/bin/compare-sequences.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1179 2016-10-24 23:36:53.000000 dark-matter-4.0.9/bin/convert-blast-xml-to-json.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1584 2016-10-31 17:37:21.000000 dark-matter-4.0.9/bin/convert-diamond-to-json.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     4841 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/convert-diamond-to-sam.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      528 2015-05-01 08:27:43.000000 dark-matter-4.0.9/bin/convert-sam-to-fastq.sh
+-rwxrwxr-x   0 terry      (501) staff       (20)     1342 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/create-newick-relabeling-output.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      111 2017-05-08 11:22:57.000000 dark-matter-4.0.9/bin/dark-matter-version.py
+-rwxrwxr-x   0 terry      (501) staff       (20)      520 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/describe-protein-database.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1728 2017-02-13 16:20:08.000000 dark-matter-4.0.9/bin/dna-to-aa.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     5393 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/download-genbank.sh
+-rwxr-xr-x   0 terry      (501) staff       (20)     1259 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/e-value-to-bit-score.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     5545 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/extract-ORFs.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     2968 2017-03-03 10:05:48.000000 dark-matter-4.0.9/bin/fasta-base-indices.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      588 2017-09-22 10:12:42.000000 dark-matter-4.0.9/bin/fasta-count.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     3765 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/fasta-diff.sh
+-rwxrwxr-x   0 terry      (501) staff       (20)    20538 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/fasta-identity-table.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      512 2017-03-03 10:05:48.000000 dark-matter-4.0.9/bin/fasta-ids.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     1407 2021-08-24 13:14:53.000000 dark-matter-4.0.9/bin/fasta-join.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      535 2017-02-13 16:20:08.000000 dark-matter-4.0.9/bin/fasta-lengths.py
+-rwxrwxr-x   0 terry      (501) staff       (20)      492 2021-08-17 14:54:46.000000 dark-matter-4.0.9/bin/fasta-sequences.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      506 2017-12-06 09:59:11.000000 dark-matter-4.0.9/bin/fasta-sort.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     3784 2018-01-29 11:44:38.000000 dark-matter-4.0.9/bin/fasta-split-by-id.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     3575 2021-08-17 15:14:32.000000 dark-matter-4.0.9/bin/fasta-split.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1673 2016-09-07 14:55:30.000000 dark-matter-4.0.9/bin/fasta-subset.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      419 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/fasta-subtraction.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1791 2018-03-01 09:56:23.000000 dark-matter-4.0.9/bin/fasta-to-phylip.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     4891 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/fasta-variable-sites.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     3065 2018-04-16 23:38:28.000000 dark-matter-4.0.9/bin/filter-fasta-by-complexity.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     4113 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/filter-fasta-by-taxonomy.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     3527 2021-08-17 15:16:18.000000 dark-matter-4.0.9/bin/filter-fasta.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     6147 2021-08-17 14:54:53.000000 dark-matter-4.0.9/bin/filter-hits-to-fasta.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     8530 2017-05-24 20:29:37.000000 dark-matter-4.0.9/bin/filter-reads-alignments.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     4544 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/filter-sam.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      572 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/find-hits.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     3055 2021-08-17 14:54:46.000000 dark-matter-4.0.9/bin/format-fasta.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     8720 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/genome-protein-summary.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     2136 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/get-features.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     2172 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/get-hosts.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     4263 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/get-reads.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     2893 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/get-taxonomy.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      642 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/graph-evalues.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1588 2018-01-09 15:17:05.000000 dark-matter-4.0.9/bin/local-align.py
+-rwxrwxr-x   0 terry      (501) staff       (20)    10130 2021-08-17 14:54:58.000000 dark-matter-4.0.9/bin/make-consensus.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     2377 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/make-fasta-database.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     9031 2021-08-17 14:54:50.000000 dark-matter-4.0.9/bin/make-protein-database.py
+-rwxrwxr-x   0 terry      (501) staff       (20)      845 2021-08-17 14:54:46.000000 dark-matter-4.0.9/bin/ncbi-fetch-id.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     1564 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/newick-to-ascii.py
+-rwxrwxr-x   0 terry      (501) staff       (20)    19208 2021-08-17 14:54:53.000000 dark-matter-4.0.9/bin/noninteractive-alignment-panel.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     1397 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/parse-genbank-flat-file.py
+-rwxrwxr-x   0 terry      (501) staff       (20)    10764 2021-10-01 15:32:44.000000 dark-matter-4.0.9/bin/plot-references-by-inter-read-distance.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1006 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/position-summary.py
+-rwxrwxr-x   0 terry      (501) staff       (20)      862 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/pre-commit.sh
+-rwxr-xr-x   0 terry      (501) staff       (20)      519 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/print-blast-xml-for-derek.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      517 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/print-blast-xml.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      906 2016-09-07 14:55:30.000000 dark-matter-4.0.9/bin/print-read-lengths.py
+-rwxrwxr-x   0 terry      (501) staff       (20)    11947 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/proteins-to-pathogens-civ.py
+-rwxrwxr-x   0 terry      (501) staff       (20)    11659 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/proteins-to-pathogens.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      615 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/randomize-fasta.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      729 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/read-blast-json.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      667 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/read-blast-xml.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     2564 2021-10-01 15:32:44.000000 dark-matter-4.0.9/bin/reference-read-scores-to-JSON.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     2581 2021-08-17 14:54:38.000000 dark-matter-4.0.9/bin/relabel-newick-tree.py
+-rwxrwxr-x   0 terry      (501) staff       (20)    14642 2021-08-17 14:54:58.000000 dark-matter-4.0.9/bin/run-bowtie2.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     3482 2018-04-16 23:38:28.000000 dark-matter-4.0.9/bin/run-bwa.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     4827 2021-08-17 14:54:46.000000 dark-matter-4.0.9/bin/sam-coverage-depth.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     2601 2021-08-17 14:54:46.000000 dark-matter-4.0.9/bin/sam-coverage.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     5885 2021-08-17 15:13:05.000000 dark-matter-4.0.9/bin/sam-reference-read-counts.py
+-rwxrwxr-x   0 terry      (501) staff       (20)      444 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/sam-references.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     3449 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/sam-to-fasta-alignment.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      275 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/sff-to-fastq.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     5973 2016-09-07 14:55:30.000000 dark-matter-4.0.9/bin/split-fasta-by-adaptors.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     2385 2021-08-17 14:54:05.000000 dark-matter-4.0.9/bin/subset-protein-database.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     2795 2017-02-13 16:20:08.000000 dark-matter-4.0.9/bin/summarize-fasta-bases.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     1023 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/summarize-reads.py
+-rwxrwxr-x   0 terry      (501) staff       (20)      221 2021-08-17 14:54:50.000000 dark-matter-4.0.9/bin/translate.py
+-rwxrwxr-x   0 terry      (501) staff       (20)     1709 2021-08-17 14:54:50.000000 dark-matter-4.0.9/bin/trim-primers.py
+-rwxr-xr-x   0 terry      (501) staff       (20)      557 2015-12-07 18:00:12.000000 dark-matter-4.0.9/bin/trim-reads.py
+-rwxr-xr-x   0 terry      (501) staff       (20)     9382 2016-09-07 14:55:30.000000 dark-matter-4.0.9/bin/write-htcondor-job-spec.py
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.598690 dark-matter-4.0.9/dark/
+-rw-rw-r--   0 terry      (501) staff       (20)      351 2021-10-03 19:42:37.000000 dark-matter-4.0.9/dark/__init__.py
+-rw-rw-r--   0 terry      (501) staff       (20)    37165 2021-08-17 14:54:46.000000 dark-matter-4.0.9/dark/aa.py
+-rw-rw-r--   0 terry      (501) staff       (20)     2824 2021-08-17 14:54:46.000000 dark-matter-4.0.9/dark/aligners.py
+-rw-rw-r--   0 terry      (501) staff       (20)    19331 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/alignments.py
+-rw-r--r--   0 terry      (501) staff       (20)     1411 2015-05-01 08:27:43.000000 dark-matter-4.0.9/dark/analyze_reads.py
+-rw-r--r--   0 terry      (501) staff       (20)      819 2015-05-01 08:27:43.000000 dark-matter-4.0.9/dark/baseimage.py
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.600603 dark-matter-4.0.9/dark/blast/
+-rw-r--r--   0 terry      (501) staff       (20)        0 2015-05-01 08:27:43.000000 dark-matter-4.0.9/dark/blast/__init__.py
+-rw-rw-r--   0 terry      (501) staff       (20)    11202 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/blast/alignments.py
+-rw-rw-r--   0 terry      (501) staff       (20)    12742 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/blast/conversion.py
+-rw-r--r--   0 terry      (501) staff       (20)     1061 2015-12-07 18:00:12.000000 dark-matter-4.0.9/dark/blast/hacks.py
+-rw-rw-r--   0 terry      (501) staff       (20)     7637 2021-08-17 14:54:53.000000 dark-matter-4.0.9/dark/blast/hsp.py
+-rw-rw-r--   0 terry      (501) staff       (20)     1761 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/blast/params.py
+-rw-rw-r--   0 terry      (501) staff       (20)     1057 2021-08-17 14:54:53.000000 dark-matter-4.0.9/dark/blast/records.py
+-rw-r--r--   0 terry      (501) staff       (20)     2257 2015-05-01 08:27:43.000000 dark-matter-4.0.9/dark/blast/score.py
+-rw-rw-r--   0 terry      (501) staff       (20)    12559 2021-08-17 14:54:50.000000 dark-matter-4.0.9/dark/bowtie2.py
+-rw-rw-r--   0 terry      (501) staff       (20)     5555 2021-08-17 14:54:58.000000 dark-matter-4.0.9/dark/btop.py
+-rw-rw-r--   0 terry      (501) staff       (20)     1835 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/cigar.py
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.601565 dark-matter-4.0.9/dark/civ/
+-rw-rw-r--   0 terry      (501) staff       (20)        0 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/civ/__init__.py
+-rw-rw-r--   0 terry      (501) staff       (20)    22462 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/civ/graphics.py
+-rw-rw-r--   0 terry      (501) staff       (20)     6677 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/civ/html.py
+-rw-rw-r--   0 terry      (501) staff       (20)    94038 2021-10-03 19:42:37.000000 dark-matter-4.0.9/dark/civ/proteins.py
+-rw-r--r--   0 terry      (501) staff       (20)      866 2015-05-01 08:27:43.000000 dark-matter-4.0.9/dark/codonDistance.py
+-rw-rw-r--   0 terry      (501) staff       (20)     3758 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/colors.py
+-rw-r--r--   0 terry      (501) staff       (20)     4382 2016-10-31 11:28:25.000000 dark-matter-4.0.9/dark/consensus.py
+-rw-r--r--   0 terry      (501) staff       (20)      277 2016-03-18 20:57:48.000000 dark-matter-4.0.9/dark/database.py
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.603137 dark-matter-4.0.9/dark/diamond/
+-rw-r--r--   0 terry      (501) staff       (20)        0 2016-10-24 09:27:12.000000 dark-matter-4.0.9/dark/diamond/__init__.py
+-rw-rw-r--   0 terry      (501) staff       (20)     8932 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/diamond/alignments.py
+-rw-rw-r--   0 terry      (501) staff       (20)    18385 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/diamond/conversion.py
+-rw-r--r--   0 terry      (501) staff       (20)     8972 2018-12-11 11:06:01.000000 dark-matter-4.0.9/dark/diamond/hsp.py
+-rw-rw-r--   0 terry      (501) staff       (20)     3506 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/diamond/run.py
+-rw-rw-r--   0 terry      (501) staff       (20)    15748 2021-08-17 14:54:58.000000 dark-matter-4.0.9/dark/diamond/sam.py
+-rw-rw-r--   0 terry      (501) staff       (20)     1373 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/dimension.py
+-rw-r--r--   0 terry      (501) staff       (20)     1525 2014-10-27 10:38:50.000000 dark-matter-4.0.9/dark/distance.py
+-rw-rw-r--   0 terry      (501) staff       (20)    16883 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/dna.py
+-rw-r--r--   0 terry      (501) staff       (20)      994 2015-12-07 18:00:12.000000 dark-matter-4.0.9/dark/entrez.py
+-rw-rw-r--   0 terry      (501) staff       (20)      397 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/errors.py
+-rw-rw-r--   0 terry      (501) staff       (20)    16081 2021-08-17 14:54:50.000000 dark-matter-4.0.9/dark/fasta.py
+-rw-rw-r--   0 terry      (501) staff       (20)     3741 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/fasta_ss.py
+-rw-r--r--   0 terry      (501) staff       (20)     1456 2016-12-14 13:37:44.000000 dark-matter-4.0.9/dark/fastq.py
+-rw-rw-r--   0 terry      (501) staff       (20)    12233 2021-08-17 14:54:53.000000 dark-matter-4.0.9/dark/features.py
+-rw-rw-r--   0 terry      (501) staff       (20)    18835 2021-08-17 14:54:50.000000 dark-matter-4.0.9/dark/filter.py
+-rw-rw-r--   0 terry      (501) staff       (20)     2127 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/fpcache.py
+-rw-rw-r--   0 terry      (501) staff       (20)    16422 2021-10-03 19:42:37.000000 dark-matter-4.0.9/dark/genbank.py
+-rw-rw-r--   0 terry      (501) staff       (20)     9689 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/genomes.py
+-rw-rw-r--   0 terry      (501) staff       (20)    37967 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/graphics.py
+-rw-rw-r--   0 terry      (501) staff       (20)     7156 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/hsp.py
+-rw-rw-r--   0 terry      (501) staff       (20)    11911 2021-08-24 13:14:53.000000 dark-matter-4.0.9/dark/html.py
+-rw-r--r--   0 terry      (501) staff       (20)     6072 2017-04-21 09:11:56.000000 dark-matter-4.0.9/dark/intervals.py
+-rw-r--r--   0 terry      (501) staff       (20)     1108 2015-05-01 08:27:43.000000 dark-matter-4.0.9/dark/ipynb.py
+-rw-rw-r--   0 terry      (501) staff       (20)    14817 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/local_align.py
+-rw-rw-r--   0 terry      (501) staff       (20)    16447 2021-08-17 14:54:53.000000 dark-matter-4.0.9/dark/mutations.py
+-rw-r--r--   0 terry      (501) staff       (20)      535 2016-03-16 00:16:11.000000 dark-matter-4.0.9/dark/ncbidb.py
+-rw-r--r--   0 terry      (501) staff       (20)     2745 2016-12-07 11:27:46.000000 dark-matter-4.0.9/dark/orfs.py
+-rw-rw-r--   0 terry      (501) staff       (20)     4451 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/process.py
+-rw-rw-r--   0 terry      (501) staff       (20)    44260 2021-08-17 14:54:38.000000 dark-matter-4.0.9/dark/proteins.py
+-rw-rw-r--   0 terry      (501) staff       (20)    64784 2021-08-17 14:54:50.000000 dark-matter-4.0.9/dark/reads.py
+-rw-rw-r--   0 terry      (501) staff       (20)    41610 2021-10-01 15:32:44.000000 dark-matter-4.0.9/dark/sam.py
+-rw-r--r--   0 terry      (501) staff       (20)     1367 2015-05-01 08:27:43.000000 dark-matter-4.0.9/dark/score.py
+-rw-rw-r--   0 terry      (501) staff       (20)     2939 2021-08-17 14:54:05.000000 dark-matter-4.0.9/dark/sequence.py
+-rw-r--r--   0 terry      (501) staff       (20)     1142 2014-08-02 08:59:00.000000 dark-matter-4.0.9/dark/simplify.py
+-rw-r--r--   0 terry      (501) staff       (20)     4059 2017-02-09 14:45:59.000000 dark-matter-4.0.9/dark/summarize.py
+-rw-rw-r--   0 terry      (501) staff       (20)    23555 2021-08-17 14:54:46.000000 dark-matter-4.0.9/dark/taxonomy.py
+-rw-rw-r--   0 terry      (501) staff       (20)    20236 2021-08-17 14:54:53.000000 dark-matter-4.0.9/dark/titles.py
+-rw-rw-r--   0 terry      (501) staff       (20)    11499 2021-10-01 15:32:44.000000 dark-matter-4.0.9/dark/utils.py
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.604357 dark-matter-4.0.9/dark_matter.egg-info/
+-rw-rw-r--   0 terry      (501) staff       (20)      763 2021-10-03 19:42:47.000000 dark-matter-4.0.9/dark_matter.egg-info/PKG-INFO
+-rw-rw-r--   0 terry      (501) staff       (20)     4298 2021-10-03 19:42:47.000000 dark-matter-4.0.9/dark_matter.egg-info/SOURCES.txt
+-rw-rw-r--   0 terry      (501) staff       (20)        1 2021-10-03 19:42:47.000000 dark-matter-4.0.9/dark_matter.egg-info/dependency_links.txt
+-rw-rw-r--   0 terry      (501) staff       (20)      217 2021-10-03 19:42:47.000000 dark-matter-4.0.9/dark_matter.egg-info/requires.txt
+-rw-rw-r--   0 terry      (501) staff       (20)        5 2021-10-03 19:42:47.000000 dark-matter-4.0.9/dark_matter.egg-info/top_level.txt
+-rw-rw-r--   0 terry      (501) staff       (20)       38 2021-10-03 19:42:47.614776 dark-matter-4.0.9/setup.cfg
+-rw-rw-r--   0 terry      (501) staff       (20)     4906 2021-10-01 15:32:44.000000 dark-matter-4.0.9/setup.py
+drwxrwxr-x   0 terry      (501) staff       (20)        0 2021-10-03 19:42:47.614053 dark-matter-4.0.9/test/
+-rw-rw-r--   0 terry      (501) staff       (20)    38223 2021-08-17 14:54:53.000000 dark-matter-4.0.9/test/test_aa.py
+-rw-rw-r--   0 terry      (501) staff       (20)     7224 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_alignments.py
+-rw-rw-r--   0 terry      (501) staff       (20)     4539 2021-08-17 14:54:05.000000 dark-matter-4.0.9/test/test_analyze_reads.py
+-rw-rw-r--   0 terry      (501) staff       (20)    18487 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_bowtie2.py
+-rw-rw-r--   0 terry      (501) staff       (20)    10223 2021-08-17 14:54:58.000000 dark-matter-4.0.9/test/test_btop.py
+-rw-rw-r--   0 terry      (501) staff       (20)     5197 2021-08-17 14:54:05.000000 dark-matter-4.0.9/test/test_cigar.py
+-rw-r--r--   0 terry      (501) staff       (20)     1059 2015-05-01 08:27:43.000000 dark-matter-4.0.9/test/test_codonDistance.py
+-rw-rw-r--   0 terry      (501) staff       (20)     6080 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_colors.py
+-rw-rw-r--   0 terry      (501) staff       (20)     3798 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_dimension.py
+-rw-r--r--   0 terry      (501) staff       (20)      831 2014-10-27 10:38:50.000000 dark-matter-4.0.9/test/test_distance.py
+-rw-rw-r--   0 terry      (501) staff       (20)    41767 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_dna.py
+-rw-rw-r--   0 terry      (501) staff       (20)    40962 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_fasta.py
+-rw-rw-r--   0 terry      (501) staff       (20)     6412 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_fasta_ss.py
+-rw-rw-r--   0 terry      (501) staff       (20)     4526 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_fastq.py
+-rw-rw-r--   0 terry      (501) staff       (20)    24040 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_features.py
+-rw-rw-r--   0 terry      (501) staff       (20)    14079 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_filter.py
+-rw-rw-r--   0 terry      (501) staff       (20)    18296 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_genbank.py
+-rw-rw-r--   0 terry      (501) staff       (20)     8753 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_genomes.py
+-rw-r--r--   0 terry      (501) staff       (20)     1342 2016-02-21 22:27:36.000000 dark-matter-4.0.9/test/test_graphics.py
+-rw-rw-r--   0 terry      (501) staff       (20)     5801 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_hsp.py
+-rw-rw-r--   0 terry      (501) staff       (20)     2891 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_html.py
+-rw-r--r--   0 terry      (501) staff       (20)    21091 2017-04-21 09:11:56.000000 dark-matter-4.0.9/test/test_intervals.py
+-rw-rw-r--   0 terry      (501) staff       (20)    11532 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_local_align.py
+-rw-r--r--   0 terry      (501) staff       (20)     4451 2015-12-07 20:56:44.000000 dark-matter-4.0.9/test/test_mutations.py
+-rw-r--r--   0 terry      (501) staff       (20)     1293 2014-08-02 08:58:59.000000 dark-matter-4.0.9/test/test_orfs.py
+-rw-rw-r--   0 terry      (501) staff       (20)     2718 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_process.py
+-rw-rw-r--   0 terry      (501) staff       (20)    50108 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_proteins.py
+-rw-rw-r--   0 terry      (501) staff       (20)   143353 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_reads.py
+-rw-rw-r--   0 terry      (501) staff       (20)    68403 2021-10-01 15:32:44.000000 dark-matter-4.0.9/test/test_sam.py
+-rw-r--r--   0 terry      (501) staff       (20)     1685 2015-05-01 08:27:43.000000 dark-matter-4.0.9/test/test_score.py
+-rw-rw-r--   0 terry      (501) staff       (20)     5244 2021-08-17 14:54:50.000000 dark-matter-4.0.9/test/test_sequence.py
+-rw-r--r--   0 terry      (501) staff       (20)     1892 2014-08-02 08:58:59.000000 dark-matter-4.0.9/test/test_simplify.py
+-rw-rw-r--   0 terry      (501) staff       (20)     9767 2021-08-17 14:54:05.000000 dark-matter-4.0.9/test/test_summarize.py
+-rw-rw-r--   0 terry      (501) staff       (20)    15477 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_taxonomy.py
+-rw-rw-r--   0 terry      (501) staff       (20)    42821 2021-08-17 14:54:38.000000 dark-matter-4.0.9/test/test_titles.py
+-rw-rw-r--   0 terry      (501) staff       (20)    16458 2021-08-17 15:14:32.000000 dark-matter-4.0.9/test/test_utils.py
```

### Comparing `dark-matter-4.0.84/README.md` & `dark-matter-4.0.9/README.md`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 ## Dark matter
 
 A collection of Python tools for filtering and visualizing
 [Next Generation Sequencing](https://en.wikipedia.org/wiki/DNA_sequencing#Next-generation_methods)
 reads.
 
-Runs under Python 3.6 to 3.9 (though 7 of 1682 tests fail under 3.7 due to the `unittest` module and mocking of `open`).
-[Change log](CHANGELOG.md)
-[![Build Status](https://app.travis-ci.com/acorg/dark-matter.svg?branch=master)](https://app.travis-ci.com/acorg/dark-matter)
+Runs under Python 2.7 (mostly), 3.5, 3.6, and 3.7. [Change log](CHANGELOG.md)
+[![Build Status](https://travis-ci.org/acorg/dark-matter.svg?branch=master)](https://travis-ci.org/acorg/dark-matter)
 
 ## Installation
 
 On Linux (at least) you will need to first:
 
 ```sh
 sudo apt install zlib1g-dev libbz2-dev liblzma-dev
```

### Comparing `dark-matter-4.0.84/bin/alignments-per-read.py` & `dark-matter-4.0.9/bin/alignments-per-read.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 #!/usr/bin/env python
 
 """
 Read in BLAST records and print a count of how many sequences
 each read matches with, followed by the name of the read.
 """
 
+from __future__ import print_function
+
 import sys
 
 from dark.blast.alignments import BlastReadsAlignments
 from dark.fasta import FastaReads
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     if len(sys.argv) < 3:
-        print(
-            "Usage: %s reads.fasta BLAST-files.json..." % sys.argv[0], file=sys.stderr
-        )
+        print('Usage: %s reads.fasta BLAST-files.json...' %
+              sys.argv[0], file=sys.stderr)
     else:
         readsFile = sys.argv[1]
         jsonFiles = sys.argv[2:]
         reads = FastaReads(readsFile)
         readsAlignments = BlastReadsAlignments(readsFile, jsonFiles)
         for readAlignments in readsAlignments:
             print(len(readAlignments.alignments), readAlignments.read.id)
```

### Comparing `dark-matter-4.0.84/bin/check-fasta-json-blast-consistency.py` & `dark-matter-4.0.9/bin/check-fasta-json-blast-consistency.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,14 +4,16 @@
 Verify that a FASTA file and our JSON BLAST file that was produced from it
 do not violate some basic compatibility checks.
 
 Exits non-zero with an error message on stderr if there's a problem, else
 exits silently with zero status.
 """
 
+from __future__ import print_function
+
 import sys
 
 from dark.blast.alignments import BlastReadsAlignments
 from dark.fasta import FastaReads
 
 
 def check(fastaFile, jsonFiles):
@@ -25,58 +27,45 @@
     @param jsonFiles: A C{list} of names of our BLAST JSON. These may
         may be compressed (as bz2).
     @param fastaFile: The C{str} name of a FASTA-containing file.
     """
     reads = FastaReads(fastaFile)
     readsAlignments = BlastReadsAlignments(reads, jsonFiles)
     for index, readAlignments in enumerate(readsAlignments):
+
         # Check that all the alignments in the BLAST JSON do not have query
         # sequences or query offsets that are greater than the length of
         # the sequence given in the FASTA file.
         fastaLen = len(readAlignments.read)
         for readAlignment in readAlignments:
             for hsp in readAlignment.hsps:
                 # The FASTA sequence should be at least as long as the
                 # query in the JSON BLAST record (minus any gaps).
-                assert fastaLen >= len(hsp.query) - hsp.query.count("-"), (
-                    "record %d: FASTA len %d < HSP query len %d.\n"
-                    "FASTA: %s\nQuery match: %s"
-                    % (
-                        index,
-                        fastaLen,
-                        len(hsp.query),
-                        readAlignments.read.sequence,
-                        hsp.query,
-                    )
-                )
+                assert (fastaLen >=
+                        len(hsp.query) - hsp.query.count('-')), (
+                    'record %d: FASTA len %d < HSP query len %d.\n'
+                    'FASTA: %s\nQuery match: %s' % (
+                        index, fastaLen, len(hsp.query),
+                        readAlignments.read.sequence, hsp.query))
                 # The FASTA sequence length should be larger than either of
                 # the query offsets mentioned in the JSON BLAST
                 # record. That's because readStart and readEnd are offsets
                 # into the read - so they can't be bigger than the read
                 # length.
                 #
                 # TODO: These asserts should be more informative when they
                 # fail.
                 assert fastaLen >= hsp.readEnd >= hsp.readStart, (
-                    "record %d: FASTA len %d not greater than both read "
-                    "offsets (%d - %d), or read offsets are non-increasing. "
-                    "FASTA: %s\nQuery match: %s"
-                    % (
-                        index,
-                        fastaLen,
-                        hsp.readStart,
-                        hsp.readEnd,
-                        readAlignments.read.sequence,
-                        hsp.query,
-                    )
-                )
+                    'record %d: FASTA len %d not greater than both read '
+                    'offsets (%d - %d), or read offsets are non-increasing. '
+                    'FASTA: %s\nQuery match: %s' % (
+                        index, fastaLen, hsp.readStart, hsp.readEnd,
+                        readAlignments.read.sequence, hsp.query))
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     if len(sys.argv) >= 3:
         check(sys.argv[1], sys.argv[2:])
     else:
-        print(
-            "Usage: %s file.fasta file1.json file2.json..." % sys.argv[0],
-            file=sys.stderr,
-        )
+        print('Usage: %s file.fasta file1.json file2.json...' %
+              sys.argv[0], file=sys.stderr)
         sys.exit(1)
```

### Comparing `dark-matter-4.0.84/bin/compare-consensuses.py` & `dark-matter-4.0.9/bin/compare-consensuses.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,11 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 from os.path import exists, join
 from os import mkdir
 from tempfile import mkdtemp
 
 from dark.process import Executor
@@ -16,24 +18,22 @@
     @param outputDir: A C{str} output directory name, or C{None}.
     @param force: If C{True}, allow overwriting of pre-existing files.
     @return: The C{str} output directory name.
     """
     if outputDir:
         if exists(outputDir):
             if not force:
-                print(
-                    "Will not overwrite pre-existing files. Use --force to " "make me.",
-                    file=sys.stderr,
-                )
+                print('Will not overwrite pre-existing files. Use --force to '
+                      'make me.', file=sys.stderr)
                 sys.exit(1)
         else:
             mkdir(outputDir)
     else:
         outputDir = mkdtemp()
-        print("Writing output files to %s" % outputDir)
+        print('Writing output files to %s' % outputDir)
 
     return outputDir
 
 
 def samtoolsMpileup(outFile, referenceFile, alignmentFile, executor):
     """
     Use samtools mpileup to generate VCF.
@@ -41,207 +41,181 @@
     @param outFile: The C{str} name to write the output to.
     @param referenceFile: The C{str} name of the FASTA file with the reference
         sequence.
     @param alignmentFile: The C{str} name of the SAM or BAM alignment file.
     @param executor: An C{Executor} instance.
     """
     executor.execute(
-        "samtools mpileup -u -v -f %s %s > %s" % (referenceFile, alignmentFile, outFile)
-    )
+        'samtools mpileup -u -v -f %s %s > %s' %
+        (referenceFile, alignmentFile, outFile))
 
 
 def bcftoolsMpileup(outFile, referenceFile, alignmentFile, executor):
     """
     Use bcftools mpileup to generate VCF.
 
     @param outFile: The C{str} name to write the output to.
     @param referenceFile: The C{str} name of the FASTA file with the reference
         sequence.
     @param alignmentFile: The C{str} name of the SAM or BAM alignment file.
     @param executor: An C{Executor} instance.
     """
     executor.execute(
-        "bcftools mpileup -Ov -f %s %s > %s" % (referenceFile, alignmentFile, outFile)
-    )
+        'bcftools mpileup -Ov -f %s %s > %s' %
+        (referenceFile, alignmentFile, outFile))
 
 
 def bcftoolsCallMulti(outFile, vcfFile, executor):
     """
     Use bcftools to make consensus calls, using the  -m (multiallelic) option.
 
     @param outFile: The C{str} name to write the output to.
     @param vcfFile: The C{str} name of the VCF file with the calls from
         the pileup.
     @param executor: An C{Executor} instance.
     """
     # Note that this just gives a call on the first genome in the calls file.
-    executor.execute("bcftools call -m -Ov -o %s < %s" % (outFile, vcfFile))
+    executor.execute(
+        'bcftools call -m -Ov -o %s < %s' % (outFile, vcfFile))
 
 
 def bcftoolsCallConsensus(outFile, vcfFile, executor):
     """
     Use bcftools to make consensus calls, using the original -c option.
 
     @param outFile: The C{str} name to write the output to.
     @param vcfFile: The C{str} name of the VCF file with the calls from
         the pileup.
     @param executor: An C{Executor} instance.
     """
     # Note that this just gives a call on the first genome in the calls file.
-    executor.execute("bcftools call -c -Ov -o %s < %s" % (outFile, vcfFile))
+    executor.execute(
+        'bcftools call -c -Ov -o %s < %s' % (outFile, vcfFile))
 
 
 def bcftoolsConsensus(outFile, vcfFile, id_, referenceFile, executor):
     """
     Use bcftools to extract consensus FASTA.
 
     @param outFile: The C{str} name to write the output to.
     @param vcfFile: The C{str} name of the VCF file with the calls from
         the pileup.
     @param id_: The C{str} identifier to use in the resulting FASTA sequence.
     @param referenceFile: The C{str} name of the FASTA file with the reference
         sequence.
     @param executor: An C{Executor} instance.
     """
-    bgz = vcfFile + ".gz"
-    executor.execute("bgzip -c %s > %s" % (vcfFile, bgz))
-    executor.execute("tabix %s" % bgz)
-    executor.execute(
-        "bcftools consensus %s < %s | "
-        "filter-fasta.py --idLambda 'lambda id: \"%s\"' > %s"
-        % (bgz, referenceFile, id_, outFile)
-    )
+    bgz = vcfFile + '.gz'
+    executor.execute('bgzip -c %s > %s' % (vcfFile, bgz))
+    executor.execute('tabix %s' % bgz)
+    executor.execute(
+        'bcftools consensus %s < %s | '
+        'filter-fasta.py --idLambda \'lambda id: "%s"\' > %s' %
+        (bgz, referenceFile, id_, outFile))
 
 
 def vcfutilsConsensus(outFile, vcfFile, id_, _, executor):
     """
     Use vcftools to extract consensus FASTA.
 
     @param outFile: The C{str} name to write the output to.
     @param vcfFile: The C{str} name of the VCF file with the calls from
         the pileup.
     @param id_: The C{str} identifier to use in the resulting FASTA sequence.
     @param executor: An C{Executor} instance.
     """
     executor.execute(
-        "vcfutils.pl vcf2fq < %s | "
-        "filter-fasta.py --fastq --quiet --saveAs fasta "
-        "--idLambda 'lambda id: \"%s\"' > %s" % (vcfFile, id_, outFile)
-    )
+        'vcfutils.pl vcf2fq < %s | '
+        'filter-fasta.py --fastq --quiet --saveAs fasta '
+        '--idLambda \'lambda id: "%s"\' > %s' %
+        (vcfFile, id_, outFile))
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description="Compare different consensus making methods.",
-    )
+        description='Compare different consensus making methods.')
 
     parser.add_argument(
-        "--referenceFile",
-        required=True,
-        metavar="FILENAME",
-        help="The name of the FASTA file containing the reference sequence.",
-    )
+        '--referenceFile', required=True, metavar='FILENAME',
+        help='The name of the FASTA file containing the reference sequence.')
 
     parser.add_argument(
-        "--alignmentFile",
-        required=True,
-        metavar="FILENAME",
-        help=(
-            "The name of the SAM or BAM file containing an alignment to the "
-            "reference."
-        ),
-    )
+        '--alignmentFile', required=True, metavar='FILENAME',
+        help=('The name of the SAM or BAM file containing an alignment to the '
+              'reference.'))
 
     parser.add_argument(
-        "--verbose",
-        type=int,
-        default=0,
-        metavar="N",
-        help=(
-            "The integer verbosity level (0 = no output, 1 = some output, "
-            "2 = maximal output)."
-        ),
-    )
+        '--verbose', type=int, default=0, metavar='N',
+        help=('The integer verbosity level (0 = no output, 1 = some output, '
+              '2 = maximal output).'))
 
     parser.add_argument(
-        "--force",
-        default=False,
-        action="store_true",
-        help="If given, overwrite pre-existing files.",
-    )
+        '--force', default=False, action='store_true',
+        help='If given, overwrite pre-existing files.')
 
     parser.add_argument(
-        "--outputDir", metavar="DIRNAME", help="The directory to save result files to."
-    )
+        '--outputDir', metavar='DIRNAME',
+        help='The directory to save result files to.')
 
     args = parser.parse_args()
 
     outputDir = makeOuputDir(args.outputDir, args.force)
 
     executor = Executor()
 
     pileuppers = (
-        ("samtools-mpileup", samtoolsMpileup),
-        ("bcftools-mpileup", bcftoolsMpileup),
-    )
+        ('samtools-mpileup', samtoolsMpileup),
+        ('bcftools-mpileup', bcftoolsMpileup))
 
-    callers = (("bcftools-c", bcftoolsCallConsensus), ("bcftools-m", bcftoolsCallMulti))
+    callers = (
+        ('bcftools-c', bcftoolsCallConsensus),
+        ('bcftools-m', bcftoolsCallMulti))
 
     consensusers = (
-        ("bcftools-consensus", bcftoolsConsensus),
-        ("vcfutils-vcf2fq", vcfutilsConsensus),
-    )
+        ('bcftools-consensus', bcftoolsConsensus),
+        ('vcfutils-vcf2fq', vcfutilsConsensus))
 
     consensusFiles = []
 
     for pileupName, pileupFunc in pileuppers:
         pileupMiddle = pileupName
-        pileupFile = join(outputDir, "pileup-" + pileupMiddle + ".vcf")
-        pileupFunc(pileupFile, args.referenceFile, args.alignmentFile, executor)
+        pileupFile = join(outputDir, 'pileup-' + pileupMiddle + '.vcf')
+        pileupFunc(pileupFile, args.referenceFile,
+                   args.alignmentFile, executor)
 
         for callerName, callerFunc in callers:
-            callerMiddle = pileupMiddle + "-" + callerName
-            callerFile = join(outputDir, "calls-" + callerMiddle + ".vcf")
+            callerMiddle = pileupMiddle + '-' + callerName
+            callerFile = join(outputDir, 'calls-' + callerMiddle + '.vcf')
             callerFunc(callerFile, pileupFile, executor)
 
             for consensusName, consensusFunc in consensusers:
-                consensusMiddle = callerMiddle + "-" + consensusName
-                consensusFile = join(
-                    outputDir, "consensus-" + consensusMiddle + ".fasta"
-                )
+                consensusMiddle = callerMiddle + '-' + consensusName
+                consensusFile = join(outputDir,
+                                     'consensus-' + consensusMiddle + '.fasta')
                 consensusFiles.append(consensusFile)
-                consensusFunc(
-                    consensusFile,
-                    callerFile,
-                    consensusMiddle,
-                    args.referenceFile,
-                    executor,
-                )
+                consensusFunc(consensusFile, callerFile, consensusMiddle,
+                              args.referenceFile, executor)
 
     # Let's assume there's at least one consensus file.
-    consensusesFile = join(outputDir, "consensuses.fasta")
-    executor.execute("cat %s > %s" % (" ".join(consensusFiles), consensusesFile))
+    consensusesFile = join(outputDir, 'consensuses.fasta')
+    executor.execute(
+        'cat %s > %s' % (' '.join(consensusFiles), consensusesFile))
 
-    htmlFile = join(outputDir, "consensus-identity.html")
+    htmlFile = join(outputDir, 'consensus-identity.html')
     executor.execute(
-        (
-            "fasta-identity-table.py --footer --showGaps --showLengths < %s | "
-            "perl -pe 's/-(bcftools|vcfutils)/ $1/g' > %s"
-        )
-        % (consensusesFile, htmlFile)
-    )
+        ('fasta-identity-table.py --footer --showGaps --showLengths < %s | '
+         "perl -pe 's/-(bcftools|vcfutils)/ $1/g' > %s") %
+        (consensusesFile, htmlFile))
 
     verbose = args.verbose
     if verbose > 0:
-        print("The following commands were executed:")
+        print('The following commands were executed:')
         for line in executor.log:
-            if line.startswith("#"):
+            if line.startswith('#'):
                 if verbose > 1:
                     print(line)
             else:
                 print(line)
 
-    print(
-        "Identity table comparing %d consensuses written to %s"
-        % (len(consensusFiles), htmlFile)
-    )
+    print('Identity table comparing %d consensuses written to %s' %
+          (len(consensusFiles), htmlFile))
```

### Comparing `dark-matter-4.0.84/bin/compare-sequences.py` & `dark-matter-4.0.9/bin/compare-sequences.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,299 +1,193 @@
 #!/usr/bin/env python
 
+from __future__ import print_function, division
+
 import sys
 import argparse
 from math import log10
 import multiprocessing
 
-from dark.aligners import edlibAlign, mafft, needle
+from dark.aligners import mafft, needle
 from dark.dna import compareDNAReads, matchToString, AMBIGUOUS
-from dark.reads import Reads, addFASTACommandLineOptions, parseFASTACommandLineOptions
+from dark.reads import (Reads, addFASTACommandLineOptions,
+                        parseFASTACommandLineOptions)
 from dark.utils import parseRangeExpression
 
-MAFFT_DEFAULT_ARGS = "--globalpair --maxiterate 1000 --preservecase"
+MAFFT_DEFAULT_ARGS = '--globalpair --maxiterate 1000 --preservecase'
 MAFFT_ALGORITHMS_URL = (
-    "https://mafft.cbrc.jp/alignment/software/algorithms/algorithms.html"
-)
-NEEDLE_DEFAULT_ARGS = "auto"
+    'https://mafft.cbrc.jp/alignment/software/algorithms/algorithms.html')
+NEEDLE_DEFAULT_ARGS = 'auto'
 
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description="Compare two sequences.",
-)
+    description='Compare two sequences.')
+
+parser.add_argument(
+    '--index1', type=int, default=1,
+    help='The (1-based) index in the input of the first sequence.')
+
+parser.add_argument(
+    '--index2', type=int, default=2,
+    help='The (1-based) index in the input of the second sequence.')
+
+parser.add_argument(
+    '--align', default=False, action='store_true',
+    help=('If given, use mafft (the default) or needle (according to the '
+          'algorithm selected by --aligner) to align the two sequences.'))
 
 parser.add_argument(
-    "--index1",
-    type=int,
-    default=1,
-    help="The (1-based) index in the input of the first sequence.",
-)
-
-parser.add_argument(
-    "--index2",
-    type=int,
-    default=2,
-    help="The (1-based) index in the input of the second sequence.",
-)
-
-parser.add_argument(
-    "--align",
-    action="store_true",
-    help=(
-        "If given, use mafft (the default) or needle (according to the "
-        "algorithm selected by --aligner) to align the two sequences."
-    ),
-)
-
-parser.add_argument(
-    "--aligner",
-    default="mafft",
-    choices=("edlib", "mafft", "needle"),
-    help="The alignment algorithm to use.",
-)
-
-parser.add_argument(
-    "--alignerOptions",
-    help=(
-        "Optional arguments to pass to the alignment algorithm. If the "
-        'aligner is mafft, the default options are %r. If needle, "%s". '
-        "Do not try to set the number of threads here - use the --threads "
-        "argument instead. If you are using mafft, see %s for some possible "
-        "option combinations."
-        % (MAFFT_DEFAULT_ARGS, NEEDLE_DEFAULT_ARGS, MAFFT_ALGORITHMS_URL)
-    ),
-)
-
-parser.add_argument(
-    "--threads",
-    type=int,
-    default=multiprocessing.cpu_count(),
-    help=(
-        "The number of threads to use when running the aligner (if --align "
-        "is used and the alignment algorithm can make use of multiple "
-        "threads (mafft can, needle cannot))."
-    ),
-)
-
-parser.add_argument(
-    "--alignmentFile", help="The file to save the alignment to (implies --align)."
-)
-
-parser.add_argument(
-    "--strict",
-    action="store_true",
-    help="If given, do not allow ambiguous nucleotide symbols to match.",
-)
-
-parser.add_argument(
-    "--quiet",
-    dest="verbose",
-    action="store_false",
-    help=("Do not print information about aligning, or falling back to " "stretcher."),
-)
-
-parser.add_argument(
-    "--noGapLocations",
-    dest="includeGapLocations",
-    action="store_false",
-    help="Do not indicate the (1-based) locations of sequence gaps.",
-)
-
-parser.add_argument(
-    "--noNoCoverageLocations",
-    dest="includeCoverageLocations",
-    action="store_false",
-    help="Do not indicate the (1-based) locations of no coverage.",
-)
-
-parser.add_argument(
-    "--sites",
-    help=(
-        "Specify (1-based) sequence sites to keep. All other sites will "
-        "be ignored. The sites must be given in the form e.g., "
-        "24,100-200,260."
-    ),
-)
-
-parser.add_argument(
-    "--showDiffs",
-    action="store_true",
-    help="Print (1-based) sites where the sequence nucleotides differ.",
-)
-
-parser.add_argument(
-    "--showAmbiguous",
-    action="store_true",
-    help=(
-        "Print (1-based) sites where either sequence has an ambiguous "
-        "nucleotide code."
-    ),
-)
-
-parser.add_argument(
-    "--includeAmbiguousMatches",
-    action="store_true",
-    help=(
-        "Print (1-based) sites of ambiguous matches. The output gives the "
-        "site, the base from the first sequence, then the base from the "
-        "second sequence."
-    ),
-)
-
-parser.add_argument(
-    "--includeNonGapMismatches",
-    action="store_true",
-    help=(
-        "Print (1-based) sites of mismatches that do not involve a gap. The "
-        "output gives the site, the base from the first sequence, then the "
-        "base from the second sequence."
-    ),
-)
-
-parser.add_argument(
-    "--gapChars",
-    default="-",
-    metavar="CHARS",
-    help=(
-        "The sequence characters that should be considered to be gaps. "
-        "These characters will be ignored in computing sequence lengths "
-        "and identity fractions."
-    ),
-)
-
-parser.add_argument(
-    "--noCoverageChars",
-    metavar="CHARS",
-    help=(
-        "The sequence characters that indicate lack of coverage. "
-        "These characters will be ignored in identity fractions."
-    ),
-)
+    '--aligner', default='mafft', choices=('mafft', 'needle'),
+    help='The alignment algorithm to use.')
+
+parser.add_argument(
+    '--alignerOptions',
+    help=('Optional arguments to pass to the alignment algorithm. If the '
+          'aligner is mafft, the default options are %r. If needle, "%s". '
+          'Do not try to set the number of threads here - use the --threads '
+          'argument instead. If you are using mafft, see %s for some possible '
+          'option combinations.' %
+          (MAFFT_DEFAULT_ARGS, NEEDLE_DEFAULT_ARGS, MAFFT_ALGORITHMS_URL)))
+
+parser.add_argument(
+    '--threads', type=int, default=multiprocessing.cpu_count(),
+    help=('The number of threads to use when running the aligner (if --align '
+          'is used and the alignment algorithm can make use of multiple '
+          'threads (mafft can, needle cannot)).'))
+
+parser.add_argument(
+    '--alignmentFile',
+    help='The file to save the alignment to (implies --align).')
+
+parser.add_argument(
+    '--strict', default=False, action='store_true',
+    help='If given, do not allow ambiguous nucleotide symbols to match.')
+
+parser.add_argument(
+    '--quiet', dest='verbose', default=True, action='store_false',
+    help=('Do not print information about aligning, or falling back to '
+          'stretcher.'))
+
+parser.add_argument(
+    '--noGapLocations', dest='includeGapLocations', action='store_false',
+    default=True,
+    help='Do not indicate the (1-based) locations of sequence gaps.')
+
+parser.add_argument(
+    '--sites',
+    help=('Specify (1-based) sequence sites to keep. All other sites will '
+          'be ignored. The sites must be given in the form e.g., '
+          '24,100-200,260.'))
+
+parser.add_argument(
+    '--showDiffs', default=False, action='store_true',
+    help='Print (1-based) sites where the sequence nucleotides differ.')
+
+parser.add_argument(
+    '--showAmbiguous', default=False, action='store_true',
+    help=('Print (1-based) sites where either sequence has an ambiguous '
+          'nucleotide code.'))
 
 addFASTACommandLineOptions(parser)
 args = parser.parse_args()
 
 keepSequences = set([args.index1 - 1, args.index2 - 1])
 
-reads = list(parseFASTACommandLineOptions(args).filter(keepSequences=keepSequences))
+reads = list(parseFASTACommandLineOptions(args).filter(
+    keepSequences=keepSequences))
 
 if len(reads) == 1:
     if len(keepSequences) == 1:
         # This is ok, they want to compare a sequence with itself.
         reads = Reads([reads[0], reads[0]])
     else:
-        print(
-            "Could not find both requested sequence indices. Exiting.", file=sys.stderr
-        )
+        print('Could not find both requested sequence indices. Exiting.')
         sys.exit(1)
 elif len(reads) != 2:
-    print("Could not find both requested sequence indices. Exiting.", file=sys.stderr)
+    print('Could not find both requested sequence indices. Exiting.')
     sys.exit(1)
 
 if args.alignmentFile:
     args.align = True
 
 if args.align:
     len1, len2 = map(len, reads)
     if len1 == len2:
-        print("Pre-alignment, sequence lengths were identical: %d" % len1)
+        print('Pre-alignment, sequence lengths were identical: %d' % len1)
     else:
-        print(
-            "Pre-alignment, sequence lengths: %d, %d (difference %d)"
-            % (len1, len2, abs(len1 - len2))
-        )
-
-    print("  Gaps:")
-    print("    Id: %s %d" % (reads[0].id, reads[0].sequence.count("-")))
-    print("    Id: %s %d" % (reads[1].id, reads[1].sequence.count("-")))
+        print('Pre-alignment, sequence lengths: %d, %d (difference %d)' % (
+            len1, len2, abs(len1 - len2)))
 
-    if args.aligner == "mafft":
+    if args.aligner == 'mafft':
         # Be careful in examining args.alignerOptions because we want the
         # user to be able to pass an empty string (so check against None
         # before deciding to use the default.)
-        options = (
-            MAFFT_DEFAULT_ARGS if args.alignerOptions is None else args.alignerOptions
-        )
-        reads = mafft(reads, args.verbose, options=options, threads=args.threads)
-    elif args.aligner == "needle":
+        options = (MAFFT_DEFAULT_ARGS if args.alignerOptions is None
+                   else args.alignerOptions)
+        reads = mafft(reads, args.verbose, options=options,
+                      threads=args.threads)
+    else:
+        assert args.aligner == 'needle'
         # Be careful in examining args.alignerOptions because we want the
         # user to be able to pass an empty string (so check against None
         # before deciding to use the default.)
-        options = (
-            NEEDLE_DEFAULT_ARGS if args.alignerOptions is None else args.alignerOptions
-        )
+        options = (NEEDLE_DEFAULT_ARGS if args.alignerOptions is None
+                   else args.alignerOptions)
         reads = needle(reads, args.verbose, options=options)
-    else:
-        assert args.aligner == "edlib"
-        reads = edlibAlign(reads)
 
     if args.alignmentFile:
         assert reads.save(args.alignmentFile) == 2
 
-offsets = (
-    parseRangeExpression(args.sites, convertToZeroBased=True) if args.sites else None
-)
+offsets = (parseRangeExpression(args.sites, convertToZeroBased=True)
+           if args.sites else None)
 
 read1, read2 = reads
 len1, len2 = map(len, reads)
 identicalLengths = len1 == len2
 
 # Sanity check.
 if args.align:
     assert identicalLengths
 
-match = compareDNAReads(
-    read1,
-    read2,
-    matchAmbiguous=(not args.strict),
-    offsets=offsets,
-    gapChars=args.gapChars,
-    noCoverageChars=args.noCoverageChars,
-)
+match = compareDNAReads(read1, read2, matchAmbiguous=(not args.strict),
+                        offsets=offsets)
 
-x = "Post-alignment, sequence" if args.align else "Sequence"
+x = 'Post-alignment, sequence' if args.align else 'Sequence'
 if identicalLengths:
-    print("%s lengths are identical: %s" % (x, len1))
+    print('%s lengths are identical: %s' % (x, len1))
 else:
-    print("%s lengths: %d, %d (difference %d)" % (x, len1, len2, abs(len1 - len2)))
+    print('%s lengths: %d, %d (difference %d)' % (x, len1, len2,
+                                                  abs(len1 - len2)))
 
-print(
-    matchToString(
-        match,
-        read1,
-        read2,
-        matchAmbiguous=(not args.strict),
-        offsets=offsets,
-        includeGapLocations=args.includeGapLocations,
-        includeNoCoverageLocations=args.includeCoverageLocations,
-        includeAmbiguousMatches=args.includeAmbiguousMatches,
-        includeNonGapMismatches=args.includeNonGapMismatches,
-    )
-)
+print(matchToString(match, read1, read2, matchAmbiguous=(not args.strict),
+                    offsets=offsets,
+                    includeGapLocations=args.includeGapLocations))
 
 if args.showDiffs:
     # Print all sites where the sequences differ.
     width = int(log10(max(len1, len2))) + 1
     headerPrinted = False
-    for site, (a, b) in enumerate(zip(read1.sequence, read2.sequence), start=1):
+    for site, (a, b) in enumerate(zip(read1.sequence, read2.sequence),
+                                  start=1):
         if a != b:
             if not headerPrinted:
-                print("Differences (site, %s, %s):" % (read1.id, read2.id))
+                print('Differences (site, %s, %s):' % (read1.id, read2.id))
                 headerPrinted = True
-            print("  %*d %s %s" % (width, site, a, b))
+            print('  %*d %s %s' % (width, site, a, b))
 
     if not headerPrinted:
-        print("No sequence differences found.")
+        print('No sequence differences found.')
 
 if args.showAmbiguous:
     width = int(log10(max(len1, len2))) + 1
     headerPrinted = False
-    for site, (a, b) in enumerate(zip(read1.sequence, read2.sequence), start=1):
-        if len(AMBIGUOUS.get(a, "")) > 1 or len(AMBIGUOUS.get(b, "")) > 1:
+    for site, (a, b) in enumerate(zip(read1.sequence, read2.sequence),
+                                  start=1):
+        if len(AMBIGUOUS.get(a, '')) > 1 or len(AMBIGUOUS.get(b, '')) > 1:
             if not headerPrinted:
-                print("Ambiguities (site, %s, %s):" % (read1.id, read2.id))
+                print('Ambiguities (site, %s, %s):' % (read1.id, read2.id))
                 headerPrinted = True
-            print("  %*d %s %s" % (width, site, a, b))
+            print('  %*d %s %s' % (width, site, a, b))
 
     if not headerPrinted:
-        print("No sequence ambiguities found.")
+        print('No sequence ambiguities found.')
```

### Comparing `dark-matter-4.0.84/bin/convert-blast-xml-to-json.py` & `dark-matter-4.0.9/bin/convert-blast-xml-to-json.py`

 * *Files 26% similar despite different names*

```diff
@@ -3,52 +3,39 @@
 import argparse
 import bz2file
 import sys
 
 from dark.blast.conversion import XMLRecordsReader
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
+
     parser = argparse.ArgumentParser(
-        description="Convert a BLAST XML file to JSON.",
-        epilog=(
-            "Give a BLAST XML file and convert it to JSON. Optionally "
-            "compress the JSON output."
-        ),
+        description='Convert a BLAST XML file to JSON.',
+        epilog=('Give a BLAST XML file and convert it to JSON. Optionally '
+                'compress the JSON output.')
     )
 
     parser.add_argument(
-        "--json",
-        metavar="JSON-output-file",
-        help=(
-            "the JSON filename to write the converted XML to. If omitted, "
-            "standard output will be used."
-        ),
-    )
+        '--json', metavar='JSON-output-file',
+        help=('the JSON filename to write the converted XML to. If omitted, '
+              'standard output will be used.'))
 
     parser.add_argument(
-        "--xml",
-        metavar="BLAST-XML-file",
-        default=sys.stdin,
-        help=(
-            "the BLAST XML output file to convert. If omitted, standard "
-            "input will be read."
-        ),
-    )
+        '--xml', metavar='BLAST-XML-file', default=sys.stdin,
+        help=('the BLAST XML output file to convert. If omitted, standard '
+              'input will be read.'))
 
     parser.add_argument(
-        "--bzip2",
-        default=False,
-        action="store_true",
-        help="If True, compress the JSON output using bzip2.",
-    )
+        '--bzip2', default=False, action='store_true',
+        help='If True, compress the JSON output using bzip2.')
 
     args = parser.parse_args()
 
     if args.bzip2:
-        fp = bz2file.BZ2File(args.json or sys.stdout, "w")
+        fp = bz2file.BZ2File(args.json or sys.stdout, 'w')
     else:
-        fp = open(args.json, "w") if args.json else sys.stdout
+        fp = open(args.json, 'w') if args.json else sys.stdout
 
     reader = XMLRecordsReader(args.xml)
     reader.saveAsJSON(fp)
     fp.close()
```

### Comparing `dark-matter-4.0.84/bin/convert-diamond-to-json.py` & `dark-matter-4.0.9/bin/convert-diamond-to-json.py`

 * *Files 18% similar despite different names*

```diff
@@ -3,57 +3,44 @@
 import argparse
 import bz2file
 import sys
 
 from dark.diamond.conversion import DiamondTabularFormatReader
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
+
     parser = argparse.ArgumentParser(
-        description="Convert DIAMOND tabular output to JSON.",
-        epilog=(
-            "Give a DIAMOND tabular file and convert it to JSON, "
-            "optionally compressing the output. You *must* invoke "
-            "DIAMOND with the following output specification: "
-            "--outfmt 6 qtitle stitle bitscore evalue qframe qseq "
-            "qstart qend sseq sstart send slen btop"
-            "Note that only each line of the output is JSON (the full "
-            "output is not valid JSON by itself)."
-        ),
+        description='Convert DIAMOND tabular output to JSON.',
+        epilog=('Give a DIAMOND tabular file and convert it to JSON, '
+                'optionally compressing the output. You *must* invoke '
+                'DIAMOND with the following output specification: '
+                '--outfmt 6 qtitle stitle bitscore evalue qframe qseq '
+                'qstart qend sseq sstart send slen btop'
+                'Note that only each line of the output is JSON (the full '
+                'output is not valid JSON by itself).')
     )
 
     parser.add_argument(
-        "--json",
-        metavar="JSON-output-file",
-        help=(
-            "The JSON filename to write the converted DIAMOND file to. If "
-            "omitted, standard output will be used."
-        ),
-    )
+        '--json', metavar='JSON-output-file',
+        help=('The JSON filename to write the converted DIAMOND file to. If '
+              'omitted, standard output will be used.'))
 
     parser.add_argument(
-        "--diamond",
-        metavar="DIAMOND-file",
-        default=sys.stdin,
-        help=(
-            "The DIAMOND tabular output file to convert. If omitted, "
-            "standard input will be read."
-        ),
-    )
+        '--diamond', metavar='DIAMOND-file', default=sys.stdin,
+        help=('The DIAMOND tabular output file to convert. If omitted, '
+              'standard input will be read.'))
 
     parser.add_argument(
-        "--bzip2",
-        default=False,
-        action="store_true",
-        help="Compress output using bzip2.",
-    )
+        '--bzip2', default=False, action='store_true',
+        help='Compress output using bzip2.')
 
     args = parser.parse_args()
 
     if args.bzip2:
-        fp = bz2file.BZ2File(args.json or sys.stdout, "w")
+        fp = bz2file.BZ2File(args.json or sys.stdout, 'w')
     else:
-        fp = open(args.json, "w") if args.json else sys.stdout
+        fp = open(args.json, 'w') if args.json else sys.stdout
 
     reader = DiamondTabularFormatReader(args.diamond)
     reader.saveAsJSON(fp, writeBytes=args.bzip2)
     fp.close()
```

### Comparing `dark-matter-4.0.84/bin/convert-sam-to-fastq.sh` & `dark-matter-4.0.9/bin/convert-sam-to-fastq.sh`

 * *Files identical despite different names*

### Comparing `dark-matter-4.0.84/bin/create-newick-relabeling-output.py` & `dark-matter-4.0.9/bin/create-newick-relabeling-output.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,52 +1,42 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description=(
-        "Find sequences that have a specific property (as detected "
-        'by the "relabel" function in the file specified by '
-        "--relabelFunctionFile) and print a TAB-separated list of "
-        "renamings to standard output."
-    ),
-)
+    description=('Find sequences that have a specific property (as detected '
+                 'by the "relabel" function in the file specified by '
+                 '--relabelFunctionFile) and print a TAB-separated list of '
+                 'renamings to standard output.'))
 
 parser.add_argument(
-    "--relabelFunctionFile",
-    required=True,
-    help=(
-        'A file containing a Python function named "relabel" that takes a '
-        "list of reads and returns a dictionary of renamings."
-    ),
-)
+    '--relabelFunctionFile', required=True,
+    help=('A file containing a Python function named "relabel" that takes a '
+          'list of reads and returns a dictionary of renamings.'))
 
 addFASTACommandLineOptions(parser)
 args = parser.parse_args()
 reads = parseFASTACommandLineOptions(args)
 
 relabel = origRelabel = object()
 
 try:
     exec(open(args.relabelFunctionFile).read())
 except Exception as e:
-    print(
-        "Could not execute Python in %s: %s" % (args.relabelFunctionFile, e),
-        file=sys.stderr,
-    )
+    print('Could not execute Python in %s: %s' % (args.relabelFunctionFile, e),
+          file=sys.stderr)
     sys.exit(1)
 
 if relabel is origRelabel:
-    print(
-        'The Python file %s did not define a function called "relabel".'
-        % args.relabelFunctionFile,
-        file=sys.stderr,
-    )
+    print('The Python file %s did not define a function called "relabel".' %
+          args.relabelFunctionFile, file=sys.stderr)
     sys.exit(2)
 
 for old, new in relabel(reads).items():
-    print("%s\t%s" % (old, new))
+    print('%s\t%s' % (old, new))
```

### Comparing `dark-matter-4.0.84/bin/dna-to-aa.py` & `dark-matter-4.0.9/bin/dna-to-aa.py`

 * *Files 23% similar despite different names*

```diff
@@ -6,52 +6,46 @@
 that length.
 
 Note that start and stop codons will be present in the output. If you actually
 want to just output all ORFs, use extract-ORFs.py directly instead (or pipe
 the output of this program into extract-ORFs.py --type aa).
 """
 
+from __future__ import print_function
+
 import sys
 import argparse
 
 from Bio.Data.CodonTable import TranslationError
 
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
-        description="Convert DNA to AA",
-        epilog="Given DNA FASTA on stdin, output AA FASTA to stdout. "
-        "Optionally, filter by minimum required ORF length.",
+        description='Convert DNA to AA',
+        epilog='Given DNA FASTA on stdin, output AA FASTA to stdout. '
+        'Optionally, filter by minimum required ORF length.'
     )
 
     parser.add_argument(
-        "--minORFLength",
-        metavar="LEN",
-        type=int,
-        default=None,
-        help="Translations to AA that do not contain an ORF of at least "
-        "this length will not be produced.",
-    )
+        '--minORFLength', metavar='LEN', type=int, default=None,
+        help='Translations to AA that do not contain an ORF of at least '
+        'this length will not be produced.')
 
     addFASTACommandLineOptions(parser)
     args = parser.parse_args()
     reads = parseFASTACommandLineOptions(args)
     write = sys.stdout.write
     minORFLength = args.minORFLength
 
     for read in reads:
         try:
             for translation in read.translations():
-                if (
-                    minORFLength is None
-                    or translation.maximumORFLength() >= minORFLength
-                ):
-                    write(translation.toString("fasta"))
+                if (minORFLength is None or
+                        translation.maximumORFLength() >= minORFLength):
+                    write(translation.toString('fasta'))
         except TranslationError as error:
-            print(
-                "Could not translate read %r sequence "
-                "%r (%s)." % (read.id, read.sequence, error),
-                file=sys.stderr,
-            )
+            print('Could not translate read %r sequence '
+                  '%r (%s).' % (read.id, read.sequence, error),
+                  file=sys.stderr)
             sys.exit(1)
```

### Comparing `dark-matter-4.0.84/bin/download-genbank.sh` & `dark-matter-4.0.9/bin/download-genbank.sh`

 * *Files identical despite different names*

### Comparing `dark-matter-4.0.84/bin/e-value-to-bit-score.py` & `dark-matter-4.0.9/bin/e-value-to-bit-score.py`

 * *Files 24% similar despite different names*

```diff
@@ -6,54 +6,40 @@
 Example usage:
 
 $ e-value-to-bit-score.py --dbSize 168142520 --dbSequenceCount 5660 \
   --queryLength 111 --lengthAdjustment 26 --eValue 0.0813077725194
 37.3537
 """
 
+from __future__ import print_function
+
 import argparse
 
 from dark.blast.score import eValueToBitScore
 
 
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser(description="Convert a bit score to an e-value.")
+if __name__ == '__main__':
+    parser = argparse.ArgumentParser(
+        description='Convert a bit score to an e-value.')
 
     parser.add_argument(
-        "--eValue", type=float, required=True, help="The e-value to convert."
-    )
+        '--eValue', type=float, required=True, help='The e-value to convert.')
 
     parser.add_argument(
-        "--dbSize",
-        type=int,
-        required=True,
-        help="The total number of bases in the sequence database.",
-    )
+        '--dbSize', type=int, required=True,
+        help='The total number of bases in the sequence database.')
 
     parser.add_argument(
-        "--dbSequenceCount",
-        type=int,
-        required=True,
-        help="The number of sequences in the database.",
-    )
+        '--dbSequenceCount', type=int, required=True,
+        help='The number of sequences in the database.')
 
     parser.add_argument(
-        "--queryLength",
-        type=int,
-        required=True,
-        help="The length of the query sequence.",
-    )
+        '--queryLength', type=int, required=True,
+        help='The length of the query sequence.')
 
     parser.add_argument(
-        "--lengthAdjustment", type=int, required=True, help="The length adjustment."
-    )
+        '--lengthAdjustment', type=int, required=True,
+        help='The length adjustment.')
 
     args = parser.parse_args()
-    print(
-        eValueToBitScore(
-            args.eValue,
-            args.dbSize,
-            args.dbSequenceCount,
-            args.queryLength,
-            args.lengthAdjustment,
-        )
-    )
+    print(eValueToBitScore(args.eValue, args.dbSize, args.dbSequenceCount,
+                           args.queryLength, args.lengthAdjustment))
```

### Comparing `dark-matter-4.0.84/bin/extract-ORFs.py` & `dark-matter-4.0.9/bin/extract-ORFs.py`

 * *Files 20% similar despite different names*

```diff
@@ -9,165 +9,130 @@
 unless we are asked to allow ORFs that are open at at least one end.
 
 Note that no start or stop codons will appear in the output. If you are
 wanting to simply translate DNA FASTA to AA FASTA on a sequence-by-sequence
 basis leaving in start/stop codons, use dna-to-aa.py instead.
 """
 
+from __future__ import print_function
+
 import sys
 from os.path import basename
 import argparse
 
 from Bio.Data.CodonTable import TranslationError
 
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
-        description="Convert DNA or AA FASTA to AA ORF-only FASTA",
-        epilog=(
-            "Given DNA or AA FASTA on stdin, output AA ORF-only FASTA to "
-            "stdout. Optionally, filter by minimum required ORF length "
-            "and allow the output of short ORFs that are open."
-        ),
-    )
+        description='Convert DNA or AA FASTA to AA ORF-only FASTA',
+        epilog=('Given DNA or AA FASTA on stdin, output AA ORF-only FASTA to '
+                'stdout. Optionally, filter by minimum required ORF length '
+                'and allow the output of short ORFs that are open.'))
 
     parser.add_argument(
-        "--allowOpenORFs",
-        default=False,
-        action="store_true",
-        help=(
-            "If True, ORFs that do not meet the length requirement "
-            "(as specified by --minORFLength) will be output as long as "
-            "they are open."
-        ),
-    )
+        '--allowOpenORFs', default=False, action='store_true',
+        help=('If True, ORFs that do not meet the length requirement '
+              '(as specified by --minORFLength) will be output as long as '
+              'they are open.'))
 
     parser.add_argument(
-        "--minORFLength",
-        metavar="LEN",
-        type=int,
-        default=None,
-        help="Only ORFs of at least this length will be written to stdout.",
-    )
+        '--minORFLength', metavar='LEN', type=int, default=None,
+        help='Only ORFs of at least this length will be written to stdout.')
 
     parser.add_argument(
-        "--maxORFLength",
-        metavar="LEN",
-        type=int,
-        default=None,
-        help=("Only ORFs of a maximum of this length will be written to " "stdout."),
-    )
+        '--maxORFLength', metavar='LEN', type=int, default=None,
+        help=('Only ORFs of a maximum of this length will be written to '
+              'stdout.'))
 
     parser.add_argument(
-        "--kozakOnly",
-        default=False,
-        action="store_true",
-        help=(
-            "Only ORFs that also have a Kozak consensus will be written to "
-            "stdout. Only applicable if DNA reads are given."
-        ),
-    )
+        '--kozakOnly', default=False, action='store_true',
+        help=('Only ORFs that also have a Kozak consensus will be written to '
+              'stdout. Only applicable if DNA reads are given.'))
 
     parser.add_argument(
-        "--kozakInfoFile",
-        help=(
-            "Filename to which all Kozak consensus information is written. "
-            "Only applicable if DNA reads are given."
-        ),
-    )
+        '--kozakInfoFile',
+        help=('Filename to which all Kozak consensus information is written. '
+              'Only applicable if DNA reads are given.'))
 
     addFASTACommandLineOptions(parser)
 
     args = parser.parse_args()
     allowOpenORFs = args.allowOpenORFs
     minORFLength = args.minORFLength
     maxORFLength = args.maxORFLength
     kozakInfoFile = args.kozakInfoFile
     kozakOnly = args.kozakOnly
     reads = parseFASTACommandLineOptions(args)
-    aa = args.readClass in (
-        "AARead",
-        "AAReadORF",
-        "AAReadWithX",
-        "SSAARead",
-        "SSAAReadWithX",
-        "TranslatedRead",
-    )
+    aa = args.readClass in ('AARead', 'AAReadORF', 'AAReadWithX', 'SSAARead',
+                            'SSAAReadWithX', 'TranslatedRead')
 
     if aa:
-
         def translations(read):
             return (read,)
-
     else:
-
         def translations(read):
             return read.translations()
 
     if kozakInfoFile or kozakOnly:
         if aa:
-            print(
-                "Kozak sequences cannot be computed from aa sequences.", file=sys.stderr
-            )
+            print('Kozak sequences cannot be computed from aa sequences.',
+                  file=sys.stderr)
             sys.exit(1)
         else:
             from dark.dna import findKozakConsensus
 
         def writeToKozakOut(kozakread, kozakfp):
             """
             Writes out information about a Kozak sequence stored in kozakread
             to the file name given in kozakfp.
             """
-            print("Read ID: " + kozakread.id, file=kozakfp)
-            print("Kozak sequence: " + kozakread.sequence, file=kozakfp)
-            print(
-                "Offset of the Kozak sequence A: " + str(kozakread.start + 6),
-                file=kozakfp,
-            )
-            print(
-                "Quality of the Kozak consensus: " + str(kozakread.kozakQuality) + " %",
-                file=kozakfp,
-            )
+            print('Read ID: ' + kozakread.id, file=kozakfp)
+            print('Kozak sequence: ' + kozakread.sequence, file=kozakfp)
+            print('Offset of the Kozak sequence A: ' +
+                  str(kozakread.start + 6), file=kozakfp)
+            print('Quality of the Kozak consensus: ' +
+                  str(kozakread.kozakQuality) + ' %', file=kozakfp)
 
     def findORFs(kozakfp):
         for read in reads:
             try:
                 for translation in translations(read):
                     for orf in translation.ORFs(allowOpenORFs):
                         # Check the length requirements, if any.
-                        if (minORFLength is None or len(orf) >= minORFLength) and (
-                            maxORFLength is None or len(orf) <= maxORFLength
-                        ):
+                        if ((minORFLength is None or
+                             len(orf) >= minORFLength) and
+                            (maxORFLength is None or
+                             len(orf) <= maxORFLength)):
+
                             if kozakOnly:
                                 for kozakread in findKozakConsensus(read):
                                     start = orf.start * 3
-                                    if start + 1 <= kozakread.stop <= start + 3:
-                                        print(orf.toString("fasta"), end="")
+                                    if (start + 1 <=
+                                       kozakread.stop <= start + 3):
+                                        print(orf.toString('fasta'),
+                                              end='')
                             else:
-                                print(orf.toString("fasta"), end="")
+                                print(orf.toString('fasta'), end='')
                             if kozakfp:
                                 for kozakread in findKozakConsensus(read):
                                     start = orf.start * 3
-                                    if start + 1 <= kozakread.stop <= start + 3:
+                                    if (start + 1 <=
+                                       kozakread.stop <= start + 3):
                                         writeToKozakOut(kozakread, kozakfp)
 
             except TranslationError as error:
-                print(
-                    "Could not translate read %r sequence %r (%s)."
-                    % (read.id, read.sequence, error),
-                    file=sys.stderr,
-                )
+                print('Could not translate read %r sequence %r (%s).' %
+                      (read.id, read.sequence, error), file=sys.stderr)
                 if not aa:
-                    print(
-                        "Did you forget to run "
-                        '%s with "--readClass AARead"?' % (basename(sys.argv[0])),
-                        file=sys.stderr,
-                    )
+                    print('Did you forget to run '
+                          '%s with "--readClass AARead"?' %
+                          (basename(sys.argv[0])), file=sys.stderr)
                 sys.exit(1)
 
     if kozakInfoFile:
-        with open(kozakInfoFile, "a+") as kozakfp:
+        with open(kozakInfoFile, 'a+') as kozakfp:
             findORFs(kozakfp)
     else:
         findORFs(None)
```

### Comparing `dark-matter-4.0.84/bin/fasta-base-indices.py` & `dark-matter-4.0.9/bin/fasta-base-indices.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,93 +1,74 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import os
 import argparse
 
 from dark.reads import (
-    addFASTACommandLineOptions,
-    parseFASTACommandLineOptions,
-    getUnambiguousBases,
-)
+    addFASTACommandLineOptions, parseFASTACommandLineOptions, unambiguousBases)
 
 parser = argparse.ArgumentParser(
     description=(
-        "Given FASTA on standard input, and bases to look for, write the "
-        "1-based indices of where the bases occur in all sequences to "
-        "standard output. If standard output is a terminal, these will be "
-        "space separated, else newline separated. Use --any to print "
-        "indices that match any sequence."
-    ),
+        'Given FASTA on standard input, and bases to look for, write the '
+        '1-based indices of where the bases occur in all sequences to '
+        'standard output. If standard output is a terminal, these will be '
+        'space separated, else newline separated. Use --any to print '
+        'indices that match any sequence.'),
     epilog=(
-        "This can be used to find all columns of a FASTA multiple "
-        "sequence alignment that contain gaps, ambiguous nucleotides or "
-        "AAs, or to find all columns that do not contain such things. "
-        "Note that if sequences are of uneven lengths and --any is not "
-        "specified, only indices up to the length of the shortest input "
-        "sequence can be printed (i.e., there is a strict interpretation "
-        "of all sequences needing to have a matching base at an index: "
-        "if the index does not exist in even one sequence, then no base "
-        "can occur in all sequences at that index)."
-    ),
-)
+        'This can be used to find all columns of a FASTA multiple '
+        'sequence alignment that contain gaps, ambiguous nucleotides or '
+        'AAs, or to find all columns that do not contain such things. '
+        'Note that if sequences are of uneven lengths and --any is not '
+        'specified, only indices up to the length of the shortest input '
+        'sequence can be printed (i.e., there is a strict interpretation '
+        'of all sequences needing to have a matching base at an index: '
+        'if the index does not exist in even one sequence, then no base '
+        'can occur in all sequences at that index).'))
 
 parser.add_argument(
-    "--bases",
-    help=(
-        "The sequence bases whose indices should be printed. If not "
-        "specified, this will be the defined set of bases for the input "
-        'sequence type (i.e., "ACGT" for DNA). This will have the effect of '
-        "printing the indices for which any sequence has an ambiguous or "
-        "missing base."
-    ),
-)
+    '--bases',
+    help=('The sequence bases whose indices should be printed. If not '
+          'specified, this will be the defined set of bases for the input '
+          'sequence type (i.e., "ACGT" for DNA). This will have the effect of '
+          'printing the indices for which any sequence has an ambiguous or '
+          'missing base.'))
 
 parser.add_argument(
-    "--matchCase",
-    default=False,
-    action="store_true",
-    help="If specified, sequence case will be considered in matching.",
-)
+    '--matchCase', default=False, action='store_true',
+    help='If specified, sequence case will be considered in matching.')
 
 parser.add_argument(
-    "--any",
-    default=False,
-    action="store_true",
-    help=(
-        "If specified, print indices of bases that match any sequence, "
-        "otherwise (the default) indices are only printed if they match "
-        "all sequences."
-    ),
-)
+    '--any', default=False, action='store_true',
+    help=('If specified, print indices of bases that match any sequence, '
+          'otherwise (the default) indices are only printed if they match '
+          'all sequences.'))
 
 addFASTACommandLineOptions(parser)
 args = parser.parse_args()
 reads = parseFASTACommandLineOptions(args)
 
 if args.bases is None:
     # No target bases were given. Use the set of unambiguous bases for
     # the read type. Unless --any has been given, this will print
     # indices in which no ambiguous bases or gaps appear in any
     # sequence.
-    targets = getUnambiguousBases[args.readClass]
+    targets = unambiguousBases[args.readClass]
 else:
     targets = set(args.bases)
 
 indices = reads.indicesMatching(targets, args.matchCase, args.any)
 nIndices = len(indices)
 
 if nIndices:
-    separator = " " if os.isatty(1) else "\n"
+    separator = ' ' if os.isatty(1) else '\n'
     # Add one to indices to maximize happy humans.
     print(separator.join(map(lambda x: str(x + 1), sorted(indices))))
 
-print(
-    "Found %d %s where %s a base from the set {%s}."
-    % (
-        nIndices,
-        "index" if nIndices == 1 else "indices",
-        "any sequence has" if args.any else "all sequences have",
-        ", ".join(sorted(targets)),
-    ),
-    file=sys.stderr,
-)
+print('Found %d %s where %s a base from the set {%s}.' %
+      (nIndices,
+       'index' if nIndices == 1 else 'indices',
+       'any sequence has' if args.any else 'all sequences have',
+       ', '.join(sorted(targets))),
+      file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/fasta-count.py` & `dark-matter-4.0.9/bin/fasta-count.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description=("Given FASTA on stdin, print the number of sequences to stdout."),
-    )
+        description=(
+            'Given FASTA on stdin, print the number of sequences to stdout.'))
 
     addFASTACommandLineOptions(parser)
     args = parser.parse_args()
     reads = parseFASTACommandLineOptions(args)
 
     count = 0
     for read in reads:
```

### Comparing `dark-matter-4.0.84/bin/fasta-diff.sh` & `dark-matter-4.0.9/bin/fasta-diff.sh`

 * *Files identical despite different names*

### Comparing `dark-matter-4.0.84/bin/fasta-join.py` & `dark-matter-4.0.9/bin/fasta-join.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,34 +1,28 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
         description=(
-            "Given FASTA on stdin, write the ids, sequences, and "
-            "quality strings on a single TAB-separated line to stdout."
-        )
-    )
-
-    parser.add_argument(
-        "--separator",
-        default="\t",
-        help=(
-            "The character string to separate ids from "
-            "sequences and quality strings (if any)"
-        ),
-    )
-
-    parser.add_argument(
-        "--removeIds", action="store_true", help="Do not print sequence ids"
-    )
+            'Given FASTA on stdin, write the ids, sequences, and '
+            'quality strings on a single TAB-separated line to stdout.'))
+
+    parser.add_argument('--separator', default='\t',
+                        help=('The character string to separate ids from '
+                              'sequences and quality strings (if any)'))
+
+    parser.add_argument('--removeIds', default=False, action='store_true',
+                        help='Do not print sequence ids')
 
     addFASTACommandLineOptions(parser)
     args = parser.parse_args()
     sep = args.separator
     reads = parseFASTACommandLineOptions(args)
 
     # Duplicate code a little so as not to repeatedly do two tests per read.
```

### Comparing `dark-matter-4.0.84/bin/fasta-sort.py` & `dark-matter-4.0.9/bin/fasta-to-phylip.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,67 +1,57 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
-import argparse
-import re
+import tempfile
+
+from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
+
 
-from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions, Reads
+if __name__ == '__main__':
+    import argparse
 
-parser = argparse.ArgumentParser(
-    description=(
-        "Write sorted FASTA/Q to stdout. Sorting is by sequence id, "
-        "then by sequence, then by quality (if FASTQ)"
-    )
-)
-
-# TODO: Support multiple regexes and apply them one by one to allow matching on
-# different regions in an arbitrary order.
-parser.add_argument(
-    "--regex",
-    help=(
-        "A regular expression to specify a region (or regions) to extract "
-        "from sequence ids to sort on. Regions will be converted to "
-        "integers if possible."
-    ),
-)
-
-
-parser.add_argument(
-    "--reverse", "-r", action="store_true", help="Sort by decreasing value."
-)
-
-addFASTACommandLineOptions(parser)
-args = parser.parse_args()
-reads = parseFASTACommandLineOptions(args)
-
-if args.regex:
-    regex = re.compile(args.regex)
-
-    if regex.groups == 0:
-        print(
-            "You have passed a regular expression that has no capturing "
-            "group(s) specified using (...).",
-            file=sys.stderr,
-        )
-        sys.exit(1)
-
-    def key(read):
-        result = []
-        match = regex.search(read.id)
-        if match:
-            for text in match.groups():
-                try:
-                    value = int(text)
-                except ValueError:
-                    value = text
-                result.append(value)
-        return result
-
-else:
-
-    def key(read):
-        return read.id
-
-
-Reads(sorted(reads, key=key, reverse=args.reverse)).save(
-    sys.stdout, "fastq" if args.fastq else "fasta"
-)
+    parser = argparse.ArgumentParser(
+        description=('Given FASTA sequences (of equal length) on stdin '
+                     'write Phylip to stdout.'))
+
+    parser.add_argument(
+        '--addIdSpace', action='store_true', default=False,
+        help=('If True, print an extra space after each sequence id (the '
+              'space is expected by some programs that process Phylip files, '
+              'e.g., baseml).'))
+
+    addFASTACommandLineOptions(parser)
+    args = parser.parse_args()
+    idSpace = ' ' if args.addIdSpace else ''
+    reads = parseFASTACommandLineOptions(args)
+
+    count = 0
+    length = None
+    with tempfile.TemporaryFile() as fp:
+        for read in reads:
+            count += 1
+            if length is None:
+                length = len(read)
+            else:
+                if len(read) != length:
+                    raise ValueError(
+                        'FASTA sequence %r was not of the '
+                        'expected length (%d)' % (read.id, length))
+
+            name = read.id.split()[0]
+            fp.write(('%s%s %s\n' %
+                      (name, idSpace, read.sequence)).encode('utf-8'))
+
+        if count:
+            # Print the phylip header with the number of sequences and their
+            # common length.
+            print('%d %d' % (count, length))
+            fp.seek(0)
+            write = sys.stdout.write
+            while True:
+                chunk = fp.read(1024)
+                if chunk:
+                    write(chunk.decode('utf-8'))
+                else:
+                    break
```

### Comparing `dark-matter-4.0.84/bin/fasta-split-by-id.py` & `dark-matter-4.0.9/bin/fasta-split-by-id.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,124 +1,104 @@
 #!/usr/bin/env python
 
+from __future__ import print_function, division
+
 import sys
 import argparse
 from os.path import join, exists
 from os import mkdir, rename
 from math import log10
 
-from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
+from dark.reads import (addFASTACommandLineOptions,
+                        parseFASTACommandLineOptions)
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description=(
-        "Split sequences in a FASTA file into separate files, named "
-        "either by their sequence id or numerically."
-    ),
-)
-
-parser.add_argument("--outDir", default=".", help="The directory to make the files in.")
-
-parser.add_argument(
-    "--verbose",
-    default=False,
-    action="store_true",
-    help="If given, print sequence ids as they are processed.",
-)
-
-parser.add_argument(
-    "--numeric",
-    default=False,
-    action="store_true",
-    help="If given, use numeric filenames, like 1.fasta, 2.fasta, etc.",
-)
-
-parser.add_argument(
-    "--noLeadingZeroes",
-    default=False,
-    action="store_true",
-    help="If given, numeric filenames will not have leading zeroes.",
-)
-
-parser.add_argument(
-    "--force",
-    default=False,
-    action="store_true",
-    help="If given, overwrite pre-existing files.",
-)
-
-parser.add_argument(
-    "--saveAs",
-    choices=("fasta", "fastq", "fasta-ss"),
-    help=(
-        "The output format. The default is to match the input format, "
-        "so there is usually no need to specify this option. It can be "
-        "used to force conversion from FASTQ to FASTA"
-    ),
-)
+    description=('Split sequences in a FASTA file into separate files, named '
+                 'either by their sequence id or numerically.'))
+
+parser.add_argument(
+    '--outDir', default='.',
+    help='The directory to make the files in.')
+
+parser.add_argument(
+    '--verbose', default=False, action='store_true',
+    help='If given, print sequence ids as they are processed.')
+
+parser.add_argument(
+    '--numeric', default=False, action='store_true',
+    help='If given, use numeric filenames, like 1.fasta, 2.fasta, etc.')
+
+parser.add_argument(
+    '--noLeadingZeroes', default=False, action='store_true',
+    help='If given, numeric filenames will not have leading zeroes.')
+
+parser.add_argument(
+    '--force', default=False, action='store_true',
+    help='If given, overwrite pre-existing files.')
+
+parser.add_argument(
+    '--saveAs', choices=('fasta', 'fastq', 'fasta-ss'),
+    help=('The output format. The default is to match the input format, '
+          'so there is usually no need to specify this option. It can be '
+          'used to force conversion from FASTQ to FASTA'))
 
 addFASTACommandLineOptions(parser)
 args = parser.parse_args()
 reads = parseFASTACommandLineOptions(args)
 
 if not exists(args.outDir):
     mkdir(args.outDir)
 
 saveAs = (
-    args.saveAs
-    or (args.fasta and "fasta")
-    or (args.fastq and "fastq")
-    or (args.fasta_ss and "fasta-ss")
-)
+    args.saveAs or
+    (args.fasta and 'fasta') or
+    (args.fastq and 'fastq') or
+    (args.fasta_ss and 'fasta-ss'))
 
 # Note: we may be reading the FASTA input from stdin, so we cannot read it
 # more than once (and I don't want to store it all because it may be very
 # large). That's why we do a second phase of processing to renumber the
 # files we created if --numeric is used (and --noLeadingZeroes is not).
 
 count = 0
 for count, read in enumerate(parseFASTACommandLineOptions(args), start=1):
     id_ = read.id.split()[0]
     if args.numeric:
-        base = "%d.fasta" % count
+        base = '%d.fasta' % count
     else:
         id_ = read.id.split()[0]
-        base = "%s.fasta" % id_
+        base = '%s.fasta' % id_
     if args.verbose:
-        print("Writing", base)
+        print('Writing', base)
     filename = join(args.outDir, base)
     if not args.force and exists(filename):
-        print(
-            'Will not overwrite pre-existing file "%s". Use --force to '
-            "make me. Exiting." % filename,
-            file=sys.stderr,
-        )
+        print('Will not overwrite pre-existing file "%s". Use --force to '
+              'make me. Exiting.' % filename, file=sys.stderr)
         sys.exit(1)
-    with open(filename, "w") as fp:
-        print(read.toString(saveAs), end="", file=fp)
+    with open(filename, 'w') as fp:
+        print(read.toString(saveAs), end='', file=fp)
 
 # Rename numeric filenames to have leading zeroes.
 if count and args.numeric and not args.noLeadingZeroes:
     width = int(log10(count)) + 1
     if width > 1:
         if args.verbose:
-            print("Renaming to add leading zeroes")
+            print('Renaming to add leading zeroes')
         for i in range(1, count + 1):
             old = str(i)
-            new = "%0*d" % (width, i)
+            new = '%0*d' % (width, i)
             if old == new:
                 # We've reached the point where the new names have as many
                 # digits as the old, so we can stop.
                 break
             else:
-                oldFilename = "%s.fasta" % join(args.outDir, old)
-                newFilename = "%s.fasta" % join(args.outDir, new)
+                oldFilename = '%s.fasta' % join(args.outDir, old)
+                newFilename = '%s.fasta' % join(args.outDir, new)
                 if not args.force and exists(newFilename):
-                    print(
-                        'Will not overwrite pre-existing file "%s". Use '
-                        "--force to make me. Exiting." % newFilename,
-                        file=sys.stderr,
-                    )
+                    print('Will not overwrite pre-existing file "%s". Use '
+                          '--force to make me. Exiting.' % newFilename,
+                          file=sys.stderr)
                     sys.exit(1)
                 if args.verbose:
-                    print("  ", oldFilename, "->", newFilename)
+                    print('  ', oldFilename, '->', newFilename)
                 rename(oldFilename, newFilename)
```

### Comparing `dark-matter-4.0.84/bin/fasta-split.py` & `dark-matter-4.0.9/bin/fasta-split.py`

 * *Files 12% similar despite different names*

```diff
@@ -3,119 +3,101 @@
 import sys
 import argparse
 from os.path import exists
 from os import mkdir, rename
 from math import log10
 from pathlib import Path
 
-from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions, Reads
+from dark.reads import (addFASTACommandLineOptions,
+                        parseFASTACommandLineOptions, Reads)
 from dark.utils import take
 
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
     description=(
-        "Split sequences in a FASTA/Q file into numerically named files, "
-        "each containing a given number of sequences."
-    ),
-)
+        'Split sequences in a FASTA/Q file into numerically named files, '
+        'each containing a given number of sequences.'))
 
-parser.add_argument("--outDir", default=".", help="The directory to make the files in.")
+parser.add_argument(
+    '--outDir', default='.',
+    help='The directory to make the files in.')
 
 parser.add_argument(
-    "--verbose",
-    action="store_true",
-    help="If given, print sequence ids as they are processed.",
-)
+    '--verbose', action='store_true',
+    help='If given, print sequence ids as they are processed.')
 
 parser.add_argument(
-    "--count",
-    type=int,
-    default=100,
-    help="The number of sequences to put in each file.",
-)
+    '--count', type=int, default=100,
+    help='The number of sequences to put in each file.')
 
 parser.add_argument(
-    "--noLeadingZeroes",
-    action="store_true",
-    help="If given, numeric filenames will not have leading zeroes.",
-)
+    '--noLeadingZeroes', action='store_true',
+    help='If given, numeric filenames will not have leading zeroes.')
 
 parser.add_argument(
-    "--force", action="store_true", help="If given, overwrite pre-existing files."
-)
+    '--force', action='store_true',
+    help='If given, overwrite pre-existing files.')
 
 parser.add_argument(
-    "--saveAs",
-    choices=("fasta", "fastq", "fasta-ss"),
-    help=(
-        "The output format. The default is to match the input format, "
-        "so there is usually no need to specify this option. It can be "
-        "used to force conversion from FASTQ to FASTA"
-    ),
-)
+    '--saveAs', choices=('fasta', 'fastq', 'fasta-ss'),
+    help=('The output format. The default is to match the input format, '
+          'so there is usually no need to specify this option. It can be '
+          'used to force conversion from FASTQ to FASTA'))
 
 addFASTACommandLineOptions(parser)
 args = parser.parse_args()
 reads = parseFASTACommandLineOptions(args)
 
 if not exists(args.outDir):
     mkdir(args.outDir)
 
 saveAs = (
-    args.saveAs
-    or (args.fasta and "fasta")
-    or (args.fastq and "fastq")
-    or (args.fasta_ss and "fasta-ss")
-)
+    args.saveAs or
+    (args.fasta and 'fasta') or
+    (args.fastq and 'fastq') or
+    (args.fasta_ss and 'fasta-ss'))
 
 # Note: we may be reading the FASTA input from stdin, so we cannot read it
 # more than once (and I don't want to store it all because it may be very
 # large). That's why we do a second phase of processing to renumber the
 # files we created (if --noLeadingZeroes is not used).
 
 outDir = Path(args.outDir)
 
 count = 0
 for count, reads in enumerate(
-    take(parseFASTACommandLineOptions(args), args.count), start=1
-):
-    filename = outDir / f"{count}.fasta"
+        take(parseFASTACommandLineOptions(args), args.count), start=1):
+    filename = outDir / f'{count}.fasta'
     if not args.force and filename.exists():
-        print(
-            f"Will not overwrite pre-existing file {str(filename)!r}. "
-            f"Use --force to make me. Exiting.",
-            file=sys.stderr,
-        )
+        print(f'Will not overwrite pre-existing file {str(filename)!r}. '
+              f'Use --force to make me. Exiting.', file=sys.stderr)
         sys.exit(1)
     if args.verbose:
-        print(f"Writing {filename}")
-    with open(filename, "w") as fp:
+        print(f'Writing {filename}')
+    with open(filename, 'w') as fp:
         Reads(reads).save(fp, saveAs)
 
 # Rename numeric filenames to have leading zeroes.
 if count and not args.noLeadingZeroes:
     width = int(log10(count)) + 1
     if width > 1:
         if args.verbose:
-            print("Renaming to add leading zeroes.")
+            print('Renaming to add leading zeroes.')
         for i in range(1, count + 1):
             old = str(i)
-            new = "%0*d" % (width, i)
+            new = '%0*d' % (width, i)
             if old == new:
                 # We've reached the point where the new names have as many
                 # digits as the old, so we can stop.
                 break
             else:
-                oldFilename = outDir / f"{old}.fasta"
-                newFilename = outDir / f"{new}.fasta"
+                oldFilename = outDir / f'{old}.fasta'
+                newFilename = outDir / f'{new}.fasta'
                 if newFilename.exists() and not args.force:
-                    print(
-                        f"Will not overwrite pre-existing file "
-                        f"{str(newFilename)!r}. Use --force to make me. "
-                        f"Exiting.",
-                        file=sys.stderr,
-                    )
+                    print(f'Will not overwrite pre-existing file '
+                          f'{str(newFilename)!r}. Use --force to make me. '
+                          f'Exiting.', file=sys.stderr)
                     sys.exit(1)
                 if args.verbose:
-                    print(f"  {str(oldFilename)} -> {str(newFilename)}")
+                    print(f'  {str(oldFilename)} -> {str(newFilename)}')
                 rename(oldFilename, newFilename)
```

### Comparing `dark-matter-4.0.84/bin/fasta-subset.py` & `dark-matter-4.0.9/bin/fasta-subset.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,31 +1,34 @@
 #!/usr/bin/env python
 
 """
 Given a set of FASTA sequence identifiers from sys.argv and/or in a file, read
 FASTA from stdin, and print FASTA to stdout for the given sequence ids.
 """
 
+from __future__ import print_function
+
 import sys
 import argparse
 
 from Bio import SeqIO
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
-        description="Extract a subset of FASTA reads by id",
-        epilog="Given a set of FASTA sequence identifiers from sys.argv "
-        "or in a file, read FASTA from stdin, and print FASTA to stdout "
-        "for the given sequence ids.",
-    )
+        description='Extract a subset of FASTA reads by id',
+        epilog='Given a set of FASTA sequence identifiers from sys.argv '
+        'or in a file, read FASTA from stdin, and print FASTA to stdout '
+        'for the given sequence ids.')
 
-    parser.add_argument("ids", default=None, nargs="*", help="Wanted read ids.")
+    parser.add_argument(
+        'ids', default=None, nargs='*', help='Wanted read ids.')
 
-    parser.add_argument("--readIdFile", default=None, help="A file of wanted read ids.")
+    parser.add_argument(
+        '--readIdFile', default=None, help='A file of wanted read ids.')
 
     args = parser.parse_args()
     wanted = set()
 
     if args.ids:
         wanted.update(args.ids)
 
@@ -33,27 +36,25 @@
         with open(args.readIdFile) as fp:
             for line in fp:
                 wanted.add(line[:-1])
 
     found = []
 
     if wanted:
-        for seq in SeqIO.parse(sys.stdin, "fasta"):
+        for seq in SeqIO.parse(sys.stdin, 'fasta'):
             if seq.description in wanted:
                 wanted.remove(seq.description)
                 found.append(seq)
 
         if found:
-            SeqIO.write(found, sys.stdout, "fasta")
+            SeqIO.write(found, sys.stdout, 'fasta')
 
-        print("Found %d sequences." % len(found), file=sys.stderr)
+        print('Found %d sequences.' % len(found), file=sys.stderr)
 
         if wanted:
-            print(
-                "WARNING: %d sequence%s not found: %s"
-                % (len(wanted), "" if len(wanted) == 1 else "s were", " ".join(wanted)),
-                file=sys.stderr,
-            )
+            print('WARNING: %d sequence%s not found: %s' % (
+                len(wanted), '' if len(wanted) == 1 else 's were',
+                ' '.join(wanted)), file=sys.stderr)
     else:
         # No wanted ids were given.
         parser.print_help(sys.stderr)
         sys.exit(1)
```

### Comparing `dark-matter-4.0.84/bin/fasta-variable-sites.py` & `dark-matter-4.0.9/bin/fasta-variable-sites.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,180 +1,124 @@
 #!/usr/bin/env python
 
 import sys
-from typing import Optional
 
 from dark.errors import ReadLengthsNotIdenticalError
 from dark.reads import (
-    addFASTACommandLineOptions,
-    parseFASTACommandLineOptions,
-    Reads,
-    Read,
-)
+    addFASTACommandLineOptions, parseFASTACommandLineOptions, Reads)
 
 
 def printHeader(variableSites, args, baseOffset):
     n = len(variableSites)
-    print(
-        "%d site%s %svariable (threshold for homogeneity: %.3f)."
-        % (
-            n,
-            " was" if n == 1 else "s were",
-            "confirmed " if args.confirm else "",
-            args.homogeneous,
-        ),
-        file=sys.stderr,
-    )
+    print('%d site%s %svariable (threshold for homogeneity: %.3f).' %
+          (n, ' was' if n == 1 else 's were',
+           'confirmed ' if args.confirm else '', args.homogeneous),
+          file=sys.stderr)
     if args.reference:
-        print(
-            "Offsets adjusted by %d, relative to sequence %r."
-            % (baseOffset, args.reference),
-            file=sys.stderr,
-        )
+        print('Offsets adjusted by %d, relative to sequence %r.' %
+              (baseOffset, args.reference), file=sys.stderr)
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
         description=(
-            "Given FASTA on standard input, write reads with only the "
-            "variable sites to standard output. If no sites are variable, "
-            "nothing is written to standard output."
-        )
-    )
-
-    parser.add_argument(
-        "--printSites",
-        action="store_true",
-        default=False,
-        help=(
-            "Print the variable site locations to standard error along "
-            "with the nucleotides found at the site, the homogeneity "
-            "fraction of the site and the reference base (if a reference "
-            "is given)."
-        ),
-    )
-
-    parser.add_argument(
-        "--sitesOnly",
-        action="store_true",
-        default=False,
-        help=(
-            "Only print the (comma separated) variable sites to standard "
-            "output. This output can then be used directly as an argument "
-            "for --keepSites to filter-fasta.py"
-        ),
-    )
-
-    parser.add_argument(
-        "--homogeneous",
-        default=1.0,
-        type=float,
-        help=(
-            "If the most-common nucleotide frequency at a site is at least "
-            "this value, the site will be considered homogeneous."
-        ),
-    )
-
-    parser.add_argument(
-        "--confirm",
-        action="store_true",
-        default=False,
-        help=(
-            "Only keep sites where there is confirm variation (i.e., "
-            "ambiguous sites that are compatible with there being no "
-            "variation are not included)."
-        ),
-    )
-
-    parser.add_argument(
-        "--reference",
-        help=(
-            "A sequence id. Site offsets will be reported relative to this "
-            "sequence. That means the number of gap (hyphen) chars at the "
-            "start of this sequence will be counted and offsets will be "
-            "incremented by that amount (and lower offsets in sequences "
-            "that start before the specified sequence will be ignored)."
-        ),
-    )
-
-    parser.add_argument(
-        "--unknownAreAmbiguous",
-        action="store_true",
-        default=False,
-        help=(
-            "Any unknown character (e.g., a '-' gap or '?' unknown base) "
-            "will be treated as being fully ambiguous (i.e., could be any "
-            "of ACGT). Otherwise, all unknown characters are counted "
-            "as '-' characters."
-        ),
-    )
+            'Given FASTA on standard input, write reads with only the '
+            'variable sites to standard output. If no sites are variable, '
+            'nothing is written to standard output.'))
+
+    parser.add_argument(
+        '--printSites', action='store_true', default=False,
+        help=('Print the variable site locations to standard error along '
+              'with the nucleotides found at the site, the homogeneity '
+              'fraction of the site and the reference base (if a reference '
+              'is given).'))
+
+    parser.add_argument(
+        '--sitesOnly', action='store_true', default=False,
+        help=('Only print the (comma separated) variable sites to standard '
+              'output. This output can then be used directly as an argument '
+              'for --keepSites to filter-fasta.py'))
+
+    parser.add_argument(
+        '--homogeneous', default=1.0, type=float,
+        help=('If the most-common nucleotide frequency at a site is at least '
+              'this value, the site will be considered homogeneous.'))
+
+    parser.add_argument(
+        '--confirm', action='store_true', default=False,
+        help=('Only keep sites where there is confirm variation (i.e., '
+              'ambiguous sites that are compatible with there being no '
+              'variation are not included).'))
+
+    parser.add_argument(
+        '--reference',
+        help=('A sequence id. Site offsets will be reported relative to this '
+              'sequence. That means the number of gap (hyphen) chars at the '
+              'start of this sequence will be counted and offsets will be '
+              'incremented by that amount (and lower offsets in sequences '
+              'that start before the specified sequence will be ignored).'))
+
+    parser.add_argument(
+        '--unknownAreAmbiguous', action='store_true', default=False,
+        help=("Any unknown character (e.g., a '-' gap or '?' unknown base) "
+              "will be treated as being fully ambiguous (i.e., could be any "
+              "of ACGT). Otherwise, all unknown characters are counted "
+              "as '-' characters."))
 
     addFASTACommandLineOptions(parser)
     args = parser.parse_args()
     reads = Reads(list(parseFASTACommandLineOptions(args)))
 
     if not reads:
         sys.exit(0)
 
-    reference: Optional[Read]
-
     if args.reference:
         for read in reads:
             if read.id == args.reference:
                 break
         else:
-            print(
-                "Could not find --reference sequence %r." % args.reference,
-                file=sys.stderr,
-            )
+            print('Could not find --reference sequence %r.' % args.reference,
+                  file=sys.stderr)
             sys.exit(1)
-        baseOffset = len(read.sequence) - len(read.sequence.lstrip("-"))
+        baseOffset = len(read.sequence) - len(read.sequence.lstrip('-'))
         reference = read
     else:
         baseOffset = 0
         reference = None
 
     try:
         variableSites = reads.variableSites(
-            confirm=args.confirm,
-            homogeneityLevel=args.homogeneous,
-            unknownAreAmbiguous=args.unknownAreAmbiguous,
-        )
+            confirm=args.confirm, homogeneityLevel=args.homogeneous,
+            unknownAreAmbiguous=args.unknownAreAmbiguous)
     except ReadLengthsNotIdenticalError:
-        print("Input sequences are not all the same length!", file=sys.stderr)
+        print('Input sequences are not all the same length!', file=sys.stderr)
         sys.exit(2)
 
     if variableSites:
         toDelete = set()
         if args.printSites:
             for site, counts in variableSites.items():
                 if site >= baseOffset:
-                    ref = (" (ref %s)" % reference.sequence[site]) if reference else ""
-                    print(
-                        "%d: %s%s" % (site + 1 - baseOffset, counts, ref),
-                        file=sys.stderr,
-                    )
+                    ref = ((' (ref %s)' % reference.sequence[site])
+                           if reference else '')
+                    print('%d: %s%s' % (site + 1 - baseOffset, counts, ref),
+                          file=sys.stderr)
                 else:
                     toDelete.add(site)
 
         for site in toDelete:
             del variableSites[site]
 
     if variableSites:
         if args.sitesOnly:
-            print(
-                ",".join(
-                    map(lambda site: str(site + 1 - baseOffset), sorted(variableSites))
-                )
-            )
+            print(','.join(map(lambda site: str(site + 1 - baseOffset),
+                               sorted(variableSites))))
         else:
-            saveAs = "fasta" if args.fasta else "fastq"
+            saveAs = 'fasta' if args.fasta else 'fastq'
             reads.filter(keepSites=set(variableSites)).save(sys.stdout, saveAs)
             printHeader(variableSites, args, baseOffset)
     else:
-        print(
-            "No sites were %svariable (threshold for homogeneity: %.3f)."
-            % ("confirmed " if args.confirm else "", args.homogeneous),
-            file=sys.stderr,
-        )
+        print('No sites were %svariable (threshold for homogeneity: %.3f).' %
+              ('confirmed ' if args.confirm else '', args.homogeneous),
+              file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/filter-fasta-by-complexity.py` & `dark-matter-4.0.9/bin/filter-fasta-by-complexity.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,109 +5,95 @@
 with too many bases in low complexity regions.
 
 You must have dustmasker in your shell's PATH for this code to succeed.
 dustmasker is part of the NCBI BLAST+ suite. You can get it from
 ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST
 """
 
+from __future__ import print_function
+
 import sys
 from os import close, unlink
 from time import time
 import argparse
 from subprocess import call
 from tempfile import mkstemp
 
 from dark.fasta import FastaReads
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
-        description="Filter FASTA for low complexity sequences",
-        epilog="Read DNA FASTA from stdin and print FASTA to stdout, "
-        "excluding sequences of low complexity.",
-    )
+        description='Filter FASTA for low complexity sequences',
+        epilog='Read DNA FASTA from stdin and print FASTA to stdout, '
+        'excluding sequences of low complexity.')
 
-    parser.add_argument("fasta", help="The FASTA file to read.")
+    parser.add_argument(
+        'fasta', help='The FASTA file to read.')
 
     parser.add_argument(
-        "--maxLowComplexity",
-        metavar="FRAC",
-        type=float,
-        default=0.1,
-        help="Sequences with a fraction of low-complexity bases up to this "
-        "level will be filtered out.",
-    )
+        '--maxLowComplexity', metavar='FRAC', type=float, default=0.1,
+        help='Sequences with a fraction of low-complexity bases up to this '
+        'level will be filtered out.')
 
     parser.add_argument(
-        "--rejectFile",
-        metavar="FILE",
-        default=None,
-        help="The name of a file to save rejected sequences to.",
-    )
+        '--rejectFile', metavar='FILE', default=None,
+        help='The name of a file to save rejected sequences to.')
 
     args = parser.parse_args()
     fd, outFilename = mkstemp()
     close(fd)
 
     if args.rejectFile is not None:
-        rejectFp = open(args.rejectFile, "w")
+        rejectFp = open(args.rejectFile, 'w')
         reject = rejectFp.write
     else:
-
         def reject(_):
             return None
 
-    cmd = 'dustmasker -in "%s" -out "%s" -outfmt fasta' % (args.fasta, outFilename)
-    print("Running dustmasker. Hang in there... ", end=" ", file=sys.stderr)
+    cmd = 'dustmasker -in "%s" -out "%s" -outfmt fasta' % (
+        args.fasta, outFilename)
+    print('Running dustmasker. Hang in there... ', end=' ', file=sys.stderr)
     start = time()
 
     try:
         status = call(cmd, shell=True)
-        print(
-            "done.\ndustmasker completed in %.2f seconds." % (time() - start),
-            file=sys.stderr,
-        )
+        print('done.\ndustmasker completed in %.2f seconds.' % (
+            time() - start), file=sys.stderr)
         if status < 0:
             # Child terminated by signal.
             unlink(outFilename)
             sys.exit(-status)
         elif status > 0:
-            print("WARNING: Child exited with status", status, file=sys.stderr)
-            print("Output left in", outFilename, file=sys.stderr)
+            print('WARNING: Child exited with status', status, file=sys.stderr)
+            print('Output left in', outFilename, file=sys.stderr)
             sys.exit(status)
     except OSError as e:
-        print("Execution failed:", e, file=sys.stderr)
+        print('Execution failed:', e, file=sys.stderr)
         unlink(outFilename)
         sys.exit(1)
 
     save = sys.stdout.write
     reads = FastaReads(outFilename)
     maxLowComplexity = args.maxLowComplexity
     readCount = rejectCount = 0
 
     for read in reads:
         readCount += 1
-        fasta = read.toString("fasta")
+        fasta = read.toString('fasta')
         if read.lowComplexityFraction() < maxLowComplexity:
             save(fasta)
         else:
             reject(fasta)
             rejectCount += 1
 
     unlink(outFilename)
 
     if args.rejectFile is not None:
         rejectFp.close()
 
-    print(
-        (
-            "%d sequences read, %d (%.2f%%) saved, %d (%.2f%%) rejected."
-            % (
-                readCount,
-                readCount - rejectCount,
-                (readCount - rejectCount) / float(readCount) * 100.0,
-                rejectCount,
-                rejectCount / float(readCount) * 100.0,
-            )
-        ),
-        file=sys.stderr,
-    )
+    print((
+        '%d sequences read, %d (%.2f%%) saved, %d (%.2f%%) rejected.' % (
+            readCount, readCount - rejectCount,
+            (readCount - rejectCount) / float(readCount) * 100.0,
+            rejectCount,
+            rejectCount / float(readCount) * 100.0)), file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/filter-fasta-by-taxonomy.py` & `dark-matter-4.0.9/bin/filter-fasta-by-taxonomy.py`

 * *Files 23% similar despite different names*

```diff
@@ -15,18 +15,19 @@
 
 You must have the NCBI taxonomy database installed locally for this code to
 succeed.  See the file doc/taxonomy.md for instructions on how to set that up.
 If you see sequences unexpectedly rejected because they have no associated
 taxonomy, make sure you have the latest taxonomy files loaded into MySQL.
 """
 
+from __future__ import print_function
+
 import sys
 import argparse
 import re
-from typing import Optional, TextIO
 
 from dark.fasta import FastaReads
 from dark.taxonomy import LineageFetcher
 
 
 def writeDetails(accept, readId, taxonomy, fp):
     """
@@ -34,86 +35,66 @@
 
     @param accept: A C{bool} indicating whether the read was accepted,
         according to its taxonomy.
     @param readId: The C{str} id of the read.
     @taxonomy: A C{list} of taxonomy C{str} levels.
     @fp: An open file pointer to write to.
     """
-    fp.write(
-        "%s %s\n       %s\n\n"
-        % (
-            "MATCH:" if accept else "MISS: ",
-            readId,
-            " | ".join(taxonomy) if taxonomy else "No taxonomy found.",
-        )
-    )
+    fp.write('%s %s\n       %s\n\n' % (
+        'MATCH:' if accept else 'MISS: ', readId,
+        ' | '.join(taxonomy) if taxonomy else 'No taxonomy found.'))
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
-        description="Filter FASTA based on taxonomy",
-        epilog="Read DNA FASTA from stdin and print FASTA to stdout, only "
-        "including sequences that match the requested taxonomy regular "
-        "expression at any level.",
-    )
+        description='Filter FASTA based on taxonomy',
+        epilog='Read DNA FASTA from stdin and print FASTA to stdout, only '
+        'including sequences that match the requested taxonomy regular '
+        'expression at any level.')
 
     parser.add_argument(
-        "--taxonomy",
-        required=True,
-        help="The regex to match the taxonomy on. Case is ignored.",
-    )
+        '--taxonomy', required=True,
+        help='The regex to match the taxonomy on. Case is ignored.')
 
     parser.add_argument(
-        "--invert",
-        action="store_true",
-        default=False,
-        help="If True, only write sequences whose taxonomy does not match.",
-    )
+        '--invert', action='store_true', default=False,
+        help='If True, only write sequences whose taxonomy does not match.')
 
     parser.add_argument(
-        "--detailsFile",
-        metavar="FILE",
-        default=None,
-        help="The name of a file to save taxonomy details to",
-    )
+        '--detailsFile', metavar='FILE', default=None,
+        help='The name of a file to save taxonomy details to')
 
     args = parser.parse_args()
 
     try:
         regexp = re.compile(args.taxonomy, re.I)
     except re.error as e:
-        print(
-            "Could not compile %r to a regular expression:" % args.taxonomy,
-            e,
-            file=sys.stderr,
-        )
+        print('Could not compile %r to a regular expression:' % args.taxonomy,
+              e, file=sys.stderr)
         sys.exit(1)
 
-    detailsFp: Optional[TextIO]
-
     if args.detailsFile is not None:
-        detailsFp = open(args.detailsFile, "w")
+        detailsFp = open(args.detailsFile, 'w')
 
         def details(accept, readId, taxonomy):
             return writeDetails(accept, readId, taxonomy, detailsFp)
-
     else:
         detailsFp = None
 
         def details(accept, readId, taxonomy):
             return None
 
     lineageFetcher = LineageFetcher()
     reads = FastaReads(sys.stdin)
     save = sys.stdout.write
     readCount = saveCount = noTaxonomyCount = 0
 
     for read in reads:
         readCount += 1
-        fasta = read.toString("fasta")
+        fasta = read.toString('fasta')
         taxonomy = lineageFetcher.lineage(read.id)
         if taxonomy:
             for taxonomyId, scientificName in taxonomy:
                 if regexp.match(scientificName):
                     details(True, read.id, taxonomy)
                     if not args.invert:
                         saveCount += 1
@@ -129,21 +110,14 @@
 
     if detailsFp:
         detailsFp.close()
 
     lineageFetcher.close()
 
     rejectCount = readCount - saveCount - noTaxonomyCount
-    print(
-        "%d sequences read, %d (%.2f%%) saved, %d (%.2f%%) rejected, "
-        "%d (%.2f%%) no taxomony found."
-        % (
-            readCount,
-            saveCount,
-            saveCount / float(readCount) * 100.0,
-            rejectCount,
-            (rejectCount) / float(readCount) * 100.0,
-            noTaxonomyCount,
-            noTaxonomyCount / float(readCount) * 100.0,
-        ),
-        file=sys.stderr,
-    )
+    print('%d sequences read, %d (%.2f%%) saved, %d (%.2f%%) rejected, '
+          '%d (%.2f%%) no taxomony found.' % (
+              readCount,
+              saveCount, saveCount / float(readCount) * 100.0,
+              rejectCount, (rejectCount) / float(readCount) * 100.0,
+              noTaxonomyCount, noTaxonomyCount / float(readCount) * 100.0),
+          file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/filter-fasta.py` & `dark-matter-4.0.9/bin/filter-fasta.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,121 +1,90 @@
 #!/usr/bin/env python
 
+from __future__ import print_function, division
+
 import sys
 
 from dark.filter import (
-    addFASTAFilteringCommandLineOptions,
-    parseFASTAFilteringCommandLineOptions,
-    addFASTAEditingCommandLineOptions,
-    parseFASTAEditingCommandLineOptions,
-)
+    addFASTAFilteringCommandLineOptions, parseFASTAFilteringCommandLineOptions,
+    addFASTAEditingCommandLineOptions, parseFASTAEditingCommandLineOptions)
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description=(
-            "Given FASTA on stdin and a set of filtering criteria "
-            "write filtered FASTA to stdout."
-        ),
-    )
+        description=('Given FASTA on stdin and a set of filtering criteria '
+                     'write filtered FASTA to stdout.'))
 
     parser.add_argument(
-        "--quiet",
-        action="store_true",
-        default=False,
-        help=("If True, do not print the final sequence summary."),
-    )
+        '--quiet', action='store_true', default=False,
+        help=('If True, do not print the final sequence summary.'))
 
     parser.add_argument(
-        "--saveAs",
-        choices=("fasta", "fastq", "fasta-ss"),
-        help=(
-            "The output format. The default is to match the input format, "
-            "so there is usually no need to specify this option. It can be "
-            "used to force conversion from FASTQ to FASTA"
-        ),
-    )
+        '--saveAs', choices=('fasta', 'fastq', 'fasta-ss'),
+        help=('The output format. The default is to match the input format, '
+              'so there is usually no need to specify this option. It can be '
+              'used to force conversion from FASTQ to FASTA'))
 
     parser.add_argument(
-        "--checkResultCount",
-        type=int,
-        help=(
-            "The number of reads expected in the output. If this number is "
-            "not seen, the script exits with status 1 and an error "
-            "message is printed unless --quiet was used."
-        ),
-    )
+        '--checkResultCount', type=int,
+        help=('The number of reads expected in the output. If this number is '
+              'not seen, the script exits with status 1 and an error '
+              'message is printed unless --quiet was used.'))
 
     addFASTACommandLineOptions(parser)
     addFASTAFilteringCommandLineOptions(parser)
     addFASTAEditingCommandLineOptions(parser)
 
     args = parser.parse_args()
 
     # Note that we must call parseFASTACommandLineOptions here before we
     # examine args.fasta in the following code. That's because
     # parseFASTACommandLineOptions sets args.fasta to be True if no format
     # is given.
     reads = parseFASTAEditingCommandLineOptions(
-        args,
-        parseFASTAFilteringCommandLineOptions(args, parseFASTACommandLineOptions(args)),
-    )
+        args, parseFASTAFilteringCommandLineOptions(
+            args, parseFASTACommandLineOptions(args)))
 
     saveAs = (
-        args.saveAs
-        or (args.fasta and "fasta")
-        or (args.fastq and "fastq")
-        or (args.fasta_ss and "fasta-ss")
-    )
+        args.saveAs or
+        (args.fasta and 'fasta') or
+        (args.fastq and 'fastq') or
+        (args.fasta_ss and 'fasta-ss'))
 
     # Check for incompatible read/write formats. We can't write FASTQ
     # unless we have FASTQ on input (else we won't have quality information),
     # and we can't write PDB FASTA with secondary structure information
     # unless we have that on input.
-    if saveAs == "fastq" and not args.fastq:
+    if saveAs == 'fastq' and not args.fastq:
         raise ValueError(
-            "You have specified --saveAs fastq without using --fastq "
-            "to indicate that the input is FASTQ. Please be explicit."
-        )
-    elif saveAs == "fasta-ss" and not args.fasta_ss:
+            'You have specified --saveAs fastq without using --fastq '
+            'to indicate that the input is FASTQ. Please be explicit.')
+    elif saveAs == 'fasta-ss' and not args.fasta_ss:
         raise ValueError(
-            "You have specified --saveAs fasta-ss without using --fasta-ss "
-            "to indicate that the input is PDB FASTA. Please be explicit."
-        )
+            'You have specified --saveAs fasta-ss without using --fasta-ss '
+            'to indicate that the input is PDB FASTA. Please be explicit.')
 
     write = sys.stdout.write
     kept = 0
     for read in reads:
         kept += 1
         write(read.toString(format_=saveAs))
 
     total = reads.unfilteredLength()
 
     if not args.quiet:
-        print(
-            "Read %d sequence%s, kept %d (%.2f%%)."
-            % (
-                total,
-                "" if total == 1 else "s",
-                kept,
-                0.0 if total == 0 else kept / total * 100.0,
-            ),
-            file=sys.stderr,
-        )
+        print('Read %d sequence%s, kept %d (%.2f%%).' %
+              (total, '' if total == 1 else 's', kept,
+               0.0 if total == 0 else kept / total * 100.0), file=sys.stderr)
 
     if args.checkResultCount is not None:
         if kept != args.checkResultCount:
             if not args.quiet:
-                print(
-                    "Did not write the expected %d sequence%s (wrote %d)."
-                    % (
-                        args.checkResultCount,
-                        "" if args.checkResultCount == 1 else "s",
-                        kept,
-                    ),
-                    file=sys.stderr,
-                )
+                print('Did not write the expected %d sequence%s (wrote %d).' %
+                      (args.checkResultCount,
+                       '' if args.checkResultCount == 1 else 's', kept),
+                      file=sys.stderr)
             sys.exit(1)
```

### Comparing `dark-matter-4.0.84/bin/filter-hits-to-fasta.py` & `dark-matter-4.0.9/bin/filter-hits-to-fasta.py`

 * *Files 25% similar despite different names*

```diff
@@ -4,173 +4,124 @@
 Given a JSON BLAST output file, a FASTA sequence file, and interesting
 criteria, write a FASTA file (to sys.stdout) of the reads that match the
 criteria.
 
 Run with --help for help.
 """
 
+from __future__ import print_function
+
 import sys
 import argparse
 
 from dark.reads import Reads
 from dark.fasta import FastaReads
 from dark.titles import TitlesAlignments
 from dark.blast.alignments import BlastReadsAlignments
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
+
     parser = argparse.ArgumentParser(
-        description="Extract FASTA from matching BLAST hits.",
-        epilog="Given JSON BLAST output files, a FASTA sequence file, "
-        "and filtering criteria, produce a FASTA file on stdout "
-        "containing the reads that match the criteria.",
+        description='Extract FASTA from matching BLAST hits.',
+        epilog='Given JSON BLAST output files, a FASTA sequence file, '
+        'and filtering criteria, produce a FASTA file on stdout '
+        'containing the reads that match the criteria.'
     )
 
     # Args for the JSON BLAST and FASTA files.
     parser.add_argument(
-        "json",
-        metavar="BLAST-JSON-file",
-        nargs="+",
-        help="the JSON file of BLAST output.",
-    )
+        'json', metavar='BLAST-JSON-file', nargs='+',
+        help='the JSON file of BLAST output.')
 
     parser.add_argument(
-        "--fasta",
-        metavar="FASTA-file",
-        required=True,
-        help="the FASTA file of sequences that were given to BLAST.",
-    )
+        '--fasta', metavar='FASTA-file', required=True,
+        help='the FASTA file of sequences that were given to BLAST.')
 
     # Args for filtering on ReadsAlignments.
     parser.add_argument(
-        "--minStart",
-        type=int,
-        default=None,
-        help="Reads that start before this subject offset should not be " "shown.",
-    )
+        '--minStart', type=int, default=None,
+        help='Reads that start before this subject offset should not be '
+        'shown.')
 
     parser.add_argument(
-        "--maxStop",
-        type=int,
-        default=None,
-        help="Reads that end after this subject offset should not be shown.",
-    )
+        '--maxStop', type=int, default=None,
+        help='Reads that end after this subject offset should not be shown.')
 
     parser.add_argument(
-        "--oneAlignmentPerRead",
-        default=False,
-        action="store_true",
-        help="If C{True}, only keep the best alignment for each read.",
-    )
+        '--oneAlignmentPerRead', default=False, action='store_true',
+        help='If C{True}, only keep the best alignment for each read.')
 
     parser.add_argument(
-        "--scoreCutoff",
-        type=float,
-        default=None,
-        help=("A float score. Matches with scores worse than " "this will be ignored."),
-    )
+        '--scoreCutoff', type=float, default=None,
+        help=('A float score. Matches with scores worse than '
+              'this will be ignored.'))
 
     parser.add_argument(
-        "--maxHspsPerHit",
-        type=int,
-        default=None,
-        help="A numeric max number of HSPs to show for each hit on hitId.",
-    )
+        '--maxHspsPerHit', type=int, default=None,
+        help='A numeric max number of HSPs to show for each hit on hitId.')
 
     parser.add_argument(
-        "--whitelist",
-        nargs="+",
-        default=None,
-        help="sequence titles that should be whitelisted",
-    )
+        '--whitelist', nargs='+', default=None,
+        help='sequence titles that should be whitelisted')
 
     parser.add_argument(
-        "--blacklist",
-        nargs="+",
-        default=None,
-        help="sequence titles that should be blacklisted",
-    )
+        '--blacklist', nargs='+', default=None,
+        help='sequence titles that should be blacklisted')
 
     parser.add_argument(
-        "--titleRegex", default=None, help="a regex that sequence titles must match."
-    )
+        '--titleRegex', default=None,
+        help='a regex that sequence titles must match.')
 
     parser.add_argument(
-        "--negativeTitleRegex",
-        default=None,
-        help="a regex that sequence titles must not match.",
-    )
+        '--negativeTitleRegex', default=None,
+        help='a regex that sequence titles must not match.')
 
     parser.add_argument(
-        "--truncateTitlesAfter",
-        default=None,
-        help="a string that titles will be truncated beyond. If a truncated "
-        "title has already been seen, that title will be skipped.",
-    )
+        '--truncateTitlesAfter', default=None,
+        help='a string that titles will be truncated beyond. If a truncated '
+        'title has already been seen, that title will be skipped.')
 
     parser.add_argument(
-        "--minSequenceLen",
-        type=int,
-        default=None,
-        help="sequences of lesser length will be elided.",
-    )
+        '--minSequenceLen', type=int, default=None,
+        help='sequences of lesser length will be elided.')
 
     parser.add_argument(
-        "--maxSequenceLen",
-        type=int,
-        default=None,
-        help="sequences of greater length will be elided.",
-    )
+        '--maxSequenceLen', type=int, default=None,
+        help='sequences of greater length will be elided.')
 
     parser.add_argument(
-        "--taxonomy",
-        default=None,
-        help="a string of the taxonomic group on which should be "
-        'filtered. eg "Vira" will filter on viruses.',
-    )
+        '--taxonomy', default=None,
+        help='a string of the taxonomic group on which should be '
+        'filtered. eg "Vira" will filter on viruses.')
 
     # Args for filtering on TitlesAlignments.
     parser.add_argument(
-        "--minMatchingReads",
-        type=int,
-        default=None,
-        help="sequences that are matched by fewer reads will be elided.",
-    )
+        '--minMatchingReads', type=int, default=None,
+        help='sequences that are matched by fewer reads will be elided.')
 
     parser.add_argument(
-        "--maxMatchingReads",
-        type=int,
-        default=None,
-        help="sequences that are matched by more reads will be elided.",
-    )
+        '--maxMatchingReads', type=int, default=None,
+        help='sequences that are matched by more reads will be elided.')
 
     parser.add_argument(
-        "--minMedianScore",
-        type=float,
-        default=None,
-        help="sequences that are matched with a median score that is "
-        "worse will be elided.",
-    )
+        '--minMedianScore', type=float, default=None,
+        help='sequences that are matched with a median score that is '
+        'worse will be elided.')
 
     parser.add_argument(
-        "--withScoreBetterThan",
-        type=float,
-        default=None,
-        help="sequences that are matched without at least one score "
-        "at least this good will be elided.",
-    )
+        '--withScoreBetterThan', type=float, default=None,
+        help='sequences that are matched without at least one score '
+        'at least this good will be elided.')
 
     parser.add_argument(
-        "--minNewReads",
-        type=float,
-        default=None,
-        help="The fraction of its reads by which a new read set must differ "
-        "from all previously seen read sets in order to be considered "
-        "acceptably different.",
-    )
+        '--minNewReads', type=float, default=None,
+        help='The fraction of its reads by which a new read set must differ '
+        'from all previously seen read sets in order to be considered '
+        'acceptably different.')
 
     args = parser.parse_args()
     reads = FastaReads(args.fasta)
     readsAlignments = BlastReadsAlignments(reads, args.json)
 
     # Convert white/blacklists lists to sets.
     if args.whitelist is not None:
@@ -187,42 +138,36 @@
         maxHspsPerHit=args.maxHspsPerHit,
         scoreCutoff=args.scoreCutoff,
         whitelist=args.whitelist,
         blacklist=args.blacklist,
         titleRegex=args.titleRegex,
         negativeTitleRegex=args.negativeTitleRegex,
         truncateTitlesAfter=args.truncateTitlesAfter,
-        taxonomy=args.taxonomy,
-    )
+        taxonomy=args.taxonomy)
 
     reads = Reads()
     count = 0
 
-    if (
-        args.minMatchingReads is None
-        and args.maxMatchingReads is None
-        and args.minMedianScore is None
-        and args.withScoreBetterThan is None
-        and args.minNewReads is None
-    ):
+    if (args.minMatchingReads is None and
+            args.maxMatchingReads is None and args.minMedianScore is None and
+            args.withScoreBetterThan is None and args.minNewReads is None):
         # No need to collect into titles, just get the read ids from
         # the matching alignments.
         for readAlignment in readsAlignments:
             reads.add(readAlignment.read)
             count += 1
     else:
         # We need to collect alignments into titles.
         titlesAlignments = TitlesAlignments(readsAlignments).filter(
             minMatchingReads=args.minMatchingReads,
             maxMatchingReads=args.maxMatchingReads,
             minMedianScore=args.minMedianScore,
             withScoreBetterThan=args.withScoreBetterThan,
-            minNewReads=args.minNewReads,
-        )
+            minNewReads=args.minNewReads)
 
         for titleAlignments in titlesAlignments.values():
             for alignment in titleAlignments.alignments:
                 reads.add(alignment.read)
                 count += 1
 
     reads.save(sys.stdout)
-    print("Found %d matching reads." % count, file=sys.stderr)
+    print('Found %d matching reads.' % count, file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/filter-reads-alignments.py` & `dark-matter-4.0.9/bin/filter-reads-alignments.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,287 +1,202 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 from itertools import chain
 
 from dark.fasta import FastaReads
 from dark.fastq import FastqReads
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
+
     # We do not use the addFASTACommandLineOptions and
     # parseFASTACommandLineOptions utility functions below because we allow
     # multiple FASTA or FASTQ files on the command line, which we specify
     # by --fasta and --fastq. And those names clash with the option names
     # used by those utility functions.
 
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description=(
-            "Filter reads alignments to select a subset of reads. ",
-            "Given BLAST or DIAMOND JSON output files and the "
-            "FASTA (or FASTQ) query sequence files given to BLAST or "
-            "DIAMOND, and some filtering criteria, print the input "
-            "reads that pass the filtering.",
-        ),
-    )
-
-    parser.add_argument(
-        "--matcher",
-        default="blast",
-        choices=("blast", "diamond"),
-        help="The matching algorithm that was used to produce the JSON.",
-    )
-
-    parser.add_argument(
-        "--json",
-        metavar="FILE.JSON[.BZ2]",
-        nargs="+",
-        action="append",
-        required=True,
-        help="the JSON file(s) of BLAST or DIAMOND output.",
-    )
+        description=('Filter reads alignments to select a subset of reads. ',
+                     'Given BLAST or DIAMOND JSON output files and the '
+                     'FASTA (or FASTQ) query sequence files given to BLAST or '
+                     'DIAMOND, and some filtering criteria, print the input '
+                     'reads that pass the filtering.'))
+
+    parser.add_argument(
+        '--matcher', default='blast', choices=('blast', 'diamond'),
+        help='The matching algorithm that was used to produce the JSON.')
+
+    parser.add_argument(
+        '--json', metavar='FILE.JSON[.BZ2]', nargs='+', action='append',
+        required=True, help='the JSON file(s) of BLAST or DIAMOND output.')
 
     # A mutually exclusive group for either FASTA or FASTQ files.
     group = parser.add_mutually_exclusive_group(required=True)
 
     group.add_argument(
-        "--fasta",
-        metavar="FILE.FASTA",
-        nargs="+",
-        action="append",
-        help=("the FASTA file(s) of sequences that were given to BLAST " "or DIAMOND."),
-    )
+        '--fasta', metavar='FILE.FASTA', nargs='+', action='append',
+        help=('the FASTA file(s) of sequences that were given to BLAST '
+              'or DIAMOND.'))
 
     group.add_argument(
-        "--fastq",
-        metavar="FILE.FASTQ",
-        nargs="+",
-        action="append",
-        help=("the FASTQ file(s) of sequences that were given to BLAST " "or DIAMOND."),
-    )
+        '--fastq', metavar='FILE.FASTQ', nargs='+', action='append',
+        help=('the FASTQ file(s) of sequences that were given to BLAST '
+              'or DIAMOND.'))
 
     # Args specific to DIAMOND.
 
     # A group for either the DIAMOND FASTA file or a sqlite3 database
     # of the FASTA used to make the DIAMOND database.
     group = parser.add_mutually_exclusive_group()
 
     group.add_argument(
-        "--diamondDatabaseFastaFilename",
-        metavar="FILE.FASTA",
-        help=(
-            "The filename of the FASTA file used to make the DIAMOND "
-            "database. If --matcher diamond is used, either this argument "
-            "or --diamondSqliteDatabaseFilename must be specified."
-        ),
-    )
+        '--diamondDatabaseFastaFilename', metavar='FILE.FASTA',
+        help=('The filename of the FASTA file used to make the DIAMOND '
+              'database. If --matcher diamond is used, either this argument '
+              'or --diamondSqliteDatabaseFilename must be specified.'))
 
     group.add_argument(
-        "--diamondSqliteDatabaseFilename",
-        metavar="FILE.SQL",
-        help=(
-            "The filename of the sqlite3 database file of FASTA metadata, "
-            "made from the FASTA that was used to make the DIAMOND "
-            "database. If --matcher diamond is used, either this argument "
-            "or --diamondDatabaseFilename must be specified."
-        ),
-    )
-
-    parser.add_argument(
-        "--diamondDatabaseFastaDirectory",
-        metavar="DIR",
-        help=(
-            "The directory where the FASTA file used to make the DIAMOND "
-            "database can be found. This argument is only useful when "
-            "--diamondSqliteDatabaseFilename is specified."
-        ),
-    )
+        '--diamondSqliteDatabaseFilename', metavar='FILE.SQL',
+        help=('The filename of the sqlite3 database file of FASTA metadata, '
+              'made from the FASTA that was used to make the DIAMOND '
+              'database. If --matcher diamond is used, either this argument '
+              'or --diamondDatabaseFilename must be specified.'))
+
+    parser.add_argument(
+        '--diamondDatabaseFastaDirectory', metavar='DIR',
+        help=('The directory where the FASTA file used to make the DIAMOND '
+              'database can be found. This argument is only useful when '
+              '--diamondSqliteDatabaseFilename is specified.'))
 
     # Args for filtering on ReadsAlignments.
     parser.add_argument(
-        "--minStart",
-        type=int,
-        metavar="OFFSET",
-        help="Reads that start before this subject offset should not be " "shown.",
-    )
+        '--minStart', type=int, metavar='OFFSET',
+        help='Reads that start before this subject offset should not be '
+        'shown.')
 
     parser.add_argument(
-        "--maxStop",
-        type=int,
-        metavar="OFFSET",
-        help="Reads that end after this subject offset should not be shown.",
-    )
+        '--maxStop', type=int, metavar='OFFSET',
+        help='Reads that end after this subject offset should not be shown.')
 
     parser.add_argument(
-        "--oneAlignmentPerRead",
-        default=False,
-        action="store_true",
-        help="If True, only keep the best alignment for each read.",
-    )
+        '--oneAlignmentPerRead', default=False, action='store_true',
+        help='If True, only keep the best alignment for each read.')
 
     parser.add_argument(
-        "--maxAlignmentsPerRead",
-        type=int,
-        metavar="N",
-        help=(
-            "Reads with more than this many alignments will be elided. Pass "
-            "zero to only keep reads with no matches (alignments)."
-        ),
-    )
+        '--maxAlignmentsPerRead', type=int, metavar='N',
+        help=('Reads with more than this many alignments will be elided. Pass '
+              'zero to only keep reads with no matches (alignments).'))
 
     parser.add_argument(
-        "--scoreCutoff",
-        type=float,
-        metavar="SCORE",
-        help=("A float score. Matches with scores worse than this will be " "ignored."),
-    )
+        '--scoreCutoff', type=float, metavar='SCORE',
+        help=('A float score. Matches with scores worse than this will be '
+              'ignored.'))
 
     parser.add_argument(
-        "--maxHspsPerHit",
-        type=int,
-        metavar="N",
-        help=("A numeric maximum number of HSPs to keep for each subject " "match."),
-    )
+        '--maxHspsPerHit', type=int, metavar='N',
+        help=('A numeric maximum number of HSPs to keep for each subject '
+              'match.'))
 
     parser.add_argument(
-        "--whitelist",
-        nargs="+",
-        action="append",
-        metavar="TITLE",
-        help="subject titles that should be whitelisted",
-    )
+        '--whitelist', nargs='+', action='append',
+        metavar='TITLE', help='subject titles that should be whitelisted')
 
     parser.add_argument(
-        "--blacklist",
-        nargs="+",
-        action="append",
-        metavar="TITLE",
-        help="subject titles that should be blacklisted",
-    )
+        '--blacklist', nargs='+', action='append',
+        metavar='TITLE', help='subject titles that should be blacklisted')
 
     parser.add_argument(
-        "--titleRegex",
-        metavar="TITLE-REGEX",
-        help="a regex that subject titles must match.",
-    )
+        '--titleRegex', metavar='TITLE-REGEX',
+        help='a regex that subject titles must match.')
 
     parser.add_argument(
-        "--negativeTitleRegex",
-        metavar="TITLE-REGEX",
-        help="a regex that subject titles must not match.",
-    )
+        '--negativeTitleRegex', metavar='TITLE-REGEX',
+        help='a regex that subject titles must not match.')
 
     parser.add_argument(
-        "--truncateTitlesAfter",
-        help=(
-            "a string that subject titles will be truncated beyond. If the "
-            "truncated version of a title has already been seen, "
-            "that title will be skipped."
-        ),
-    )
+        '--truncateTitlesAfter',
+        help=('a string that subject titles will be truncated beyond. If the '
+              'truncated version of a title has already been seen, '
+              'that title will be skipped.'))
 
     parser.add_argument(
-        "--minSequenceLen",
-        type=int,
-        metavar="N",
-        help="subjects of lesser length will be elided.",
-    )
+        '--minSequenceLen', type=int, metavar='N',
+        help='subjects of lesser length will be elided.')
 
     parser.add_argument(
-        "--maxSequenceLen",
-        type=int,
-        metavar="N",
-        help="subjects of greater length will be elided.",
-    )
+        '--maxSequenceLen', type=int, metavar='N',
+        help='subjects of greater length will be elided.')
 
     parser.add_argument(
-        "--taxonomy",
-        metavar="NAME",
-        help=(
-            "the taxonomic group that subjects must match "
-            'E.g., "Vira" will filter on viruses.'
-        ),
-    )
+        '--taxonomy', metavar='NAME',
+        help=('the taxonomic group that subjects must match '
+              'E.g., "Vira" will filter on viruses.'))
 
     args = parser.parse_args()
 
     # Flatten lists of lists that we get from using both nargs='+' and
     # action='append'. We use both because it allows people to use (e.g.)
     # --json on the command line either via "--json file1 --json file2" or
     # "--json file1 file2", or a combination of these. That way it's not
     # necessary to remember which way you're supposed to use it and you also
     # can't be hit by the subtle problem encountered in
     # https://github.com/acorg/dark-matter/issues/453
     jsonFiles = list(chain.from_iterable(args.json))
-    whitelist = set(chain.from_iterable(args.whitelist)) if args.whitelist else None
-    blacklist = set(chain.from_iterable(args.blacklist)) if args.blacklist else None
+    whitelist = (
+        set(chain.from_iterable(args.whitelist)) if args.whitelist else None)
+    blacklist = (
+        set(chain.from_iterable(args.blacklist)) if args.blacklist else None)
 
     # TODO: Add a --readClass command-line option in case we want to
     # process FASTA containing AA sequences.
     if args.fasta:
         reads = FastaReads(list(chain.from_iterable(args.fasta)))
     else:
         reads = FastqReads(list(chain.from_iterable(args.fastq)))
 
-    if args.matcher == "blast":
+    if args.matcher == 'blast':
         from dark.blast.alignments import BlastReadsAlignments
-
         readsAlignments = BlastReadsAlignments(reads, jsonFiles)
     else:
         # Must be 'diamond' (due to parser.add_argument 'choices' argument).
-        if (
-            args.diamondDatabaseFastaFilename is None
-            and args.diamondSqliteDatabaseFilename is None
-        ):
-            print(
-                "Either --diamondDatabaseFastaFilename or "
-                "--diamondSqliteDatabaseFilename must be used with "
-                "--matcher diamond.",
-                file=sys.stderr,
-            )
+        if (args.diamondDatabaseFastaFilename is None and
+                args.diamondSqliteDatabaseFilename is None):
+            print('Either --diamondDatabaseFastaFilename or '
+                  '--diamondSqliteDatabaseFilename must be used with '
+                  '--matcher diamond.', file=sys.stderr)
             sys.exit(1)
-        elif not (
-            args.diamondDatabaseFastaFilename is None
-            or args.diamondSqliteDatabaseFilename is None
-        ):
-            print(
-                "--diamondDatabaseFastaFilename and "
-                "--diamondSqliteDatabaseFilename cannot both be used with "
-                "--matcher diamond.",
-                file=sys.stderr,
-            )
+        elif not (args.diamondDatabaseFastaFilename is None or
+                  args.diamondSqliteDatabaseFilename is None):
+            print('--diamondDatabaseFastaFilename and '
+                  '--diamondSqliteDatabaseFilename cannot both be used with '
+                  '--matcher diamond.', file=sys.stderr)
             sys.exit(1)
 
         from dark.diamond.alignments import DiamondReadsAlignments
-
         readsAlignments = DiamondReadsAlignments(
-            reads,
-            jsonFiles,
+            reads, jsonFiles,
             databaseFilename=args.diamondDatabaseFastaFilename,
             databaseDirectory=args.diamondDatabaseFastaDirectory,
-            sqliteDatabaseFilename=args.diamondSqliteDatabaseFilename,
-        )
+            sqliteDatabaseFilename=args.diamondSqliteDatabaseFilename)
 
     readsAlignments.filter(
         maxAlignmentsPerRead=args.maxAlignmentsPerRead,
         minSequenceLen=args.minSequenceLen,
         maxSequenceLen=args.maxSequenceLen,
-        minStart=args.minStart,
-        maxStop=args.maxStop,
+        minStart=args.minStart, maxStop=args.maxStop,
         oneAlignmentPerRead=args.oneAlignmentPerRead,
         maxHspsPerHit=args.maxHspsPerHit,
         scoreCutoff=args.scoreCutoff,
-        whitelist=whitelist,
-        blacklist=blacklist,
-        titleRegex=args.titleRegex,
-        negativeTitleRegex=args.negativeTitleRegex,
-        truncateTitlesAfter=args.truncateTitlesAfter,
-        taxonomy=args.taxonomy,
-    )
+        whitelist=whitelist, blacklist=blacklist,
+        titleRegex=args.titleRegex, negativeTitleRegex=args.negativeTitleRegex,
+        truncateTitlesAfter=args.truncateTitlesAfter, taxonomy=args.taxonomy)
 
-    format_ = "fasta" if args.fasta else "fastq"
+    format_ = 'fasta' if args.fasta else 'fastq'
     write = sys.stdout.write
 
     for readAlignments in readsAlignments:
         write(readAlignments.read.toString(format_=format_))
```

### Comparing `dark-matter-4.0.84/bin/format-fasta.py` & `dark-matter-4.0.9/bin/format-fasta.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,98 +1,83 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import hashlib
 
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
-        description=(
-            "Given FASTA on stdin, write it to stdout according to a given format."
-        )
-    )
+        description=('Given FASTA on stdin, write it to stdout according to a '
+                     'given format.'))
 
     parser.add_argument(
-        "--prefix",
-        help=(
-            "The string prefix to be used. E.g., use --prefix r for raw "
-            'strings. The default is "f" (i.e., use Python f-strings) for '
-            'Python 3.6 and later, or else "" (i.e., regular strings).'
-        ),
-    )
+        '--prefix',
+        help=('The string prefix to be used. E.g., use --prefix r for raw '
+              'strings. The default is "f" (i.e., use Python f-strings) for '
+              'Python 3.6 and later, or else "" (i.e., regular strings).'))
 
     parser.add_argument(
-        "--start",
-        default=1,
-        type=int,
-        help='The integer to start counting from, for the "count" variable.',
-    )
+        '--start', default=1, type=int,
+        help='The integer to start counting from, for the "count" variable.')
 
     parser.add_argument(
-        "--end",
-        help=(
-            'A string to use as the "end" keyword argument for print(). '
-            "This will be passed to eval, allowing convenient use of "
-            "Python string constructs such as \\t on the command line. "
-            "If not specified, a newline will be printed."
-        ),
-    )
+        '--end',
+        help=('A string to use as the "end" keyword argument for print(). '
+              'This will be passed to eval, allowing convenient use of '
+              'Python string constructs such as \\t on the command line. '
+              'If not specified, a newline will be printed.'))
 
     parser.add_argument(
-        "--format",
-        help=(
-            "The output format. The default is to reproduce the input. "
-            "The format can be that used by Python to specify items in a "
-            'dictionary. Available dictionary items are "id", "sequence", '
-            '"quality", "length", "count", and "md5" (of the sequence). A '
-            "dark.reads.Read instance (named 'read') and an 'md5' "
-            "function (that takes and returns a string) are both also in "
-            "scope for each FASTA record and these can be accessed using "
-            "f-string format (with Python 3.6 or greater). The passed "
-            "format string will be eval'd in a double quoted string, as "
-            "with the --end string, allowing the use of Python string "
-            "conveniences such as \\t on the command line."
-        ),
-    )
+        '--format',
+        help=("The output format. The default is to reproduce the input. "
+              "The format can be that used by Python to specify items in a "
+              'dictionary. Available dictionary items are "id", "sequence", '
+              '"quality", "length", "count", and "md5" (of the sequence). A '
+              "dark.reads.Read instance (named 'read') and an 'md5' "
+              "function (that takes and returns a string) are both also in "
+              "scope for each FASTA record and these can be accessed using "
+              "f-string format (with Python 3.6 or greater). The passed "
+              "format string will be eval'd in a double quoted string, as "
+              "with the --end string, allowing the use of Python string "
+              "conveniences such as \\t on the command line."))
 
     addFASTACommandLineOptions(parser)
     args = parser.parse_args()
     reads = parseFASTACommandLineOptions(args)
 
     format_ = args.format
-    end = "\n" if args.end is None else eval('"' + args.end + '"')
+    end = '\n' if args.end is None else eval('"' + args.end + '"')
 
     if args.prefix is None:
-        prefix = "" if sys.version_info < (3, 6) else "f"
+        prefix = '' if sys.version_info < (3, 6) else 'f'
     else:
         prefix = args.prefix
 
     if format_ is None:
-        format_ = (
-            r">%(id)s\n%(sequence)s"
-            if args.fasta
-            else r"@%(id)s\n%(sequence)s\n+\n%(quality)s"
-        )
+        format_ = (r'>%(id)s\n%(sequence)s' if args.fasta else
+                   r'@%(id)s\n%(sequence)s\n+\n%(quality)s')
 
-    needMd5 = "%(md5)" in format_
-    needLength = "%(length)" in format_
+    needMd5 = '%(md5)' in format_
+    needLength = '%(length)' in format_
 
     def md5(s):
-        return hashlib.md5(s.encode("utf-8")).hexdigest()
+        return hashlib.md5(s.encode('utf-8')).hexdigest()
 
     for count, read in enumerate(reads, start=args.start):
         sequence = read.sequence
         d = {
-            "count": count,
-            "id": read.id,
-            "quality": read.quality,
-            "sequence": sequence,
+            'count': count,
+            'id': read.id,
+            'quality': read.quality,
+            'sequence': sequence,
         }
         if needMd5:
-            d["md5"] = md5(sequence)
+            d['md5'] = md5(sequence)
         if needLength:
-            d["length"] = len(sequence)
+            d['length'] = len(sequence)
 
         print(eval(prefix + '"' + format_ + '" % d'), end=end)
```

### Comparing `dark-matter-4.0.84/bin/genome-protein-summary.py` & `dark-matter-4.0.9/bin/genome-protein-summary.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 from itertools import chain
 
 from dark.civ.proteins import SqliteIndex
 from dark.errors import NoSuchGenomeError
 from dark.filter import (
-    addFASTAFilteringCommandLineOptions,
-    parseFASTAFilteringCommandLineOptions,
-)
+    addFASTAFilteringCommandLineOptions, parseFASTAFilteringCommandLineOptions)
 from dark.genbank import GenomeRanges
 from dark.genomes import GenomeProteinInfo
 from dark.reads import Reads
 from dark.sam import SAMFilter, samReferences
 from dark.utils import pct
 
 
@@ -26,198 +26,147 @@
         'depth', 'name', 'offset', or 'readCount'.
     @param minReadOffsetCount: The minimum number of reads offsets that must
         overlap a protein for the read to be considered as sufficiently
         intersecting the protein.
     """
     genome = gpi.genome
 
-    print("Summary of %s (%s):" % (genome["name"], genome["accession"]))
-    print("  Length: %d" % genome["length"])
-    print("  Protein count: %d" % genome["proteinCount"])
-    print("  Total protein offsets: %s" % (pct(len(gpi.offsets), genome["length"])))
+    print('Summary of %s (%s):' % (genome['name'], genome['accession']))
+    print('  Length: %d' % genome['length'])
+    print('  Protein count: %d' % genome['proteinCount'])
+    print('  Total protein offsets: %s' % (
+        pct(len(gpi.offsets), genome['length'])))
 
     if gpi.samFiles:
-        print("  SAM files analyzed: %d" % len(gpi.samFiles))
+        print('  SAM files analyzed: %d' % len(gpi.samFiles))
         for i, filename in enumerate(gpi.samFiles, start=1):
-            print("    %d: %s" % (i, filename))
+            print('    %d: %s' % (i, filename))
     else:
         return
 
-    print("  Whole genome coverage (not just proteins):")
-    print("    Reads matching genome: %d" % len(gpi.readIdsMatchingGenome))
-    print(
-        "    Covered genome offsets: %s"
-        % (pct(len(gpi.coveredOffsetCount), genome["length"]))
-    )
-    print(
-        "    Average depth across genome: %.3f"
-        % (sum(gpi.coveredOffsetCount.values()) / genome["length"])
-    )
+    print('  Whole genome coverage (not just proteins):')
+    print('    Reads matching genome: %d' % len(gpi.readIdsMatchingGenome))
+    print('    Covered genome offsets: %s' % (
+        pct(len(gpi.coveredOffsetCount), genome['length'])))
+    print('    Average depth across genome: %.3f' % (
+        sum(gpi.coveredOffsetCount.values()) / genome['length']))
 
     coveredProteinOffsetCount = coveredProteinBasesCount = 0
     for offset in gpi.offsets:
         coveredProteinOffsetCount += bool(gpi.coveredOffsetCount[offset])
         coveredProteinBasesCount += gpi.coveredOffsetCount[offset]
 
-    print("  Total protein coverage (irrespective of minReadOffsetCount):")
-    print("    Reads matching proteins: %d" % len(gpi.readIdsForAllProteins()))
-    print(
-        "    Proteins with any coverage: %s"
-        % pct(len(gpi.coveredProteins), genome["proteinCount"])
-    )
-    print(
-        "    Covered protein offsets: %s"
-        % (pct(coveredProteinOffsetCount, len(gpi.offsets)))
-    )
-    print(
-        "    Average depth across proteins: %.3f"
-        % (coveredProteinBasesCount / len(gpi.offsets))
-    )
-
-    if sortOn == "name":
+    print('  Total protein coverage (irrespective of minReadOffsetCount):')
+    print('    Reads matching proteins: %d' % len(gpi.readIdsForAllProteins()))
+    print('    Proteins with any coverage: %s' %
+          pct(len(gpi.coveredProteins), genome['proteinCount']))
+    print('    Covered protein offsets: %s' % (
+        pct(coveredProteinOffsetCount, len(gpi.offsets))))
+    print('    Average depth across proteins: %.3f' % (
+        coveredProteinBasesCount / len(gpi.offsets)))
 
+    if sortOn == 'name':
         def key(proteinAccession):
-            return gpi.proteins[proteinAccession]["name"]
-
+            return gpi.proteins[proteinAccession]['name']
         reverse = False
-    elif sortOn == "offset":
-
+    elif sortOn == 'offset':
         def key(proteinAccession):
-            return GenomeRanges(gpi.proteins[proteinAccession]["offsets"]).ranges[0][0]
-
+            return GenomeRanges(
+                gpi.proteins[proteinAccession]['offsets']).ranges[0][0]
         reverse = False
-    elif sortOn == "readCount":
-
+    elif sortOn == 'readCount':
         def key(proteinAccession):
             coverage = gpi.proteinCoverageInfo(proteinAccession)
-            return len(coverage["readIds"])
-
+            return len(coverage['readIds'])
         reverse = True
-    elif sortOn == "coverage":
-
+    elif sortOn == 'coverage':
         def key(proteinAccession):
             coverage = gpi.proteinCoverageInfo(proteinAccession)
-            return coverage["coveredOffsets"] / coverage["ntLength"]
-
+            return coverage['coveredOffsets'] / coverage['ntLength']
         reverse = True
-    elif sortOn == "depth":
-
+    elif sortOn == 'depth':
         def key(proteinAccession):
             coverage = gpi.proteinCoverageInfo(proteinAccession)
-            return coverage["totalBases"] / coverage["ntLength"]
-
+            return coverage['totalBases'] / coverage['ntLength']
         reverse = True
 
     if minReadOffsetCount is None:
-        print("  Proteins covered (no minReadOffsetCount):")
+        print('  Proteins covered (no minReadOffsetCount):')
     else:
-        print("  Proteins covered (minReadOffsetCount=%d):" % minReadOffsetCount)
+        print('  Proteins covered (minReadOffsetCount=%d):' %
+              minReadOffsetCount)
 
     proteinCount = 0
-    for proteinAccession in sorted(gpi.coveredProteins, key=key, reverse=reverse):
+    for proteinAccession in sorted(gpi.coveredProteins, key=key,
+                                   reverse=reverse):
         protein = gpi.proteins[proteinAccession]
 
-        coverage = gpi.proteinCoverageInfo(proteinAccession, minReadOffsetCount)
+        coverage = gpi.proteinCoverageInfo(proteinAccession,
+                                           minReadOffsetCount)
 
-        readCount = len(coverage["readIds"])
+        readCount = len(coverage['readIds'])
 
         if readCount:
             proteinCount += 1
 
-            print(
-                "    %d: %s (%d AA, %d nt with stop codon, %s)"
-                % (
-                    proteinCount,
-                    protein["product"],
-                    protein["length"],
-                    protein["length"] * 3 + 3,
-                    protein["accession"],
-                )
-            )
-
-            print("      Read count: %d" % readCount)
-
-            print(
-                "      Covered offsets: %s"
-                % (pct(coverage["coveredOffsets"], coverage["ntLength"]))
-            )
-
-            print(
-                "      Average depth: %.3f"
-                % (coverage["totalBases"] / coverage["ntLength"])
-            )
-
-            print("      Offsets: %s" % protein["offsets"])
-
-    print(
-        "  Proteins matched: %s (sorted by %s):"
-        % (pct(proteinCount, genome["proteinCount"]), sortOn)
-    )
+            print('    %d: %s (%d AA, %d nt with stop codon, %s)' %
+                  (proteinCount, protein['product'], protein['length'],
+                   protein['length'] * 3 + 3, protein['accession']))
+
+            print('      Read count: %d' % readCount)
+
+            print('      Covered offsets: %s' % (
+                pct(coverage['coveredOffsets'], coverage['ntLength'])))
+
+            print('      Average depth: %.3f' % (
+                coverage['totalBases'] / coverage['ntLength']))
+
+            print('      Offsets: %s' % protein['offsets'])
+
+    print('  Proteins matched: %s (sorted by %s):' % (
+        pct(proteinCount, genome['proteinCount']), sortOn))
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description="Print SAM/BAM file protein match statistics.",
-    )
+        description='Print SAM/BAM file protein match statistics.')
 
     parser.add_argument(
-        "--proteinGenomeDatabase",
-        required=True,
-        help=(
-            "The filename of an Sqlite3 database holding protein and "
-            "genome information, as built by make-protein-database.py"
-        ),
-    )
+        '--proteinGenomeDatabase', required=True,
+        help=('The filename of an Sqlite3 database holding protein and '
+              'genome information, as built by make-protein-database.py'))
 
     parser.add_argument(
-        "--progress",
-        default=False,
-        action="store_true",
-        help="Print progress info to standard error.",
-    )
+        '--progress', default=False, action='store_true',
+        help='Print progress info to standard error.')
 
     parser.add_argument(
-        "--sortOn",
-        default="readCount",
-        choices=("coverage", "depth", "name", "offset", "readCount"),
-        help="How to sort proteins for output.",
-    )
+        '--sortOn', default='readCount',
+        choices=('coverage', 'depth', 'name', 'offset', 'readCount'),
+        help='How to sort proteins for output.')
 
     parser.add_argument(
-        "--minReadOffsetCount",
-        type=int,
-        help=(
-            "The minimum number of reads offsets that must overlap a "
-            "protein for the read to be considered as sufficiently "
-            "intersecting the protein. Use this to prevent reads that "
-            "just overlap the protein in a very small number offsets "
-            "from being counted."
-        ),
-    )
+        '--minReadOffsetCount', type=int,
+        help=('The minimum number of reads offsets that must overlap a '
+              'protein for the read to be considered as sufficiently '
+              'intersecting the protein. Use this to prevent reads that '
+              'just overlap the protein in a very small number offsets '
+              'from being counted.'))
 
     parser.add_argument(
-        "--skipTranslationChecks",
-        dest="checkTranslations",
-        action="store_false",
-        default=True,
-        help=(
-            "Skip the sanity check that database protein sequences can all "
-            "be translated from the database genome sequence."
-        ),
-    )
+        '--skipTranslationChecks', dest='checkTranslations',
+        action='store_false', default=True,
+        help=('Skip the sanity check that database protein sequences can all '
+              'be translated from the database genome sequence.'))
 
     addFASTAFilteringCommandLineOptions(parser)
     SAMFilter.addFilteringOptions(
-        parser,
-        samfileIsPositional=False,
-        samfileAction="append",
-        samfileNargs="*",
-        samfileRequired=False,
-    )
+        parser, samfileIsPositional=False, samfileAction='append',
+        samfileNargs='*', samfileRequired=False)
 
     args = parser.parse_args()
 
     samfiles = list(chain.from_iterable(args.samfile)) if args.samfile else []
 
     if samfiles:
         if args.referenceId:
@@ -226,56 +175,46 @@
             # If all SAM files have just one reference and they're all the
             # same, use that. Else complain.
             referenceIds = set()
             for filename in samfiles:
                 referenceIds.update(samReferences(filename))
 
             if len(referenceIds) != 1:
-                print(
-                    "No reference id(s) specified with --referenceId, and "
-                    "the given SAM/BAM files do not contain exactly one "
-                    "(identical) reference. Please use --referenceId"
-                )
+                print('No reference id(s) specified with --referenceId, and '
+                      'the given SAM/BAM files do not contain exactly one '
+                      '(identical) reference. Please use --referenceId')
                 sys.exit(1)
     else:
         if args.referenceId:
             referenceIds = args.referenceId
         else:
-            print("No reference id(s) specified with --referenceId.")
+            print('No reference id(s) specified with --referenceId.')
             sys.exit(1)
 
     # We don't have a file of reads, we just want a read filter that we
     # can use to filter the SAM file query sequences.
     reads = parseFASTAFilteringCommandLineOptions(args, Reads())
     samFilter = SAMFilter.parseFilteringOptions(args, reads.filterRead)
     filterAlignment = samFilter.filterAlignment
 
     proteinGenomeDB = SqliteIndex(args.proteinGenomeDatabase)
 
     for referenceId in referenceIds:
         try:
             gpInfo = GenomeProteinInfo(
-                referenceId, proteinGenomeDB, checkTranslations=args.checkTranslations
-            )
+                referenceId, proteinGenomeDB,
+                checkTranslations=args.checkTranslations)
         except NoSuchGenomeError:
-            print(
-                "Reference %r not found in genome database. Ignoring." % referenceId,
-                file=sys.stderr,
-            )
+            print('Reference %r not found in genome database. Ignoring.' %
+                  referenceId, file=sys.stderr)
         else:
             if samfiles:
                 if args.progress:
-                    print(
-                        "Processing %d SAM file%s for matches with %r:"
-                        % (
-                            len(samfiles),
-                            "" if len(samfiles) == 1 else "s",
-                            referenceId,
-                        ),
-                        file=sys.stderr,
-                    )
+                    print('Processing %d SAM file%s for matches with %r:' %
+                          (len(samfiles), '' if len(samfiles) == 1 else 's',
+                           referenceId), file=sys.stderr)
                 for i, filename in enumerate(samfiles, start=1):
                     if args.progress:
-                        print("  %d: %s" % (i, filename), file=sys.stderr)
+                        print('  %d: %s' % (i, filename), file=sys.stderr)
                     gpInfo.addSAM(filename, filterAlignment)
 
             summarize(gpInfo, args.sortOn, args.minReadOffsetCount)
```

### Comparing `dark-matter-4.0.84/bin/get-features.py` & `dark-matter-4.0.9/bin/get-features.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 from re import compile
 import sys
-
 from dark.entrez import getSequence
 
 
 def main(gi, ranges):
     """
     Print the features of the genbank entry given by gi. If ranges is
     non-emtpy, only print features that include the ranges.
@@ -21,54 +22,47 @@
 
     if record is None:
         print("Looks like you're offline.")
         sys.exit(3)
     else:
         printed = set()
         if ranges:
-            for start, end in ranges:
+            for (start, end) in ranges:
                 for index, feature in enumerate(record.features):
-                    if (
-                        start < int(feature.location.end)
-                        and end > int(feature.location.start)
-                        and index not in printed
-                    ):
+                    if (start < int(feature.location.end) and
+                            end > int(feature.location.start) and
+                            index not in printed):
                         print(feature)
                         printed.add(index)
         else:
             # Print all features.
             for feature in record.features:
                 print(feature)
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     if len(sys.argv) < 2:
-        print(
-            "Usage: %s gi-number [offset1, offset2, ...]" % sys.argv[0], file=sys.stderr
-        )
+        print('Usage: %s gi-number [offset1, offset2, ...]' %
+              sys.argv[0], file=sys.stderr)
         sys.exit(1)
 
-    rangeRegex = compile(r"^(\d+)(?:-(\d+))?$")
+    rangeRegex = compile(r'^(\d+)(?:-(\d+))?$')
     ranges = []
     for arg in sys.argv[2:]:
         match = rangeRegex.match(arg)
         if match:
             start, end = match.groups()
             start = int(start)
             if end is None:
                 end = start
             else:
                 end = int(end)
             if start > end:
                 start, end = end, start
             ranges.append((start, end))
         else:
-            print(
-                (
-                    "Illegal argument %r. Ranges must single numbers or "
-                    "number-number." % arg
-                ),
-                file=sys.stderr,
-            )
+            print((
+                'Illegal argument %r. Ranges must single numbers or '
+                'number-number.' % arg), file=sys.stderr)
             sys.exit(2)
 
     main(sys.argv[1], ranges)
```

### Comparing `dark-matter-4.0.84/bin/get-hosts.py` & `dark-matter-4.0.9/bin/get-hosts.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,22 +1,23 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 import re
 
 from dark.taxonomy import (
     addTaxonomyDatabaseCommandLineOptions,
-    parseTaxonomyDatabaseCommandLineOptions,
-)
+    parseTaxonomyDatabaseCommandLineOptions)
 
-VERSION_REGEX = re.compile(r"\.\d+$")
+VERSION_REGEX = re.compile(r'\.\d+$')
 
 
-def getHosts(id_, db) -> set[str]:
+def hosts(id_, db):
     """
     Look up hosts for an accession or taxonomy id.
 
     @param id_: The C{str} accession number or taxonomy id to look up.
     @param db: The sqlite3 taxonomy database to consult.
     @return: A C{set} of C{str} host names.
     """
@@ -25,67 +26,53 @@
     except ValueError:
         hosts = db.hosts(id_)
     else:
         hosts = db.hosts(idInt)
 
     if hosts is None and VERSION_REGEX.search(id_) is None:
         # Try adding a version number.
-        hosts = db.hosts(id_ + ".1")
+        hosts = db.hosts(id_ + '.1')
 
     return hosts
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description="Print hosts for accession numbers or taxonomy ids",
-    )
+        description='Print hosts for accession numbers or taxonomy ids')
 
     parser.add_argument(
-        "ids",
-        nargs="*",
-        help=(
-            "The ids (accession numbers, names, or taxonomy ids) to print "
-            "host information for. If not given, ids are read from "
-            "standard input, one per line."
-        ),
-    )
+        'ids', nargs='*',
+        help=('The ids (accession numbers, names, or taxonomy ids) to print '
+              'host information for. If not given, ids are read from '
+              'standard input, one per line.'))
 
     parser.add_argument(
-        "--database",
-        required=True,
-        help=(
-            "The file holding the sqlite3 taxonomy database. See "
-            "https://github.com/acorg/ncbi-taxonomy-database for how to "
-            "build one."
-        ),
-    )
+        '--database', required=True,
+        help=('The file holding the sqlite3 taxonomy database. See '
+              'https://github.com/acorg/ncbi-taxonomy-database for how to '
+              'build one.'))
 
     parser.add_argument(
-        "--printId",
-        default=False,
-        action="store_true",
-        help="If specified, also print the id.",
-    )
+        '--printId', default=False, action='store_true',
+        help='If specified, also print the id.')
 
     addTaxonomyDatabaseCommandLineOptions(parser)
 
     args = parser.parse_args()
 
     db = parseTaxonomyDatabaseCommandLineOptions(args, parser)
 
     if args.ids:
         ids = args.ids
     else:
         ids = (line[:-1] for line in sys.stdin)
 
     for id_ in ids:
         if args.printId:
-            print(id_ + ":")
-        hosts = getHosts(id_, db)
+            print(id_ + ':')
+        hosts = hosts(id_, db)
         if hosts:
-            print(", ".join(sorted(hosts)))
+            print(', '.join(sorted(hosts)))
         else:
-            print(
-                "No host information for %r found in the taxonomy database." % id_,
-                file=sys.stderr,
-            )
+            print('No host information for %r found in the taxonomy database.'
+                  % id_, file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/get-reads.py` & `dark-matter-4.0.9/bin/get-reads.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,9 +1,11 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 from re import compile
 import argparse
 
 from dark.blast.alignments import BlastReadsAlignments
 from dark.titles import TitlesAlignments
 from dark.fasta import FastaReads
@@ -21,118 +23,90 @@
     @param xRange: A (start, end) list of C{int}s, giving an X-axis range or
         C{None} if the entire X axis range should be printed.
     @param bitRange: A (start, end) list of C{int}s, giving a bit score range
         or C{None} if the entire bit score range should be printed.
     """
     reads = FastaReads(fastaFilename)
     blastReadsAlignments = BlastReadsAlignments(reads, recordFilenames)
-    filtered = blastReadsAlignments.filter(
-        whitelist=set([title]), negativeTitleRegex="."
-    )
+    filtered = blastReadsAlignments.filter(whitelist=set([title]),
+                                           negativeTitleRegex='.')
     titlesAlignments = TitlesAlignments(filtered)
 
     if title not in titlesAlignments:
-        print("%s: Title %r not found in BLAST output" % (sys.argv[0], title))
+        print('%s: Title %r not found in BLAST output' % (sys.argv[0], title))
         sys.exit(3)
 
     for titleAlignment in titlesAlignments[title]:
         for hsp in titleAlignment.hsps:
-            if (
-                xRange is None
-                or (xRange[0] <= hsp.subjectEnd and xRange[1] >= hsp.subjectStart)
-            ) and (bitRange is None or (bitRange[0] <= hsp.score.score <= bitRange[1])):
-                print(
-                    (
-                        "query: %s, start: %d, end: %d, score: %d"
-                        % (
-                            titleAlignment.read.id,
-                            hsp.subjectStart,
-                            hsp.subjectEnd,
-                            hsp.score.score,
-                        )
-                    )
-                )
+            if ((xRange is None or (xRange[0] <= hsp.subjectEnd and
+                                    xRange[1] >= hsp.subjectStart)) and
+                (bitRange is None or (bitRange[0] <= hsp.score.score <=
+                                      bitRange[1]))):
+                print(('query: %s, start: %d, end: %d, score: %d' % (
+                       titleAlignment.read.id, hsp.subjectStart,
+                       hsp.subjectEnd, hsp.score.score)))
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     if len(sys.argv) < 3:
-        print(
-            (
-                "Usage: %s recordFilename, fastaFilename, "
-                "title, xCoords, bitCoords" % sys.argv[0]
-            ),
-            file=sys.stderr,
-        )
+        print((
+            'Usage: %s recordFilename, fastaFilename, '
+            'title, xCoords, bitCoords' % sys.argv[0]), file=sys.stderr)
         sys.exit(1)
 
     parser = argparse.ArgumentParser(
-        description=(
-            "Print the reads that are " "at specified positions in an alignmentGraph"
-        ),
-        epilog=(
-            "Given a JSON BLAST output file, a title and an x and / or "
-            "bitRange, print the reads that are within the given Ranges."
-        ),
-    )
+        description=('Print the reads that are '
+                     'at specified positions in an alignmentGraph'),
+        epilog=('Given a JSON BLAST output file, a title and an x and / or '
+                'bitRange, print the reads that are within the given Ranges.'))
 
     parser.add_argument(
-        "json",
-        metavar="BLAST-JSON-file",
-        nargs="+",
-        help="the JSON file of BLAST output.",
-    )
+        'json', metavar='BLAST-JSON-file', nargs='+',
+        help='the JSON file of BLAST output.')
 
     parser.add_argument(
-        "fasta", metavar="fastaFile", help="the FASTA file of BLAST input."
-    )
+        'fasta', metavar='fastaFile', help='the FASTA file of BLAST input.')
 
     parser.add_argument(
-        "title", metavar="SEQUENCE-TITLE", help="The title of the subject sequence."
-    )
+        'title', metavar='SEQUENCE-TITLE',
+        help='The title of the subject sequence.')
 
-    parser.add_argument("--xRange", default=None, help="a range on the x-axis.")
+    parser.add_argument(
+        '--xRange', default=None,
+        help='a range on the x-axis.')
 
     parser.add_argument(
-        "--bitRange", default=None, help="a bit score range on the y-axis."
-    )
+        '--bitRange', default=None,
+        help='a bit score range on the y-axis.')
 
     args = parser.parse_args()
 
     def _getRange(inputRange):
         """
         Convert a string input range into a pair of integers.
 
         @param inputRange: A C{str}, either  a single number like '10', or a
             hyphen-separated pair of numbers like '3-9'. May also be C{None}.
         @return: Either C{None} if inputRange is C{None} or the empty string,
             else a (start, end) list of C{int}s.
         """
         if inputRange:
-            rangeRegex = compile(r"^(\d+)(?:-(\d+))?$")
+            rangeRegex = compile(r'^(\d+)(?:-(\d+))?$')
             match = rangeRegex.match(inputRange)
             if match:
                 start, end = match.groups()
                 start = int(start)
                 if end is None:
                     end = start
                 else:
                     end = int(end)
                 if start > end:
                     start, end = end, start
                 return start, end
             else:
-                print(
-                    (
-                        "Illegal argument %r. Ranges must single numbers or "
-                        "number-number." % inputRange
-                    ),
-                    file=sys.stderr,
-                )
+                print((
+                    'Illegal argument %r. Ranges must single numbers or '
+                    'number-number.' % inputRange), file=sys.stderr)
                 sys.exit(2)
 
-    main(
-        args.json,
-        args.fasta,
-        args.title,
-        _getRange(args.xRange),
-        _getRange(args.bitRange),
-    )
+    main(args.json, args.fasta, args.title,
+         _getRange(args.xRange), _getRange(args.bitRange))
```

### Comparing `dark-matter-4.0.84/bin/get-taxonomy.py` & `dark-matter-4.0.9/bin/get-taxonomy.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 import re
 
 from dark.taxonomy import (
-    formatLineage,
-    addTaxonomyDatabaseCommandLineOptions,
-    parseTaxonomyDatabaseCommandLineOptions,
-)
+    formatLineage, addTaxonomyDatabaseCommandLineOptions,
+    parseTaxonomyDatabaseCommandLineOptions)
 
-VERSION_REGEX = re.compile(r"\.\d+$")
+VERSION_REGEX = re.compile(r'\.\d+$')
 
 
 def taxonomyInfo(id_, db, namesOnly, separator):
     """
     Convert the lineage information for C{id_} into a formatted string.
 
     @param id_: The C{str} accession number or C{int} taxonomy id to
@@ -31,61 +31,45 @@
     except ValueError:
         lineage = db.lineage(id_)
     else:
         lineage = db.lineage(idInt)
 
     if lineage is None and VERSION_REGEX.search(id_) is None:
         # Try adding a version number.
-        lineage = db.lineage(id_ + ".1")
+        lineage = db.lineage(id_ + '.1')
 
     if lineage:
         return formatLineage(lineage, namesOnly, separator)
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description=(
-            "Print taxonomy information for accession numbers or " "taxonomy ids."
-        ),
-    )
+        description=('Print taxonomy information for accession numbers or '
+                     'taxonomy ids.'))
 
     parser.add_argument(
-        "ids",
-        nargs="*",
-        metavar="id",
-        help=(
-            "The ids (accession numbers, names, or taxonomy ids) to print "
-            "taxonomy information for. If not given, ids are read from "
-            "standard input, one per line."
-        ),
-    )
+        'ids', nargs='*', metavar='id',
+        help=('The ids (accession numbers, names, or taxonomy ids) to print '
+              'taxonomy information for. If not given, ids are read from '
+              'standard input, one per line.'))
 
     parser.add_argument(
-        "--separator",
-        help=(
-            "The string to separate output columns with. Default is to "
-            "print aligned output padded with multiple spaces (or a TAB if "
-            "--namesOnly is used)."
-        ),
-    )
+        '--separator',
+        help=('The string to separate output columns with. Default is to '
+              'print aligned output padded with multiple spaces (or a TAB if '
+              '--namesOnly is used).'))
 
     parser.add_argument(
-        "--namesOnly",
-        default=False,
-        action="store_true",
-        help="If specified, only print the taxonomic names.",
-    )
+        '--namesOnly', default=False, action='store_true',
+        help='If specified, only print the taxonomic names.')
 
     parser.add_argument(
-        "--print",
-        default=False,
-        action="store_true",
-        help="If specified, also print the id.",
-    )
+        '--print', default=False, action='store_true',
+        help='If specified, also print the id.')
 
     addTaxonomyDatabaseCommandLineOptions(parser)
 
     args = parser.parse_args()
 
     db = parseTaxonomyDatabaseCommandLineOptions(args, parser)
 
@@ -93,17 +77,18 @@
         ids = args.ids
     else:
         ids = (line.strip() for line in sys.stdin)
 
     separator = args.separator
 
     if args.namesOnly and separator is None:
-        separator = "\t"
+        separator = '\t'
 
     for id_ in ids:
         if args.print:
-            print(id_ + ":")
+            print(id_ + ':')
         result = taxonomyInfo(id_, db, args.namesOnly, separator)
         if result:
             print(result)
         else:
-            print("%r was not found in the taxonomy database" % id_, file=sys.stderr)
+            print('%r was not found in the taxonomy database' % id_,
+                  file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/make-consensus.py` & `dark-matter-4.0.9/bin/make-consensus.py`

 * *Files 15% similar despite different names*

```diff
@@ -6,323 +6,271 @@
 from tempfile import mkdtemp
 from os.path import join, basename
 
 from dark.fasta import FastaReads
 from dark.process import Executor
 
 IVAR_FREQUENCY_THRESHOLD_DEFAULT = 0.6
-IVAR_DOCS = "https://andersen-lab.github.io/ivar/html/manualpage.html#autotoc_md19"
+IVAR_DOCS = (
+    'https://andersen-lab.github.io/ivar/html/manualpage.html#autotoc_md19')
 
 
 def main():
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description="Make a consensus sequence.",
-    )
+        description='Make a consensus sequence.')
 
-    parser.add_argument("--reference", required=True, help="The reference FASTA file.")
+    parser.add_argument(
+        '--reference', required=True,
+        help='The reference FASTA file.')
+
+    parser.add_argument(
+        '--bam',
+        help=('The BAM file from which the consensus should be made. '
+              'Required if --maskLowCoverage is used. If no BAM file is '
+              'given, a VCF file must be provided. If both a BAM and a VCF '
+              'file are given, the VCF file will take precedence.'))
 
     parser.add_argument(
-        "--bam",
-        help=(
-            "The BAM file from which the consensus should be made. "
-            "Required if --maskLowCoverage is used. If no BAM file is "
-            "given, a VCF file must be provided. If both a BAM and a VCF "
-            "file are given, the VCF file will take precedence."
-        ),
-    )
-
-    parser.add_argument(
-        "--vcfFile",
-        help=(
-            "The VCF file. If omitted, bcftools will be used to make a VCF "
-            "file from the BAM file."
-        ),
-    )
+        '--vcfFile',
+        help=('The VCF file. If omitted, bcftools will be used to make a VCF '
+              'file from the BAM file.'))
 
     group = parser.add_mutually_exclusive_group()
 
     group.add_argument(
-        "--id",
-        help=(
-            "The id to use in the consensus sequence in the output FASTA. "
-            "If not given, the reference sequence id will be used."
-        ),
-    )
+        '--id',
+        help=('The id to use in the consensus sequence in the output FASTA. '
+              'If not given, the reference sequence id will be used.'))
 
     group.add_argument(
-        "--idLambda",
-        metavar="LAMBDA-FUNCTION",
-        help=(
-            "A one-argument function taking and returning a read id. "
-            "This can be used to set the id of the reference sequence based "
-            "on the id of the reference sequence (the function will be "
-            "called with the id of the reference sequence). E.g., "
-            "--idLambda \"lambda id: id.split('_')[0]\" or "
-            "--idLambda \"lambda id: id[:10] + '-consensus'\"."
-        ),
-    )
-
-    parser.add_argument(
-        "--sample",
-        help=(
-            "The name of the sample (from the @RG SM tag in the original "
-            "alignment BAM file) for which a consensus should be made. "
-            "If not given, the first sample name (from the #CHROM header) "
-            "in the VCF file will be used."
-        ),
-    )
-
-    parser.add_argument(
-        "--dryRun",
-        action="store_true",
-        help="Do not run commands, just print what would be done.",
-    )
-
-    parser.add_argument(
-        "--maskLowCoverage",
-        default=0,
-        type=int,
-        help=(
-            "Put an N into sites where the coverage is below the specified "
-            "cutoff. If you specify a negative numer, masking will be "
-            "turned off. Requires --bam."
-        ),
-    )
-
-    parser.add_argument(
-        "--log",
-        action="store_true",
-        help=(
-            "Show a log of commands that were (or would be, if --dryRun is "
-            "used) executed."
-        ),
-    )
-
-    parser.add_argument(
-        "--noClean",
-        action="store_false",
-        dest="clean",
-        help="Do not remove intermediate files or the temporary directory.",
-    )
-
-    parser.add_argument(
-        "--callHaplotypesGATK",
-        action="store_true",
-        help=(
-            "Use GATK to call haplotypes. See "
-            "https://gatk.broadinstitute.org for details on GATK."
-        ),
-    )
-
-    parser.add_argument(
-        "--picardJar",
-        help=(
-            "The path to the Picard jar file. See "
-            "https://github.com/broadinstitute/picard for details on "
-            "Picard."
-        ),
-    )
-
-    parser.add_argument(
-        "--ivar",
-        action="store_true",
-        help="If given, ivar will be used to call the consensus.",
-    )
-
-    parser.add_argument(
-        "--ivarFrequencyThreshold",
-        type=float,
-        help=(
-            f"The frequency threshold used by ivar when calling the "
-            f"consensus. If the frequency of the most-common nucleotide at "
-            f"a site meets this threshold, the nucleotide will be called. "
-            f"Otherwise, an ambiguous nucleotide code will be produced, "
-            f"based on the smallest set of most-frequent nucleotides whose "
-            f"summed frequencies meet the threshold. See {IVAR_DOCS} for "
-            f"more information. If not given, "
-            f"{IVAR_FREQUENCY_THRESHOLD_DEFAULT} is used. Can only be used "
-            f"if --ivar is also specified."
-        ),
-    )
-
-    parser.add_argument(
-        "--ivarBedFile",
-        help="If ivar should trim primers, a BED file of the primer " "positions.",
-    )
+        '--idLambda', metavar='LAMBDA-FUNCTION',
+        help=('A one-argument function taking and returning a read id. '
+              'This can be used to set the id of the reference sequence based '
+              'on the id of the reference sequence (the function will be '
+              'called with the id of the reference sequence). E.g., '
+              '--idLambda "lambda id: id.split(\'_\')[0]" or '
+              '--idLambda "lambda id: id[:10] + \'-consensus\'".'))
+
+    parser.add_argument(
+        '--sample',
+        help=('The name of the sample (from the @RG SM tag in the original '
+              'alignment BAM file) for which a consensus should be made. '
+              'If not given, the first sample name (from the #CHROM header) '
+              'in the VCF file will be used.'))
+
+    parser.add_argument(
+        '--dryRun', default=False, action='store_true',
+        help='Do not run commands, just print what would be done.')
+
+    parser.add_argument(
+        '--maskLowCoverage', default=0, type=int,
+        help=('Put an N into sites where the coverage is below the specified '
+              'cutoff. If you specify a negative numer, masking will be '
+              'turned off. Requires --bam.'))
+
+    parser.add_argument(
+        '--log', default=False, action='store_true',
+        help=('Show a log of commands that were (or would be, if --dryRun is '
+              'used) executed.'))
+
+    parser.add_argument(
+        '--noClean', default=True, action='store_false', dest='clean',
+        help=('Do not remove intermediate files or the temporary directory.'))
+
+    parser.add_argument(
+        '--callHaplotypesGATK', default=False, action='store_true',
+        help=('Use GATK to call haplotypes. See '
+              'https://gatk.broadinstitute.org for details on GATK.'))
+
+    parser.add_argument(
+        '--picardJar',
+        help=('The path to the Picard jar file. See '
+              'https://github.com/broadinstitute/picard for details on '
+              'Picard.'))
+
+    parser.add_argument(
+        '--ivar', default=False, action='store_true',
+        help='If given, ivar will be used to call the consensus.')
+
+    parser.add_argument(
+        '--ivarFrequencyThreshold', type=float,
+        help=(f'The frequency threshold used by ivar when calling the '
+              f'consensus. If the frequency of the most-common nucleotide at '
+              f'a site meets this threshold, the nucleotide will be called. '
+              f'Otherwise, an ambiguous nucleotide code will be produced, '
+              f'based on the smallest set of most-frequent nucleotides whose '
+              f'summed frequencies meet the threshold. See {IVAR_DOCS} for '
+              f'more information. If not given, '
+              f'{IVAR_FREQUENCY_THRESHOLD_DEFAULT} is used. Can only be used '
+              f'if --ivar is also specified.'))
+
+    parser.add_argument(
+        '--ivarBedFile',
+        help=('If ivar should trim primers, a BED file of the primer '
+              'positions.'))
 
     args = parser.parse_args()
 
     if not (args.bam or args.vcfFile):
-        print("At least one of --bam or --vcfFile must be given.", file=sys.stderr)
+        print('At least one of --bam or --vcfFile must be given.',
+              file=sys.stderr)
         sys.exit(1)
 
     if args.maskLowCoverage and not args.bam:
-        print("If --maskLowCoverage is used, --bam must be too.", file=sys.stderr)
+        print('If --maskLowCoverage is used, --bam must be too.',
+              file=sys.stderr)
         sys.exit(1)
 
     if args.ivar and not args.bam:
-        print("If --ivar is used, --bam must be too.", file=sys.stderr)
+        print('If --ivar is used, --bam must be too.', file=sys.stderr)
         sys.exit(1)
 
     if args.ivarFrequencyThreshold is not None and not args.ivar:
-        print(
-            "If --ivarFrequencyThreshold is used, --ivar must be too.", file=sys.stderr
-        )
+        print('If --ivarFrequencyThreshold is used, --ivar must be too.',
+              file=sys.stderr)
         sys.exit(1)
 
     if args.ivar and args.ivarFrequencyThreshold is None:
         args.ivarFrequencyThreshold = IVAR_FREQUENCY_THRESHOLD_DEFAULT
 
     e = Executor(args.dryRun)
 
-    tempdir = mkdtemp(prefix="consensus-")
+    tempdir = mkdtemp(prefix='consensus-')
 
     if args.vcfFile:
         vcfFile = args.vcfFile
     else:
         # No VCF file provided, so make one.
-        vcfFile = join(tempdir, "vcf.gz")
+        vcfFile = join(tempdir, 'vcf.gz')
         if args.callHaplotypesGATK:
             e.execute("samtools index '%s'" % args.bam)
             if args.picardJar:
                 picardJar = args.picardJar
             else:
                 try:
-                    picardJar = os.environ["PICARD_JAR"]
+                    picardJar = os.environ['PICARD_JAR']
                 except KeyError:
-                    print(
-                        "If you use --callHaplotypesGATK, you must give a "
-                        "Picard JAR file with --picardJar or else set "
-                        "PICARD_JAR in your environment.",
-                        file=sys.stderr,
-                    )
+                    print('If you use --callHaplotypesGATK, you must give a '
+                          'Picard JAR file with --picardJar or else set '
+                          'PICARD_JAR in your environment.', file=sys.stderr)
                     sys.exit(1)
 
-            indexFile = args.reference + ".fai"
+            indexFile = args.reference + '.fai'
             if os.path.exists(indexFile):
                 removeIndex = False
             else:
                 removeIndex = True
                 e.execute("samtools faidx '%s'" % args.reference)
 
-            if args.reference.lower().endswith(".fasta"):
-                dictFile = args.reference[: -len(".fasta")] + ".dict"
+            if args.reference.lower().endswith('.fasta'):
+                dictFile = args.reference[:-len('.fasta')] + '.dict'
             else:
-                dictFile = args.reference + ".dict"
+                dictFile = args.reference + '.dict'
 
             if os.path.exists(dictFile):
                 removeDict = False
             else:
                 removeDict = True
                 e.execute(
                     "java -jar '%s' CreateSequenceDictionary R='%s' O='%s'"
-                    % (picardJar, args.reference, dictFile)
-                )
+                    % (picardJar, args.reference, dictFile))
 
             e.execute(
-                "gatk --java-options -Xmx4g HaplotypeCaller "
+                'gatk --java-options -Xmx4g HaplotypeCaller '
                 "--reference '%s' "
                 "--input '%s' "
                 "--output '%s' "
                 "--sample-ploidy 1 "
-                "-ERC GVCF" % (args.reference, args.bam, vcfFile)
-            )
+                '-ERC GVCF' %
+                (args.reference, args.bam, vcfFile))
 
             if removeIndex:
                 e.execute("rm '%s'" % indexFile)
 
             if removeDict:
                 e.execute("rm '%s'" % dictFile)
         else:
-            e.execute(
-                "bcftools mpileup --max-depth 5000 -Ou -f '%s' '%s' | "
-                "bcftools call --ploidy 1 -mv -Oz -o '%s'"
-                % (args.reference, args.bam, vcfFile)
-            )
+            e.execute("bcftools mpileup --max-depth 5000 -Ou -f '%s' '%s' | "
+                      "bcftools call --ploidy 1 -mv -Oz -o '%s'" %
+                      (args.reference, args.bam, vcfFile))
 
             e.execute("bcftools index '%s'" % vcfFile)
 
     if args.maskLowCoverage >= 0:
         # Make a BED file.
-        bedFile = join(tempdir, "mask.bed")
+        bedFile = join(tempdir, 'mask.bed')
         # The doubled-% below are so that Python doesn't try to fill in the
         # values and instead just generates a single % that awk sees.
         e.execute(
             "samtools depth -a '%s' | "
-            'awk \'$3 < %d {printf "%%s\\t%%d\\t%%d\\n", '
-            "$1, $2 - 1, $2}' > '%s'" % (args.bam, args.maskLowCoverage, bedFile)
-        )
-        maskArg = "--mask " + bedFile
+            "awk '$3 < %d {printf \"%%s\\t%%d\\t%%d\\n\", "
+            "$1, $2 - 1, $2}' > '%s'" %
+            (args.bam, args.maskLowCoverage, bedFile))
+        maskArg = '--mask ' + bedFile
     else:
-        maskArg = ""
+        maskArg = ''
 
     if args.sample:
         sample = args.sample
     else:
-        result = e.execute("gunzip -c '%s' | egrep -m 1 '^#CHROM' | cut -f10" % vcfFile)
-        sample = "SAMPLE-NAME" if args.dryRun else result.stdout.strip()
+        result = e.execute(
+            "gunzip -c '%s' | egrep -m 1 '^#CHROM' | cut -f10" % vcfFile)
+        sample = result.stdout.strip()
 
-    consensusFile = join(tempdir, "consensus.fasta")
+    consensusFile = join(tempdir, 'consensus.fasta')
 
     if args.ivar:
         if args.ivarBedFile:
-            tempBamFile = join(tempdir, basename(args.bam) + "-trimmed")
+            tempBamFile = join(tempdir, basename(args.bam) + '-trimmed')
             result = e.execute(
-                "ivar trim -i %r -b %r -p %r -e"
-                % (args.bam, args.ivarBedFile, tempBamFile)
-            )
-            ivarTempBamFile = tempBamFile + ".bam"
-            sortedIvarTempBamFile = tempBamFile + "-trimmed-sorted.bam"
+                "ivar trim -i %r -b %r -p %r -e" % (
+                    args.bam, args.ivarBedFile, tempBamFile))
+            ivarTempBamFile = tempBamFile + '.bam'
+            sortedIvarTempBamFile = tempBamFile + '-trimmed-sorted.bam'
             result = e.execute(
-                "samtools sort %r -o %r" % (ivarTempBamFile, sortedIvarTempBamFile)
-            )
+                "samtools sort %r -o %r" % (
+                    ivarTempBamFile, sortedIvarTempBamFile))
             bamFile = sortedIvarTempBamFile
         else:
             bamFile = args.bam
 
-        ivarConsensusFile = join(tempdir, "temporary-consensus")
+        ivarConsensusFile = join(tempdir, 'temporary-consensus')
         result = e.execute(
             "samtools mpileup -A -Q 0 %r | "
-            "ivar consensus -p %r -q 20 -t %r -m %r"
-            % (
-                bamFile,
-                ivarConsensusFile,
-                args.ivarFrequencyThreshold,
-                args.maskLowCoverage,
-            )
-        )
+            "ivar consensus -p %r -q 20 -t %r -m %r" % (
+                bamFile, ivarConsensusFile, args.ivarFrequencyThreshold,
+                args.maskLowCoverage))
 
-        result = e.execute("mv %s %s" % (ivarConsensusFile + ".fa", consensusFile))
+        result = e.execute(
+            "mv %s %s" % (ivarConsensusFile + '.fa', consensusFile))
 
     else:
         result = e.execute(
             "bcftools consensus --sample '%s' --iupac-codes %s --fasta-ref "
-            "'%s' '%s' > '%s'"
-            % (sample, maskArg, args.reference, vcfFile, consensusFile)
-        )
-
-        if not args.dryRun and result.stderr:
-            print(result.stderr, end="", file=sys.stderr)
-
-    if not args.dryRun:
-        consensus = list(FastaReads(consensusFile))[0]
-        if args.id is not None:
-            consensus.id = args.id
-        elif args.idLambda is not None:
-            idLambda = eval(args.idLambda)
-            consensus.id = idLambda(consensus.id)
+            "'%s' '%s' > '%s'" %
+            (sample, maskArg, args.reference, vcfFile, consensusFile))
+
+    consensus = list(FastaReads(consensusFile))[0]
+    if args.id is not None:
+        consensus.id = args.id
+    elif args.idLambda is not None:
+        idLambda = eval(args.idLambda)
+        consensus.id = idLambda(consensus.id)
+
+    print(consensus.toString('fasta'), end='')
 
-        print(consensus.toString("fasta"), end="")
+    if result.stderr:
+        print(result.stderr, end='', file=sys.stderr)
 
     if args.dryRun or args.log:
-        print("\n".join(e.log), file=sys.stderr)
+        print('\n'.join(e.log), file=sys.stderr)
 
     if tempdir:
         if args.clean:
             e.execute("rm -r '%s'" % tempdir)
         else:
-            print("Temporary directory %r." % tempdir, file=sys.stderr)
+            print('Temporary directory %r.' % tempdir, file=sys.stderr)
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     main()
```

### Comparing `dark-matter-4.0.84/bin/make-fasta-database.py` & `dark-matter-4.0.9/bin/make-fasta-database.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,69 +1,53 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import os
 from time import time
 from itertools import chain
 
 from dark.fasta import SqliteIndex
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
-        description="Create an sqlite3 database from FASTA sequences."
-    )
+        description='Create an sqlite3 database from FASTA sequences.')
 
     parser.add_argument(
-        "--out",
-        required=True,
-        help=(
-            "The output file. This file must not exist (use --force to " "overwrite)."
-        ),
-    )
+        '--out', required=True,
+        help=('The output file. This file must not exist (use --force to '
+              'overwrite).'))
 
     parser.add_argument(
-        "--force",
-        default=False,
-        action="store_true",
-        help="If True and the output file already exists, overwrite it.",
-    )
+        '--force', default=False, action='store_true',
+        help='If True and the output file already exists, overwrite it.')
 
     parser.add_argument(
-        "--quiet",
-        default=False,
-        action="store_true",
-        help="If True do not print indexing progress.",
-    )
+        '--quiet', default=False, action='store_true',
+        help='If True do not print indexing progress.')
 
     parser.add_argument(
-        "--fasta",
-        metavar="FASTA-file",
-        nargs="+",
-        action="append",
+        '--fasta', metavar='FASTA-file', nargs='+', action='append',
         required=True,
-        help=(
-            "the FASTA file(s) to make the database from. These may be "
-            "uncompressed, or compressed with bgzip (from samtools), with "
-            "a .gz suffix."
-        ),
-    )
+        help=('the FASTA file(s) to make the database from. These may be '
+              'uncompressed, or compressed with bgzip (from samtools), with '
+              'a .gz suffix.'))
 
     args = parser.parse_args()
 
     if os.path.exists(args.out):
         if args.force:
             os.unlink(args.out)
         else:
-            print(
-                "Output file '%s' already exists. Use --force to overwrite." % args.out,
-                file=sys.stderr,
-            )
+            print("Output file '%s' already exists. Use --force to overwrite."
+                  % args.out, file=sys.stderr)
             sys.exit(1)
 
     index = SqliteIndex(args.out)
 
     # Flatten the lists of lists that we get from using both nargs='+' and
     # action='append'. We use both because it allows people to use (e.g.)
     # --fasta on the command line either via "--fasta file1 --fasta file2"
@@ -73,19 +57,16 @@
     # https://github.com/acorg/dark-matter/issues/453
     fastaFiles = list(chain.from_iterable(args.fasta))
 
     verbose = not args.quiet
 
     for filename in fastaFiles:
         if verbose:
-            print("Indexing '%s' ... " % filename, end="", file=sys.stderr)
+            print("Indexing '%s' ... " % filename, end='', file=sys.stderr)
             start = time()
 
         count = index.addFile(filename)
 
         if verbose:
             elapsed = time() - start
-            print(
-                "indexed %d sequence%s in %.2f seconds."
-                % (count, "" if count == 1 else "s", elapsed),
-                file=sys.stderr,
-            )
+            print('indexed %d sequence%s in %.2f seconds.' %
+                  (count, '' if count == 1 else 's', elapsed), file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/make-protein-database.py` & `dark-matter-4.0.9/bin/make-protein-database.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,20 +1,21 @@
 #!/usr/bin/env python
 
+from __future__ import print_function, division
+
 import sys
 import warnings
 from time import time
 from itertools import chain
 import argparse
 
 from dark.civ.proteins import SqliteIndexWriter
 from dark.taxonomy import (
     addTaxonomyDatabaseCommandLineOptions,
-    parseTaxonomyDatabaseCommandLineOptions,
-)
+    parseTaxonomyDatabaseCommandLineOptions)
 
 
 def filenamesAndAdders(args, db):
     """
     Get the filenames and database adding functions.
 
     @param args: A C{Namespace} instance as returned by argparse.
@@ -28,314 +29,207 @@
     # to use (e.g.) --gb on the command line either via "--gb file1 --gb
     # file2" or "--gb file1 file2", or a combination of these. That way
     # it's not necessary to remember which way you're supposed to use it
     # and you also can't be hit by the subtle problem encountered in
     # https://github.com/acorg/dark-matter/issues/453
 
     if not (args.gb or args.json):
-        print(
-            "At least one of --gb or --json must be used to indicate input "
-            "files to process.",
-            file=sys.stderr,
-        )
+        print('At least one of --gb or --json must be used to indicate input '
+              'files to process.', file=sys.stderr)
         sys.exit(1)
 
     if args.gb:
         for filename in chain.from_iterable(args.gb):
-            yield filename, db.addGenBankFile, "gb"
+            yield filename, db.addGenBankFile, 'gb'
 
     if args.json:
         for filename in chain.from_iterable(args.json):
-            yield filename, db.addJSONFile, "json"
+            yield filename, db.addJSONFile, 'json'
 
 
 def main(args, parser):
     """
     Build the protein database.
 
     @param args: The namespace of command-line arguments returned by
         argparse.parse_args()
     @param parser: An C{argparse.ArgumentParser} instance.
     """
 
-    if (
-        args.minGenomeLength is not None
-        and args.maxGenomeLength is not None
-        and args.minGenomeLength > args.maxGenomeLength
-    ):
-        raise ValueError("--minGenomeLength cannot be larger than --maxGenomeLength")
+    if (args.minGenomeLength is not None and
+            args.maxGenomeLength is not None and
+            args.minGenomeLength > args.maxGenomeLength):
+        raise ValueError(
+            '--minGenomeLength cannot be larger than --maxGenomeLength')
 
     if args.excludeExclusiveHost:
-        excludeExclusiveHosts = set(chain.from_iterable(args.excludeExclusiveHost))
+        excludeExclusiveHosts = set(chain.from_iterable(
+            args.excludeExclusiveHost))
     else:
         excludeExclusiveHosts = None
 
-    if args.allowedTaxonomicRanks:
-        allowedTaxonomicRanks = set()
-        for nameRank in chain.from_iterable(args.allowedTaxonomicRanks):
-            name, rank = map(str.lower, map(str.strip, nameRank.split(":", maxsplit=1)))
-            allowedTaxonomicRanks.add((name, rank))
-    else:
-        allowedTaxonomicRanks = None
-
     taxonomyDatabase = parseTaxonomyDatabaseCommandLineOptions(args, parser)
     progress = args.progress
 
     if progress:
         overallStart = time()
         totalGenomeCount = totalProteinCount = 0
 
     with SqliteIndexWriter(args.databaseFile) as db:
         for fileCount, (filename, addFunc, type_) in enumerate(
-            filenamesAndAdders(args, db), start=1
-        ):
+                filenamesAndAdders(args, db), start=1):
+
             if args.logFile:
-                print("\n>>> Indexing '%s'." % filename, end="\n\n", file=args.logFile)
+                print("\n>>> Indexing '%s'." % filename, end='\n\n',
+                      file=args.logFile)
 
             if progress:
                 start = time()
 
             examinedGenomeCount, genomeCount, proteinCount = addFunc(
-                filename,
-                dnaOnly=args.dnaOnly,
-                rnaOnly=args.rnaOnly,
-                allowedTaxonomicRanks=allowedTaxonomicRanks,
+                filename, dnaOnly=args.dnaOnly, rnaOnly=args.rnaOnly,
                 minGenomeLength=args.minGenomeLength,
                 maxGenomeLength=args.maxGenomeLength,
                 excludeExclusiveHosts=excludeExclusiveHosts,
                 excludeFungusOnlyViruses=args.excludeFungusOnlyViruses,
                 excludePlantOnlyViruses=args.excludePlantOnlyViruses,
                 databaseName=args.databaseName,
                 taxonomyDatabase=taxonomyDatabase,
                 proteinSource=args.proteinSource,
                 genomeSource=args.genomeSource,
-                duplicationPolicy=args.duplicationPolicy,
-                logfp=args.logFile,
-            )
+                duplicationPolicy=args.duplicationPolicy, logfp=args.logFile)
 
             if examinedGenomeCount == 0:
-                if type_ == "gb":
-                    print(
-                        "WARNING: No genomes found in %r. Did the GenBank "
-                        "download fail on that file?" % filename,
-                        file=sys.stderr,
-                    )
+                if type_ == 'gb':
+                    print('WARNING: No genomes found in %r. Did the GenBank '
+                          'download fail on that file?' % filename,
+                          file=sys.stderr)
                 else:
-                    assert type_ == "json"
-                    print(
-                        "WARNING: no genomes found in JSON file %r." % filename,
-                        file=sys.stderr,
-                    )
+                    assert type_ == 'json'
+                    print('WARNING: no genomes found in JSON file %r.' %
+                          filename, file=sys.stderr)
 
             if progress:
                 elapsed = time() - start
                 totalGenomeCount += genomeCount
                 totalProteinCount += proteinCount
-                print(
-                    "Processed %r: added %3d of %3d genome%s (%5d "
-                    "protein%s) in %.2f seconds."
-                    % (
-                        filename,
-                        genomeCount,
-                        examinedGenomeCount,
-                        " " if examinedGenomeCount == 1 else "s",
-                        proteinCount,
-                        "" if proteinCount == 1 else "s",
-                        elapsed,
-                    ),
-                    file=sys.stderr,
-                )
+                print('Processed %r: added %3d of %3d genome%s (%5d '
+                      'protein%s) in %.2f seconds.' %
+                      (filename, genomeCount, examinedGenomeCount,
+                       ' ' if examinedGenomeCount == 1 else 's',
+                       proteinCount, '' if proteinCount == 1 else 's',
+                       elapsed), file=sys.stderr)
 
     if progress:
         elapsed = time() - overallStart
-        print(
-            "%d files (containing %d genomes and %d proteins) "
-            "indexed in %.2f seconds (%.2f mins)."
-            % (fileCount, totalGenomeCount, totalProteinCount, elapsed, elapsed / 60),
-            file=sys.stderr,
-        )
+        print('%d files (containing %d genomes and %d proteins) '
+              'indexed in %.2f seconds (%.2f mins).' %
+              (fileCount, totalGenomeCount, totalProteinCount, elapsed,
+               elapsed / 60), file=sys.stderr)
 
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description=(
-        "Create a genome/protein sqlite3 database from GenBank "
-        "and JSON files. The protein sequences for the database are "
-        "printed to standard output for indexing by other tools."
-    ),
-)
-
-parser.add_argument(
-    "--databaseFile",
-    required=True,
-    help=("The output file. This file must not exist (use --force to " "overwrite)."),
-)
-
-parser.add_argument(
-    "--databaseName",
-    help=(
-        "The database that the records in the (--gb) GenBank files came "
-        'from (e.g., "refseq" or "RVDB").'
-    ),
-)
-
-parser.add_argument(
-    "--duplicationPolicy",
-    choices=("error", "ignore"),
-    default="ignore",
-    help=(
-        "What to do if a to-be-inserted accession number is already "
-        'present in the database. "error" results in a ValueError being '
-        'raised, "ignore" will ignore the duplicate. It should also be '
-        "possible to update (i.e., replace) but that is not supported yet."
-    ),
-)
-
-parser.add_argument("--progress", action="store_true", help="Print indexing progress.")
-
-parser.add_argument(
-    "--logFile",
-    type=argparse.FileType("w"),
-    help="Write indexing details to a log file.",
-)
-
-parser.add_argument(
-    "--noWarnings",
-    action="store_true",
-    help="Do not print warnings about unparseable GenBank or JSON records.",
-)
+    description=('Create a genome/protein sqlite3 database from GenBank '
+                 'and JSON files. The protein sequences for the database are '
+                 'printed to standard output for indexing by other tools.'))
+
+parser.add_argument(
+    '--databaseFile', required=True,
+    help=('The output file. This file must not exist (use --force to '
+          'overwrite).'))
+
+parser.add_argument(
+    '--databaseName',
+    help=('The database that the records in the (--gb) GenBank files came '
+          'from (e.g., "refseq" or "RVDB").'))
+
+parser.add_argument(
+    '--duplicationPolicy', choices=('error', 'ignore'), default='ignore',
+    help=('What to do if a to-be-inserted accession number is already '
+          'present in the database. "error" results in a ValueError being '
+          'raised, "ignore" will ignore the duplicate. It should also be '
+          'possible to update (i.e., replace) but that is not supported yet.'))
+
+parser.add_argument(
+    '--progress', default=False, action='store_true',
+    help='Print indexing progress.')
+
+parser.add_argument(
+    '--logFile', type=argparse.FileType('w'),
+    help='Write indexing details to a log file.')
+
+parser.add_argument(
+    '--noWarnings', default=False, action='store_true',
+    help='Do not print warnings about unparseable GenBank or JSON records.')
 
 # A mutually exclusive group for DNA/RNA only.
 group = parser.add_mutually_exclusive_group()
 
 group.add_argument(
-    "--dnaOnly", action="store_true", help="If given, only include DNA viruses."
-)
+    '--dnaOnly', default=False, action='store_true',
+    help='If given, only include DNA viruses.')
 
 group.add_argument(
-    "--rnaOnly", action="store_true", help="If given, only include RNA viruses."
-)
+    '--rnaOnly', default=False, action='store_true',
+    help='If given, only include RNA viruses.')
+
+parser.add_argument(
+    '--maxGenomeLength', type=int,
+    help='Genomes longer than this will not be considered.')
+
+parser.add_argument(
+    '--minGenomeLength', type=int,
+    help='Genomes shorter than this will not be considered.')
+
+parser.add_argument(
+    '--excludeFungusOnlyViruses', default=False, action='store_true',
+    help=('If given, exclude fungus-only viruses (i.e., viruses that only '
+          'infect fungi host species).'))
+
+parser.add_argument(
+    '--excludePlantOnlyViruses', default=False, action='store_true',
+    help=('If given, exclude plant-only viruses (i.e., viruses that only '
+          'infect plant host species).'))
+
+parser.add_argument(
+    '--gb', metavar='GenBank-file', nargs='+', action='append',
+    help=('The GenBank file(s) to make the database from. These may be '
+          'uncompressed, or compressed with bgzip (from samtools), with '
+          'a .gz suffix.'))
+
+parser.add_argument(
+    '--json', metavar='JSON-file', nargs='+', action='append',
+    help=('The JSON file(s) to make the database from. These contain '
+          'genome and protein information for cases where sequences that '
+          'are not in GenBank should be added.'))
+
+parser.add_argument(
+    '--proteinSource', default='GENBANK',
+    help=('The source of the accession numbers for the proteins found in the '
+          'input files. This becomes part of the sequence id printed in the '
+          'protein FASTA output.'))
+
+parser.add_argument(
+    '--genomeSource', default='GENBANK',
+    help=('The source of the accession numbers for the genomes in the input '
+          'files. This becomes part of the sequence id printed in the '
+          'protein FASTA output.'))
 
 parser.add_argument(
-    "--maxGenomeLength",
-    type=int,
-    help="Genomes longer than this will not be considered.",
-)
-
-parser.add_argument(
-    "--minGenomeLength",
-    type=int,
-    help="Genomes shorter than this will not be considered.",
-)
-
-parser.add_argument(
-    "--excludeFungusOnlyViruses",
-    action="store_true",
-    help=(
-        "If given, exclude fungus-only viruses (i.e., viruses that only "
-        "infect fungi host species)."
-    ),
-)
-
-parser.add_argument(
-    "--excludePlantOnlyViruses",
-    action="store_true",
-    help=(
-        "If given, exclude plant-only viruses (i.e., viruses that only "
-        "infect plant host species)."
-    ),
-)
-
-parser.add_argument(
-    "--gb",
-    metavar="GenBank-file",
-    nargs="+",
-    action="append",
-    help=(
-        "The GenBank file(s) to make the database from. These may be "
-        "uncompressed, or compressed with bgzip (from samtools), with "
-        "a .gz suffix."
-    ),
-)
-
-parser.add_argument(
-    "--json",
-    metavar="JSON-file",
-    nargs="+",
-    action="append",
-    help=(
-        "The JSON file(s) to make the database from. These contain "
-        "genome and protein information for cases where sequences that "
-        "are not in GenBank should be added."
-    ),
-)
-
-parser.add_argument(
-    "--allowedTaxonomicRanks",
-    metavar="name:rank",
-    nargs="+",
-    action="append",
-    help=(
-        "Strings of the form name:rank to restrict included viruses to be "
-        "from any of a specific set of taxonomic ranks. May be repeated. E.g., "
-        "--allowedTaxonomicRanks nidovirales:order "
-        "--allowedTaxonomicRanks retroviridae:family "
-        "Viruses will be included only if they match at least one of the name, "
-        "rank pairs. The strings are case insensitive."
-    ),
-)
-
-parser.add_argument(
-    "--proteinSource",
-    default="GenBank",
-    help=(
-        "The source of the accession numbers for the proteins found in the "
-        "input files. This becomes part of the sequence id printed in the "
-        "protein FASTA output."
-    ),
-)
-
-parser.add_argument(
-    "--genomeSource",
-    default="GenBank",
-    help=(
-        "The source of the accession numbers for the genomes in the input "
-        "files. This becomes part of the sequence id printed in the "
-        "protein FASTA output."
-    ),
-)
-
-parser.add_argument(
-    "--excludeExclusiveHost",
-    metavar="hostname",
-    nargs="+",
-    action="append",
-    choices=(
-        "algae",
-        "archaea",
-        "bacteria",
-        "diatom",
-        "environment",
-        "eukaryotes",
-        "fungi",
-        "human",
-        "invertebrates",
-        "plants",
-        "protozoa",
-        "vertebrates",
-    ),
-    help=(
-        "A host type that should be excluded, but only if this is the only "
-        "host of the virus."
-    ),
-)
+    '--excludeExclusiveHost', metavar='hostname', nargs='+', action='append',
+    choices=('algae', 'archaea', 'bacteria', 'diatom', 'environment',
+             'eukaryotes', 'fungi', 'human', 'invertebrates', 'plants',
+             'protozoa', 'vertebrates'),
+    help=('A host type that should be excluded, but only if this is the only '
+          'host of the virus.'))
 
 addTaxonomyDatabaseCommandLineOptions(parser)
 
 args = parser.parse_args()
 
 if args.noWarnings:
     with warnings.catch_warnings():
-        warnings.simplefilter("ignore")
+        warnings.simplefilter('ignore')
         main(args, parser)
 else:
     main(args, parser)
```

### Comparing `dark-matter-4.0.84/bin/newick-to-ascii.py` & `dark-matter-4.0.9/bin/newick-to-ascii.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,64 +1,48 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 from ete3 import Tree
 import argparse
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description="Print a Newick phylogenetic tree in ASCII.",
-)
-
-parser.add_argument(
-    "--treeFile",
-    metavar="FILENAME",
-    default=sys.stdin,
-    type=open,
-    help="The Newick tree file.",
-)
+    description='Print a Newick phylogenetic tree in ASCII.')
 
 parser.add_argument(
-    "--outgroupRegex",
-    metavar="TAXON-REGEX",
-    help=(
-        "A regular expression (for taxa names). The lowest common parent of "
-        "any matching taxa will be used as an outgroup."
-    ),
-)
+    '--treeFile', metavar='FILENAME', default=sys.stdin, type=open,
+    help='The Newick tree file.')
 
 parser.add_argument(
-    "--format",
-    metavar="N",
-    type=int,
-    help="The format of the Newick to be passed to ete3",
-)
+    '--outgroupRegex', metavar='TAXON-REGEX',
+    help=('A regular expression (for taxa names). The lowest common parent of '
+          'any matching taxa will be used as an outgroup.'))
 
 parser.add_argument(
-    "--verbose",
-    action="store_true",
-    help=("Print information about the outgroup (if any) taxa to standard " "error"),
-)
+    '--verbose', action='store_true',
+    help=('Print information about the outgroup (if any) taxa to standard '
+          'error'))
 
 args = parser.parse_args()
 
-tree = Tree(args.treeFile.read(), format=args.format)
+tree = Tree(args.treeFile.read())
 
 if args.outgroupRegex:
     from re import compile
-
     regex = compile(args.outgroupRegex)
     taxa = [leaf.name for leaf in tree.iter_leaves() if regex.match(leaf.name)]
 
     if taxa:
         ca = tree.get_common_ancestor(taxa)
         if args.verbose:
-            print("Taxa for outgroup:", taxa, file=sys.stderr)
-            print("Common ancestor:", ca.name, file=sys.stderr)
-            print("Common ancestor is tree:", tree == ca, file=sys.stderr)
+            print('Taxa for outgroup:', taxa, file=sys.stderr)
+            print('Common ancestor:', ca.name, file=sys.stderr)
+            print('Common ancestor is tree:', tree == ca, file=sys.stderr)
 
         if len(taxa) == 1:
             tree.set_outgroup(tree & taxa[0])
         else:
             if ca == tree:
                 tree.set_outgroup(tree.get_midpoint_outgroup())
             else:
```

### Comparing `dark-matter-4.0.84/bin/parse-genbank-flat-file.py` & `dark-matter-4.0.9/bin/parse-genbank-flat-file.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,51 +1,52 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 from Bio import SeqIO
 
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description="Parse GenBank flat files. Exit non-zero if parsing fails.",
-)
+    description='Parse GenBank flat files. Exit non-zero if parsing fails.')
 
 parser.add_argument(
-    "--expectedCount",
-    type=int,
-    help=(
-        "The expected number of records in each GenBank file. If given "
-        "and this number is not present in any file, exit non-zero."
-    ),
-)
+    '--expectedCount', type=int,
+    help=('The expected number of records in each GenBank file. If given '
+          'and this number is not present in any file, exit non-zero.'))
 
-parser.add_argument("files", nargs="+", help="The files to parse.")
+parser.add_argument(
+    'files', nargs='+',
+    help='The files to parse.')
 
-parser.add_argument("--quiet", action="store_true", help="If given, write no output.")
+parser.add_argument(
+    '--quiet', default=False, action='store_true',
+    help='If given, write no output.')
 
 args = parser.parse_args()
 
 expectedCount = args.expectedCount
 totalCount = 0
 
 for i in args.files:
     count = 0
     try:
-        records = SeqIO.parse(open(i), "gb")
+        records = SeqIO.parse(open(i), 'gb')
         for record in records:
             count += 1
     except ValueError:
         if not args.quiet:
-            print("Could not parse %s" % i, file=sys.stderr)
+            print('Could not parse %s' % i)
         sys.exit(1)
     else:
         if not args.quiet:
-            print("Read %d records from %s" % (count, i), file=sys.stderr)
+            print('Read %d records from %s' % (count, i))
         if expectedCount is not None and count != expectedCount:
             if not args.quiet:
-                print("Expected %d records. Exiting." % expectedCount, file=sys.stderr)
+                print('Expected %d records. Exiting.' % expectedCount)
             sys.exit(1)
         totalCount += count
 
 if not args.quiet:
-    print("Total records read: %d" % totalCount, file=sys.stderr)
+    print('Total records read: %d' % totalCount)
```

### Comparing `dark-matter-4.0.84/bin/plot-references-by-inter-read-distance.py` & `dark-matter-4.0.9/bin/plot-references-by-inter-read-distance.py`

 * *Files 19% similar despite different names*

```diff
@@ -28,15 +28,17 @@
     @return: A 2-C{tuple} with an C{int} index and the passed C{str} genotype.
         This will ensure that sorting will be first on the index, then on the
         genotype name.
     """
     # The index is 0 for single-character genotypes (apart from ?, which
     # comes last), followed by 1 for genotypes with longer names
     # (Chimpanzee, Gibbon, etc), followed by 2 for unknown (?) genotypes.
-    return (2 if genotype == "?" else (0 if len(genotype) == 1 else 1), genotype)
+    return (
+        2 if genotype == '?' else (0 if len(genotype) == 1 else 1),
+        genotype)
 
 
 def getFigure(referenceIds, categories, dm, transform, args):
     """
     Make a 3D figure.
 
     @param referenceIds: A C{list} of C{str} reference ids.
@@ -45,73 +47,65 @@
     @param transform: An C{MDS} transform.
     @param args: A C{Namespace} object returned by argparse, containing
         argument values passed on the command line.
     @return: A plotly express figure instance.
     """
     readCounts = [len(dm.scores[id_]) for id_ in referenceIds]
 
-    if not (len(transform) == len(readCounts) == len(categories) == len(referenceIds)):
+    if not (len(transform) == len(readCounts) == len(categories) ==
+            len(referenceIds)):
         raise ValueError(
-            f"Unequal lengths: transform={len(transform)}, "
-            f"readCounts={len(readCounts)}, categories={len(categories)}, "
-            f"referenceIds={len(referenceIds)}."
-        )
+            f'Unequal lengths: transform={len(transform)}, '
+            f'readCounts={len(readCounts)}, categories={len(categories)}, '
+            f'referenceIds={len(referenceIds)}.')
 
-    if args.categorySortKey == "HBV genotype":
+    if args.categorySortKey == 'HBV genotype':
         categorySortKey = HBVGenotypeKey
     else:
-
         def categorySortKey(c):
             return c
 
-    df = pd.DataFrame(
-        {
-            "x": transform[:, 0],
-            "y": transform[:, 1],
-            "Read count": readCounts,
-            args.categoryName: categories,
-            "Accession": referenceIds,
-        }
-    )
-
-    categoryOrders = {args.categoryName: sorted(categories, key=categorySortKey)}
+    df = pd.DataFrame({
+        'x': transform[:, 0],
+        'y': transform[:, 1],
+        'Read count': readCounts,
+        args.categoryName: categories,
+        'Accession': referenceIds,
+    })
+
+    categoryOrders = {
+        args.categoryName: sorted(categories, key=categorySortKey)
+    }
 
     if args.twoD:
-        fig = px.scatter(
-            df,
-            x="x",
-            y="y",
-            color=args.categoryName,
-            opacity=0.70,
-            title="Reference map",
-            hover_data=("Accession", "Read count"),
-            category_orders=categoryOrders,
-        )
+        fig = px.scatter(df, x='x', y='y',
+                         color=args.categoryName, opacity=0.70,
+                         title='Reference map',
+                         hover_data=('Accession', 'Read count'),
+                         category_orders=categoryOrders)
     else:
-        fig = px.scatter_3d(
-            df,
-            x="x",
-            y="y",
-            z="Read count",
-            color=args.categoryName,
-            opacity=0.70,
-            title="Reference map",
-            hover_data=("Accession",),
-            category_orders=categoryOrders,
-        )
+        fig = px.scatter_3d(df, x='x', y='y', z='Read count',
+                            color=args.categoryName, opacity=0.70,
+                            title='Reference map', hover_data=('Accession',),
+                            category_orders=categoryOrders)
 
-    fig.update_traces(marker={"size": 4.2})
+    fig.update_traces(marker={'size': 4.2})
 
     fig.update_layout(
         margin=dict(l=0, r=0, b=0, t=0),
-        legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
+        legend=dict(
+            yanchor='top',
+            y=0.99,
+            xanchor='left',
+            x=0.01
+        )
     )
 
     if args.logZ and not args.twoD:
-        fig.update_layout(scene_zaxis_type="log")
+        fig.update_layout(scene_zaxis_type='log')
 
     return fig
 
 
 def getTransform(referenceIds, dm, args):
     """
     Get the MDS-transformed locations of the references.
@@ -122,36 +116,33 @@
         argument values passed on the command line.
     @return: A numpy n x 2 array of x, y locations (where n is the number of
         reference ids).
     """
     if args.mdsFile and exists(args.mdsFile):
         if args.verbose:
             modificationTime = time.strftime(
-                "%Y-%m-%d %H:%M:%S", time.localtime(os.path.getmtime(args.mdsFile))
-            )
-            print(
-                f"Loading cached MDS transform file dated "
-                f"{modificationTime} from {args.mdsFile!r}.",
-                file=sys.stderr,
-            )
+                '%Y-%m-%d %H:%M:%S',
+                time.localtime(os.path.getmtime(args.mdsFile)))
+            print(f'Loading cached MDS transform file dated '
+                  f'{modificationTime} from {args.mdsFile!r}.',
+                  file=sys.stderr)
         transform = np.load(args.mdsFile)
     else:
-        distance = dm.matrix(
-            referenceIds=referenceIds, metric=args.metric, similarity=False
-        )
-        mds = MDS(dissimilarity="precomputed", n_jobs=8)
+        distance = dm.matrix(referenceIds=referenceIds, metric=args.metric,
+                             similarity=False)
+        mds = MDS(dissimilarity='precomputed', n_jobs=8)
         if args.verbose:
-            print("Starting MDS fit.", file=sys.stderr)
+            print('Starting MDS fit.', file=sys.stderr)
         transform = mds.fit_transform(distance)
         if args.verbose:
-            print("Finished MDS fit.", file=sys.stderr)
+            print('Finished MDS fit.', file=sys.stderr)
 
         # Cache the result if an MDS file name was given.
         if args.mdsFile:
-            with open(args.mdsFile, "wb") as fp:
+            with open(args.mdsFile, 'wb') as fp:
                 np.save(fp, transform)
 
     return transform
 
 
 def getDistanceMatrix(args):
     """
@@ -161,65 +152,60 @@
         argument values passed on the command line.
     @return: A C{DistanceMatrix} instance.
     """
     dm = DistanceMatrix()
 
     if args.samFile:
         for filename in args.samFile:
-            dm.addFile(filename, scoreTag="AS")
+            dm.addFile(filename, scoreTag='AS')
 
         # Cache the distance matrix scores if a file name was given.
         if args.scoreFile:
-            with open(args.scoreFile, "w") as fp:
+            with open(args.scoreFile, 'w') as fp:
                 dm.save(fp)
     else:
         # The argparse group should ensure that --scoreFile was used if
         # --samFile was not.
         assert args.scoreFile
 
         if exists(args.scoreFile):
             with open(args.scoreFile) as fp:
                 dm.load(fp)
         else:
-            print("Score file {args.scoreFile!r} does not exist.", file=sys.stderr)
+            print('Score file {args.scoreFile!r} does not exist.',
+                  file=sys.stderr)
             sys.exit(1)
 
     return dm
 
 
 def main(args):
     """
     Plot references according to their distances from each other, based on
     common read matches (and non-matches).
 
     @param args: A C{Namespace} object returned by argparse, containing
         argument values passed on the command line.
     """
     if not (args.samFile or args.scoreFile):
-        print(
-            "At least a SAM file or a score file name must be given.", file=sys.stderr
-        )
+        print('At least a SAM file or a score file name must be given.',
+              file=sys.stderr)
         sys.exit(1)
 
     dm = getDistanceMatrix(args)
 
     if args.minMatchingReads is None:
         referenceIds = sorted(dm.scores)
     else:
         referenceIds = sorted(
-            referenceId
-            for (referenceId, reads) in dm.scores.items()
-            if len(reads) >= args.minMatchingReads
-        )
+            referenceId for (referenceId, reads) in dm.scores.items()
+            if len(reads) >= args.minMatchingReads)
         if args.verbose:
-            print(
-                f"Found {len(referenceIds)} references with at least "
-                f"{args.minMatchingReads} matching reads.",
-                file=sys.stderr,
-            )
+            print(f'Found {len(referenceIds)} references with at least '
+                  f'{args.minMatchingReads} matching reads.', file=sys.stderr)
 
     if args.categoryFile:
         with open(args.categoryFile) as fp:
             categoryDict = readLabels(fp)
         categories = [categoryDict.get(id_, id_) for id_ in referenceIds]
     else:
         categories = referenceIds
@@ -238,121 +224,90 @@
 
     transform = getTransform(referenceIds, dm, args)
 
     fig = getFigure(referenceIds, categories, dm, transform, args)
 
     fig.write_html(args.htmlFile)
     if args.verbose:
-        print(f"Wrote {args.htmlFile!r}.", file=sys.stderr)
+        print(f'Wrote {args.htmlFile!r}.', file=sys.stderr)
 
 
 def makeParser():
     """
     Make a command-line argument parser.
 
     @return: An C{argparse.ArgumentParser} instance.
     """
     parser = argparse.ArgumentParser(
-        description=(
-            "Plot references according to their distances from one "
-            "another, based on common read matches (and "
-            "non-matches)."
-        )
-    )
+        description=('Plot references according to their distances from one '
+                     'another, based on common read matches (and '
+                     'non-matches).'))
 
     parser.add_argument(
-        "--samFile", action="append", help="The SAM file(s) to load. May be repeated."
-    )
+        '--samFile', action='append',
+        help='The SAM file(s) to load. May be repeated.')
 
     parser.add_argument(
-        "--scoreFile",
-        help=(
-            "A (JSON) file to read (JSON) the reference/read score matrix "
-            "from. This should have been produced by an earlier call with a "
-            "--scoreFile argument or else by saving the output of "
-            "reference-read-scores-to-JSON.py  If the file does not exist, "
-            "it will be created."
-        ),
-    )
+        '--scoreFile',
+        help=('A (JSON) file to read (JSON) the reference/read score matrix '
+              'from. This should have been produced by an earlier call with a '
+              '--scoreFile argument or else by saving the output of '
+              'reference-read-scores-to-JSON.py  If the file does not exist, '
+              'it will be created.'))
 
     parser.add_argument(
-        "--htmlFile", required=True, help="The HTML plotly file to write."
-    )
+        '--htmlFile', required=True,
+        help='The HTML plotly file to write.')
 
     parser.add_argument(
-        "--mdsFile", help="A JSON to cache the result of the MDS optimization."
-    )
+        '--mdsFile',
+        help='A JSON to cache the result of the MDS optimization.')
 
     parser.add_argument(
-        "--categoryName",
-        default="Genotype",
-        help=(
-            "The name of the categories to which reference sequences are "
-            'assigned (e.g., "Genotype"). This name will appear at the '
-            "top of the legend."
-        ),
-    )
+        '--categoryName', default='Genotype',
+        help=('The name of the categories to which reference sequences are '
+              'assigned (e.g., "Genotype"). This name will appear at the '
+              'top of the legend.'))
 
     parser.add_argument(
-        "--categorySortKey",
-        choices=("HBV genotype",),
-        help=(
-            "The name of the function to use to sort categories (for the "
-            "legend). If not given, categories will be sorted by name."
-        ),
-    )
+        '--categorySortKey', choices=('HBV genotype',),
+        help=('The name of the function to use to sort categories (for the '
+              'legend). If not given, categories will be sorted by name.'))
 
     parser.add_argument(
-        "--categoryFile",
-        help=(
-            "A file containing labels for reference sequences. The format "
-            "is lines containing a reference name, a TAB, and a new name "
-            "(to be shown in the plot). If no label file is given, or if "
-            "there is no new name for a reference, the original reference "
-            "names will be used."
-        ),
-    )
+        '--categoryFile',
+        help=('A file containing labels for reference sequences. The format '
+              'is lines containing a reference name, a TAB, and a new name '
+              '(to be shown in the plot). If no label file is given, or if '
+              'there is no new name for a reference, the original reference '
+              'names will be used.'))
 
     parser.add_argument(
-        "--minMatchingReads",
-        type=int,
-        help=(
-            "The minimum number of reads that must match a reference for it "
-            "to be included."
-        ),
-    )
+        '--minMatchingReads', type=int,
+        help=('The minimum number of reads that must match a reference for it '
+              'to be included.'))
 
     parser.add_argument(
-        "--verbose", action="store_true", help="Print extra information."
-    )
+        '--verbose', action='store_true',
+        help='Print extra information.')
 
     group = parser.add_mutually_exclusive_group()
 
     group.add_argument(
-        "--2d",
-        "--2D",
-        action="store_true",
-        dest="twoD",
-        help=(
-            "Make the figure in two dimensions, instead of three. The third "
-            "dimensions (reference matching read count) is omitted."
-        ),
-    )
+        '--2d', '--2D', action='store_true', dest='twoD',
+        help=('Make the figure in two dimensions, instead of three. The third '
+              'dimensions (reference matching read count) is omitted.'))
 
     group.add_argument(
-        "--logZ",
-        action="store_true",
-        help="Log the z (read count) axis (only valid if --2d is not used).",
-    )
+        '--logZ', action='store_true',
+        help='Log the z (read count) axis (only valid if --2d is not used).')
 
     parser.add_argument(
-        "--metric",
-        choices=("jaccard", "soergel"),
-        default="soergel",
-        help=("The distance metric to use."),
-    )
+        '--metric',
+        choices=('jaccard', 'soergel'), default='soergel',
+        help=('The distance metric to use.'))
 
     return parser
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     main(makeParser().parse_args())
```

### Comparing `dark-matter-4.0.84/bin/position-summary.py` & `dark-matter-4.0.9/bin/position-summary.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,39 +1,30 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import argparse
 
 from dark.fasta import FastaReads
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
-        description=(
-            "For a fasta file with sequences, summarize what is "
-            "happening at a specific position."
-        ),
-    )
-
-    parser.add_argument(
-        "--fastaFile", required=True, help="The name of the FASTA file to read."
-    )
-
-    parser.add_argument(
-        "--position",
-        required=True,
-        type=int,
-        help="The (one-based) position to examine.",
-    )
+        description='For a fasta file with sequences, summarize what is '
+                    'happening at a specific position.')
+
+    parser.add_argument('--fastaFile', required=True,
+                        help='The name of the FASTA file to read.')
+
+    parser.add_argument('--position', required=True, type=int,
+                        help='The (one-based) position to examine.')
 
     args = parser.parse_args()
     reads = FastaReads(args.fastaFile)
     result = reads.summarizePosition(args.position - 1)
-    nReads = result["readCount"]
 
-    print(
-        "%d of %d sequences were excluded due to length."
-        % (result["excludedCount"], nReads)
-    )
-
-    denominator = (nReads - result["excludedCount"]) / 100.0
-    for base, count in result["countAtPosition"].items():
-        print("%s: Total: %s (%.2f%%)" % (base, count, count / denominator))
+    print('%d of %d sequences were excluded due to length.' % (
+        result['excludedCount'], len(reads)))
+
+    denominator = (len(reads) - result['excludedCount']) / 100.0
+    for base, count in result['countAtPosition'].items():
+        print('%s: Total: %s (%.2f%%)' % (base, count, count / denominator))
```

### Comparing `dark-matter-4.0.84/bin/pre-commit.sh` & `dark-matter-4.0.9/bin/pre-commit.sh`

 * *Files identical despite different names*

### Comparing `dark-matter-4.0.84/bin/print-read-lengths.py` & `dark-matter-4.0.9/bin/print-read-lengths.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,37 +1,33 @@
 #!/usr/bin/env python
 
 """
 Read a FASTA or FASTQ file (or read stdin) and print a line for each sequence,
 with the length of the sequence followed by its name.
 """
 
+from __future__ import print_function
+
 import sys
 import argparse
 from Bio import SeqIO
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
+
     parser = argparse.ArgumentParser(
-        description="Print lengths of reads in a FASTA or FASTQ file",
+        description='Print lengths of reads in a FASTA or FASTQ file',
     )
 
     parser.add_argument(
-        "reads",
-        nargs="?",
-        type=argparse.FileType("r"),
-        default=sys.stdin,
-        help="The input sequence file (in either FASTA or FASTQ format). "
-        "If not given, sequences will be read from stdin.",
-    )
+        'reads', nargs='?', type=argparse.FileType('r'), default=sys.stdin,
+        help='The input sequence file (in either FASTA or FASTQ format). '
+        'If not given, sequences will be read from stdin.')
 
     parser.add_argument(
-        "--format",
-        default="fasta",
-        choices=["fasta", "fastq"],
-        help="The format of the input.",
-    )
+        '--format', default='fasta', choices=['fasta', 'fastq'],
+        help='The format of the input.')
 
     args = parser.parse_args()
 
     for seq in SeqIO.parse(args.reads, args.format):
-        print("%d %s" % (len(seq), seq.description))
+        print('%d %s' % (len(seq), seq.description))
```

### Comparing `dark-matter-4.0.84/bin/proteins-to-pathogens-civ.py` & `dark-matter-4.0.9/bin/proteins-to-pathogens-civ.py`

 * *Files 19% similar despite different names*

```diff
@@ -46,342 +46,246 @@
     Read count
     HSP count
     Protein length (in amino acids)
     Title (in the above-mentioned "protein name [pathogen name]" format)
 
 """
 
+from __future__ import print_function
 import argparse
 import sys
 from os.path import exists
 
 # It's not clear that the PDF backend is the right choice here, but it
 # works (i.e., the generation of PNG images works fine).
 import matplotlib
-
-matplotlib.use("PDF")
+matplotlib.use('PDF')
 
 # These imports are here because dark.civ.proteins imports
 # matplotlib.pyplot and we need to set the matplotlib backend before the
 # import. So please don't move this import higher in this file.
 
 from dark.civ.proteins import ProteinGrouper, SqliteIndex
 from dark.colors import ColorsForCounts
 from dark.taxonomy import (
     addTaxonomyDatabaseCommandLineOptions,
-    parseTaxonomyDatabaseCommandLineOptions,
-)
+    parseTaxonomyDatabaseCommandLineOptions)
 
 
 def main(db, taxdb, args):
-    grouper = ProteinGrouper(
-        db,
-        taxdb,
-        assetDir=args.assetDir,
-        sampleName=args.sampleName,
-        sampleNameRegex=args.sampleNameRegex,
-        format_=args.format,
-        saveReadLengths=args.showReadLengths,
-        titleRegex=args.titleRegex,
-        negativeTitleRegex=args.negativeTitleRegex,
-        pathogenDataDir=args.pathogenDataDir,
-    )
+    grouper = ProteinGrouper(db, taxdb,
+                             assetDir=args.assetDir,
+                             sampleName=args.sampleName,
+                             sampleNameRegex=args.sampleNameRegex,
+                             format_=args.format,
+                             saveReadLengths=args.showReadLengths,
+                             titleRegex=args.titleRegex,
+                             negativeTitleRegex=args.negativeTitleRegex,
+                             pathogenDataDir=args.pathogenDataDir)
 
     if args.filenames:
         filenames = args.filenames
     else:
         filenames = (line[:-1] for line in sys.stdin)
 
     for filename in filenames:
         with open(filename) as fp:
             grouper.addFile(filename, fp)
 
-    preambleText = ""
+    preambleText = ''
     if args.preamble:
         for preamble in args.preamble:
             if exists(preamble):
                 preambleText += open(preamble).read()
             else:
                 preambleText += preamble
 
     if args.html:
-        readCountColors = ColorsForCounts(
-            args.readCountColor, args.defaultReadCountColor
-        )
-
-        print(
-            grouper.toHTML(
-                args.pathogenPanelFilename,
-                readCountColors=readCountColors,
-                minProteinFraction=args.minProteinFraction,
-                minProteinCount=args.minProteinCount,
-                pathogenType=args.pathogenType,
-                title=args.title,
-                preamble=preambleText,
-                sampleIndexFilename=args.sampleIndexFilename,
-                omitVirusLinks=args.omitVirusLinks,
-                bootstrapTreeviewDir=args.bootstrapTreeviewDir,
-            )
-        )
+        readCountColors = ColorsForCounts(args.readCountColor,
+                                          args.defaultReadCountColor)
+
+        print(grouper.toHTML(
+            args.pathogenPanelFilename,
+            readCountColors=readCountColors,
+            minProteinFraction=args.minProteinFraction,
+            minProteinCount=args.minProteinCount,
+            pathogenType=args.pathogenType,
+            title=args.title, preamble=preambleText,
+            sampleIndexFilename=args.sampleIndexFilename,
+            omitVirusLinks=args.omitVirusLinks,
+            bootstrapTreeviewDir=args.bootstrapTreeviewDir))
     else:
-        print(
-            grouper.toStr(
-                title=args.title, preamble=args.preamble, pathogenType=args.pathogenType
-            )
-        )
+        print(grouper.toStr(
+            title=args.title, preamble=args.preamble,
+            pathogenType=args.pathogenType))
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description="Group proteins by the pathogen they're from.",
-    )
+        description="Group proteins by the pathogen they're from.")
 
     parser.add_argument(
-        "filenames",
-        nargs="*",
-        help=(
-            "File names to read input from. The input will typically be "
-            "generated by alignment-panel-civ.py"
-        ),
-    )
-
-    parser.add_argument(
-        "--proteinGenomeDatabase",
-        required=True,
-        help=(
-            "The filename of an Sqlite3 database holding protein and "
-            "genome information, as built by make-protein-database.py"
-        ),
-    )
+        'filenames', nargs='*',
+        help=('File names to read input from. The input will typically be '
+              'generated by alignment-panel-civ.py'))
+
+    parser.add_argument(
+        '--proteinGenomeDatabase', required=True,
+        help=('The filename of an Sqlite3 database holding protein and '
+              'genome information, as built by make-protein-database.py'))
 
     # A mutually exclusive group for either --sampleName or --sampleNameRegex
     group = parser.add_mutually_exclusive_group()
 
     group.add_argument(
-        "--sampleName",
-        help=(
-            "An (optional) sample name. Use when all input files are for a "
-            "single sample. Cannot be used with --sampleNameRegex."
-        ),
-    )
+        '--sampleName',
+        help=('An (optional) sample name. Use when all input files are for a '
+              'single sample. Cannot be used with --sampleNameRegex.'))
 
     group.add_argument(
-        "--sampleNameRegex",
-        help=(
-            "An (optional) regular expression that can be used to extract a "
-            "short sample name from full sample file name.  The regular "
-            "expression must have a matching group (delimited by "
-            "parentheses) that captures the part of the file name that "
-            "should be used as the sample name."
-        ),
-    )
-
-    parser.add_argument(
-        "--pathogenPanelFilename",
-        nargs="?",
-        const=None,
-        help=(
-            "An (optional) filename to write a pathogen-sample panel PNG " "image to."
-        ),
-    )
-
-    parser.add_argument(
-        "--sampleIndexFilename",
-        help=(
-            "An (optional) filename to write a sample index file to. "
-            "Lines in the file will have an integer index, a space, and "
-            "then the sample name. Only produced if --html is used "
-            "(because the pathogen-NNN-sample-MMM.fastq are only written "
-            "in that case)."
-        ),
-    )
-
-    parser.add_argument(
-        "--html",
-        action="store_true",
-        help="If specified, output HTML instead of plain text.",
-    )
-
-    parser.add_argument(
-        "--format",
-        default="fasta",
-        choices=("fasta", "fastq"),
-        help=(
-            "Give the format of the sequence files written by "
-            "alignment-panel-civ.py."
-        ),
-    )
-
-    parser.add_argument(
-        "--minProteinFraction",
-        type=float,
-        default=0.0,
-        help=(
-            "The minimum fraction of proteins in a pathogen that must be "
-            "matched by a particular sample in order for that pathogen to "
-            "be displayed for that sample."
-        ),
-    )
-
-    parser.add_argument(
-        "--minProteinCount",
-        type=int,
-        default=0,
-        help=(
-            "The minimum number of proteins in a pathogen that must be "
-            "matched by a particular sample in order for that pathogen to "
-            "be displayed for that sample."
-        ),
-    )
-
-    parser.add_argument(
-        "--pathogenType",
-        default="viral",
-        choices=("bacterial", "viral", "generic"),
-        help=(
-            "Specify the pathogen type. This option only affects the "
-            "language used in HTML output."
-        ),
-    )
-
-    parser.add_argument(
-        "--showReadLengths",
-        action="store_true",
-        help=(
-            "If specified, the HTML output (use --html to get this) will "
-            "contain the lengths of all reads that match proteins for a "
-            "pathogen."
-        ),
-    )
-
-    parser.add_argument(
-        "--assetDir",
-        default="out",
-        help=(
-            "The output directory where noninteractive-alignment-panel.py "
-            "put its plots and FASTA/FASTQ files."
-        ),
-    )
-
-    parser.add_argument(
-        "--pathogenDataDir",
-        default="pathogen-data",
-        help=(
-            "The directory where per-pathogen information (e.g., collected "
-            "reads across all samples) should be written."
-        ),
-    )
-
-    parser.add_argument("--title", help="The title to show at the top of the output.")
-
-    parser.add_argument(
-        "--preamble",
-        action="append",
-        help=(
-            "Optional preamble text to show after the title. The argument "
-            "value may also name a file, in which case the file contents "
-            "will be inserted into the output. May be repeated."
-        ),
-    )
-
-    parser.add_argument("--titleRegex", help="A regex that pathogen names must match.")
-
-    parser.add_argument(
-        "--negativeTitleRegex", help="a regex that pathogen names must not match."
-    )
-
-    parser.add_argument(
-        "--omitVirusLinks",
-        action="store_true",
-        help=(
-            "If specified, the HTML output (use --html to get this) for "
-            "viruses will not contain links to ICTV and ViralZone. "
-            "This should be used when working with viruses that do not yet "
-            "have names that can be looked up."
-        ),
-    )
-
-    parser.add_argument(
-        "--defaultReadCountColor",
-        default="black",
-        help=(
-            "The font color for read counts. This will be used for all "
-            "read counts that do not otherwise have a color due to use of "
-            "--readCountColor. Only valid if --html is used."
-        ),
-    )
-
-    parser.add_argument(
-        "--readCountColor",
-        action="append",
-        help=(
-            "Specify read count coloring. This option must be given as "
-            'a space separated "value color" pair. The value is an integer '
-            "read count and the color is any color specification that can "
-            "be given to CSS. This argument can be repeated. E.g., "
-            '--readCountColor "0.9 red" --readCountColor '
-            '"0.75 rgb(23, 190, 207)" --readCountColor "0.1 #CF3CF3". Read '
-            "counts will be colored using the color of the highest count "
-            "threshold they satisfy. The default is to color all read "
-            "counts with the --defaultReadCountColor color. Only valid if "
-            "--html is used."
-        ),
-    )
-
-    parser.add_argument(
-        "--bootstrapTreeviewDir",
-        help=(
-            "The directory where the bootstrap treeview JS and CSS files "
-            "can be found. This can be a relative path from the location "
-            "where the output HTML will be served from or can be a URL "
-            "directory. In both cases, HTML will be emitted looking for "
-            "files with names bootstrap-treeview.min.css and "
-            "bootstrap-treeview.min.js in the directory (or URL directory). "
-            "Only valid if --html is used."
-        ),
-    )
+        '--sampleNameRegex',
+        help=('An (optional) regular expression that can be used to extract a '
+              'short sample name from full sample file name.  The regular '
+              'expression must have a matching group (delimited by '
+              'parentheses) that captures the part of the file name that '
+              'should be used as the sample name.'))
+
+    parser.add_argument(
+        '--pathogenPanelFilename', nargs='?', const=None,
+        help=('An (optional) filename to write a pathogen-sample panel PNG '
+              'image to.'))
+
+    parser.add_argument(
+        '--sampleIndexFilename',
+        help=('An (optional) filename to write a sample index file to. '
+              'Lines in the file will have an integer index, a space, and '
+              'then the sample name. Only produced if --html is used '
+              '(because the pathogen-NNN-sample-MMM.fastq are only written '
+              'in that case).'))
+
+    parser.add_argument(
+        '--html', default=False, action='store_true',
+        help='If specified, output HTML instead of plain text.')
+
+    parser.add_argument(
+        '--format', default='fasta', choices=('fasta', 'fastq'),
+        help=('Give the format of the sequence files written by '
+              'alignment-panel-civ.py.'))
+
+    parser.add_argument(
+        '--minProteinFraction', type=float, default=0.0,
+        help=('The minimum fraction of proteins in a pathogen that must be '
+              'matched by a particular sample in order for that pathogen to '
+              'be displayed for that sample.'))
+
+    parser.add_argument(
+        '--minProteinCount', type=int, default=0,
+        help=('The minimum number of proteins in a pathogen that must be '
+              'matched by a particular sample in order for that pathogen to '
+              'be displayed for that sample.'))
+
+    parser.add_argument(
+        '--pathogenType', default='viral', choices=('bacterial', 'viral'),
+        help=('Specify the pathogen type. This option only affects the '
+              'language used in HTML output.'))
+
+    parser.add_argument(
+        '--showReadLengths', default=False, action='store_true',
+        help=('If specified, the HTML output (use --html to get this) will '
+              'contain the lengths of all reads that match proteins for a '
+              'pathogen.'))
+
+    parser.add_argument(
+        '--assetDir', default='out',
+        help=('The output directory where noninteractive-alignment-panel.py '
+              'put its plots and FASTA/FASTQ files.'))
+
+    parser.add_argument(
+        '--pathogenDataDir', default='pathogen-data',
+        help=('The directory where per-pathogen information (e.g., collected '
+              'reads across all samples) should be written.'))
+
+    parser.add_argument(
+        '--title',
+        help='The title to show at the top of the output.')
+
+    parser.add_argument(
+        '--preamble', action='append',
+        help=('Optional preamble text to show after the title. The argument '
+              'value may also name a file, in which case the file contents '
+              'will be inserted into the output. May be repeated.'))
+
+    parser.add_argument(
+        '--titleRegex',
+        help='A regex that pathogen names must match.')
+
+    parser.add_argument(
+        '--negativeTitleRegex',
+        help='a regex that pathogen names must not match.')
+
+    parser.add_argument(
+        '--omitVirusLinks', default=False, action='store_true',
+        help=('If specified, the HTML output (use --html to get this) for '
+              'viruses will not contain links to ICTV and ViralZone. '
+              'This should be used when working with viruses that do not yet '
+              'have names that can be looked up.'))
+
+    parser.add_argument(
+        '--defaultReadCountColor', default='black',
+        help=('The font color for read counts. This will be used for all '
+              'read counts that do not otherwise have a color due to use of '
+              '--readCountColor. Only valid if --html is used.'))
+
+    parser.add_argument(
+        '--readCountColor', action='append',
+        help=('Specify read count coloring. This option must be given as '
+              'a space separated "value color" pair. The value is an integer '
+              'read count and the color is any color specification that can '
+              'be given to CSS. This argument can be repeated. E.g., '
+              '--readCountColor "0.9 red" --readCountColor '
+              '"0.75 rgb(23, 190, 207)" --readCountColor "0.1 #CF3CF3". Read '
+              'counts will be colored using the color of the highest count '
+              'threshold they satisfy. The default is to color all read '
+              'counts with the --defaultReadCountColor color. Only valid if '
+              '--html is used.'))
+
+    parser.add_argument(
+        '--bootstrapTreeviewDir',
+        help=('The directory where the bootstrap treeview JS and CSS files '
+              'can be found. This can be a relative path from the location '
+              'where the output HTML will be served from or can be a URL '
+              'directory. In both cases, HTML will be emitted looking for '
+              'files with names bootstrap-treeview.min.css and '
+              'bootstrap-treeview.min.js in the directory (or URL directory). '
+              'Only valid if --html is used.'))
 
     addTaxonomyDatabaseCommandLineOptions(parser)
 
     args = parser.parse_args()
 
     if not args.html:
         if args.sampleIndexFilename:
-            print(
-                "It does not make sense to use --sampleIndexFilename "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --sampleIndexFilename '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
         if args.omitVirusLinks:
-            print(
-                "It does not make sense to use --omitVirusLinks "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --omitVirusLinks '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
         if args.readCountColor:
-            print(
-                "It does not make sense to use --readCountColor "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --readCountColor '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
         if args.bootstrapTreeviewDir:
-            print(
-                "It does not make sense to use --bootstrapTreeviewDir "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --bootstrapTreeviewDir '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
 
-    if args.omitVirusLinks and args.pathogenType != "viral":
-        print(
-            "The --omitVirusLinks option only makes sense with " "--pathogenType viral",
-            file=sys.stderr,
-        )
+    if args.omitVirusLinks and args.pathogenType != 'viral':
+        print('The --omitVirusLinks option only makes sense with '
+              '--pathogenType viral', file=sys.stderr)
         sys.exit(1)
 
     with SqliteIndex(args.proteinGenomeDatabase) as db:
         taxdb = parseTaxonomyDatabaseCommandLineOptions(args, parser)
         main(db, taxdb, args)
```

### Comparing `dark-matter-4.0.84/bin/proteins-to-pathogens.py` & `dark-matter-4.0.9/bin/proteins-to-pathogens.py`

 * *Files 17% similar despite different names*

```diff
@@ -41,324 +41,230 @@
     Best bit score
     Read count
     HSP count
     Protein length
     Title (in the format "protein name [pathogen name]")
 """
 
+from __future__ import print_function
 import argparse
 import sys
 from itertools import chain
 
 # It's not clear that the PDF backend is the right choice here, but it
 # works (i.e., the generation of PNG images works fine).
 import matplotlib
-
-matplotlib.use("PDF")
+matplotlib.use('PDF')
 
 # These imports are here because dark.proteins imports matplotlib.pyplot
 # and we need to set the matplotlib backend before the import. So please
 # don't move this import higher in this file.
 
 from dark.proteins import ProteinGrouper
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description="Group proteins by the pathogen they're from.",
-    )
+        description="Group proteins by the pathogen they're from.")
+
+    parser.add_argument(
+        'filenames', nargs='*', help='Sample file names to read input from.')
+
+    parser.add_argument(
+        '--sampleName',
+        help=('An (optional) sample name. This is only used in producing '
+              'HTML output. Should be used when all input files are for a '
+              'single sample. Cannot be used with --sampleNameRegex.'))
+
+    parser.add_argument(
+        '--sampleNameRegex',
+        help=('An (optional) regular expression that can be used to extract a '
+              'short sample name from full sample file name.  The regular '
+              'expression must have a matching group (delimited by '
+              'parentheses) that captures the part of the file name that '
+              'should be used as the sample name.'))
+
+    parser.add_argument(
+        '--pathogenPanelFilename',
+        help=('An (optional) filename to write a pathogen-sample panel PNG '
+              'image to.'))
+
+    parser.add_argument(
+        '--sampleIndexFilename',
+        help=('An (optional) filename to write a sample index file to. '
+              'Lines in the file will have an integer index, a space, and '
+              'then the sample name. Only produced if --html is used '
+              '(because the pathogen-NNN-sample-MMM.fastq are only written '
+              'in that case).'))
+
+    parser.add_argument(
+        '--pathogenIndexFilename',
+        help=('An (optional) filename to write a pathogen index file to. '
+              'Lines in the file will have an integer index, a space, and '
+              'then the pathogen name. Only produced if --html is used '
+              '(because the pathogen-NNN-sample-MMM.fastq are only written '
+              'in that case).'))
+
+    parser.add_argument(
+        '--html', default=False, action='store_true',
+        help='If specified, output HTML instead of plain text.')
+
+    parser.add_argument(
+        '--format', default='fasta', choices=('fasta', 'fastq'),
+        help=('Give the format of the sequence files written by '
+              'noninteractive-alignment-panel.py when it created the '
+              'summary-proteins files given on output.'))
+
+    parser.add_argument(
+        '--proteinFastaFilename', '--pff', nargs='+', action='append',
+        help=('Optional filename(s) giving the name of the FASTA file(s) '
+              'with the protein AA sequences with their associated pathogens '
+              'in square brackets. This is the format used by NCBI for '
+              'bacterial and viral reference sequence protein files. If '
+              'given, the contents of this file will be used to determine how '
+              'many proteins each matched pathogen has. This makes it much '
+              'easier to spot significant matches (as opposed to those where, '
+              'say, just one protein from a pathogen is matched).'))
+
+    parser.add_argument(
+        '--minProteinFraction', type=float, default=0.0,
+        help=('The minimum fraction of proteins in a pathogen that must be '
+              'matched by a particular sample in order for that pathogen to '
+              'be displayed for that sample.'))
+
+    parser.add_argument(
+        '--minProteinCount', type=int, default=0,
+        help=('The minimum number of proteins in a pathogen that must be '
+              'matched by a particular sample in order for that pathogen to '
+              'be displayed for that sample.'))
+
+    parser.add_argument(
+        '--pathogenType', default='viral', choices=('bacterial', 'viral'),
+        help=('Specify the pathogen type. This option only affects the '
+              'language used in HTML output.'))
+
+    parser.add_argument(
+        '--showReadLengths', default=False, action='store_true',
+        help=('If specified, the HTML output (use --html to get this) will '
+              'contain the lengths of all reads that match proteins for a '
+              'pathogen.'))
+
+    parser.add_argument(
+        '--assetDir', default='out',
+        help=('The output directory where noninteractive-alignment-panel.py '
+              'puts its HTML, plots and FASTA or FASTQ files, needed for '
+              'using --html.'))
+
+    parser.add_argument(
+        '--pathogenDataDir', default='pathogen-data',
+        help=('The directory where per-pathogen information (e.g., collected '
+              'reads across all samples) should be written.'))
+
+    parser.add_argument(
+        '--title', default='Summary of pathogens',
+        help='The title to show at the top of the output.')
+
+    parser.add_argument(
+        '--preamble',
+        help='Optional preamble text to show after the title.')
+
+    parser.add_argument(
+        '--titleRegex', default=None,
+        help='A regex that pathogen names must match.')
+
+    parser.add_argument(
+        '--negativeTitleRegex', default=None,
+        help='a regex that pathogen names must not match.')
 
     parser.add_argument(
-        "filenames", nargs="*", help="Sample file names to read input from."
-    )
+        '--omitVirusLinks', default=False, action='store_true',
+        help=('If specified, the HTML output (use --html to get this) for '
+              'viruses will not contain links to ICTV and ViralZone. '
+              'This should be used when working with viruses that do not yet '
+              'have names that can be looked up.'))
 
     parser.add_argument(
-        "--sampleName",
-        help=(
-            "An (optional) sample name. This is only used in producing "
-            "HTML output. Should be used when all input files are for a "
-            "single sample. Cannot be used with --sampleNameRegex."
-        ),
-    )
-
-    parser.add_argument(
-        "--sampleNameRegex",
-        help=(
-            "An (optional) regular expression that can be used to extract a "
-            "short sample name from full sample file name.  The regular "
-            "expression must have a matching group (delimited by "
-            "parentheses) that captures the part of the file name that "
-            "should be used as the sample name."
-        ),
-    )
-
-    parser.add_argument(
-        "--pathogenPanelFilename",
-        help=(
-            "An (optional) filename to write a pathogen-sample panel PNG " "image to."
-        ),
-    )
-
-    parser.add_argument(
-        "--sampleIndexFilename",
-        help=(
-            "An (optional) filename to write a sample index file to. "
-            "Lines in the file will have an integer index, a space, and "
-            "then the sample name. Only produced if --html is used "
-            "(because the pathogen-NNN-sample-MMM.fastq are only written "
-            "in that case)."
-        ),
-    )
-
-    parser.add_argument(
-        "--pathogenIndexFilename",
-        help=(
-            "An (optional) filename to write a pathogen index file to. "
-            "Lines in the file will have an integer index, a space, and "
-            "then the pathogen name. Only produced if --html is used "
-            "(because the pathogen-NNN-sample-MMM.fastq are only written "
-            "in that case)."
-        ),
-    )
-
-    parser.add_argument(
-        "--html",
-        default=False,
-        action="store_true",
-        help="If specified, output HTML instead of plain text.",
-    )
-
-    parser.add_argument(
-        "--format",
-        default="fasta",
-        choices=("fasta", "fastq"),
-        help=(
-            "Give the format of the sequence files written by "
-            "noninteractive-alignment-panel.py when it created the "
-            "summary-proteins files given on output."
-        ),
-    )
-
-    parser.add_argument(
-        "--proteinFastaFilename",
-        "--pff",
-        nargs="+",
-        action="append",
-        help=(
-            "Optional filename(s) giving the name of the FASTA file(s) "
-            "with the protein AA sequences with their associated pathogens "
-            "in square brackets. This is the format used by NCBI for "
-            "bacterial and viral reference sequence protein files. If "
-            "given, the contents of this file will be used to determine how "
-            "many proteins each matched pathogen has. This makes it much "
-            "easier to spot significant matches (as opposed to those where, "
-            "say, just one protein from a pathogen is matched)."
-        ),
-    )
-
-    parser.add_argument(
-        "--minProteinFraction",
-        type=float,
-        default=0.0,
-        help=(
-            "The minimum fraction of proteins in a pathogen that must be "
-            "matched by a particular sample in order for that pathogen to "
-            "be displayed for that sample."
-        ),
-    )
-
-    parser.add_argument(
-        "--minProteinCount",
-        type=int,
-        default=0,
-        help=(
-            "The minimum number of proteins in a pathogen that must be "
-            "matched by a particular sample in order for that pathogen to "
-            "be displayed for that sample."
-        ),
-    )
-
-    parser.add_argument(
-        "--pathogenType",
-        default="viral",
-        choices=("bacterial", "viral"),
-        help=(
-            "Specify the pathogen type. This option only affects the "
-            "language used in HTML output."
-        ),
-    )
-
-    parser.add_argument(
-        "--showReadLengths",
-        default=False,
-        action="store_true",
-        help=(
-            "If specified, the HTML output (use --html to get this) will "
-            "contain the lengths of all reads that match proteins for a "
-            "pathogen."
-        ),
-    )
-
-    parser.add_argument(
-        "--assetDir",
-        default="out",
-        help=(
-            "The output directory where noninteractive-alignment-panel.py "
-            "puts its HTML, plots and FASTA or FASTQ files, needed for "
-            "using --html."
-        ),
-    )
-
-    parser.add_argument(
-        "--pathogenDataDir",
-        default="pathogen-data",
-        help=(
-            "The directory where per-pathogen information (e.g., collected "
-            "reads across all samples) should be written."
-        ),
-    )
-
-    parser.add_argument(
-        "--title",
-        default="Summary of pathogens",
-        help="The title to show at the top of the output.",
-    )
-
-    parser.add_argument(
-        "--preamble", help="Optional preamble text to show after the title."
-    )
-
-    parser.add_argument(
-        "--titleRegex", default=None, help="A regex that pathogen names must match."
-    )
-
-    parser.add_argument(
-        "--negativeTitleRegex",
-        default=None,
-        help="a regex that pathogen names must not match.",
-    )
-
-    parser.add_argument(
-        "--omitVirusLinks",
-        default=False,
-        action="store_true",
-        help=(
-            "If specified, the HTML output (use --html to get this) for "
-            "viruses will not contain links to ICTV and ViralZone. "
-            "This should be used when working with viruses that do not yet "
-            "have names that can be looked up."
-        ),
-    )
-
-    parser.add_argument(
-        "--omitSampleProteinCount",
-        default=False,
-        action="store_true",
-        help=(
-            "If specified, the HTML output (use --html to get this) for "
-            "viruses will not contain counts of the number of proteins "
-            "matched by each sample for a given pathogen. This should be "
-            "used when working with RVDB where there are many sequences "
-            "for some proteins and a sample matches many of them, leading "
-            "to incorrect reporting of the number of proteins of a pathogen "
-            "that are matched by samples."
-        ),
-    )
+        '--omitSampleProteinCount', default=False, action='store_true',
+        help=('If specified, the HTML output (use --html to get this) for '
+              'viruses will not contain counts of the number of proteins '
+              'matched by each sample for a given pathogen. This should be '
+              'used when working with RVDB where there are many sequences '
+              'for some proteins and a sample matches many of them, leading '
+              'to incorrect reporting of the number of proteins of a pathogen '
+              'that are matched by samples.'))
 
     args = parser.parse_args()
 
     if args.sampleName and args.sampleNameRegex:
-        print(
-            "It does not make sense to use --sampleName "
-            "as well as --sampleNameRegex",
-            file=sys.stderr,
-        )
+        print('It does not make sense to use --sampleName '
+              'as well as --sampleNameRegex', file=sys.stderr)
         sys.exit(1)
 
     if not args.html:
         if args.sampleIndexFilename:
-            print(
-                "It does not make sense to use --sampleIndexFilename "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --sampleIndexFilename '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
         if args.pathogenIndexFilename:
-            print(
-                "It does not make sense to use --pathogenIndexFilename "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --pathogenIndexFilename '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
         if args.omitVirusLinks:
-            print(
-                "It does not make sense to use --omitVirusLinks "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --omitVirusLinks '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
         if args.omitSampleProteinCount:
-            print(
-                "It does not make sense to use --omitSampleProteinCount "
-                "without also using --html",
-                file=sys.stderr,
-            )
+            print('It does not make sense to use --omitSampleProteinCount '
+                  'without also using --html', file=sys.stderr)
             sys.exit(1)
 
-    if args.omitVirusLinks and args.pathogenType != "viral":
-        print(
-            "The --omitVirusLinks option only makes sense with " "--pathogenType viral",
-            file=sys.stderr,
-        )
+    if args.omitVirusLinks and args.pathogenType != 'viral':
+        print('The --omitVirusLinks option only makes sense with '
+              '--pathogenType viral', file=sys.stderr)
         sys.exit(1)
 
     if args.proteinFastaFilename:
         # Flatten lists of lists that we get from using both nargs='+' and
         # action='append'. We use both because it allows people to use
         # (e.g.)  --pff on the command line either via "--pff file1 --pff
         # file2" or "--pff file1 file2", or a combination of these. That
         # way it's not necessary to remember which way you're supposed to
         # use it and you also can't be hit by the subtle problem
         # encountered in https://github.com/acorg/dark-matter/issues/453
-        proteinFastaFilenames = list(chain.from_iterable(args.proteinFastaFilename))
+        proteinFastaFilenames = list(chain.from_iterable(
+            args.proteinFastaFilename))
     else:
         proteinFastaFilenames = None
 
-    grouper = ProteinGrouper(
-        assetDir=args.assetDir,
-        sampleName=args.sampleName,
-        sampleNameRegex=args.sampleNameRegex,
-        format_=args.format,
-        proteinFastaFilenames=proteinFastaFilenames,
-        saveReadLengths=args.showReadLengths,
-        titleRegex=args.titleRegex,
-        negativeTitleRegex=args.negativeTitleRegex,
-        pathogenDataDir=args.pathogenDataDir,
-    )
+    grouper = ProteinGrouper(assetDir=args.assetDir,
+                             sampleName=args.sampleName,
+                             sampleNameRegex=args.sampleNameRegex,
+                             format_=args.format,
+                             proteinFastaFilenames=proteinFastaFilenames,
+                             saveReadLengths=args.showReadLengths,
+                             titleRegex=args.titleRegex,
+                             negativeTitleRegex=args.negativeTitleRegex,
+                             pathogenDataDir=args.pathogenDataDir)
 
     if args.filenames:
         filenames = args.filenames
     else:
         filenames = (line[:-1] for line in sys.stdin)
 
     for filename in filenames:
         with open(filename) as fp:
             grouper.addFile(filename, fp)
 
     if args.html:
-        print(
-            grouper.toHTML(
-                args.pathogenPanelFilename,
-                minProteinFraction=args.minProteinFraction,
-                minProteinCount=args.minProteinCount,
-                pathogenType=args.pathogenType,
-                title=args.title,
-                preamble=args.preamble,
-                sampleIndexFilename=args.sampleIndexFilename,
-                pathogenIndexFilename=args.pathogenIndexFilename,
-                omitVirusLinks=args.omitVirusLinks,
-                omitSampleProteinCount=args.omitSampleProteinCount,
-            )
-        )
+        print(grouper.toHTML(
+            args.pathogenPanelFilename,
+            minProteinFraction=args.minProteinFraction,
+            minProteinCount=args.minProteinCount,
+            pathogenType=args.pathogenType,
+            title=args.title, preamble=args.preamble,
+            sampleIndexFilename=args.sampleIndexFilename,
+            pathogenIndexFilename=args.pathogenIndexFilename,
+            omitVirusLinks=args.omitVirusLinks,
+            omitSampleProteinCount=args.omitSampleProteinCount))
     else:
         print(grouper.toStr())
```

### Comparing `dark-matter-4.0.84/bin/randomize-fasta.py` & `dark-matter-4.0.9/bin/randomize-fasta.py`

 * *Files 20% similar despite different names*

```diff
@@ -4,18 +4,20 @@
 Read DNA FASTA from stdin and print FASTA to stdout, with the sequences
 randomized. The read ids and lengths are preserved.
 
 Note: This produces DNA sequences. If you have AA reads and you need this
       functionality, we can add it.
 """
 
+from __future__ import print_function
+
 import sys
 from numpy.random import choice
 
 from dark.fasta import FastaReads
 from dark.reads import DNARead
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     for read in FastaReads(sys.stdin):
-        seq = "".join(choice(["A", "C", "G", "T"], len(read), replace=True))
-        print(DNARead(read.id, seq).toString("fasta"))
+        seq = ''.join(choice(['A', 'C', 'G', 'T'], len(read), replace=True))
+        print(DNARead(read.id, seq).toString('fasta'))
```

### Comparing `dark-matter-4.0.84/bin/read-blast-json.py` & `dark-matter-4.0.9/bin/read-blast-json.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,27 +1,26 @@
 #!/usr/bin/env python
 
 """
 Read simplified JSON BLAST records and report the elapsed time.
 """
 
+from __future__ import print_function
+
+from dark.conversion import JSONRecordsReader
 from time import time
 import sys
 
-from dark.blast.conversion import JSONRecordsReader
-
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     if len(sys.argv) != 2:
-        print("Usage: %s file.json" % sys.argv[0], file=sys.stderr)
+        print('Usage: %s file.json' % sys.argv[0], file=sys.stderr)
         sys.exit(1)
     else:
         start = time()
         jsonReader = JSONRecordsReader(sys.argv[1])
         records = jsonReader.records()
         for count, record in enumerate(records, start=1):
             pass
         elapsed = time() - start
-        print(
-            "Read %d JSON BLAST records in %.3f secs (%.0f records/sec)"
-            % (count, elapsed, float(count) / float(elapsed))
-        )
+        print('Read %d JSON BLAST records in %.3f secs (%.0f records/sec)' % (
+            count, elapsed, float(count) / float(elapsed)))
```

### Comparing `dark-matter-4.0.84/bin/relabel-newick-tree.py` & `dark-matter-4.0.9/bin/relabel-newick-tree.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,11 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 from ete3 import Tree
 import argparse
 
 
 def readNames(fp):
     """
@@ -13,79 +15,62 @@
 
     @raise ValueError: If there is a duplicate old name given or if a line
         cannot be split into two TAB-separated fields.
     @return: A C{dict} of old to new names.
     """
     result = {}
     for line in fp:
-        old, new = line.strip().split("\t")
+        old, new = line.strip().split('\t')
         if old in result:
-            raise ValueError("Sequence id %r appears twice in the input." % old)
+            raise ValueError('Sequence id %r appears twice in the input.' %
+                             old)
         else:
             result[old] = new
 
     return result
 
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description=("Relabel a Newick tree according to a file of from/to " "names."),
-)
+    description=('Relabel a Newick tree according to a file of from/to '
+                 'names.'))
+
+parser.add_argument(
+    'newickFile',
+    help='The Newick tree file.')
+
+parser.add_argument(
+    '--nameFile',
+    help=('The file of renamings. Each line should contain an existing (in '
+          'the tree) sequence id, a TAB, and then a new sequence id. If not '
+          'given, the renaming is read from standard input.'))
 
-parser.add_argument("newickFile", help="The Newick tree file.")
+parser.add_argument(
+    '--inputFormat', type=int, default=0,
+    help=('The format argument to pass to the ete3 Tree class initializer to '
+          'read the input Newick.'))
+
+parser.add_argument(
+    '--outputFormat', type=int, default=0,
+    help=('The format argument to pass to the ete3 Tree writer for the '
+          'resulting tree.'))
+
+parser.add_argument(
+    '--quotedNames', default=False, action='store_true',
+    help=('If given, pass quoted_node_names=True to the ete3 Tree class '
+          'initializer'))
 
 parser.add_argument(
-    "--nameFile",
-    help=(
-        "The file of renamings. Each line should contain an existing (in "
-        "the tree) sequence id, a TAB, and then a new sequence id. If not "
-        "given, the renaming is read from standard input."
-    ),
-)
-
-parser.add_argument(
-    "--inputFormat",
-    type=int,
-    default=0,
-    help=(
-        "The format argument to pass to the ete3 Tree class initializer to "
-        "read the input Newick."
-    ),
-)
-
-parser.add_argument(
-    "--outputFormat",
-    type=int,
-    default=0,
-    help=(
-        "The format argument to pass to the ete3 Tree writer for the " "resulting tree."
-    ),
-)
-
-parser.add_argument(
-    "--quotedNames",
-    default=False,
-    action="store_true",
-    help=(
-        "If given, pass quoted_node_names=True to the ete3 Tree class " "initializer"
-    ),
-)
-
-parser.add_argument(
-    "--verbose",
-    default=False,
-    action="store_true",
-    help="If given, print details of the renaming(s).",
-)
+    '--verbose', default=False, action='store_true',
+    help='If given, print details of the renaming(s).')
 
 args = parser.parse_args()
 
-tree = Tree(
-    args.newickFile, format=args.inputFormat, quoted_node_names=args.quotedNames
-)
+tree = Tree(args.newickFile, format=args.inputFormat,
+            quoted_node_names=args.quotedNames)
 
 if args.nameFile:
     with open(args.nameFile) as fp:
         names = readNames(fp)
 else:
     names = readNames(sys.stdin)
 
@@ -94,12 +79,12 @@
 for node in tree.traverse():
     try:
         newName = names[node.name]
     except KeyError:
         pass
     else:
         if args.verbose:
-            print("Renaming %s to %s" % (node.name, newName), file=sys.stderr)
+            print('Renaming %s to %s' % (node.name, newName), file=sys.stderr)
         node.name = newName
 
 # Print the tree, including the name of the root.
-print("%s%s;" % (tree.write(format=args.outputFormat)[:-1], tree.name))
+print('%s%s;' % (tree.write(format=args.outputFormat)[:-1], tree.name))
```

### Comparing `dark-matter-4.0.84/bin/run-bowtie2.py` & `dark-matter-4.0.9/bin/run-bowtie2.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,146 +1,132 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import os
 import sys
 import argparse
 import multiprocessing
 from os.path import exists, join
 from tempfile import mkdtemp
 import pysam
 
 from dark.process import Executor
 from dark.bowtie2 import Bowtie2
 
 DEFAULT_SAMTOOLS_VIEW_FLAGS = (
-    pysam.FUNMAP | pysam.FSECONDARY | pysam.FDUP | pysam.FSUPPLEMENTARY
-)
+    pysam.FUNMAP | pysam.FSECONDARY | pysam.FDUP | pysam.FSUPPLEMENTARY)
 
 
 def saveStdin(args, e):
     if os.isatty(0):
-        print("Reading sequences to match against from stdin.", file=sys.stderr)
-    dirname = mkdtemp(prefix="run-bt2-stdin-", dir=args.tempdir)
+        print('Reading sequences to match against from stdin.',
+              file=sys.stderr)
+    dirname = mkdtemp(prefix='run-bt2-stdin-', dir=args.tempdir)
     if args.tmpChmod:
-        e.execute(f"chmod {args.tmpChmod} {dirname}")
-    filename = join(dirname, "stdin.fastq")
+        e.execute(f'chmod {args.tmpChmod} {dirname}')
+    filename = join(dirname, 'stdin.fastq')
     count = 0
 
-    with open(filename, "w") as fp:
+    with open(filename, 'w') as fp:
         for line in sys.stdin:
             fp.write(line)
             count += 1
 
     if count == 0:
-        print("Standard input was empty! Exiting.", file=sys.stderr)
+        print('Standard input was empty! Exiting.', file=sys.stderr)
         sys.exit(1)
 
     return dirname, filename
 
 
 def processMatch(args, e):
     """
     Run Bowtie2 to find matches.
     """
     if not args.index and not args.reference:
-        print("One of --index or --reference must be given.", file=sys.stderr)
+        print('One of --index or --reference must be given.', file=sys.stderr)
         sys.exit(0)
 
     if args.markDuplicatesPicard or args.callHaplotypesGATK:
         if args.picardJar:
             picardJar = args.picardJar
         else:
             try:
-                picardJar = os.environ["PICARD_JAR"]
+                picardJar = os.environ['PICARD_JAR']
             except KeyError:
-                print(
-                    "If you use --markDuplicatesPicard or "
-                    "--callHaplotypesGATK, you must give a Picard JAR file "
-                    "with --picardJar or else set PICARD_JAR in your "
-                    "environment.",
-                    file=sys.stderr,
-                )
+                print('If you use --markDuplicatesPicard or '
+                      '--callHaplotypesGATK, you must give a Picard JAR file '
+                      'with --picardJar or else set PICARD_JAR in your '
+                      'environment.', file=sys.stderr)
                 sys.exit(0)
 
     bt2 = Bowtie2(
         executor=e,
-        threads=(multiprocessing.cpu_count() if args.threads is None else args.threads),
+        threads=(multiprocessing.cpu_count() if args.threads is None
+                 else args.threads),
         verboseFp=(sys.stderr if args.verbose else None),
-        dryRun=args.dryRun,
-        tempdir=args.tempdir,
-        tmpChmod=args.tmpChmod,
-    )
+        dryRun=args.dryRun, tempdir=args.tempdir, tmpChmod=args.tmpChmod)
 
     bt2.buildIndex(args.index or args.reference)
 
     if not args.align:
         if args.verbose:
-            print("Bowtie2 alignment not done due to --noAlign.", file=sys.stderr)
-        print("Bowtie2 temporary directory %r." % bt2.tempdir, file=sys.stderr)
+            print('Bowtie2 alignment not done due to --noAlign.',
+                  file=sys.stderr)
+        print('Bowtie2 temporary directory %r.' % bt2.tempdir, file=sys.stderr)
         sys.exit(0)
 
     if args.fastq1:
         stdinDir, fastq1, fastq2 = None, args.fastq1, args.fastq2
     else:
         stdinDir, fastq1 = saveStdin(args, e)
         fastq2 = None
 
     if args.out:
         if exists(args.out) and not (args.force or args.dryRun):
-            print(
-                "Will not overwrite pre-existing output file %r. "
-                "Use --force to make me." % args.out,
-                file=sys.stderr,
-            )
+            print('Will not overwrite pre-existing output file %r. '
+                  'Use --force to make me.' % args.out, file=sys.stderr)
             sys.exit(1)
 
         if args.indexBAM:
-            bai = args.out + ".bai"
+            bai = args.out + '.bai'
             if exists(bai) and not (args.force or args.dryRun):
-                print(
-                    "Will not overwrite pre-existing output file %r. "
-                    "Use --force to make me." % bai,
-                    file=sys.stderr,
-                )
+                print('Will not overwrite pre-existing output file %r. '
+                      'Use --force to make me.' % bai, file=sys.stderr)
                 sys.exit(1)
             needBAI = True
         else:
             needBAI = False
 
     if args.callHaplotypesGATK:
         if args.vcfFile:
-            for filename in (args.vcfFile, args.vcfFile + ".tbi"):
+            for filename in (args.vcfFile, args.vcfFile + '.tbi'):
                 if exists(filename) and not args.force:
-                    print(
-                        "Will not overwrite pre-existing VCF file %r. "
-                        "Use --force to make me." % filename,
-                        file=sys.stderr,
-                    )
+                    print('Will not overwrite pre-existing VCF file %r. '
+                          'Use --force to make me.' % filename,
+                          file=sys.stderr)
                     sys.exit(1)
 
     if args.callHaplotypesBcftools:
         if args.vcfFile:
             if exists(args.vcfFile) and not args.force:
-                print(
-                    "Will not overwrite pre-existing VCF file %r. "
-                    "Use --force to make me." % args.vcfFile,
-                    file=sys.stderr,
-                )
+                print('Will not overwrite pre-existing VCF file %r. '
+                      'Use --force to make me.' % filename, file=sys.stderr)
                 sys.exit(1)
 
     bt2.align(bowtie2Args=args.bowtie2Args, fastq1=fastq1, fastq2=fastq2)
 
     if args.bam:
         bt2.makeBAM(args.samtoolsViewArgs)
 
     if args.sort and not (
-        args.markDuplicatesPicard
-        or args.markDuplicatesGATK
-        or args.removePrimersFromBedFile
-    ):
+            args.markDuplicatesPicard or
+            args.markDuplicatesGATK or
+            args.removePrimersFromBedFile):
         bt2.sort()
 
     if args.removePrimersFromBedFile:
         bt2.sort()
         bt2.removePrimers(args.removePrimersFromBedFile)
 
     if args.markDuplicatesPicard:
@@ -152,32 +138,32 @@
         bt2.markDuplicatesGATK()
 
     if args.removeDuplicates:
         bt2.removeDuplicates()
 
     if args.callHaplotypesGATK:
         bt2.indexBAM()
-        bt2.callHaplotypesGATK(
-            picardJar=picardJar, vcfFile=args.vcfFile, referenceFasta=args.reference
-        )
+        bt2.callHaplotypesGATK(picardJar=picardJar, vcfFile=args.vcfFile,
+                               referenceFasta=args.reference)
 
     if args.callHaplotypesBcftools:
         bt2.indexBAM()
-        bt2.callHaplotypesBcftools(vcfFile=args.vcfFile, referenceFasta=args.reference)
+        bt2.callHaplotypesBcftools(vcfFile=args.vcfFile,
+                                   referenceFasta=args.reference)
 
     if args.bam and args.indexBAM:
         bt2.indexBAM()
 
     if args.out:
         e.execute("mv '%s' '%s'" % (bt2.outputFile(), args.out))
         if needBAI:
             e.execute("mv '%s.bai' '%s.bai'" % (bt2.outputFile(), args.out))
     else:
         if not args.dryRun:
-            with open(bt2.outputFile(), "rb") as fp:
+            with open(bt2.outputFile(), 'rb') as fp:
                 read, write = fp.read, sys.stdout.write
                 while True:
                     data = read(2048)
                     if data:
                         write(data)
                     else:
                         break
@@ -185,354 +171,259 @@
     if stdinDir:
         # Remove the directory where we stashed standard input.
         e.execute("rm -r '%s'" % stdinDir)
 
     if args.clean:
         bt2.close()
     else:
-        print("Bowtie2 temporary directory %r." % bt2.tempdir, file=sys.stderr)
+        print('Bowtie2 temporary directory %r.' % bt2.tempdir, file=sys.stderr)
 
 
 def processOneIgnore(args, index, count, tempdir, e):
     """
     Process one ignored index.
     """
     if args.verbose:
-        print("Preparing to ignore reads matching index %r." % index, file=sys.stderr)
+        print('Preparing to ignore reads matching index %r.' % index,
+              file=sys.stderr)
 
     bt2 = Bowtie2(
         executor=e,
-        threads=(multiprocessing.cpu_count() if args.threads is None else args.threads),
+        threads=(multiprocessing.cpu_count() if args.threads is None
+                 else args.threads),
         verboseFp=(sys.stderr if args.verbose else None),
-        dryRun=args.dryRun,
-        tempdir=tempdir,
-        tmpChmod=args.tmpChmod,
-    )
+        dryRun=args.dryRun, tempdir=tempdir, tmpChmod=args.tmpChmod)
 
     bt2.buildIndex(index)
 
-    unAlignedFile = join(tempdir, "unaligned-%d" % count)
+    unAlignedFile = join(tempdir, 'unaligned-%d' % count)
 
     if args.fastq1 and args.fastq2:
         bt2.align(
-            bowtie2Args="%s --un-conc-gz %s" % (args.bowtie2Args, unAlignedFile),
-            fastq1=args.fastq1,
-            fastq2=args.fastq2,
-            discardSAM=True,
-        )
-
-        for i in "1", "2":
-            src = unAlignedFile + "." + i
-            dst = src + ".gz"
+            bowtie2Args='%s --un-conc-gz %s' % (args.bowtie2Args,
+                                                unAlignedFile),
+            fastq1=args.fastq1, fastq2=args.fastq2, discardSAM=True)
+
+        for i in '1', '2':
+            src = unAlignedFile + '.' + i
+            dst = src + '.gz'
             e.execute("mv '%s' '%s'" % (src, dst))
-            setattr(args, "fastq" + i, dst)
+            setattr(args, 'fastq' + i, dst)
 
         if not e.dryRun:
             assert exists(args.fastq1)
             assert exists(args.fastq2)
     else:
         bt2.align(
-            bowtie2Args="%s --un-gz %s" % (args.bowtie2Args, unAlignedFile),
-            fastq1=args.fastq1,
-            discardSAM=True,
-        )
+            bowtie2Args='%s --un-gz %s' % (args.bowtie2Args,
+                                           unAlignedFile),
+            fastq1=args.fastq1, discardSAM=True)
 
         e.execute("mv '%s' '%s.gz'" % (unAlignedFile, unAlignedFile))
-        args.fastq1 = unAlignedFile + ".gz"
+        args.fastq1 = unAlignedFile + '.gz'
         if not e.dryRun:
             assert exists(args.fastq1)
 
     if args.clean:
         bt2.close()
     else:
-        print(
-            "Bowtie2 temporary ignore index directory %r." % bt2.tempdir,
-            file=sys.stderr,
-        )
+        print('Bowtie2 temporary ignore index directory %r.' % bt2.tempdir,
+              file=sys.stderr)
 
 
 def processIgnores(args, e):
     """
     Ignore the indices in args.ignoredIndices
     """
     if e.dryRun:
-        tempdir = "/tmp/ignores"
+        tempdir = '/tmp/ignores'
     else:
-        tempdir = mkdtemp(prefix="bt2-ignores-", dir=args.tempdir)
+        tempdir = mkdtemp(prefix='bt2-ignores-', dir=args.tempdir)
         if args.tmpChmod:
-            e.execute(f"chmod {args.tmpChmod} {tempdir}")
+            e.execute(f'chmod {args.tmpChmod} {tempdir}')
 
     for count, ignoreIndex in enumerate(args.ignoredIndices):
         processOneIgnore(args, ignoreIndex, count, tempdir, e)
     return tempdir
 
 
 def main():
     parser = argparse.ArgumentParser(
         formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-        description=(
-            "Run bowtie2 on a FASTA file. Optionally convert the "
-            "result to BAM, sorting, and indexing."
-        ),
-    )
-
-    parser.add_argument(
-        "--index",
-        help=(
-            "Either: an accession number, a filename or the name of a "
-            "pre-existing bowtie2 index (created with bowtie2-build). If "
-            "not given and --reference is used, the reference will be "
-            "used to build a bowtie2 index."
-        ),
-    )
-
-    parser.add_argument(
-        "--ignoreIndex",
-        action="append",
-        dest="ignoredIndices",
-        help=(
-            "Either: an accession number, a filename or the name of a "
-            "pre-existing bowtie2 index (created with bowtie2-build). "
-            "Reads matching this index will be ignored. May be repeated."
-        ),
-    )
-
-    parser.add_argument(
-        "--fastq1",
-        "-1",
-        help=(
-            "The FASTQ reads to match against the bowtie2 index given by "
-            "--index. Also use --fast2 if you have paired reads. "
-            "If not given, single-end FASTQ reads will be read from "
-            "standard input."
-        ),
-    )
-
-    parser.add_argument(
-        "--fastq2",
-        "-2",
-        help=(
-            "The FASTQ reads to match against the bowtie2 index given by "
-            "--index. Use this with --fastq1 to specify the mate "
-            "file for paired-end reads."
-        ),
-    )
-
-    parser.add_argument(
-        "--bowtie2Args",
-        default="--no-unal",
-        help=(
-            "Extra arguments to be passed to Bowtie2 (use --threads to "
-            "specify a thread count)."
-        ),
-    )
-
-    parser.add_argument(
-        "--samtoolsViewArgs",
-        default="-F %d -q 30" % DEFAULT_SAMTOOLS_VIEW_FLAGS,
-        help="Arguments to be passed to samtools view to create the BAM file.",
-    )
-
-    parser.add_argument(
-        "--tempdir",
-        help=(
-            "The temporary directory to use. If not specified, the value "
-            "of the TMPDIR environment variable (if any) is used, or else "
-            "/tmp."
-        ),
-    )
-
-    parser.add_argument(
-        "--out",
-        "-o",
-        help=(
-            "The output file name. If not given, the resulting SAM or BAM "
-            "will be written to standard output will be used."
-        ),
-    )
-
-    parser.add_argument(
-        "--reference",
-        help=(
-            "The reference FASTA file for use with --callHaplotypesGATK and "
-            "--callHaplotypesBcftools. This will be used to build a Bowtie2 "
-            "index if --index is not given."
-        ),
-    )
-
-    parser.add_argument(
-        "--vcfFile",
-        help=(
-            "The file to write VCF info to if --callHaplotypesGATK or "
-            "--callHaplotypesBcftools are used."
-        ),
-    )
-
-    parser.add_argument(
-        "--markDuplicatesGATK",
-        action="store_true",
-        help=(
-            "Use GATK to mark duplicates. See "
-            "https://gatk.broadinstitute.org for details on GATK."
-        ),
-    )
-
-    parser.add_argument(
-        "--markDuplicatesPicard",
-        action="store_true",
-        help=(
-            "Use Picard to mark duplicates. See "
-            "https://github.com/broadinstitute/picard for details on "
-            "Picard."
-        ),
-    )
-
-    parser.add_argument(
-        "--picardJar",
-        help=(
-            "The path to the Picard jar file. See "
-            "https://github.com/broadinstitute/picard for details on "
-            "Picard."
-        ),
-    )
-
-    parser.add_argument(
-        "--tmpChmod",
-        help=(
-            "A chmod string for setting the permission on the temporary "
-            "directory created. This will be passed to chmod(1), so you "
-            'could specify "g+rwx", for example.'
-        ),
-    )
-
-    parser.add_argument(
-        "--removeDuplicates",
-        action="store_true",
-        help=(
-            "Remove duplicates from the resulting SAM/BAM file. Best used "
-            "in combination with an option that marks duplicates, such as "
-            "--markDuplicatesGATK."
-        ),
-    )
-
-    parser.add_argument(
-        "--verbose",
-        action="store_true",
-        help=(
-            "Print a description of commands as they are (or would be, if "
-            "--dryRun is used) executed."
-        ),
-    )
-
-    parser.add_argument(
-        "--log",
-        action="store_true",
-        help=(
-            "Show a log of commands that were (or would be, if --dryRun is "
-            "used) executed."
-        ),
-    )
-
-    parser.add_argument(
-        "--threads",
-        type=int,
-        help="The number of threads to use when running bowtie2 commands.",
-    )
-
-    parser.add_argument(
-        "--noAlign",
-        action="store_false",
-        dest="align",
-        help="Do not align with Bowtie2, just build an index.",
-    )
-
-    parser.add_argument(
-        "--noBAM", action="store_false", dest="bam", help="Do not convert SAM to BAM."
-    )
-
-    parser.add_argument(
-        "--noSort", action="store_false", dest="sort", help="Do not sort the BAM."
-    )
-
-    parser.add_argument(
-        "--noIndexBAM",
-        action="store_false",
-        dest="indexBAM",
-        help="Do not index the BAM file.",
-    )
-
-    parser.add_argument(
-        "--noClean",
-        action="store_false",
-        dest="clean",
-        help="Do not remove intermediate files or the temporary directory.",
-    )
-
-    parser.add_argument(
-        "--force", action="store_true", help="Overwrite pre-existing output file."
-    )
-
-    parser.add_argument(
-        "--dryRun",
-        action="store_true",
-        help="Do not run commands, just print what would be done.",
-    )
+        description=('Run bowtie2 on a FASTA file. Optionally convert the '
+                     'result to BAM, sorting, and indexing.'))
+
+    parser.add_argument(
+        '--index',
+        help=('Either: an accession number, a filename or the name of a '
+              'pre-existing bowtie2 index (created with bowtie2-build). If '
+              'not given and --reference is used, the reference will be '
+              'used to build a bowtie2 index.'))
+
+    parser.add_argument(
+        '--ignoreIndex', action='append', dest='ignoredIndices',
+        help=('Either: an accession number, a filename or the name of a '
+              'pre-existing bowtie2 index (created with bowtie2-build). '
+              'Reads matching this index will be ignored. May be repeated.'))
+
+    parser.add_argument(
+        '--fastq1', '-1',
+        help=('The FASTQ reads to match against the bowtie2 index given by '
+              '--index. Also use --fast2 if you have paired reads. '
+              'If not given, single-end FASTQ reads will be read from '
+              'standard input.'))
+
+    parser.add_argument(
+        '--fastq2', '-2',
+        help=('The FASTQ reads to match against the bowtie2 index given by '
+              '--index. Use this with --fastq1 to specify the mate '
+              'file for paired-end reads.'))
+
+    parser.add_argument(
+        '--bowtie2Args', default='--no-unal',
+        help=('Extra arguments to be passed to Bowtie2 (use --threads to '
+              'specify a thread count).'))
+
+    parser.add_argument(
+        '--samtoolsViewArgs',
+        default='-F %d -q 30' % DEFAULT_SAMTOOLS_VIEW_FLAGS,
+        help='Arguments to be passed to samtools view to create the BAM file.')
+
+    parser.add_argument(
+        '--tempdir',
+        help=('The temporary directory to use. If not specified, the value '
+              'of the TMPDIR environment variable (if any) is used, or else '
+              '/tmp.'))
+
+    parser.add_argument(
+        '--out', '-o',
+        help=('The output file name. If not given, the resulting SAM or BAM '
+              'will be written to standard output will be used.'))
+
+    parser.add_argument(
+        '--reference',
+        help=('The reference FASTA file for use with --callHaplotypesGATK and '
+              '--callHaplotypesBcftools. This will be used to build a Bowtie2 '
+              'index if --index is not given.'))
+
+    parser.add_argument(
+        '--vcfFile',
+        help=('The file to write VCF info to if --callHaplotypesGATK or '
+              '--callHaplotypesBcftools are used.'))
+
+    parser.add_argument(
+        '--markDuplicatesGATK', default=False, action='store_true',
+        help=('Use GATK to mark duplicates. See '
+              'https://gatk.broadinstitute.org for details on GATK.'))
+
+    parser.add_argument(
+        '--markDuplicatesPicard', default=False, action='store_true',
+        help=('Use Picard to mark duplicates. See '
+              'https://github.com/broadinstitute/picard for details on '
+              'Picard.'))
+
+    parser.add_argument(
+        '--picardJar',
+        help=('The path to the Picard jar file. See '
+              'https://github.com/broadinstitute/picard for details on '
+              'Picard.'))
+
+    parser.add_argument(
+        '--tmpChmod',
+        help=('A chmod string for setting the permission on the temporary '
+              'directory created. This will be passed to chmod(1), so you '
+              'could specify "g+rwx", for example.'))
+
+    parser.add_argument(
+        '--removeDuplicates', default=False, action='store_true',
+        help=('Remove duplicates from the resulting SAM/BAM file. Best used '
+              'in combination with an option that marks duplicates, such as '
+              '--markDuplicatesGATK.'))
+
+    parser.add_argument(
+        '--verbose', default=False, action='store_true',
+        help=('Print a description of commands as they are (or would be, if '
+              '--dryRun is used) executed.'))
+
+    parser.add_argument(
+        '--log', default=False, action='store_true',
+        help=('Show a log of commands that were (or would be, if --dryRun is '
+              'used) executed.'))
+
+    parser.add_argument(
+        '--threads', type=int,
+        help='The number of threads to use when running bowtie2 commands.')
+
+    parser.add_argument(
+        '--noAlign', default=True, action='store_false', dest='align',
+        help='Do not align with Bowtie2, just build an index.')
+
+    parser.add_argument(
+        '--noBAM', default=True, action='store_false', dest='bam',
+        help='Do not convert SAM to BAM.')
+
+    parser.add_argument(
+        '--noSort', default=True, action='store_false', dest='sort',
+        help='Do not sort the BAM.')
+
+    parser.add_argument(
+        '--noIndexBAM', default=True, action='store_false', dest='indexBAM',
+        help='Do not index the BAM file.')
+
+    parser.add_argument(
+        '--noClean', default=True, action='store_false', dest='clean',
+        help='Do not remove intermediate files or the temporary directory.')
+
+    parser.add_argument(
+        '--force', default=False, action='store_true',
+        help='Overwrite pre-existing output file.')
+
+    parser.add_argument(
+        '--dryRun', default=False, action='store_true',
+        help='Do not run commands, just print what would be done.')
 
     haplotypeCaller = parser.add_mutually_exclusive_group()
 
     haplotypeCaller.add_argument(
-        "--callHaplotypesGATK",
-        action="store_true",
-        help=(
-            "Use GATK to call haplotypes. See "
-            "https://gatk.broadinstitute.org for details on GATK."
-        ),
-    )
+        '--callHaplotypesGATK', default=False, action='store_true',
+        help=('Use GATK to call haplotypes. See '
+              'https://gatk.broadinstitute.org for details on GATK.'))
 
     haplotypeCaller.add_argument(
-        "--callHaplotypesBcftools",
-        action="store_true",
-        help="Use bcftools call to call haplotypes.",
-    )
+        '--callHaplotypesBcftools', default=False, action='store_true',
+        help='Use bcftools call to call haplotypes.')
 
     parser.add_argument(
-        "--removePrimersFromBedFile",
-        help=(
-            "If a bed file with Primers is specified, the Primers "
-            "will be soft-clipped from the bam file using iVar"
-        ),
-    )
+        '--removePrimersFromBedFile',
+        help=('If a bed file with Primers is specified, the Primers '
+              'will be soft-clipped from the bam file using iVar'))
 
     args = parser.parse_args()
 
     if args.indexBAM and not args.bam:
-        print(
-            "The --indexBAM option only makes sense if you do not use " "--noBAM.",
-            file=sys.stderr,
-        )
+        print('The --indexBAM option only makes sense if you do not use '
+              '--noBAM.', file=sys.stderr)
         sys.exit(1)
 
     e = Executor(args.dryRun)
 
     if args.tempdir is None:
-        args.tempdir = os.environ.get("TMPDIR", "/tmp")
+        args.tempdir = os.environ.get('TMPDIR', '/tmp')
 
     if args.ignoredIndices:
         ignoresDir = processIgnores(args, e)
 
     processMatch(args, e)
 
     if args.ignoredIndices:
         if args.clean:
             e.execute("rm -r '%s'" % ignoresDir)
         else:
-            print(
-                "Temporary directory with non-ignored inputs %r." % ignoresDir,
-                file=sys.stderr,
-            )
+            print('Temporary directory with non-ignored inputs %r.' %
+                  ignoresDir, file=sys.stderr)
 
     if args.dryRun or args.log:
-        print("\n".join(e.log), file=sys.stderr)
+        print('\n'.join(e.log), file=sys.stderr)
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     main()
```

### Comparing `dark-matter-4.0.84/bin/run-bwa.py` & `dark-matter-4.0.9/bin/run-bwa.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,139 +1,104 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import sys
 import argparse
 from os.path import exists, basename
 
 from dark.process import Executor
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description=(
-        "Run bwa on a FASTA file. Optionally convert the result to "
-        "BAM, sorting, and indexing."
-    ),
-)
+    description=('Run bwa on a FASTA file. Optionally convert the result to '
+                 'BAM, sorting, and indexing.'))
 
 parser.add_argument(
-    "--bwaIndex",
-    required=True,
-    help="The name of the BWA index (created with bwa index).",
-)
+    '--bwaIndex', required=True,
+    help='The name of the BWA index (created with bwa index).')
 
 parser.add_argument(
-    "--bwaArgs", default="mem", help="All arguments to be passed to BWA."
-)
+    '--bwaArgs', default='mem',
+    help='All arguments to be passed to BWA.')
 
 parser.add_argument(
-    "--fastaFile",
-    required=True,
-    help=(
-        "The name of the FASTA file whose sequences should be aligned with "
-        "the BWA index."
-    ),
-)
+    '--fastaFile', required=True,
+    help=('The name of the FASTA file whose sequences should be aligned with '
+          'the BWA index.'))
 
 parser.add_argument(
-    "--base",
-    help=(
-        "The base name of files to create. Suffixes such as .sam and .bam "
-        "will be added. If not given, the basename of the --fastaFile name "
-        "will be used, stripped of its final suffix."
-    ),
-)
+    '--base',
+    help=('The base name of files to create. Suffixes such as .sam and .bam '
+          'will be added. If not given, the basename of the --fastaFile name '
+          'will be used, stripped of its final suffix.'))
 
 parser.add_argument(
-    "--verbose",
-    default=False,
-    action="store_true",
-    help="If specified, show the commands that were (or would be) executed.",
-)
+    '--verbose', default=False, action='store_true',
+    help='If specified, show the commands that were (or would be) executed.')
 
 parser.add_argument(
-    "--noBAM",
-    default=False,
-    action="store_true",
-    help="If specified, do not convert SAM to BAM.",
-)
+    '--noBAM', default=False, action='store_true',
+    help='If specified, do not convert SAM to BAM.')
 
 parser.add_argument(
-    "--noSort",
-    default=False,
-    action="store_true",
-    help="If specified, do not sort the BAM.",
-)
+    '--noSort', default=False, action='store_true',
+    help='If specified, do not sort the BAM.')
 
 parser.add_argument(
-    "--noIndex",
-    default=False,
-    action="store_true",
-    help="If specified, do not index the sorted BAM.",
-)
+    '--noIndex', default=False, action='store_true',
+    help='If specified, do not index the sorted BAM.')
 
 parser.add_argument(
-    "--noClean",
-    default=False,
-    action="store_true",
-    help="If specified, do not remove intermediate .sam and .bam files.",
-)
+    '--noClean', default=False, action='store_true',
+    help='If specified, do not remove intermediate .sam and .bam files.')
 
 parser.add_argument(
-    "--force",
-    default=False,
-    action="store_true",
-    help="If specified, overwrite pre-existing output files.",
-)
+    '--force', default=False, action='store_true',
+    help='If specified, overwrite pre-existing output files.')
 
 parser.add_argument(
-    "--dryRun",
-    default=False,
-    action="store_true",
-    help="If specified, do not run commands, just print what would be done.",
-)
+    '--dryRun', default=False, action='store_true',
+    help='If specified, do not run commands, just print what would be done.')
 
 args = parser.parse_args()
 
 if args.base is None:
-    fields = basename(args.fastaFile).rsplit(".", 1)
+    fields = basename(args.fastaFile).rsplit('.', 1)
     if len(fields) < 2:
-        print(
-            "No --base argument was given and the --fastaFile argument "
-            "does not have a .suffix that can be stripped.",
-            file=sys.stderr,
-        )
+        print('No --base argument was given and the --fastaFile argument '
+              'does not have a .suffix that can be stripped.',
+              file=sys.stderr)
         sys.exit(1)
     base = fields[0]
 else:
     base = args.base
 
 
-samFile = base + ".sam"
-bamFile = base + ".bam"
-sortedBamFile = base + "-sorted.bam"
+samFile = base + '.sam'
+bamFile = base + '.bam'
+sortedBamFile = base + '-sorted.bam'
 
 if not (args.force or args.dryRun):
     existing = []
     for filename in samFile, bamFile, sortedBamFile:
         if exists(filename):
             existing.append(filename)
     if existing:
-        print(
-            "Will not overwrite pre-existing file%s %s. "
-            "Use --force to make me."
-            % ("" if len(existing) == 1 else "s", ", ".join(existing)),
-            file=sys.stderr,
-        )
+        print('Will not overwrite pre-existing file%s %s. '
+              'Use --force to make me.' % (
+                  '' if len(existing) == 1 else 's',
+                  ', '.join(existing)),
+              file=sys.stderr)
         sys.exit(2)
 
 e = Executor(args.dryRun)
 
-e.execute(
-    "bwa %s '%s' '%s' > '%s'" % (args.bwaArgs, args.bwaIndex, args.fastaFile, samFile)
-)
+e.execute("bwa %s '%s' '%s' > '%s'" % (
+    args.bwaArgs, args.bwaIndex, args.fastaFile, samFile))
 
 if not args.noBAM:
     e.execute("samtools view -b < '%s' > '%s'" % (samFile, bamFile))
 
     if not args.noClean:
         e.execute("rm '%s'" % samFile)
 
@@ -143,8 +108,8 @@
         if not args.noClean:
             e.execute("rm '%s'" % bamFile)
 
         if not args.noIndex:
             e.execute("samtools index '%s'" % sortedBamFile)
 
 if args.dryRun or args.verbose:
-    print("\n".join(e.log))
+    print('\n'.join(e.log))
```

### Comparing `dark-matter-4.0.84/bin/sam-coverage.py` & `dark-matter-4.0.9/bin/sam-coverage.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,53 +1,43 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 import argparse
 from collections import defaultdict, Counter
 
 from dark.filter import (
-    addFASTAFilteringCommandLineOptions,
-    parseFASTAFilteringCommandLineOptions,
-)
+    addFASTAFilteringCommandLineOptions, parseFASTAFilteringCommandLineOptions)
 from dark.reads import Reads
 from dark.sam import samfile, SAMFilter
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description="Print SAM/BAM file coverage statistics.",
-)
+    description='Print SAM/BAM file coverage statistics.')
 
 parser.add_argument(
-    "--noFilter",
-    default=False,
-    action="store_true",
-    help=(
-        "Do not use our SAM filtering. Note that if you give this option, "
-        "any filtering option (other than --referenceId) you also specify "
-        "that is provided by the SAMFilter.addFilteringOptions will be "
-        "silently ignored!"
-    ),
-)
+    '--noFilter', default=False, action='store_true',
+    help=('Do not use our SAM filtering. Note that if you give this option, '
+          'any filtering option (other than --referenceId) you also specify '
+          'that is provided by the SAMFilter.addFilteringOptions will be '
+          'silently ignored!'))
 
 addFASTAFilteringCommandLineOptions(parser)
 SAMFilter.addFilteringOptions(parser, samfileIsPositional=True)
 
 args = parser.parse_args()
 
 if args.noFilter:
     # Do not do our custom SAM filtering.
     def filterRead(read):
         return True
-
 else:
-
     def filterRead(read):
-        return not (read.is_del or read.is_refskip) and samFilter.filterAlignment(
-            read.alignment
-        )
-
+        return (not (read.is_del or read.is_refskip) and
+                samFilter.filterAlignment(read.alignment))
 
 # We don't have a file of reads, we just want a read filter that we can use
 # to filter the SAM file query sequences and to get reference lengths from.
 reads = parseFASTAFilteringCommandLineOptions(args, Reads())
 samFilter = SAMFilter.parseFilteringOptions(args, reads.filterRead)
 
 coveredOffsets = defaultdict(Counter)
@@ -63,21 +53,14 @@
                 coveringReads[referenceId].add(read.alignment.query_name)
 
 referenceLengths = samFilter.referenceLengths()
 
 for referenceId in sorted(referenceLengths):
     offsetsCovered = len(coveredOffsets[referenceId])
     referenceLength = referenceLengths[referenceId]
-    print(
-        "%s: length %d, covering reads %d, covered sites %d (%.4f%%), "
-        "mean coverage depth %.4f (min: %d, max: %d)"
-        % (
-            referenceId,
-            referenceLength,
-            len(coveringReads[referenceId]),
-            offsetsCovered,
-            offsetsCovered / referenceLength * 100.0,
-            sum(coveredOffsets[referenceId].values()) / referenceLength,
-            min(coveredOffsets[referenceId].values(), default=0),
-            max(coveredOffsets[referenceId].values(), default=0),
-        )
-    )
+    print('%s: length %d, covering reads %d, covered sites %d (%.4f%%), '
+          'mean coverage depth %.4f (min: %d, max: %d)' %
+          (referenceId, referenceLength, len(coveringReads[referenceId]),
+           offsetsCovered, offsetsCovered / referenceLength * 100.0,
+           sum(coveredOffsets[referenceId].values()) / referenceLength,
+           min(coveredOffsets[referenceId].values(), default=0),
+           max(coveredOffsets[referenceId].values(), default=0)))
```

### Comparing `dark-matter-4.0.84/bin/sam-to-fasta-alignment.py` & `dark-matter-4.0.9/bin/sam-to-fasta-alignment.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,91 +1,76 @@
 #!/usr/bin/env python
 
 """
 Extract aligned (i.e., padded) queries in FASTA format from a SAM/BAM file.
 """
 
+from __future__ import division, print_function
+
 import sys
 import argparse
 
 from dark.filter import (
-    addFASTAFilteringCommandLineOptions,
-    parseFASTAFilteringCommandLineOptions,
-)
+    addFASTAFilteringCommandLineOptions, parseFASTAFilteringCommandLineOptions)
 from dark.reads import Reads
 from dark.sam import SAMFilter, PaddedSAM
 from dark.utils import nucleotidesToStr
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description="Produce aligned FASTA queries from a SAM/BAM file.",
-)
+    description='Produce aligned FASTA queries from a SAM/BAM file.')
 
 parser.add_argument(
-    "--rcSuffix",
-    default="",
-    help=(
-        "A string to add to the end of query names that are reverse "
-        "complemented. This is added before the /1, /2, etc., that are "
-        "added for duplicated ids (if there are duplicates and "
-        "--allowDuplicateIds is not used)"
-    ),
-)
+    '--rcSuffix', default='',
+    help=('A string to add to the end of query names that are reverse '
+          'complemented. This is added before the /1, /2, etc., that are '
+          'added for duplicated ids (if there are duplicates and '
+          '--allowDuplicateIds is not used)'))
 
 parser.add_argument(
-    "--rcNeeded",
-    default=False,
-    action="store_true",
-    help=(
-        "If given, queries that are flagged as matching when reverse "
-        "complemented will be reverse complemented in the output. This "
-        "must be used if the program that created the SAM/BAM input "
-        "flags reversed matches but does not also store the reverse "
-        "complemented query. The bwa program (mem and aln followed by "
-        "samse) stores the queries reversed complemented if the match "
-        "was, so this option is not needed for bwa. If in doubt, test the "
-        "output of your matching program as this is very important!"
-    ),
-)
+    '--rcNeeded', default=False, action='store_true',
+    help=('If given, queries that are flagged as matching when reverse '
+          'complemented will be reverse complemented in the output. This '
+          'must be used if the program that created the SAM/BAM input '
+          'flags reversed matches but does not also store the reverse '
+          'complemented query. The bwa program (mem and aln followed by '
+          'samse) stores the queries reversed complemented if the match '
+          'was, so this option is not needed for bwa. If in doubt, test the '
+          'output of your matching program as this is very important!'))
 
 parser.add_argument(
-    "--listReferenceInsertions",
-    default=False,
-    action="store_true",
-    help=(
-        "If given, information about reference sequence insertions will be "
-        'printed to standard error. These correspond to "I" CIGAR '
-        "operations that for the match would require inserting query bases "
-        "into the reference. Because we cannot change the reference (in "
-        "fact we typically do not have the reference in the SAM/BAM file), "
-        "we cut the inserted bases out of the aligned query and save the "
-        "information about what would have been inserted and where. That "
-        "information is printed by this option. The output gives the "
-        "0-based offset where the inserted base would be placed, followed "
-        "by a list of the nucleotides that were suggested as being "
-        "inserted and the number of times each nucleotide was suggested. "
-        'So for example the output might contain "27: T:3, G:10" which '
-        "indicates that 13 query (3 with T and 10 with G) matches would "
-        "insert a nucleotide into the reference at offset 27."
-    ),
-)
+    '--listReferenceInsertions', default=False, action='store_true',
+    help=('If given, information about reference sequence insertions will be '
+          'printed to standard error. These correspond to "I" CIGAR '
+          'operations that for the match would require inserting query bases '
+          'into the reference. Because we cannot change the reference (in '
+          'fact we typically do not have the reference in the SAM/BAM file), '
+          'we cut the inserted bases out of the aligned query and save the '
+          'information about what would have been inserted and where. That '
+          'information is printed by this option. The output gives the '
+          '0-based offset where the inserted base would be placed, followed '
+          'by a list of the nucleotides that were suggested as being '
+          'inserted and the number of times each nucleotide was suggested. '
+          'So for example the output might contain "27: T:3, G:10" which '
+          'indicates that 13 query (3 with T and 10 with G) matches would '
+          'insert a nucleotide into the reference at offset 27.'))
 
 SAMFilter.addFilteringOptions(parser)
 addFASTAFilteringCommandLineOptions(parser)
 
 args = parser.parse_args()
 reads = parseFASTAFilteringCommandLineOptions(args, Reads())
-samFilter = SAMFilter.parseFilteringOptions(args, filterRead=reads.filterRead)
+samFilter = SAMFilter.parseFilteringOptions(
+    args, filterRead=reads.filterRead)
 paddedSAM = PaddedSAM(samFilter)
 
 for read in paddedSAM.queries(rcSuffix=args.rcSuffix, rcNeeded=args.rcNeeded):
-    print(read.toString("fasta"), end="")
+    print(read.toString('fasta'), end='')
 
 if args.listReferenceInsertions:
     if paddedSAM.referenceInsertions:
-        print(
-            "(0-based) insertions into the reference:\n%s"
-            % nucleotidesToStr(paddedSAM.referenceInsertions, "  "),
-            file=sys.stderr,
-        )
+        print('(0-based) insertions into the reference:\n%s' %
+              nucleotidesToStr(paddedSAM.referenceInsertions, '  '),
+              file=sys.stderr)
     else:
-        print("No matches required an insertion into the reference.", file=sys.stderr)
+        print('No matches required an insertion into the reference.',
+              file=sys.stderr)
```

### Comparing `dark-matter-4.0.84/bin/split-fasta-by-adaptors.py` & `dark-matter-4.0.9/bin/split-fasta-by-adaptors.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,28 +1,23 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 from Bio import SeqIO
 from collections import defaultdict
 import sys
 from dark.distance import levenshtein
 from math import log10, ceil
 
 # The name of the unknown adaptor.
-UNKNOWN = "UNKNOWN"
+UNKNOWN = 'UNKNOWN'
 
 
-def splitFASTAByAdaptor(
-    knownAdaptors,
-    adaptorLen,
-    adaptorOffset,
-    maximumDistance,
-    outputPrefix,
-    dryRun,
-    verbose,
-):
+def splitFASTAByAdaptor(knownAdaptors, adaptorLen, adaptorOffset,
+                        maximumDistance, outputPrefix, dryRun, verbose):
     """
     @param knownAdaptors: A C{set} of expected adaptor sequences.
     @param adaptorLen: The C{int} length of each adaptor sequence.
     @param adaptorOffset: The zero-based C{int} offset of the adaptor in
         each sequence.
     @param maximumDistance: The maximum distance an unknown adaptor will be
         mapped to in an attempt to find its nearest known adaptor.
@@ -34,162 +29,120 @@
         adaptor classes found and assigned.
     """
     adaptors = defaultdict(int)
     unknowns = 0
     classes = dict(zip(knownAdaptors, knownAdaptors))
     reads = []
 
-    for count, seq in enumerate(SeqIO.parse(sys.stdin, "fasta"), start=1):
+    for count, seq in enumerate(SeqIO.parse(sys.stdin, 'fasta'), start=1):
         reads.append(seq)
         adaptor = str(seq.seq)[adaptorOffset:][:adaptorLen].upper()
         adaptors[adaptor] += 1
 
-    order = sorted(adaptors, key=lambda adaptor: adaptors[adaptor], reverse=True)
+    order = sorted(adaptors, key=lambda adaptor: adaptors[adaptor],
+                   reverse=True)
 
     for adaptor in order:
         if adaptor in knownAdaptors:
             if verbose:
-                print("%s: %s. Known adaptor" % (adaptor, adaptors[adaptor]))
+                print('%s: %s. Known adaptor' % (adaptor, adaptors[adaptor]))
         else:
-            distances = sorted(
-                (levenshtein(adaptor, known), known) for known in knownAdaptors
-            )
+            distances = sorted((levenshtein(adaptor, known), known) for
+                               known in knownAdaptors)
             # Treat the read as unclassifiable if it's too far from its
             # nearest neighbor or if its nearest neighbor is ambiguous.
             nearest = distances[0][0]
-            if nearest > maximumDistance or (
-                len(knownAdaptors) > 1 and nearest == distances[1][0]
-            ):
+            if nearest > maximumDistance or (len(knownAdaptors) > 1 and
+                                             nearest == distances[1][0]):
                 unknowns += 1
                 classes[adaptor] = UNKNOWN
                 if verbose:
-                    print(
-                        "%s: %s. Unknown, distances %r"
-                        % (adaptor, adaptors[adaptor], [d[0] for d in distances])
-                    )
+                    print('%s: %s. Unknown, distances %r' % (
+                        adaptor, adaptors[adaptor], [d[0] for d in distances]))
             else:
                 correctedAdaptor = distances[0][1]
                 classes[adaptor] = correctedAdaptor
                 if verbose:
-                    print(
-                        "%s: %s. Assigned to class %s, at dist %d"
-                        % (
-                            adaptor,
-                            adaptors[adaptor],
-                            correctedAdaptor,
-                            distances[0][0],
-                        )
-                    )
+                    print('%s: %s. Assigned to class %s, at dist %d' % (
+                        adaptor, adaptors[adaptor], correctedAdaptor,
+                        distances[0][0]))
 
     readGroups = defaultdict(list)
 
     # Collect reads into classes.
     for read in reads:
         adaptor = str(read.seq)[adaptorOffset:][:adaptorLen].upper()
-        readGroups[classes[adaptor]].append(read[adaptorOffset + adaptorLen :])
+        readGroups[classes[adaptor]].append(read[adaptorOffset + adaptorLen:])
 
     # Calculate the number of digits in the size of the biggest read group
     # so we can nicely align the output.
     width = int(ceil(log10(max(len(group) for group in readGroups.values()))))
 
     # The width of the count of files we'll write, so file names have zero
     # padded numeric prefixes.
     filesWidth = int(ceil(log10(len(readGroups))))
 
     # Write out the FASTA files for each adaptor class (this includes the
     # unclassifiable reads if any unknown adaptors were found).
     for count, adaptor in enumerate(sorted(readGroups), start=1):
         reads = readGroups[adaptor]
-        filename = "%s%0*d-%s.fasta" % (outputPrefix, filesWidth, count, adaptor)
-        description = (
-            "unrecognized adaptors" if adaptor == UNKNOWN else "adaptor %s" % adaptor
-        )
+        filename = '%s%0*d-%s.fasta' % (outputPrefix, filesWidth, count,
+                                        adaptor)
+        description = ('unrecognized adaptors' if adaptor == UNKNOWN
+                       else 'adaptor %s' % adaptor)
         if dryRun:
-            print(
-                "Would write %*d sequences for %s to %s"
-                % (width, len(reads), description, filename)
-            )
+            print('Would write %*d sequences for %s to %s' % (
+                width, len(reads), description, filename))
         else:
-            with open(filename, "w") as fp:
-                SeqIO.write(reads, fp, "fasta")
-            print(
-                "Wrote %*d sequences for %s to %s"
-                % (width, len(reads), description, filename)
-            )
+            with open(filename, 'w') as fp:
+                SeqIO.write(reads, fp, 'fasta')
+            print('Wrote %*d sequences for %s to %s' % (
+                width, len(reads), description, filename))
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
-        description=(
-            "From a set of known adaptors and a FASTA on stdin, "
-            "write FASTA files split by adaptor"
-        )
-    )
-
-    parser.add_argument(
-        "adaptors",
-        nargs="+",
-        metavar="adaptor",
-        help="the set of adaptors that were used in sequencing",
-    )
-
-    parser.add_argument(
-        "--adaptor-offset",
-        metavar="N",
-        type=int,
-        default=0,
-        dest="adaptorOffset",
-        help="the offset of the adaptor in each sequence",
-    )
-
-    parser.add_argument(
-        "--maximum-distance",
-        metavar="dist",
-        type=int,
-        default=2,
-        dest="maximumDistance",
-        help="The maximum distance an unknown adaptor will be "
-        "mapped to in an attempt to find its nearest known adaptor.",
-    )
-
-    parser.add_argument(
-        "--outputPrefix",
-        metavar="prefix",
-        default="MID-",
-        help="the prefix to use for newly created FASTA files",
-    )
-
-    parser.add_argument(
-        "--dry-run",
-        type=bool,
-        default=False,
-        dest="dryRun",
-        help="If True, do not write new FASTA files, just show what would be " "done",
-    )
-
-    parser.add_argument(
-        "--verbose",
-        type=bool,
-        default=False,
-        help="If True, print information about adaptor classes",
-    )
+        description=('From a set of known adaptors and a FASTA on stdin, '
+                     'write FASTA files split by adaptor'))
+
+    parser.add_argument(
+        'adaptors', nargs='+', metavar='adaptor',
+        help='the set of adaptors that were used in sequencing')
+
+    parser.add_argument(
+        '--adaptor-offset', metavar='N',
+        type=int, default=0, dest='adaptorOffset',
+        help='the offset of the adaptor in each sequence')
+
+    parser.add_argument(
+        '--maximum-distance', metavar='dist',
+        type=int, default=2, dest='maximumDistance',
+        help='The maximum distance an unknown adaptor will be '
+             'mapped to in an attempt to find its nearest known adaptor.')
+
+    parser.add_argument(
+        '--outputPrefix', metavar='prefix', default='MID-',
+        help='the prefix to use for newly created FASTA files')
+
+    parser.add_argument(
+        '--dry-run', type=bool, default=False, dest='dryRun',
+        help='If True, do not write new FASTA files, just show what would be '
+        'done')
+
+    parser.add_argument(
+        '--verbose', type=bool, default=False,
+        help='If True, print information about adaptor classes')
 
     args = parser.parse_args()
     adaptorLen = len(args.adaptors[0])
     adaptors = set(args.adaptors)
 
     # Check all adaptors are the same length.
     if any((len(adaptor) != adaptorLen) for adaptor in adaptors):
-        print("All adaptors must be the same length.", file=sys.stderr)
+        print('All adaptors must be the same length.', file=sys.stderr)
         sys.exit(1)
 
-    splitFASTAByAdaptor(
-        adaptors,
-        adaptorLen,
-        args.adaptorOffset,
-        args.maximumDistance,
-        args.outputPrefix,
-        args.dryRun,
-        args.verbose,
-    )
+    splitFASTAByAdaptor(adaptors, adaptorLen, args.adaptorOffset,
+                        args.maximumDistance, args.outputPrefix, args.dryRun,
+                        args.verbose)
```

### Comparing `dark-matter-4.0.84/bin/subset-protein-database.py` & `dark-matter-4.0.9/bin/subset-protein-database.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,75 +1,58 @@
 #!/usr/bin/env python
 
+from __future__ import print_function, division
+
 import argparse
 
 from dark.proteins import SqliteIndex
 
 
 parser = argparse.ArgumentParser(
     formatter_class=argparse.ArgumentDefaultsHelpFormatter,
-    description=(
-        "Query an sqlite3 protein/genome database and write "
-        "the matching sequences to standard output as FASTA."
-    ),
-)
+    description=('Query an sqlite3 protein/genome database and write '
+                 'the matching sequences to standard output as FASTA.'))
 
 parser.add_argument(
-    "--databaseFile",
-    required=True,
-    help=(
-        "The protein/genome database file. This must be an sqlite3 database "
-        "file created by make-protein-database.py"
-    ),
-)
+    '--databaseFile', required=True,
+    help=('The protein/genome database file. This must be an sqlite3 database '
+          'file created by make-protein-database.py'))
 
 parser.add_argument(
-    "--query",
-    help=(
-        "An SQL database query. "
-        "The query must result in rows with two columns, the sequence id "
-        "and the sequence. These can be protein or nucleotide sequences, "
-        "but it is probably better not to mix them!"
-    ),
-)
+    '--query',
+    help=('An SQL database query. '
+          'The query must result in rows with two columns, the sequence id '
+          'and the sequence. These can be protein or nucleotide sequences, '
+          'but it is probably better not to mix them!'))
 
 parser.add_argument(
-    "--queryFile",
-    help=(
-        "The name of a file containing an SQL database query. "
-        "The query must result in rows with two columns, the sequence id "
-        "and the sequence. These can be protein or nucleotide sequences, "
-        "but it is probably better not to mix them!"
-    ),
-)
+    '--queryFile',
+    help=('The name of a file containing an SQL database query. '
+          'The query must result in rows with two columns, the sequence id '
+          'and the sequence. These can be protein or nucleotide sequences, '
+          'but it is probably better not to mix them!'))
 
 parser.add_argument(
-    "--keepDuplicateIds",
-    default=False,
-    action="store_true",
-    help="If specified, do not remove duplicate ids.",
-)
+    '--keepDuplicateIds', default=False, action='store_true',
+    help='If specified, do not remove duplicate ids.')
 
 parser.add_argument(
-    "--idsOnly",
-    default=False,
-    action="store_true",
-    help="If specified, only print matching sequence ids.",
-)
+    '--idsOnly', default=False, action='store_true',
+    help='If specified, only print matching sequence ids.')
 
 args = parser.parse_args()
 
 db = SqliteIndex(args.databaseFile)
 
 if args.queryFile:
     query = open(args.queryFile).read()
 elif args.query:
     query = args.query
 else:
-    raise RuntimeError("You must use either --query or --queryFile")
+    raise RuntimeError('You must use either --query or --queryFile')
 
 cur = db.execute(query)
 
 removeDuplicates = not args.keepDuplicateIds
 idsOnly = args.idsOnly
 
 if removeDuplicates:
@@ -80,20 +63,20 @@
     if rows:
         for row in rows:
             try:
                 id_, sequence, genomeName = row
             except ValueError:
                 id_, sequence = row
             else:
-                id_ = "%s [%s]" % (id_, genomeName)
+                id_ = '%s [%s]' % (id_, genomeName)
 
             if removeDuplicates:
                 if id_ in seen:
                     continue
                 else:
                     seen.add(id_)
             if idsOnly:
                 print(id_)
             else:
-                print(">%s\n%s" % (id_, sequence))
+                print('>%s\n%s' % (id_, sequence))
     else:
         break
```

### Comparing `dark-matter-4.0.84/bin/summarize-fasta-bases.py` & `dark-matter-4.0.9/bin/summarize-fasta-bases.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,100 +1,84 @@
 #!/usr/bin/env python
 
+from __future__ import print_function
+
 from collections import defaultdict
 from math import log10
 
-from dark.aaVars import NAMES
+from dark.aa import NAMES
 from dark.reads import addFASTACommandLineOptions, parseFASTACommandLineOptions
 from dark.summarize import sequenceCategoryLengths
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
-        description=(
-            "Given FASTA on stdin, write a summary of sequence base "
-            "categories to stdout. It is currently not possible to "
-            "specify the categories on the command line."
-        )
-    )
+        description=('Given FASTA on stdin, write a summary of sequence base '
+                     'categories to stdout. It is currently not possible to '
+                     'specify the categories on the command line.'))
 
     parser.add_argument(
-        "--baseType",
-        default="nucl",
-        choices=("nucl", "prot"),
-        help="The type of the bases in the input.",
-    )
+        '--baseType', default='nucl', choices=('nucl', 'prot'),
+        help='The type of the bases in the input.')
 
     parser.add_argument(
-        "--minLength",
-        default=1,
-        type=int,
-        help=(
-            "If specified, stretches of reads that are less than this "
-            "length will not be reported but will be summarized by an "
-            "ellipsis."
-        ),
-    )
+        '--minLength', default=1, type=int,
+        help=('If specified, stretches of reads that are less than this '
+              'length will not be reported but will be summarized by an '
+              'ellipsis.'))
 
     parser.add_argument(
-        "--concise",
-        action="store_true",
-        default=False,
-        help="If specified, do not show the individual sequence regions.",
-    )
+        '--concise', action='store_true', default=False,
+        help='If specified, do not show the individual sequence regions.')
 
     addFASTACommandLineOptions(parser)
     args = parser.parse_args()
     reads = parseFASTACommandLineOptions(args)
 
-    if args.baseType == "nucl":
+    if args.baseType == 'nucl':
         categories = {
-            "A": "nucl",
-            "C": "nucl",
-            "G": "nucl",
-            "T": "nucl",
-            "-": "gap",
+            'A': 'nucl',
+            'C': 'nucl',
+            'G': 'nucl',
+            'T': 'nucl',
+            '-': 'gap',
         }
-        default = "ambiguous"
+        default = 'ambiguous'
     else:
         categories = {}
         for name in NAMES:
-            categories[name] = "aa"
-        categories["-"] = "gap"
-        default = "ambiguous"
+            categories[name] = 'aa'
+        categories['-'] = 'gap'
+        default = 'ambiguous'
 
     categoryWidth = max(
-        [len(category) for category in categories.values()] + [len(default)]
-    )
+        [len(category) for category in categories.values()] + [len(default)])
 
     minLength = args.minLength
     concise = args.concise
 
     for index, read in enumerate(reads, start=1):
-        counts: dict[str, int] = defaultdict(int)
+        counts = defaultdict(int)
         readLen = len(read)
         width = int(log10(readLen)) + 1
         if not concise:
-            summary: list[str] = []
+            summary = []
             append = summary.append
             offset = 1
-        for category, count in sequenceCategoryLengths(
-            read, categories, defaultCategory=default, minLength=minLength
-        ):
+        for (category, count) in sequenceCategoryLengths(
+                read, categories, defaultCategory=default,
+                minLength=minLength):
             counts[category] += count
             if not concise:
-                append(
-                    "    %*d %-*s (offset %*d)"
-                    % (width, count, categoryWidth, category, width, offset)
-                )
+                append('    %*d %-*s (offset %*d)' %
+                       (width, count, categoryWidth, category, width, offset))
                 offset += count
-        print("%d: %s (length %d)" % (index, read.id, readLen))
+        print('%d: %s (length %d)' % (index, read.id, readLen))
         for category in sorted(counts):
             count = counts[category]
-            print(
-                "  %-*s: %*d (%6.2f%%)"
-                % (categoryWidth, category, width, count, count / readLen * 100.0)
-            )
+            print('  %-*s: %*d (%6.2f%%)' %
+                  (categoryWidth, category, width, count,
+                   count / readLen * 100.0))
         if not concise:
-            print("\n".join(summary))
+            print('\n'.join(summary))
```

### Comparing `dark-matter-4.0.84/bin/write-htcondor-job-spec.py` & `dark-matter-4.0.9/bin/write-htcondor-job-spec.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,23 +1,25 @@
 #!/usr/bin/env python
 
 """
 See the 'EPILOG' variable below, or (better) run with --help for help.
 """
 
+from __future__ import print_function
+
 import os
 import sys
 from Bio import SeqIO
 
-DEFAULT_BLAST_ARGS = ""
-DEFAULT_BLAST_DB = "nt"
-DEFAULT_BLAST_DB_DIR = "/usr/local/dark-matter/blast-dbs"
-DEFAULT_EMAIL = "tcj25@cam.ac.uk"
-DEFAULT_BLAST_EXECUTABLE_DIR = "/usr/local/dark-matter/blast/bin"
-DEFAULT_BLAST_EXECUTABLE_NAME = "blastn"
+DEFAULT_BLAST_ARGS = ''
+DEFAULT_BLAST_DB = 'nt'
+DEFAULT_BLAST_DB_DIR = '/usr/local/dark-matter/blast-dbs'
+DEFAULT_EMAIL = 'tcj25@cam.ac.uk'
+DEFAULT_BLAST_EXECUTABLE_DIR = '/usr/local/dark-matter/blast/bin'
+DEFAULT_BLAST_EXECUTABLE_NAME = 'blastn'
 DEFAULT_SEQUENCES_PER_BLAST = 100
 
 EPILOG = """Given a FASTA file argument, write out the following:
 
   1) Files named 0.fasta, 1.fasta, 2.fasta, etc. each containing a maximum
      number of sequences (given by --seqs-per-blast).
 
@@ -41,43 +43,42 @@
 
 def splitFASTA(params):
     """
     Read the FASTA file named params['fastaFile'] and print out its
     sequences into files named 0.fasta, 1.fasta, etc. with
     params['seqsPerJob'] sequences per file.
     """
-    assert params["fastaFile"][-1] == "a", (
-        "You must specify a file in " "fasta-format that ends in " ".fasta"
-    )
+    assert params['fastaFile'][-1] == 'a', ('You must specify a file in '
+                                            'fasta-format that ends in '
+                                            '.fasta')
 
     fileCount = count = seqCount = 0
     outfp = None
-    with open(params["fastaFile"]) as infp:
-        for seq in SeqIO.parse(infp, "fasta"):
+    with open(params['fastaFile']) as infp:
+        for seq in SeqIO.parse(infp, 'fasta'):
             seqCount += 1
-            if count == params["seqsPerJob"]:
+            if count == params['seqsPerJob']:
                 outfp.close()
                 count = 0
             if count == 0:
-                outfp = open("%d.fasta" % fileCount, "w")
+                outfp = open('%d.fasta' % fileCount, 'w')
                 fileCount += 1
             count += 1
-            outfp.write(">%s\n%s\n" % (seq.description, str(seq.seq)))
+            outfp.write('>%s\n%s\n' % (seq.description, str(seq.seq)))
     outfp.close()
     return fileCount, seqCount
 
 
 def printJobSpec(params):
     """
     Write out a job spec file for HTCondor to process all the small
     FASTA input files via BLAST and our JSON post-processor.
     """
-    with open("job.htcondor", "w") as outfp:
-        outfp.write(
-            """\
+    with open('job.htcondor', 'w') as outfp:
+        outfp.write("""\
 universe                  = vanilla
 executable                = process.sh
 should_transfer_files     = YES
 when_to_transfer_output   = ON_EXIT
 notify_user               = %(email)s
 max_transfer_input_mb     = -1
 max_transfer_output_mb    = -1
@@ -92,28 +93,25 @@
 input                     = $(Process).fasta
 output                    = $(Process).done
 error                     = $(Process).error
 dont_encrypt_input_files  = $(Process).fasta
 dont_encrypt_output_files = $(Process).json.bz2
 
 queue %(nJobs)d
-"""
-            % params
-        )
+""" % params)
 
 
 def printRedoScript(params):
     """
     Write out a shell script that writes a job spec file for HTCondor to
     process a single FASTA input file via BLAST and our JSON post-processor,
     runs that job, and removes the one-time spec file it wrote.
     """
-    with open("redo.sh", "w") as outfp:
-        outfp.write(
-            """\
+    with open('redo.sh', 'w') as outfp:
+        outfp.write("""\
 #!/bin/sh -e
 
 case $# in
     0) echo "Usage: `basename $0` jobid1, jobid2, ..." >&2; exit 1;;
 esac
 
 tmp=redo.tmp.$$
@@ -145,30 +143,27 @@
 
     rm -f $jobid.json.bz2 $jobid.error $jobid.done
 done
 
 rm -f job.log
 
 condor_submit $tmp
-"""
-            % params
-        )
+""" % params)
 
     # Make the script executable so we can run it.
-    os.chmod("redo.sh", 0o755)
+    os.chmod('redo.sh', 0o755)
 
 
 def printProcessScript(params):
     """
     Write out a simple process script to call BLAST and convert its XML to
     our compressed JSON format.
     """
-    with open("process.sh", "w") as outfp:
-        outfp.write(
-            """\
+    with open('process.sh', 'w') as outfp:
+        outfp.write("""\
 #!/bin/sh
 
 DM=/usr/local/dark-matter
 export PYTHONPATH=$DM/dark-matter
 export BLASTDB="%(dbDir)s"
 
 jobid=$1
@@ -187,34 +182,31 @@
 if [ -s $errs ]
 then
     echo "Completed WITH ERRORS ($errs) on `hostname` at `date`." > $jobid.done
 else
     rm $errs
     echo "Completed on `hostname` at `date`." > $jobid.done
 fi
-"""
-            % params
-        )
+""" % params)
 
     # Make the script executable so we can run it.
-    os.chmod("process.sh", 0o755)
+    os.chmod('process.sh', 0o755)
 
 
 def printFinalizeScript(params):
     """
     Write out a script that post-processes any empty .json files that
     have non-empty .xml files, figures out which jobs should be re-run, and
     also removes zero-length error files.
 
     Note that we need bash in order to set the nullglob shell option. That
     prevents an error if there are no *.fasta files.
     """
-    with open("finalize.sh", "w") as outfp:
-        outfp.write(
-            """\
+    with open('finalize.sh', 'w') as outfp:
+        outfp.write("""\
 #!/usr/bin/env bash
 
 shopt -s nullglob
 
 # redo will hold the numbers of jobs that need re-running, if any.
 redo=
 
@@ -249,105 +241,76 @@
 done
 
 if [ -n "$redo" ]
 then
     echo "Some jobs must be re-run. Please execute the following:"
     echo "./redo.sh $redo"
 fi
-"""
-            % params
-        )
+""" % params)
 
     # Make the script executable so we can run it.
-    os.chmod("finalize.sh", 0o755)
+    os.chmod('finalize.sh', 0o755)
 
 
-if __name__ == "__main__":
+if __name__ == '__main__':
     import argparse
 
     parser = argparse.ArgumentParser(
-        description="Given a FASTA file, write an HTCondor job spec for BLAST",
-        epilog=EPILOG,
-    )
+        description='Given a FASTA file, write an HTCondor job spec for BLAST',
+        epilog=EPILOG)
     parser.add_argument(
-        "fasta", metavar="FASTA-file", help="the FASTA file of sequences to BLAST."
-    )
+        'fasta', metavar='FASTA-file',
+        help='the FASTA file of sequences to BLAST.')
     parser.add_argument(
-        "--seqs-per-blast",
-        metavar="N",
-        type=int,
-        default=DEFAULT_SEQUENCES_PER_BLAST,
-        dest="seqsPerJob",
-        help="the number (>0) of sequences to pass to BLAST on each run.",
-    )
+        '--seqs-per-blast', metavar='N',
+        type=int, default=DEFAULT_SEQUENCES_PER_BLAST, dest='seqsPerJob',
+        help='the number (>0) of sequences to pass to BLAST on each run.')
     parser.add_argument(
-        "--blast-db-name",
-        metavar="BLAST-database-name",
-        default=DEFAULT_BLAST_DB,
-        dest="db",
-        help="the BLAST database to run against.",
-    )
+        '--blast-db-name', metavar='BLAST-database-name',
+        default=DEFAULT_BLAST_DB, dest='db',
+        help='the BLAST database to run against.')
     parser.add_argument(
-        "--email",
-        metavar="name@host",
-        default=DEFAULT_EMAIL,
-        dest="email",
-        help="the email address to send the job completed message to.",
-    )
+        '--email', metavar='name@host',
+        default=DEFAULT_EMAIL, dest='email',
+        help='the email address to send the job completed message to.')
     parser.add_argument(
-        "--blast-executable-name",
-        metavar="BLAST-executable-name",
-        default=DEFAULT_BLAST_EXECUTABLE_NAME,
-        dest="executableName",
-        choices=["blastn", "blastp", "blastx", "tblastn", "tblastx"],
-        help="the name of the BLAST executable to run.",
-    )
+        '--blast-executable-name', metavar='BLAST-executable-name',
+        default=DEFAULT_BLAST_EXECUTABLE_NAME, dest='executableName',
+        choices=['blastn', 'blastp', 'blastx', 'tblastn', 'tblastx'],
+        help='the name of the BLAST executable to run.')
     parser.add_argument(
-        "--blast-executable-dir",
-        metavar="/path/to/BLAST/executables",
-        default=DEFAULT_BLAST_EXECUTABLE_DIR,
-        dest="executableDir",
-        help="the directories that hold the BLAST executables.",
-    )
+        '--blast-executable-dir', metavar='/path/to/BLAST/executables',
+        default=DEFAULT_BLAST_EXECUTABLE_DIR, dest='executableDir',
+        help='the directories that hold the BLAST executables.')
     parser.add_argument(
-        "--blast-db-dir",
-        metavar="/BLAST/db/directory",
-        default=DEFAULT_BLAST_DB_DIR,
-        dest="dbDir",
-        help="the directory where your BLAST database files live.",
-    )
+        '--blast-db-dir', metavar='/BLAST/db/directory',
+        default=DEFAULT_BLAST_DB_DIR, dest='dbDir',
+        help='the directory where your BLAST database files live.')
     parser.add_argument(
-        "--blast-args",
-        metavar="args...",
-        default=DEFAULT_BLAST_ARGS,
-        dest="blastArgs",
-        help='additional arguments to pass to BLAST (e.g., "--task blastn".',
-    )
+        '--blast-args', metavar='args...',
+        default=DEFAULT_BLAST_ARGS, dest='blastArgs',
+        help='additional arguments to pass to BLAST (e.g., "--task blastn".')
 
     args = parser.parse_args()
 
     if args.seqsPerJob < 1:
         parser.print_help()
         sys.exit(1)
 
     params = {
-        "blastArgs": args.blastArgs,
-        "db": args.db,
-        "dbDir": args.dbDir.rstrip("/"),
-        "email": args.email,
-        "executableName": args.executableName,
-        "executableDir": args.executableDir.rstrip("/"),
-        "fastaFile": args.fasta,
-        "seqsPerJob": args.seqsPerJob,
+        'blastArgs': args.blastArgs,
+        'db': args.db,
+        'dbDir': args.dbDir.rstrip('/'),
+        'email': args.email,
+        'executableName': args.executableName,
+        'executableDir': args.executableDir.rstrip('/'),
+        'fastaFile': args.fasta,
+        'seqsPerJob': args.seqsPerJob,
     }
-    params["nJobs"], params["sequenceCount"] = splitFASTA(params)
+    params['nJobs'], params['sequenceCount'] = splitFASTA(params)
     printJobSpec(params)
     printProcessScript(params)
     printRedoScript(params)
     printFinalizeScript(params)
 
-    print(
-        (
-            "%(sequenceCount)d sequences split into %(nJobs)d jobs of "
-            "%(seqsPerJob)d sequences each." % params
-        )
-    )
+    print(('%(sequenceCount)d sequences split into %(nJobs)d jobs of '
+           '%(seqsPerJob)d sequences each.' % params))
```

### Comparing `dark-matter-4.0.84/dark/aa.py` & `dark-matter-4.0.9/dark/dna.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,405 +1,174 @@
-from typing import Generator, Union, Iterable, Mapping, Optional
-from itertools import zip_longest
+from __future__ import division
 
-from dark.aaVars import (
-    ABBREV3,
-    ABBREV3_TO_ABBREV1,
-    CODONS,
-    NAMES,
-    NAMES_TO_ABBREV1,
-    PROPERTIES,
-    PROPERTY_CLUSTERS,
-    PROPERTY_DETAILS,
-)
+from collections import defaultdict
 
-from dark.reads import Read
 from dark.utils import countPrint
 
+try:
+    from itertools import zip_longest
+except ImportError:
+    # zip_longest does not exist in Python 2.7 itertools. We should be able
+    # to get it via from six.moves import zip_longest according to
+    # https://pythonhosted.org/six/index.html?highlight=zip_longest but
+    # that doesn't work for me.
+    from itertools import izip_longest as zip_longest
+
+# A list of the ambiguous values is given at
+# https://en.wikipedia.org/wiki/Nucleic_acid_notation
+AMBIGUOUS = {
+    'A': {'A'},
+    'C': {'C'},
+    'G': {'G'},
+    'T': {'T'},
+    'M': {'A', 'C'},
+    'R': {'A', 'G'},
+    'W': {'A', 'T'},
+    'S': {'G', 'C'},
+    'K': {'G', 'T'},
+    'Y': {'C', 'T'},
+    'V': {'A', 'C', 'G'},
+    'H': {'A', 'C', 'T'},
+    'D': {'A', 'G', 'T'},
+    'B': {'C', 'G', 'T'},
+    'N': {'A', 'C', 'G', 'T'},
+}
+
+# Make a reverse version of AMBIGUOUS.
+BASES_TO_AMBIGUOUS = dict(
+    (''.join(sorted(bases)), symbol) for symbol, bases in AMBIGUOUS.items())
 
-class AminoAcid:
-    """
-    Hold information about an amino acid.
-
-    @param name: The full C{str} name of the amino acid.
-    @param abbrev3: The 3-letter C{str} abbreviation of the amino acid,
-        e.g., 'Arg'.
-    @param abbrev1: The 1-letter C{str} abbreviation of the amino acid,
-        e.g., 'A'.
-    @param codons: A C{list} of 3-letter codons for the amino acid.
-    @param properties: An C{int} logical-AND of the various properties
-        (see PROPERTIES, above) of this amino acid.
-    @param propertyDetails: A C{dict} containing property names and values
-        for this amino acid. E.g.:
-        {
-            'aliphaticity': -0.157024793388,
-            'aromaticity': -0.0642673521851,
-            'composition': -0.527272727273,
-            'hydrogenation': -0.401797175866,
-            'hydropathy': -1.0,
-            'hydroxythiolation': -0.51486325802,
-            'iep': 1.0,
-            'polar requirement': 0.0487804878049,
-            'polarity': 0.382716049383,
-            'volume': 0.449101796407,
-        }
-    @param propertyClusters: A C{dict} containing the property names and
-        clusters for this amino acid. E.g.:
-        {
-            'aliphaticity': 1,
-            'aromaticity': 2,
-            'composition': 1,
-            'hydrogenation': 1,
-            'hydropathy': 2,
-            'hydroxythiolation': 4,
-            'iep': 2,
-            'polar requirement': 1,
-            'polarity': 1,
-            'volume': 4,
-        }
-    """
-
-    def __init__(
-        self,
-        name: str,
-        abbrev3: str,
-        abbrev1: str,
-        codons: tuple[str, ...],
-        properties: int,
-        propertyDetails: dict[str, float],
-        propertyClusters: dict[str, int],
-    ):
-        self.name = name
-        self.abbrev3 = abbrev3
-        self.abbrev1 = abbrev1
-        self.codons = codons
-        self.properties = properties
-        self.propertyDetails = propertyDetails
-        self.propertyClusters = propertyClusters
-
-
-def find(s: str) -> Generator[AminoAcid, None, None]:
-    """
-    Find an amino acid whose name or abbreviation is s.
-
-    @param s: A C{str} amino acid specifier. This may be a full name,
-        a 3-letter abbreviation or a 1-letter abbreviation. Case is ignored.
-    return: A generator that yields matching L{AminoAcid} instances.
-    """
-
-    abbrev1 = None
-    origS = s
-
-    if " " in s:
-        # Convert first word to title case, others to lower.
-        first, rest = s.split(" ", 1)
-        s = first.title() + " " + rest.lower()
-    else:
-        s = s.title()
-
-    if s in NAMES:
-        abbrev1 = s
-    elif s in ABBREV3_TO_ABBREV1:
-        abbrev1 = ABBREV3_TO_ABBREV1[s]
-    elif s in NAMES_TO_ABBREV1:
-        abbrev1 = NAMES_TO_ABBREV1[s]
-    else:
-        # Look for a 3-letter codon.
-        def findCodon(target):
-            for abbrev1, codons in CODONS.items():
-                for codon in codons:
-                    if codon == target:
-                        return abbrev1
-
-        # Allow for RNA in this lookup by replacing U with T.
-        abbrev1 = findCodon(origS.upper().replace("U", "T"))
-
-    if abbrev1:
-        abbrev1s = [abbrev1]
-    else:
-        # Try partial matching on names.
-        abbrev1s = []
-        sLower = s.lower()
-        for abbrev1, name in NAMES.items():
-            if name.lower().find(sLower) > -1:
-                abbrev1s.append(abbrev1)
-
-    for abbrev1 in abbrev1s:
-        yield AminoAcid(
-            NAMES[abbrev1],
-            ABBREV3[abbrev1],
-            abbrev1,
-            CODONS[abbrev1],
-            PROPERTIES[abbrev1],
-            PROPERTY_DETAILS[abbrev1],
-            PROPERTY_CLUSTERS[abbrev1],
-        )
-
-
-def _propertiesOrClustersForSequence(
-    sequence: Read,
-    propertyNames: Iterable[str],
-    propertyValues: Mapping[str, Mapping[str, Union[int, float]]],
-    missingAAValue: Union[int, float],
-) -> dict[str, list[Union[int, float]]]:
-    """
-    Extract amino acid property values or cluster numbers for a sequence.
-
-    @param sequence: An C{AARead} (or a subclass) instance.
-    @param propertyNames: An iterable of C{str} property names (each of which
-        must be a key of a key in the C{propertyValues} C{dict}).
-    @param propertyValues: A C{dict} in the form of C{PROPERTY_DETAILS} or
-        C{PROPERTY_CLUSTERS} (see above).
-    @param missingAAValue: A C{float} value to use for properties when an AA
-        (e.g., 'X') is not known.
-    @raise ValueError: If an unknown property is given in C{propertyNames}.
-    @return: A C{dict} keyed by (lowercase) property name, with values that are
-        C{list}s of the corresponding C{float} property value in C{propertyValues} in
-        order of sequence position.
-    """
-    propertyNames = sorted(map(str.lower, set(propertyNames)))
-
-    # Make sure all mentioned property names exist for at least one AA.
-    knownProperties: set[str] = set()
-    for names in propertyValues.values():
-        knownProperties.update(names)
-    unknown = set(propertyNames) - knownProperties
-    if unknown:
-        raise ValueError(
-            "Unknown propert%s: %s."
-            % ("y" if len(unknown) == 1 else "ies", ", ".join(unknown))
-        )
-
-    aas = sequence.sequence.upper()
-    result: dict[str, list[float]] = {}
-
-    for propertyName in propertyNames:
-        result[propertyName] = []
-        append = result[propertyName].append
-        for aa in aas:
-            try:
-                properties = propertyValues[aa]
-            except KeyError:
-                # No such AA.
-                append(missingAAValue)
-            else:
-                append(properties[propertyName])
-
-    return result
-
-
-def propertiesForSequence(
-    sequence: Read, propertyNames: Iterable[str], missingAAValue: float = -1.1
-):
-    """
-    Extract amino acid property values for a sequence.
-
-    @param sequence: An C{AARead} (or a subclass) instance.
-    @param propertyNames: An iterable of C{str} property names (each of which
-        must be a key of a key in the C{dark.aa.PROPERTY_DETAILS} C{dict}).
-    @param missingAAValue: A C{float} value to use for properties when an AA
-        (e.g., 'X') is not known.
-    @raise ValueError: If an unknown property is given in C{propertyNames}.
-    @return: A C{dict} keyed by (lowercase) property name, with values that are
-        C{list}s of the corresponding property value according to sequence
-        position.
-    """
-    return _propertiesOrClustersForSequence(
-        sequence, propertyNames, PROPERTY_DETAILS, missingAAValue
-    )
 
-
-def clustersForSequence(
-    sequence: Read, propertyNames: Iterable[str], missingAAValue: int = 0
-):
-    """
-    Extract amino acid property cluster numbers for a sequence.
-
-    @param sequence: An C{AARead} (or a subclass) instance.
-    @param propertyNames: An iterable of C{str} property names (each of which
-        must be a key of a key in the C{dark.aa.PROPERTY_CLUSTERS} C{dict}).
-    @param missingAAValue: An C{int} value to use for properties when an AA
-        (e.g., 'X') is not known.
-    @raise ValueError: If an unknown property is given in C{propertyNames}.
-    @return: A C{dict} keyed by (lowercase) property name, with values that are
-        C{list}s of the corresponding C{int} property cluster number according to
-        sequence position.
-    """
-    return _propertiesOrClustersForSequence(
-        sequence, propertyNames, PROPERTY_CLUSTERS, missingAAValue
-    )
-
-
-# It would be nice, in some universe, to do the following. But we access the
-# match dict using a variable key and mypy cannot check that, so this doesn't work.
-# Leaving it here in case it can be used for stricter checking in the future.
-#
-# _OverallMatch = TypedDict(
-#     "_OverallMatch",
-#     {
-#         "matchCount": int,
-#         "gapMismatchCount": int,
-#         "gapGapMismatchCount": int,
-#         "nonGapMismatchCount": int,
-#     },
-# )
-#
-# _Read1Match = TypedDict(
-#     "_Read1Match",
-#     {
-#         "extraCount": int,
-#         "gapOffsets": list[int],
-#     },
-# )
-#
-# _Read2Match = TypedDict(
-#     "_Read2Match",
-#     {
-#         "extraCount": int,
-#         "gapOffsets": list[int],
-#     },
-# )
-#
-# Match = TypedDict(
-#     "Match",
-#     {
-#         "match": _OverallMatch,
-#         "read1": _Read1Match,
-#         "read2": _Read2Match,
-#     },
-# )
-
-
-# Be more relaxed.
-_Match = Mapping[str, Mapping]
-
-
-def matchToString(
-    aaMatch: _Match,
-    read1: Read,
-    read2: Read,
-    indent: str = "",
-    offsets: Optional[set[int]] = None,
-) -> str:
+def matchToString(dnaMatch, read1, read2, matchAmbiguous=True, indent='',
+                  offsets=None, includeGapLocations=True):
     """
-    Format amino acid sequence match as a string.
+    Format a DNA match as a string.
 
-    @param aaMatch: A C{dict} returned by C{compareAaReads}.
+    @param dnaMatch: A C{dict} returned by C{compareDNAReads}.
     @param read1: A C{Read} instance or an instance of one of its subclasses.
     @param read2: A C{Read} instance or an instance of one of its subclasses.
+    @param matchAmbiguous: If C{True}, ambiguous nucleotides that are
+        possibly correct were counted as actually being correct. Otherwise,
+        the match was done strictly, insisting that only non-ambiguous
+        nucleotides could contribute to the matching nucleotide count.
     @param indent: A C{str} to indent all returned lines with.
     @param offsets: If not C{None}, a C{set} of offsets of interest that were
         only considered when making C{match}.
+    @param includeGapLocations: If C{True} indicate the (1-based) locations of
+        gaps.
     @return: A C{str} describing the match.
     """
-    match = aaMatch["match"]
-    matchCount = match["matchCount"]
-    gapMismatchCount = match["gapMismatchCount"]
-    gapGapMismatchCount = match["gapGapMismatchCount"]
-    nonGapMismatchCount = match["nonGapMismatchCount"]
+    match = dnaMatch['match']
+    identicalMatchCount = match['identicalMatchCount']
+    ambiguousMatchCount = match['ambiguousMatchCount']
+    gapMismatchCount = match['gapMismatchCount']
+    gapGapMismatchCount = match['gapGapMismatchCount']
+    nonGapMismatchCount = match['nonGapMismatchCount']
 
     if offsets:
         len1 = len2 = len(offsets)
     else:
         len1, len2 = map(len, (read1, read2))
 
-    result: list[str] = []
+    result = []
     append = result.append
 
-    append("%sMatches:" % indent)
-    append(countPrint("%s  Overall" % indent, matchCount, len1, len2))
-    append(
-        countPrint(
-            "%s  Not involving gaps (i.e., identities)" % indent,
-            matchCount,
-            matchCount + nonGapMismatchCount,
-        )
-    )
-
-    append("%sMismatches:" % indent)
-    mismatchCount = gapMismatchCount + gapGapMismatchCount + nonGapMismatchCount
-    append(countPrint("%s  Overall" % indent, mismatchCount, len1, len2))
-    append(
-        countPrint(
-            "%s  Not involving gaps (i.e., conflicts)" % indent,
-            nonGapMismatchCount,
-            len1,
-            len2,
-        )
-    )
-    append(
-        countPrint(
-            "%s  Involving a gap in one sequence" % indent, gapMismatchCount, len1, len2
-        )
-    )
-    append(
-        countPrint(
-            "%s  Involving a gap in both sequences" % indent,
-            gapGapMismatchCount,
-            len1,
-            len2,
-        )
-    )
+    append(countPrint('%sExact matches' % indent, identicalMatchCount,
+                      len1, len2))
+    append(countPrint('%sAmbiguous matches' % indent, ambiguousMatchCount,
+                      len1, len2))
+    if ambiguousMatchCount and identicalMatchCount:
+        anyMatchCount = identicalMatchCount + ambiguousMatchCount
+        append(countPrint('%sExact or ambiguous matches' % indent,
+                          anyMatchCount, len1, len2))
+
+    mismatchCount = (gapMismatchCount + gapGapMismatchCount +
+                     nonGapMismatchCount)
+    append(countPrint('%sMismatches' % indent, mismatchCount, len1, len2))
+    conflicts = 'conflicts' if matchAmbiguous else 'conflicts or ambiguities'
+    append(countPrint('%s  Not involving gaps (i.e., %s)' % (indent,
+                      conflicts), nonGapMismatchCount, len1, len2))
+    append(countPrint('%s  Involving a gap in one sequence' % indent,
+                      gapMismatchCount, len1, len2))
+    append(countPrint('%s  Involving a gap in both sequences' % indent,
+                      gapGapMismatchCount, len1, len2))
 
-    for read, key in zip((read1, read2), ("read1", "read2")):
-        append("%sId: %s" % (indent, read.id))
+    for read, key in zip((read1, read2), ('read1', 'read2')):
+        append('%s  Id: %s' % (indent, read.id))
         length = len(read)
-        append("%s  Length: %d" % (indent, length))
-        gapCount = len(aaMatch[key]["gapOffsets"])
-        append(countPrint("%s  Gaps" % indent, gapCount, length))
-        if gapCount:
+        append('%s    Length: %d' % (indent, length))
+        gapCount = len(dnaMatch[key]['gapOffsets'])
+        append(countPrint('%s    Gaps' % indent, gapCount, length))
+        if includeGapLocations and gapCount:
             append(
-                "%s  Gap locations (1-based): %s"
-                % (
-                    indent,
-                    ", ".join(
-                        map(
-                            lambda offset: str(offset + 1),
-                            sorted(aaMatch[key]["gapOffsets"]),
-                        )
-                    ),
-                )
-            )
-        extraCount = aaMatch[key]["extraCount"]
+                '%s    Gap locations (1-based): %s' %
+                (indent,
+                 ', '.join(map(lambda offset: str(offset + 1),
+                               sorted(dnaMatch[key]['gapOffsets'])))))
+        ambiguousCount = len(dnaMatch[key]['ambiguousOffsets'])
+        append(countPrint('%s    Ambiguous' % indent, ambiguousCount, length))
+        extraCount = dnaMatch[key]['extraCount']
         if extraCount:
-            append(
-                countPrint("%s  Extra amino acids at end" % indent, extraCount, length)
-            )
+            append(countPrint('%s    Extra nucleotides at end' % indent,
+                              extraCount, length))
 
-    return "\n".join(result)
+    return '\n'.join(result)
 
 
-def compareAaReads(
-    read1: Read, read2: Read, gapChars: str = "-", offsets: Optional[set[int]] = None
-) -> _Match:
+def compareDNAReads(read1, read2, matchAmbiguous=True, gapChars='-',
+                    offsets=None):
     """
-    Compare two amino acid sequences.
+    Compare two DNA sequences.
 
     @param read1: A C{Read} instance or an instance of one of its subclasses.
     @param read2: A C{Read} instance or an instance of one of its subclasses.
+    @param matchAmbiguous: If C{True}, count ambiguous nucleotides that are
+        possibly correct as actually being correct, and score these in the
+        ambiguousMatchCount. Otherwise, we are strict and insist that only
+        non-ambiguous nucleotides can contribute to the matching nucleotide
+        count.
     @param gapChars: An object supporting __contains__ with characters that
         should be considered to be gaps.
     @param offsets: If not C{None}, a C{set} of offsets of interest. Offsets
         not in the set will not be considered.
     @return: A C{dict} with information about the match and the individual
         sequences (see below).
     """
-    matchCount = 0
+    identicalMatchCount = ambiguousMatchCount = 0
     gapMismatchCount = nonGapMismatchCount = gapGapMismatchCount = 0
     read1ExtraCount = read2ExtraCount = 0
     read1GapOffsets = []
     read2GapOffsets = []
+    read1AmbiguousOffsets = []
+    read2AmbiguousOffsets = []
+    empty = set()
+
+    def _identicalMatch(a, b):
+        return a == b and len(AMBIGUOUS[a]) == 1
+
+    def _ambiguousMatch(a, b, matchAmbiguous):
+        """
+        Checks if two characters match ambiguously if matchAmbiguous is True.
+        A match is an ambiguous match if it is not an identical match, but the
+        sets of ambiguous characters overlap.
+        """
+        return (matchAmbiguous and
+                not _identicalMatch(a, b) and
+                AMBIGUOUS.get(a, empty) & AMBIGUOUS.get(b, empty))
 
-    for offset, (a, b) in enumerate(
-        zip_longest(read1.sequence.upper(), read2.sequence.upper())
-    ):
+    for offset, (a, b) in enumerate(zip_longest(read1.sequence.upper(),
+                                                read2.sequence.upper())):
         # Use 'is not None' in the following to allow an empty offsets set
         # to be passed.
         if offsets is not None and offset not in offsets:
             continue
+        if len(AMBIGUOUS.get(a, '')) > 1:
+            read1AmbiguousOffsets.append(offset)
+        if len(AMBIGUOUS.get(b, '')) > 1:
+            read2AmbiguousOffsets.append(offset)
         if a is None:
             # b has an extra character at its end (it cannot be None).
             assert b is not None
             read2ExtraCount += 1
             if b in gapChars:
                 read2GapOffsets.append(offset)
         elif b is None:
@@ -423,28 +192,241 @@
             else:
                 if b in gapChars:
                     # b is a gap, a is not.
                     gapMismatchCount += 1
                     read2GapOffsets.append(offset)
                 else:
                     # Neither is a gap character.
-                    if a == b:
-                        matchCount += 1
+                    if _identicalMatch(a, b):
+                        identicalMatchCount += 1
+                    elif _ambiguousMatch(a, b, matchAmbiguous):
+                        ambiguousMatchCount += 1
                     else:
                         nonGapMismatchCount += 1
 
     return {
-        "match": {
-            "matchCount": matchCount,
-            "gapMismatchCount": gapMismatchCount,
-            "gapGapMismatchCount": gapGapMismatchCount,
-            "nonGapMismatchCount": nonGapMismatchCount,
+        'match': {
+            'identicalMatchCount': identicalMatchCount,
+            'ambiguousMatchCount': ambiguousMatchCount,
+            'gapMismatchCount': gapMismatchCount,
+            'gapGapMismatchCount': gapGapMismatchCount,
+            'nonGapMismatchCount': nonGapMismatchCount,
         },
-        "read1": {
-            "extraCount": read1ExtraCount,
-            "gapOffsets": read1GapOffsets,
+        'read1': {
+            'ambiguousOffsets': read1AmbiguousOffsets,
+            'extraCount': read1ExtraCount,
+            'gapOffsets': read1GapOffsets,
         },
-        "read2": {
-            "extraCount": read2ExtraCount,
-            "gapOffsets": read2GapOffsets,
+        'read2': {
+            'ambiguousOffsets': read2AmbiguousOffsets,
+            'extraCount': read2ExtraCount,
+            'gapOffsets': read2GapOffsets,
         },
     }
+
+
+def findKozakConsensus(read):
+    """
+    In a given DNA sequence, search for a Kozak consensus: (gcc)gccRccATGG.
+    The upper case bases in that pattern are required, and the lower case
+    bases are the ones most frequently found at the given positions. The
+    initial 'gcc' sequence (in parentheses) is of uncertain significance
+    and is not taken into account here.
+
+    @param read: A C{DNARead} instance to be checked for Kozak consensi.
+    @return: A generator that yields C{DNAKozakRead} instances.
+    """
+    from dark.reads import DNAKozakRead
+
+    readLen = len(read)
+    if readLen > 9:
+        offset = 6
+        readSeq = read.sequence
+        while offset < readLen - 3:
+            triplet = readSeq[offset:offset + 3]
+            if triplet == 'ATG':
+                if readSeq[offset + 3] == 'G':
+                    if readSeq[offset - 3] in 'GA':
+                        kozakQualityCount = sum((
+                            readSeq[offset - 1] == 'C',
+                            readSeq[offset - 2] == 'C',
+                            readSeq[offset - 4] == 'C',
+                            readSeq[offset - 5] == 'C',
+                            readSeq[offset - 6] == 'G'))
+
+                        kozakQualityPercent = kozakQualityCount / 5.0 * 100
+                        yield DNAKozakRead(read, offset - 6, offset + 4,
+                                           kozakQualityPercent)
+            offset += 1
+
+
+class FloatBaseCounts(object):
+    """
+    Hold a floating point count of possible nucleotide bases.
+
+    @param codes: An iterable of nucleotide codes.
+    @param unknownAreAmbiguous: If C{True}, any unknown character (e.g., a '-'
+        gap or '?' unknown base) will be treated as being fully ambiguous
+        (i.e., could be any of ACGT). Otherwise, all unknown characters are
+        collected under the count for '-'.
+    """
+    def __init__(self, codes, unknownAreAmbiguous=False):
+        self.codes = list(map(str.upper, codes))
+        self.unknownAreAmbiguous = unknownAreAmbiguous
+        self.n = len(self.codes)
+        counts = defaultdict(float)
+
+        default = self._default = set('ACGT') if unknownAreAmbiguous else {'-'}
+
+        for code in self.codes:
+            possible = AMBIGUOUS.get(code, default)
+            frac = 1.0 / len(possible)
+            for p in possible:
+                counts[p] += frac
+
+        # Sort first by base.
+        _sorted = [(base, counts[base]) for base in sorted(counts)]
+
+        # Then by count (reversed).
+        def key(item):
+            return item[1]
+
+        self._sorted = sorted(_sorted, key=key, reverse=True)
+        self.counts = counts
+
+    def mostFrequent(self):
+        """
+        Which bases are the most frequent?
+
+        @return: A C{set} of the most frequent bases.
+        """
+        maxCount = self._sorted[0][1]
+        return set(base for base, count in self._sorted if count == maxCount)
+
+    def highestFrequency(self):
+        """
+        What is the frequency of the most frequent base?
+
+        @return: The C{float} frequency of the most common base.
+        """
+        if len(self.counts) < 2:
+            return 1.0
+        else:
+            return self._sorted[0][1] / float(self.n)
+
+    def homogeneous(self, level):
+        """
+        Does the most frequent base occurs at least C{level} fraction of the
+        time?
+
+        @param level: A C{float} fraction.
+        @return: C{True} if the most common base occurs at least C{level}
+            fraction of the time. If there are no bases at all, this is
+            considered homogeneous.
+        """
+        return self.highestFrequency() >= level
+
+    def __len__(self):
+        return len(self.counts)
+
+    def __str__(self):
+        fmt = '%d' if all(c == int(c) for b, c in self._sorted) else '%.2f'
+        return '%s (%.3f)' % (
+            ' '.join(('%s:' + fmt) % (b, c) for b, c in self._sorted),
+            self.highestFrequency())
+
+    def variable(self, confirm=True):
+        """
+        Are the nucleotides variable?
+
+        @param confirm: If C{True}, confirm that there is variability by
+            looking at the ambiguous nucleotides. Else just report C{True}
+            if there is more than one code (which might not indicate actual
+            variability, since two codes could be ambiguous and have a
+            nucleotide in common).
+        """
+        codes = self.codes
+
+        if confirm:
+            unambiguous = set()
+            ambiguousIntersection = None
+            default = self._default
+            for code in codes:
+                possible = AMBIGUOUS.get(code, default)
+                if len(possible) == 1:
+                    unambiguous.add(code)
+                else:
+                    if ambiguousIntersection is None:
+                        ambiguousIntersection = set(possible)
+                    else:
+                        ambiguousIntersection.intersection_update(possible)
+
+            if len(unambiguous) == 0:
+                # There were no unambiguous nucleotide codes.
+
+                # Sanity check: there must have been some ambiguous sites.
+                assert ambiguousIntersection is not None
+
+                if len(ambiguousIntersection) == 0:
+                    # The ambiguous sites had nothing in common, so
+                    # variation must exist (it cannot be determined what
+                    # the variation is, but we don't care about that).
+                    return True
+                else:
+                    # All the ambiguous sites have at least one nucleotide
+                    # in common, so we can't be sure there's any variation.
+                    pass
+            elif len(unambiguous) == 1:
+                # All the unambiguous sites agree. Do any of the ambiguous
+                # sites (if any) not allow the unambiguous nucleotide in
+                # their possibilities?
+                if ambiguousIntersection is None:
+                    # There were no ambiguous sites, so there's no
+                    # variation here.
+                    pass
+                else:
+                    # If any of the ambiguous sites excludes the single
+                    # unambiguous nucleotide, then variation must exist.
+                    nt = unambiguous.pop()
+                    for code in codes:
+                        possible = AMBIGUOUS.get(code, default)
+                        if nt not in possible:
+                            return True
+            elif len(unambiguous) > 1:
+                return True
+        else:
+            if len(codes) > 1:
+                return True
+
+        return False
+
+
+def sequenceToRegex(sequence, wildcards='-?'):
+    """
+    Convert a potentially ambiguous DNA sequence into a regular expression.
+    '?' and '-' are translated into [ACGT].
+
+    @param sequence: A C{str} DNA sequence, possibly with ambiguous codes.
+        Case insensitive.
+    @param wildcards: A C{set} (or C{str}) with characters that should be
+        translated to '[ACGT]'. Note that this happens only if the standard
+        ambiguous lookup fails (the order could be changed one day if we need
+        to override, or we could allow the passing of an ambiguity mapping).
+        Wildcards are case sensitive.
+    @raise KeyError: If any character in C{sequence} is unknown.
+    @return: A C{str} regular expression with [...] for the ambiguous codes in
+        C{sequence}.
+    """
+    result = []
+    append = result.append
+    for base in sequence.upper():
+        try:
+            possible = ''.join(sorted(AMBIGUOUS[base]))
+        except KeyError:
+            if base in wildcards:
+                possible = 'ACGT'
+            else:
+                raise
+
+        append(('[%s]' % possible) if len(possible) > 1 else possible)
+
+    return ''.join(result)
```

### Comparing `dark-matter-4.0.84/dark/alignments.py` & `dark-matter-4.0.9/dark/alignments.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,103 +1,93 @@
-from __future__ import annotations
-
 import re
-from typing import Union, Optional, Literal, Type, Generator, Callable
+
 from dark.taxonomy import LineageFetcher
 from dark.filter import TitleFilter
-from dark.hsp import HSP, LSP
-from dark.reads import Read, Reads
-from dark.score import HigherIsBetterScore, LowerIsBetterScore
+from dark.score import HigherIsBetterScore
 
 
-class Alignment:
+def bestAlignment(readAlignments):
+    """
+    Find the best alignment for a read. This is the one whose first HSP
+    has the best score.
+
+    Note that the comparison of HSP score values is taken care of by
+    the HSP class. This works whether higher or lower scores are
+    considered better.
+
+    @param readAlignments: a C{ReadAlignments} instance.
+    @return: The alignment with the best first HSP score.
+
+    """
+    return max(readAlignments, key=lambda alignment: alignment.hsps[0])
+
+
+class Alignment(object):
     """
     Hold information about a read alignment.
 
     @param subjectLength: The C{int} length of the sequence a read matched
         against.
     @param subjectTitle: The C{str} title of the sequence a read matched
         against.
     """
 
-    def __init__(self, subjectLength: int, subjectTitle: str):
+    def __init__(self, subjectLength, subjectTitle):
         self.subjectLength = subjectLength
         self.subjectTitle = subjectTitle
-        self.hsps: list[Union[HSP, LSP]] = []
+        self.hsps = []
 
-    def addHsp(self, hsp: Union[HSP, LSP]) -> None:
+    def addHsp(self, hsp):
         """
-        Add an HSP (or LSP) to the list of HSPs for this alignment.
+        Add an HSP to the list of HSPs for this alignment.
 
         @param hsp: A L{dark.hsp} (or subclass) instance.
         """
         self.hsps.append(hsp)
 
 
 class ReadAlignments(list):
     """
     Holds information about the alignments for a read.
 
     @param read: A C{Read} instance.
     @param alignments: A C{list} of L{dark.alignment.Alignment} instances or
         C{None} if the read has no alignments.
     """
-
-    def __init__(self, read: Read, alignments: Optional[list[Alignment]] = None):
+    def __init__(self, read, alignments=None):
         list.__init__(self)
         self.read = read
         if alignments:
             self.extend(alignments)
 
 
-def bestAlignment(readAlignments: ReadAlignments) -> Alignment:
-    """
-    Find the best alignment for a read. This is the one whose first HSP
-    has the best score.
-
-    Note that the comparison of HSP score values is taken care of by
-    the HSP class. This works whether higher or lower scores are
-    considered better.
-
-    @param readAlignments: a C{ReadAlignments} instance.
-    @return: The alignment with the best first HSP score.
-
-    """
-    return max(readAlignments, key=lambda alignment: alignment.hsps[0])
-
-
-class ReadsAlignmentsParams:
+class ReadsAlignmentsParams(object):
     """
     Holds information about how a ReadsAlignments instance was created.
 
     @param application: The C{str} name of the application that created
         the ReadsAlignments data.
     @param applicationParams: A C{dict} holding options and their values
         given to the application that created the ReadsAlignments data.
     @param subjectIsNucleotides: A C{bool} that indicates whether subject
         sequences (that are aligned against) are at the nucleotide level.
         If C{False}, the subject is assumed to be amino acids.
     @param scoreTitle: A C{str} to describe a score. E.g, "Bit value"
         or "E value".
     """
 
-    def __init__(
-        self,
-        application: str,
-        applicationParams: Optional[dict[str, str]] = None,
-        subjectIsNucleotides: bool = True,
-        scoreTitle: str = "Score",
-    ):
+    def __init__(self, application, applicationParams=None,
+                 subjectIsNucleotides=True, scoreTitle='Score'):
         self.application = application
         self.applicationParams = applicationParams
         self.subjectIsNucleotides = subjectIsNucleotides
         self.scoreTitle = scoreTitle
 
 
-class ReadsAlignmentsFilter:
+class ReadsAlignmentsFilter(object):
     """
     Provide a filter for C{ReadsAlignments} instances.
 
     @param limit: An C{int} limit on the number of records to read.
     @param maxAlignmentsPerRead: An C{int} limit on the number of alignments a
         read may have in order not to be filtered out. Reads with a greater
         number of alignments will be elided. Pass 0 to filter out reads that
@@ -118,18 +108,18 @@
     @param percentageIdenticalCutoff: A C{float} percentage identity (i.e.,
         0.0 to 100.0 NOT a fraction). Matches with percentage identity less
         than this will be ignored.
     @param percentagePositiveCutoff: A C{float} percentage (i.e.,
         0.0 to 100.0 NOT a fraction). Matches with a percentage positive less
         than this will be ignored. An AA match is considered positive (by
         DIAMOND) if its entry in the substitution (scoring) matrix is positive.
-    @param whitelist: If not C{None}, a set of exact C{str} titles that are always
+    @param whitelist: If not C{None}, a set of exact titles that are always
         acceptable (though the match info for a whitelist title may rule it
         out for other reasons).
-    @param blacklist: If not C{None}, a set of exact C{str} titles that are never
+    @param blacklist: If not C{None}, a set of exact titles that are never
         acceptable.
     @param whitelistFile: If not C{None}, a C{str} filename containing lines
         that give exact ids that are always acceptable.
     @param blacklistFile: If not C{None}, a C{str} filename containing lines
         that give exact ids that are never acceptable.
     @param titleRegex: A regex that sequence titles must match.
     @param negativeTitleRegex: A regex that sequence titles must not match.
@@ -139,81 +129,63 @@
     @param taxonomy: Either a C{str} name or an C{int} id of the taxonomic
         group on which should be filtered. eg 'Vira' will filter on
         viruses, while 11118 will filter on Coronaviridae.
     @param readIdRegex: A case-sensitive regex C{str} that read ids must
         match.
     @return: C{self}.
     """
+    def __init__(self, limit=None, maxAlignmentsPerRead=None,
+                 minSequenceLen=None, maxSequenceLen=None,
+                 minStart=None, maxStop=None,
+                 oneAlignmentPerRead=False, maxHspsPerHit=None,
+                 scoreCutoff=None, percentageIdenticalCutoff=None,
+                 percentagePositiveCutoff=None,
+                 whitelist=None, blacklist=None,
+                 whitelistFile=None, blacklistFile=None,
+                 titleRegex=None, negativeTitleRegex=None,
+                 truncateTitlesAfter=None, taxonomy=None, readIdRegex=None):
 
-    def __init__(
-        self,
-        limit: Optional[int] = None,
-        maxAlignmentsPerRead: Optional[int] = None,
-        minSequenceLen: Optional[int] = None,
-        maxSequenceLen: Optional[int] = None,
-        minStart: Optional[int] = None,
-        maxStop: Optional[int] = None,
-        oneAlignmentPerRead: bool = False,
-        maxHspsPerHit: Optional[int] = None,
-        scoreCutoff: Optional[float] = None,
-        percentageIdenticalCutoff: Optional[float] = None,
-        percentagePositiveCutoff: Optional[float] = None,
-        whitelist: Optional[set[str]] = None,
-        blacklist: Optional[set[str]] = None,
-        whitelistFile: Optional[str] = None,
-        blacklistFile: Optional[str] = None,
-        titleRegex: Optional[str] = None,
-        negativeTitleRegex: Optional[str] = None,
-        truncateTitlesAfter: Optional[str] = None,
-        taxonomy: Optional[Union[str, int]] = None,
-        readIdRegex: Optional[str] = None,
-    ):
         self.limit = limit
         self.maxAlignmentsPerRead = maxAlignmentsPerRead
         self.minSequenceLen = minSequenceLen
         self.maxSequenceLen = maxSequenceLen
         self.minStart = minStart
         self.maxStop = maxStop
         self.oneAlignmentPerRead = oneAlignmentPerRead
         self.maxHspsPerHit = maxHspsPerHit
         self.scoreCutoff = scoreCutoff
         self.percentageIdenticalCutoff = percentageIdenticalCutoff
         self.percentagePositiveCutoff = percentagePositiveCutoff
-        self.titleFilter: Optional[TitleFilter]
-        self.lineageFetcher: Optional[LineageFetcher]
 
         # If we've been asked to filter on matched sequence titles in any way,
         # build a title filter.
-        if (
-            whitelist
-            or blacklist
-            or whitelistFile
-            or blacklistFile
-            or titleRegex
-            or negativeTitleRegex
-            or truncateTitlesAfter
-        ):
+        if (whitelist or blacklist or whitelistFile or blacklistFile or
+                titleRegex or negativeTitleRegex or truncateTitlesAfter):
             self.titleFilter = TitleFilter(
-                whitelist=whitelist,
-                blacklist=blacklist,
-                whitelistFile=whitelistFile,
-                blacklistFile=blacklistFile,
-                positiveRegex=titleRegex,
-                negativeRegex=negativeTitleRegex,
-                truncateAfter=truncateTitlesAfter,
-            )
+                whitelist=whitelist, blacklist=blacklist,
+                whitelistFile=whitelistFile, blacklistFile=blacklistFile,
+                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex,
+                truncateAfter=truncateTitlesAfter)
         else:
             self.titleFilter = None
 
+        if taxonomy is not None:
+            self.lineageFetcher = LineageFetcher()
+        else:
+            self.lineageFetcher = None
         self.taxonomy = taxonomy
-        self.lineageFetcher = None if taxonomy is None else LineageFetcher()
-        self.readIdRegex = None if readIdRegex is None else re.compile(readIdRegex)
+
+        if readIdRegex is None:
+            self.readIdRegex = None
+        else:
+            self.readIdRegex = re.compile(readIdRegex)
+
         self.count = 0
 
-    def filter(self, readAlignments) -> Union[ReadAlignments, Literal[False]]:
+    def filter(self, readAlignments):
         """
         Filter a read's alignments.
 
         @param readAlignments: A C{ReadAlignments} instance.
         @return: A C{ReadAlignments} instance if the passed
             C{readAlignments} is not filtered out, else C{False}.
         """
@@ -243,61 +215,57 @@
         #
         # Alignment-only (i.e., non-HSP based) filtering.
         #
         if self.limit is not None and self.count == self.limit:
             return False
 
         # Does the read have too many alignments?
-        if (
-            self.maxAlignmentsPerRead is not None
-            and len(readAlignments) > self.maxAlignmentsPerRead
-        ):
+        if (self.maxAlignmentsPerRead is not None and
+                len(readAlignments) > self.maxAlignmentsPerRead):
             return False
 
         # Filter on the read id.
-        if self.readIdRegex and self.readIdRegex.search(readAlignments.read.id) is None:
+        if (self.readIdRegex and
+                self.readIdRegex.search(readAlignments.read.id) is None):
             return False
 
         if self.titleFilter:
             # Remove alignments against sequences whose titles are
             # unacceptable.
             wantedAlignments = []
             for alignment in readAlignments:
-                if (
-                    self.titleFilter.accept(alignment.subjectTitle)
-                    != TitleFilter.REJECT
-                ):
+                if (self.titleFilter.accept(alignment.subjectTitle) !=
+                        TitleFilter.REJECT):
                     wantedAlignments.append(alignment)
             if wantedAlignments:
                 readAlignments[:] = wantedAlignments
             else:
                 return False
 
         # Only return alignments that are against sequences of the
         # desired length.
         minSequenceLen = self.minSequenceLen
         maxSequenceLen = self.maxSequenceLen
         if minSequenceLen is not None or maxSequenceLen is not None:
             wantedAlignments = []
             for alignment in readAlignments:
                 length = alignment.subjectLength
-                if not (
-                    (minSequenceLen is not None and length < minSequenceLen)
-                    or (maxSequenceLen is not None and length > self.maxSequenceLen)
-                ):
+                if not ((minSequenceLen is not None and
+                         length < minSequenceLen) or
+                        (maxSequenceLen is not None and
+                         length > self.maxSequenceLen)):
                     wantedAlignments.append(alignment)
             if wantedAlignments:
                 readAlignments[:] = wantedAlignments
             else:
                 return False
 
         if self.taxonomy is not None:
             wantedAlignments = []
             for alignment in readAlignments:
-                assert self.lineageFetcher
                 lineage = self.lineageFetcher.lineage(alignment.subjectTitle)
                 if lineage:
                     for taxonomyIdAndScientificName in lineage:
                         if self.taxonomy in taxonomyIdAndScientificName:
                             wantedAlignments.append(alignment)
                 else:
                     # No lineage info was found. Keep the alignment
@@ -317,15 +285,15 @@
         #
 
         # Throw out any unwanted HSPs due to maxHspsPerHit.
         if self.maxHspsPerHit is not None:
             for alignment in readAlignments:
                 hsps = alignment.hsps
                 if len(hsps) > self.maxHspsPerHit:
-                    alignment.hsps = hsps[: self.maxHspsPerHit]
+                    alignment.hsps = hsps[:self.maxHspsPerHit]
 
         # Throw out HSPs whose scores are not good enough.
         if self.scoreCutoff is not None:
             wantedAlignments = []
             for alignment in readAlignments:
                 hsps = alignment.hsps
                 wantedHsps = []
@@ -392,39 +360,39 @@
         maxStop = self.maxStop
         if minStart is not None or maxStop is not None:
             wantedAlignments = []
             for alignment in readAlignments:
                 hsps = alignment.hsps
                 wantedHsps = []
                 for hsp in hsps:
-                    if not (
-                        (minStart is not None and hsp.readStartInSubject < minStart)
-                        or (maxStop is not None and hsp.readEndInSubject > maxStop)
-                    ):
+                    if not ((minStart is not None and
+                             hsp.readStartInSubject < minStart) or
+                            (maxStop is not None and
+                             hsp.readEndInSubject > maxStop)):
                         wantedHsps.append(hsp)
                 if wantedHsps:
                     alignment.hsps = wantedHsps
                     wantedAlignments.append(alignment)
             if wantedAlignments:
                 readAlignments[:] = wantedAlignments
             else:
                 return False
 
         self.count += 1
         return readAlignments
 
-    def close(self) -> None:
+    def close(self):
         """
         Close our lineage fetcher, if any.
         """
-        if self.lineageFetcher:
+        if self.taxonomy:
             self.lineageFetcher.close()
 
 
-class ReadsAlignments:
+class ReadsAlignments(object):
     """
     Provide for filtering for a collection of reads and their alignments.
 
     You probably will not use this class directly. Instead, write a
     subclass that implements iter.
 
     See L{dark.blast.alignments.BlastReadsAlignments} and
@@ -435,86 +403,78 @@
     @param params: An instance of C{ReadsAlignmentsParams}, containing
         the details of the application that created the alignments.
     @param scoreClass: A class to hold and compare scores (see scores.py).
         Default is C{HigherIsBetterScore}, for comparing bit scores. If you
         are using e.g., BLAST e-values, pass LowerIsBetterScore instead.
     """
 
-    def __init__(
-        self,
-        reads: Reads,
-        params: ReadsAlignmentsParams,
-        scoreClass: Union[
-            Type[HigherIsBetterScore], Type[LowerIsBetterScore]
-        ] = HigherIsBetterScore,
-    ):
+    def __init__(self, reads, params, scoreClass=HigherIsBetterScore):
         self.reads = reads
         self.params = params
         self.scoreClass = scoreClass
-        self._filters: list[Callable] = []
+        self._filters = []
 
-    def getSubjectSequence(self, title: str):
+    def getSubjectSequence(self, title):
         """
         Obtain information about a sequence given its title.
 
         Must be implemented by a subclass, e.g., see
         L{blast.alignments.BlastReadsAlignments}.
 
         @param title: A C{str} sequence title from a BLAST or DIAMOND (etc.)
             match. Usually of the form
             'gi|63148399|gb|DQ011818.1| Description...'.
         @raise NotImplementedError: This method must be implemented by a
             subclass.
         """
-        raise NotImplementedError(
-            "getSubjectSequence must be implemented by a subclass"
-        )
+        raise NotImplementedError('getSubjectSequence must be implemented by '
+                                  'a subclass')
 
-    def hsps(self) -> Generator[Union[HSP, LSP], None, None]:
+    def hsps(self):
         """
         Provide access to all HSPs for all alignments of all reads.
 
         @return: A generator that yields HSPs (or LSPs).
         """
         for readAlignments in self:
-            for readAlignment in readAlignments:
-                for hsp in readAlignment.hsps:
+            for alignment in readAlignments:
+                for hsp in alignment.hsps:
                     yield hsp
 
-    def __iter__(self) -> Generator[ReadAlignments, None, None]:
+    def __iter__(self):
         """
-        Iterate through all readsAlignments, yielding the readAlignments that pass any
+        Iterate through all readsAlignments, yielding those that pass any
         filters that have been added.
 
         @return: A generator that yields readsAlignments.
         """
-        for readAlignments in self.iter():
+        for readsAlignments in self.iter():
             for filterFunc in self._filters:
-                filteredReadAlignments = filterFunc(readAlignments)
-                if filteredReadAlignments is False:
+                filteredReadsAlignments = filterFunc(readsAlignments)
+                if filteredReadsAlignments is False:
                     break
                 else:
-                    readAlignments = filteredReadAlignments
+                    readsAlignments = filteredReadsAlignments
             else:
-                yield readAlignments
+                yield readsAlignments
 
-    def iter(self) -> Union[Generator[ReadAlignments, None, None], list]:
+    def iter(self):
         """
         Placeholder to allow subclasses to provide readsAlignments.
 
         These might be extracted from a file. E.g., the
         C{dark.blast.alignments.blast.BlastReadsAlignments} class (a subclass
         of C{ReadsAlignments}) overrides this method to provide readsAlignments
         from files.
 
         @return: An iterable of C{ReadsAlignments} instances.
         """
         return []
 
-    def filter(self, **kwargs) -> ReadsAlignments:
+    def filter(self, **kwargs):
         """
         Add a filter to this C{readsAlignments}.
 
         @param kwargs: Keyword arguments, as accepted by
             C{ReadsAlignmentsFilter}.
         @return: C{self}
         """
```

### Comparing `dark-matter-4.0.84/dark/analyze_reads.py` & `dark-matter-4.0.9/dark/analyze_reads.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,26 @@
-from typing import IO, Sequence, AnyStr
-
 from Bio import SeqIO
 
 
-def _longestPrefixOfTwoSeqs(a: str, b: str):
+def _longestPrefixOfTwoSeqs(a, b):
     length = min(len(a), len(b))
     result = 0
     while result < length:
         if a[result] == b[result]:
             result += 1
         else:
             break
     return result
 
 
-def getPrefixAndSuffix(file_handle: IO[AnyStr]):
-    read_list = list(SeqIO.parse(file_handle, "fasta"))
+def getPrefixAndSuffix(file_handle):
+    read_list = list(SeqIO.parse(file_handle, 'fasta'))
     reversed_read_list = [read[::-1] for read in read_list]
 
-    def longestCommonPrefix(read_list: Sequence):
+    def longestCommonPrefix(read_list):
         sequences = read_list
         nSequences = len(sequences)
         if nSequences == 1:
             return len(sequences[0])
         elif nSequences == 0:
             return 0
         else:
@@ -40,13 +38,13 @@
             return result
 
     prefix = longestCommonPrefix(read_list)
     suffix = longestCommonPrefix(reversed_read_list)
     return prefix, suffix
 
 
-def trimReads(prefix: int, suffix: int, file_handle: IO[AnyStr]):
-    for record in SeqIO.parse(file_handle, "fasta"):
+def trimReads(prefix, suffix, file_handle):
+    for record in SeqIO.parse(file_handle, 'fasta'):
         if suffix == 0:
             yield record[prefix:]
         else:
             yield record[prefix:-suffix]
```

### Comparing `dark-matter-4.0.84/dark/baseimage.py` & `dark-matter-4.0.9/dark/baseimage.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 import numpy as np
 
 
-class BaseImage:
+class BaseImage(object):
     """
     Hold a representation of colored sequence bases in a 2D grid suitable
     for placing onto an alignment graph (see utils.py).
     """
 
-    def __init__(self, xRange: int, yRange: int, xScale: int = 1, yScale: int = 1):
+    def __init__(self, xRange, yRange, xScale=1, yScale=1):
         # np.ones is passed a (y range, x range) dimension.
-        self.data = np.ones(
-            (yRange * yScale + 1, xRange * xScale + 1), dtype=(float, 3)
-        )
+        self.data = np.ones((yRange * yScale + 1, xRange * xScale + 1),
+                            dtype=(float, 3))
         self.xScale = xScale
         self.yScale = yScale
 
-    def set(self, x: int, y: int, value: float):
+    def set(self, x, y, value):
         """
         Set the data at (x, y) to value.
         """
         xBase = int(x) * self.xScale
         yBase = int(y) * self.yScale
         for xOffset in range(self.xScale):
             for yOffset in range(self.yScale):
```

### Comparing `dark-matter-4.0.84/dark/blast/alignments.py` & `dark-matter-4.0.9/dark/blast/alignments.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from random import uniform
 from math import log10
 import copy
-from typing import Generator
 
 from dark.score import HigherIsBetterScore
-from dark.alignments import ReadsAlignments, ReadsAlignmentsParams, ReadAlignments
+from dark.alignments import ReadsAlignments, ReadsAlignmentsParams
 from dark.blast.conversion import JSONRecordsReader
 from dark.blast.params import checkCompatibleParams
 from dark.fasta import FastaReads, SqliteIndex
 from dark.reads import AARead, DNARead
 from dark.utils import numericallySortFilenames
 
 ZERO_EVALUE_UPPER_RANDOM_INCREMENT = 150
@@ -46,26 +45,19 @@
     @param randomizeZeroEValues: If C{True}, e-values that are zero will be set
         to a random (very good) value.
     @raises ValueError: if a file type is not recognized, if the number of
         reads does not match the number of records found in the BLAST result
         files, or if BLAST parameters in all files do not match.
     """
 
-    def __init__(
-        self,
-        reads,
-        blastFilenames,
-        databaseFilename=None,
-        databaseDirectory=None,
-        sqliteDatabaseFilename=None,
-        scoreClass=HigherIsBetterScore,
-        sortBlastFilenames=True,
-        randomizeZeroEValues=True,
-    ):
-        if isinstance(blastFilenames, str):
+    def __init__(self, reads, blastFilenames, databaseFilename=None,
+                 databaseDirectory=None, sqliteDatabaseFilename=None,
+                 scoreClass=HigherIsBetterScore,
+                 sortBlastFilenames=True, randomizeZeroEValues=True):
+        if type(blastFilenames) == str:
             blastFilenames = [blastFilenames]
         if sortBlastFilenames:
             self.blastFilenames = numericallySortFilenames(blastFilenames)
         else:
             self.blastFilenames = blastFilenames
         self._databaseFilename = databaseFilename
         self._sqliteDatabaseFilename = sqliteDatabaseFilename
@@ -73,41 +65,39 @@
         self._subjectTitleToSubject = None
         self.randomizeZeroEValues = randomizeZeroEValues
 
         # Prepare application parameters in order to initialize self.
         self._reader = self._getReader(self.blastFilenames[0], scoreClass)
         application = self._reader.application
         blastParams = copy.deepcopy(self._reader.params)
-        subjectIsNucleotides = application != "blastx"
-        scoreTitle = (
-            "Bit score" if scoreClass is HigherIsBetterScore else "$- log_{10}(e)$"
-        )
+        subjectIsNucleotides = application != 'blastx'
+        scoreTitle = ('Bit score' if scoreClass is HigherIsBetterScore
+                      else '$- log_{10}(e)$')
 
         applicationParams = ReadsAlignmentsParams(
-            application,
-            blastParams,
-            subjectIsNucleotides=subjectIsNucleotides,
-            scoreTitle=scoreTitle,
-        )
+            application, blastParams,
+            subjectIsNucleotides=subjectIsNucleotides, scoreTitle=scoreTitle)
 
-        ReadsAlignments.__init__(self, reads, applicationParams, scoreClass=scoreClass)
+        ReadsAlignments.__init__(self, reads, applicationParams,
+                                 scoreClass=scoreClass)
 
     def _getReader(self, filename, scoreClass):
         """
         Obtain a JSON record reader for BLAST records.
 
         @param filename: The C{str} file name holding the JSON.
         @param scoreClass: A class to hold and compare scores (see scores.py).
         """
-        if filename.endswith(".json") or filename.endswith(".json.bz2"):
+        if filename.endswith('.json') or filename.endswith('.json.bz2'):
             return JSONRecordsReader(filename, scoreClass)
         else:
-            raise ValueError("Unknown BLAST record file suffix for file %r." % filename)
+            raise ValueError(
+                'Unknown BLAST record file suffix for file %r.' % filename)
 
-    def iter(self) -> Generator[ReadAlignments, None, None]:
+    def iter(self):
         """
         Extract BLAST records and yield C{ReadAlignments} instances.
 
         For each file except the first, check that the BLAST parameters are
         compatible with those found (above, in __init__) in the first file.
 
         @return: A generator that yields C{ReadAlignments} instances.
@@ -126,37 +116,35 @@
             if first:
                 # No need to check params in the first file. We already read
                 # them in and stored them in __init__.
                 first = False
             else:
                 reader = self._getReader(blastFilename, self.scoreClass)
                 differences = checkCompatibleParams(
-                    self.params.applicationParams, reader.params
-                )
+                    self.params.applicationParams, reader.params)
                 if differences:
                     raise ValueError(
-                        "Incompatible BLAST parameters found. The parameters "
-                        "in %s differ from those originally found in %s. %s"
-                        % (blastFilename, self.blastFilenames[0], differences)
-                    )
+                        'Incompatible BLAST parameters found. The parameters '
+                        'in %s differ from those originally found in %s. %s' %
+                        (blastFilename, self.blastFilenames[0], differences))
 
             for readAlignments in reader.readAlignments(reads):
                 count += 1
                 yield readAlignments
 
         # Make sure all reads were used.
         try:
             read = next(reads)
         except StopIteration:
             pass
         else:
             raise ValueError(
-                "Reads iterator contained more reads than the number of BLAST "
-                "records found (%d). First unknown read id is %r." % (count, read.id)
-            )
+                'Reads iterator contained more reads than the number of BLAST '
+                'records found (%d). First unknown read id is %r.' %
+                (count, read.id))
 
     def getSubjectSequence(self, title):
         """
         Obtain information about a subject sequence given its title.
 
         This information is cached in self._subjectTitleToSubject. It can
         be obtained from either a) an sqlite database (given via the
@@ -168,43 +156,41 @@
 
         @param title: A C{str} sequence title from a BLAST hit. Of the form
             'gi|63148399|gb|DQ011818.1| Description...'.
         @return: An C{AARead} or C{DNARead} instance, depending on the type of
             BLAST database in use.
 
         """
-        if self.params.application in {"blastp", "blastx"}:
+        if self.params.application in {'blastp', 'blastx'}:
             readClass = AARead
         else:
             readClass = DNARead
 
         if self._subjectTitleToSubject is None:
             if self._databaseFilename is None:
                 if self._sqliteDatabaseFilename is None:
                     # Fall back to blastdbcmd.  ncbidb has to be imported
                     # as below so ncbidb.getSequence can be patched by our
                     # test suite.
                     from dark import ncbidb
-
                     seq = ncbidb.getSequence(
-                        title, self.params.applicationParams["database"]
-                    )
+                        title, self.params.applicationParams['database'])
                     return readClass(seq.description, str(seq.seq))
                 else:
                     # An Sqlite3 database is used to look up subjects.
                     self._subjectTitleToSubject = SqliteIndex(
                         self._sqliteDatabaseFilename,
                         fastaDirectory=self._databaseDirectory,
-                        readClass=readClass,
-                    )
+                        readClass=readClass)
             else:
                 # Build an in-memory dict to look up subjects. This only
                 # works for small databases, obviously.
                 titles = {}
-                for read in FastaReads(self._databaseFilename, readClass=readClass):
+                for read in FastaReads(self._databaseFilename,
+                                       readClass=readClass):
                     titles[read.id] = read
                 self._subjectTitleToSubject = titles
 
         return self._subjectTitleToSubject[title]
 
     def adjustHspsForPlotting(self, titleAlignments):
         """
@@ -226,30 +212,28 @@
         # from disk again, which is not what's wanted.
         for hsp in titleAlignments.hsps():
             if hsp.score.score == 0.0:
                 zeroHsps.append(hsp)
             else:
                 convertedEValue = -1.0 * log10(hsp.score.score)
                 hsp.score.score = convertedEValue
-                if maxConvertedEValue is None or convertedEValue > maxConvertedEValue:
+                if (maxConvertedEValue is None or
+                        convertedEValue > maxConvertedEValue):
                     maxConvertedEValue = convertedEValue
 
         if zeroHsps:
             # Save values so that we can use them in self.adjustPlot
             self._maxConvertedEValue = maxConvertedEValue
             self._zeroEValueFound = True
 
             # Adjust all zero e-value HSPs to have numerically high values.
             if self.randomizeZeroEValues:
                 for hsp in zeroHsps:
-                    hsp.score.score = (
-                        maxConvertedEValue
-                        + 2
-                        + uniform(0, ZERO_EVALUE_UPPER_RANDOM_INCREMENT)
-                    )
+                    hsp.score.score = (maxConvertedEValue + 2 + uniform(
+                        0, ZERO_EVALUE_UPPER_RANDOM_INCREMENT))
             else:
                 for count, hsp in enumerate(zeroHsps, start=1):
                     hsp.score.score = maxConvertedEValue + count
         else:
             self._zeroEValueFound = False
 
     def adjustPlot(self, readsAx):
@@ -261,10 +245,9 @@
             matplotlib.pyplot.subplot.
         """
         # If we're using bit scores, there's nothing to do.
         if self.scoreClass is HigherIsBetterScore:
             return
 
         if self._zeroEValueFound:
-            readsAx.axhline(
-                y=self._maxConvertedEValue + 0.5, color="#cccccc", linewidth=0.5
-            )
+            readsAx.axhline(y=self._maxConvertedEValue + 0.5, color='#cccccc',
+                            linewidth=0.5)
```

### Comparing `dark-matter-4.0.84/dark/blast/conversion.py` & `dark-matter-4.0.9/dark/blast/conversion.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,22 +1,24 @@
+from __future__ import print_function
+
 import six
 import bz2
 from json import dumps, loads
 from operator import itemgetter
 
 from Bio.Blast import NCBIXML
 from Bio.File import as_handle
 
 from dark.hsp import HSP, LSP
 from dark.score import HigherIsBetterScore
 from dark.alignments import Alignment, ReadAlignments
 from dark.blast.hsp import normalizeHSP
 
 
-class XMLRecordsReader:
+class XMLRecordsReader(object):
     """
     Provide a method that yields parsed XML records from a file. Store and
     make accessible the global BLAST parameters.
 
     @ivar params: A C{dict} of global BLAST parameters.
     @param filename: A C{str} filename or an open file pointer, containing XML
         BLAST records.
@@ -41,41 +43,37 @@
             BioPython source to see everything it contains.
         @return: A C{dict} with 'alignments' and 'query' keys.
         """
         alignments = []
         for alignment in record.alignments:
             hsps = []
             for hsp in alignment.hsps:
-                hsps.append(
-                    {
-                        "bits": hsp.bits,
-                        "expect": hsp.expect,
-                        "frame": hsp.frame,
-                        "identicalCount": hsp.identities,
-                        "positiveCount": hsp.positives,
-                        "query": hsp.query,
-                        "query_start": hsp.query_start,
-                        "query_end": hsp.query_end,
-                        "sbjct": hsp.sbjct,
-                        "sbjct_start": hsp.sbjct_start,
-                        "sbjct_end": hsp.sbjct_end,
-                    }
-                )
-
-            alignments.append(
-                {
-                    "hsps": hsps,
-                    "length": alignment.length,
-                    "title": alignment.title,
-                }
-            )
+                hsps.append({
+                    'bits': hsp.bits,
+                    'expect': hsp.expect,
+                    'frame': hsp.frame,
+                    'identicalCount': hsp.identities,
+                    'positiveCount': hsp.positives,
+                    'query': hsp.query,
+                    'query_start': hsp.query_start,
+                    'query_end': hsp.query_end,
+                    'sbjct': hsp.sbjct,
+                    'sbjct_start': hsp.sbjct_start,
+                    'sbjct_end': hsp.sbjct_end,
+                })
+
+            alignments.append({
+                'hsps': hsps,
+                'length': alignment.length,
+                'title': alignment.title,
+            })
 
         return {
-            "alignments": alignments,
-            "query": record.query,
+            'alignments': alignments,
+            'query': record.query,
         }
 
     def _convertBlastParamsToDict(self, record):
         """
         Pull the global BLAST parameters out of a BLAST record and return
         them as a C{dict}.
 
@@ -87,62 +85,61 @@
         @param record: An instance of C{Bio.Blast.Record.Blast}. The attributes
             on this don't seem to be documented. You'll need to look at the
             BioPython source to see everything it contains.
         @return: A C{dict}, as described above.
         """
         result = {}
         for attr in (
-            # From Bio.Blast.Record.Header
-            "application",
-            "version",
-            "date",
-            "reference",
-            "query",
-            "query_letters",
-            "database",
-            "database_sequences",
-            "database_letters",
-            # From Bio.Blast.Record.DatabaseReport
-            "database_name",
-            "posted_date",
-            "num_letters_in_database",
-            "num_sequences_in_database",
-            "ka_params",
-            "gapped",
-            "ka_params_gap",
-            # From Bio.Blast.Record.Parameters
-            "matrix",
-            "gap_penalties",
-            "sc_match",
-            "sc_mismatch",
-            "num_hits",
-            "num_sequences",
-            "num_good_extends",
-            "num_seqs_better_e",
-            "hsps_no_gap",
-            "hsps_prelim_gapped",
-            "hsps_prelim_gapped_attemped",
-            "hsps_gapped",
-            "query_id",
-            "query_length",
-            "database_length",
-            "effective_hsp_length",
-            "effective_query_length",
-            "effective_database_length",
-            "effective_search_space",
-            "effective_search_space_used",
-            "frameshift",
-            "threshold",
-            "window_size",
-            "dropoff_1st_pass",
-            "gap_x_dropoff",
-            "gap_x_dropoff_final",
-            "gap_trigger",
-            "blast_cutoff",
-        ):
+                # From Bio.Blast.Record.Header
+                'application',
+                'version',
+                'date',
+                'reference',
+                'query',
+                'query_letters',
+                'database',
+                'database_sequences',
+                'database_letters',
+                # From Bio.Blast.Record.DatabaseReport
+                'database_name',
+                'posted_date',
+                'num_letters_in_database',
+                'num_sequences_in_database',
+                'ka_params',
+                'gapped',
+                'ka_params_gap',
+                # From Bio.Blast.Record.Parameters
+                'matrix',
+                'gap_penalties',
+                'sc_match',
+                'sc_mismatch',
+                'num_hits',
+                'num_sequences',
+                'num_good_extends',
+                'num_seqs_better_e',
+                'hsps_no_gap',
+                'hsps_prelim_gapped',
+                'hsps_prelim_gapped_attemped',
+                'hsps_gapped',
+                'query_id',
+                'query_length',
+                'database_length',
+                'effective_hsp_length',
+                'effective_query_length',
+                'effective_database_length',
+                'effective_search_space',
+                'effective_search_space_used',
+                'frameshift',
+                'threshold',
+                'window_size',
+                'dropoff_1st_pass',
+                'gap_x_dropoff',
+                'gap_x_dropoff_final',
+                'gap_trigger',
+                'blast_cutoff'):
             result[attr] = getattr(record, attr)
         return result
 
     def records(self):
         """
         Yield BLAST records, as read by the BioPython NCBIXML.parse
         method. Set self.params from data in the first record.
@@ -161,23 +158,21 @@
         the BLAST parameters.
 
         @param fp: A C{str} file pointer to write to.
         """
         first = True
         for record in self.records():
             if first:
-                print(dumps(self.params, separators=(",", ":")), file=fp)
+                print(dumps(self.params, separators=(',', ':')), file=fp)
                 first = False
-            print(
-                dumps(self._convertBlastRecordToDict(record), separators=(",", ":")),
-                file=fp,
-            )
+            print(dumps(self._convertBlastRecordToDict(record),
+                        separators=(',', ':')), file=fp)
 
 
-class JSONRecordsReader:
+class JSONRecordsReader(object):
     """
     Provide a method that yields JSON records from a file. Store, check, and
     make accessible the global BLAST parameters.
 
     @param filename: A C{str} filename containing JSON BLAST records.
     @param scoreClass: A class to hold and compare scores (see scores.py).
         Default is C{HigherIsBetterScore}, for comparing bit scores. If you
@@ -192,102 +187,102 @@
         self._scoreClass = scoreClass
         if scoreClass is HigherIsBetterScore:
             self._hspClass = HSP
         else:
             self._hspClass = LSP
 
         self._open(filename)
-        self.application = self.params["application"].lower()
+        self.application = self.params['application'].lower()
 
     def _open(self, filename):
         """
         Open the input file. Set self._fp to point to it. Read the first
         line of parameters.
 
         @param filename: A C{str} filename containing JSON BLAST records.
         @raise ValueError: if the first line of the file isn't valid JSON,
             if the input file is empty, or if the JSON does not contain an
             'application' key.
         """
-        if filename.endswith(".bz2"):
+        if filename.endswith('.bz2'):
             if six.PY3:
-                self._fp = bz2.open(filename, mode="rt", encoding="UTF-8")
+                self._fp = bz2.open(filename, mode='rt', encoding='UTF-8')
             else:
                 self._fp = bz2.BZ2File(filename)
         else:
             self._fp = open(filename)
 
         line = self._fp.readline()
         if not line:
-            raise ValueError("JSON file %r was empty." % self._filename)
+            raise ValueError('JSON file %r was empty.' % self._filename)
 
         try:
             self.params = loads(line[:-1])
         except ValueError as e:
             raise ValueError(
-                "Could not convert first line of %r to JSON (%s). "
-                "Line is %r." % (self._filename, e, line[:-1])
-            )
+                'Could not convert first line of %r to JSON (%s). '
+                'Line is %r.' % (self._filename, e, line[:-1]))
         else:
-            if "application" not in self.params:
+            if 'application' not in self.params:
                 raise ValueError(
-                    "%r appears to be an old JSON file with no BLAST global "
-                    "parameters. Please re-run convert-blast-xml-to-json.py "
-                    "to convert it to the newest format." % self._filename
-                )
+                    '%r appears to be an old JSON file with no BLAST global '
+                    'parameters. Please re-run convert-blast-xml-to-json.py '
+                    'to convert it to the newest format.' % self._filename)
 
     def _dictToAlignments(self, blastDict, read):
         """
         Take a dict (made by XMLRecordsReader._convertBlastRecordToDict)
         and convert it to a list of alignments.
 
         @param blastDict: A C{dict}, from convertBlastRecordToDict.
         @param read: A C{Read} instance, containing the read that BLAST used
             to create this record.
         @raise ValueError: If the query id in the BLAST dictionary does not
             match the id of the read.
         @return: A C{list} of L{dark.alignment.Alignment} instances.
         """
-        if blastDict["query"] != read.id and blastDict["query"].split()[0] != read.id:
+        if (blastDict['query'] != read.id and
+                blastDict['query'].split()[0] != read.id):
             raise ValueError(
-                "The reads you have provided do not match the BLAST output: "
-                "BLAST record query id (%s) does not match the id of the "
-                "supposedly corresponding read (%s)." % (blastDict["query"], read.id)
-            )
+                'The reads you have provided do not match the BLAST output: '
+                'BLAST record query id (%s) does not match the id of the '
+                'supposedly corresponding read (%s).' %
+                (blastDict['query'], read.id))
 
         alignments = []
-        getScore = itemgetter("bits" if self._hspClass is HSP else "expect")
+        getScore = itemgetter('bits' if self._hspClass is HSP else 'expect')
 
-        for blastAlignment in blastDict["alignments"]:
-            alignment = Alignment(blastAlignment["length"], blastAlignment["title"])
+        for blastAlignment in blastDict['alignments']:
+            alignment = Alignment(blastAlignment['length'],
+                                  blastAlignment['title'])
             alignments.append(alignment)
-            for blastHsp in blastAlignment["hsps"]:
+            for blastHsp in blastAlignment['hsps']:
                 score = getScore(blastHsp)
-                normalized = normalizeHSP(blastHsp, len(read), self.application)
+                normalized = normalizeHSP(blastHsp, len(read),
+                                          self.application)
                 hsp = self._hspClass(
                     score,
-                    readStart=normalized["readStart"],
-                    readEnd=normalized["readEnd"],
-                    readStartInSubject=normalized["readStartInSubject"],
-                    readEndInSubject=normalized["readEndInSubject"],
-                    readFrame=blastHsp["frame"][0],
-                    subjectStart=normalized["subjectStart"],
-                    subjectEnd=normalized["subjectEnd"],
-                    subjectFrame=blastHsp["frame"][1],
-                    readMatchedSequence=blastHsp["query"],
-                    subjectMatchedSequence=blastHsp["sbjct"],
+                    readStart=normalized['readStart'],
+                    readEnd=normalized['readEnd'],
+                    readStartInSubject=normalized['readStartInSubject'],
+                    readEndInSubject=normalized['readEndInSubject'],
+                    readFrame=blastHsp['frame'][0],
+                    subjectStart=normalized['subjectStart'],
+                    subjectEnd=normalized['subjectEnd'],
+                    subjectFrame=blastHsp['frame'][1],
+                    readMatchedSequence=blastHsp['query'],
+                    subjectMatchedSequence=blastHsp['sbjct'],
                     # Use blastHsp.get on identicalCount and positiveCount
                     # because they were added in version 2.0.3 and will not
                     # be present in any of our JSON output generated before
                     # that. Those values will be None for those JSON files,
                     # but that's much better than no longer being able to
                     # read all that data.
-                    identicalCount=blastHsp.get("identicalCount"),
-                    positiveCount=blastHsp.get("positiveCount"),
-                )
+                    identicalCount=blastHsp.get('identicalCount'),
+                    positiveCount=blastHsp.get('positiveCount'))
 
                 alignment.addHsp(hsp)
 
         return alignments
 
     def readAlignments(self, reads):
         """
@@ -308,25 +303,24 @@
 
         try:
             for lineNumber, line in enumerate(self._fp, start=2):
                 try:
                     record = loads(line[:-1])
                 except ValueError as e:
                     raise ValueError(
-                        "Could not convert line %d of %r to JSON (%s). "
-                        "Line is %r." % (lineNumber, self._filename, e, line[:-1])
-                    )
+                        'Could not convert line %d of %r to JSON (%s). '
+                        'Line is %r.' %
+                        (lineNumber, self._filename, e, line[:-1]))
                 else:
                     try:
                         read = next(reads)
                     except StopIteration:
                         raise ValueError(
-                            "Read generator failed to yield read number %d "
-                            "during parsing of BLAST file %r."
-                            % (lineNumber - 1, self._filename)
-                        )
+                            'Read generator failed to yield read number %d '
+                            'during parsing of BLAST file %r.' %
+                            (lineNumber - 1, self._filename))
                     else:
                         alignments = self._dictToAlignments(record, read)
                         yield ReadAlignments(read, alignments)
         finally:
             self._fp.close()
             self._fp = None
```

### Comparing `dark-matter-4.0.84/dark/blast/hacks.py` & `dark-matter-4.0.9/dark/blast/hacks.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,29 +1,32 @@
+from __future__ import print_function
+
+
 def printBlastRecordForDerek(record):
     """
     This is a hacked version of printBlastRecord that I wrote in
     Addenbrookes hospital so Derek could try hacking on the reads
     that had low e values.  It's called by bin/print-blast-xml-for-derek.py
     """
     if len(record.alignments) == 0:
         return 0
     if record.descriptions[0].e > 1e-120:
         return 0
-    print(record.query, end=" ")
+    print(record.query, end=' ')
     for i, alignment in enumerate(record.alignments):
-        print(record.descriptions[i].e, end=" ")
+        print(record.descriptions[i].e, end=' ')
         for hspIndex, hsp in enumerate(alignment.hsps, start=1):
             if hsp.sbjct_start < hsp.sbjct_end:
                 sense = 1
                 if hsp.sbjct_start < 2200:
-                    side = "left"
+                    side = 'left'
                 else:
-                    side = "right"
+                    side = 'right'
             else:
                 sense = -1
                 if hsp.sbjct_end < 2200:
-                    side = "left"
+                    side = 'left'
                 else:
-                    side = "right"
+                    side = 'right'
             print(sense, side)
             break
     return 1
```

### Comparing `dark-matter-4.0.84/dark/blast/hsp.py` & `dark-matter-4.0.9/dark/blast/hsp.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,11 @@
-def printHSP(hsp, indent=""):
-    for attr in [
-        "bits",
-        "expect",
-        "frame",
-        "query_end",
-        "query_start",
-        "sbjct",
-        "query",
-        "sbjct_end",
-        "sbjct_start",
-    ]:
-        print("%s%s: %s" % (indent, attr, hsp[attr]))
+def printHSP(hsp, indent=''):
+    for attr in ['bits', 'expect', 'frame', 'query_end', 'query_start',
+                 'sbjct', 'query', 'sbjct_end', 'sbjct_start']:
+        print('%s%s: %s' % (indent, attr, hsp[attr]))
 
 
 def normalizeHSP(hsp, readLen, blastApplication):
     """
     Examine an HSP and return information about where the query and subject
     match begins and ends.  Return a dict with keys that allow the query to
     be displayed against the subject. The returned readStartInSubject and
@@ -51,52 +42,50 @@
         """
         Print debugging information showing the local variables from
         a call to normalizeHSP and then raise an C{AssertionError}.
 
         @param locals: A C{dict} of local variables.
         @param msg: A C{str} message to raise C{AssertionError} with.
         """
-        print("normalizeHSP error:")
-        print("  readLen: %d" % readLen)
+        print('normalizeHSP error:')
+        print('  readLen: %d' % readLen)
         for var in sorted(locals):
-            if var in ("debugPrint", "hsp"):
+            if var in ('debugPrint', 'hsp'):
                 continue
-            print("  %s: %s" % (var, locals[var]))
-        print("  Original HSP:")
-        printHSP(hsp, "    ")
+            print('  %s: %s' % (var, locals[var]))
+        print('  Original HSP:')
+        printHSP(hsp, '    ')
         if msg:
             raise AssertionError(msg)
         else:
             raise AssertionError()
 
-    readPositive = hsp["frame"][0] > 0
-    hitPositive = hsp["frame"][1] > 0
+    readPositive = hsp['frame'][0] > 0
+    hitPositive = hsp['frame'][1] > 0
 
     # The following variable names with underscores match the names of
     # attributes BioPython uses and the values (1-based) match those
     # reported by BLAST.
-    read_start = hsp["query_start"]
-    read_end = hsp["query_end"]
-    sbjct_start = hsp["sbjct_start"]
-    sbjct_end = hsp["sbjct_end"]
+    read_start = hsp['query_start']
+    read_end = hsp['query_end']
+    sbjct_start = hsp['sbjct_start']
+    sbjct_end = hsp['sbjct_end']
 
     # When the read is positive, BLASTN and TBLASTX give read offsets
     # ascending.
     #
     # TBLASTX reports negative read sense with indices ascending.
     # BLASTN does not report negative read sense.
     #
     # In all cases the read offsets should be ascending.
     if read_start > read_end:
-        debugPrint(
-            locals(),
-            'Assertion "read_start <= read_end" failed. Read '
-            "positive is %s. read_start = %d, read_end = %d"
-            % (readPositive, read_start, read_end),
-        )
+        debugPrint(locals(),
+                   'Assertion "read_start <= read_end" failed. Read '
+                   'positive is %s. read_start = %d, read_end = %d' %
+                   (readPositive, read_start, read_end))
 
     if hitPositive:
         # Make sure indices are ascending.
         if sbjct_start > sbjct_end:
             debugPrint(locals())
     else:
         # Hit is negative. Its indices will be ascending for TBLASTX
@@ -108,15 +97,15 @@
     # Now that we have asserted what we can about the original HSP values
     # and gotten them into ascending order, make some sane 0-based offsets.
     readStartInSubject = read_start - 1
     readEndInSubject = read_end
     subjectStart = sbjct_start - 1
     subjectEnd = sbjct_end
 
-    if blastApplication == "blastx":
+    if blastApplication == 'blastx':
         # In Blastx output, hit offsets are based on protein sequence
         # length but queries (and the reported offsets) are nucleotide.
         # Convert the read offsets to protein because we will plot against
         # the hit (protein).
         #
         # Note that readStartInSubject and readEndInSubject may not be 0 mod
         # 3. They are offsets into the read string giving the position of
@@ -136,28 +125,27 @@
     # variables are not named readEnd and readStart). Maybe someone made a
     # find and replace editing error which changed their names. Anyway, the
     # readLength variable is confusingly named because this function is
     # passed a 'readLen' argument, which does happen to be the full length
     # of the read.  This should be cleaned up. See ../diamond/hsp.py for
     # something cleaner.
 
-    hitGaps = hsp["sbjct"].count("-")
-    readGaps = hsp["query"].count("-")
+    hitGaps = hsp['sbjct'].count('-')
+    readGaps = hsp['query'].count('-')
 
     # Sanity check that the length of the matches in the hit and read
     # are identical, taking into account gaps in either (indicated by '-'
     # characters in the match sequences, as returned by BLAST).
     subjectLengthWithGaps = subjectLength + hitGaps
     readLengthWithGaps = readLength + readGaps
     if subjectLengthWithGaps != readLengthWithGaps:
-        debugPrint(
-            locals(),
-            "Including gaps, hit match length (%d) != Read match "
-            "length (%d)" % (subjectLengthWithGaps, readLengthWithGaps),
-        )
+        debugPrint(locals(),
+                   'Including gaps, hit match length (%d) != Read match '
+                   'length (%d)' % (subjectLengthWithGaps,
+                                    readLengthWithGaps))
 
     # TODO: check the mod 3 value of the start offsets.
 
     # Calculate read indices. These are indices relative to the hit!
 
     # unmatchedReadLeft is the number of read bases that will be sticking
     # out to the left of the start of the hit in our plots.
@@ -174,19 +162,19 @@
     else:
         readEndInSubject = subjectEnd + unmatchedReadLeft
 
         readStartInSubject = readEndInSubject - readLen - readGaps
 
     # Final sanity checks.
     if readStartInSubject > subjectStart:
-        debugPrint(locals(), "readStartInSubject > subjectStart")
+        debugPrint(locals(), 'readStartInSubject > subjectStart')
     if readEndInSubject < subjectEnd:
-        debugPrint(locals(), "readEndInSubject < subjectEnd")
+        debugPrint(locals(), 'readEndInSubject < subjectEnd')
 
     return {
-        "readStart": read_start - 1,
-        "readEnd": read_end,
-        "readStartInSubject": readStartInSubject,
-        "readEndInSubject": readEndInSubject,
-        "subjectStart": subjectStart,
-        "subjectEnd": subjectEnd,
+        'readStart': read_start - 1,
+        'readEnd': read_end,
+        'readStartInSubject': readStartInSubject,
+        'readEndInSubject': readEndInSubject,
+        'subjectStart': subjectStart,
+        'subjectEnd': subjectEnd,
     }
```

### Comparing `dark-matter-4.0.84/dark/blast/params.py` & `dark-matter-4.0.9/dark/blast/params.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,18 +1,16 @@
 # Parameters whose values may vary.
 
-VARIABLE_PARAMS = set(
-    [
-        "effective_search_space",
-        "effective_hsp_length",
-        "query",
-        "query_length",
-        "query_letters",
-    ]
-)
+VARIABLE_PARAMS = set([
+    'effective_search_space',
+    'effective_hsp_length',
+    'query',
+    'query_length',
+    'query_letters'
+])
 
 
 def checkCompatibleParams(initialParams, laterParams):
     """
     Check a later set of BLAST parameters against those originally found.
 
     @param initialParams: A C{dict} with the originally encountered BLAST
@@ -27,28 +25,22 @@
     # (as far as I've seen). This could become an issue one day if it
     # becomes non-empty and differs between JSON files that we cat
     # together. In that case we may need to be more specific in our params
     # compatible checking.
     err = []
     for param in initialParams:
         if param in laterParams:
-            if (
-                param not in VARIABLE_PARAMS
-                and initialParams[param] != laterParams[param]
-            ):
+            if (param not in VARIABLE_PARAMS and
+                    initialParams[param] != laterParams[param]):
                 err.append(
-                    "\tParam %r initial value %r differs from "
-                    "later value %r" % (param, initialParams[param], laterParams[param])
-                )
+                    '\tParam %r initial value %r differs from '
+                    'later value %r' % (param, initialParams[param],
+                                        laterParams[param]))
         else:
-            err.append(
-                "\t%r found in initial parameters, not found "
-                "in later parameters" % param
-            )
+            err.append('\t%r found in initial parameters, not found '
+                       'in later parameters' % param)
     for param in laterParams:
         if param not in initialParams:
-            err.append(
-                "\t%r found in later parameters, not seen in "
-                "initial parameters" % param
-            )
+            err.append('\t%r found in later parameters, not seen in '
+                       'initial parameters' % param)
 
-    return "Summary of differences:\n%s" % "\n".join(err) if err else None
+    return 'Summary of differences:\n%s' % '\n'.join(err) if err else None
```

### Comparing `dark-matter-4.0.84/dark/blast/records.py` & `dark-matter-4.0.9/dark/blast/records.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,21 +4,21 @@
 def printBlastRecord(record):
     """
     Print a BLAST record.
 
     @param record: A BioPython C{Bio.Blast.Record.Blast} instance.
     """
     for key in sorted(record.__dict__):
-        if key not in ["alignments", "descriptions", "reference"]:
-            print("%s: %r" % (key, record.__dict__[key]))
-    print("alignments: (%d in total):" % len(record.alignments))
+        if key not in ['alignments', 'descriptions', 'reference']:
+            print('%s: %r' % (key, record.__dict__[key]))
+    print('alignments: (%d in total):' % len(record.alignments))
     for i, alignment in enumerate(record.alignments):
-        print("  description %d:" % (i + 1))
-        for attr in ["accession", "bits", "e", "num_alignments", "score"]:
-            print("    %s: %s" % (attr, getattr(record.descriptions[i], attr)))
-        print("  alignment %d:" % (i + 1))
-        for attr in "accession", "hit_def", "hit_id", "length", "title":
-            print("    %s: %s" % (attr, getattr(alignment, attr)))
-        print("    HSPs (%d in total):" % len(alignment.hsps))
+        print('  description %d:' % (i + 1))
+        for attr in ['accession', 'bits', 'e', 'num_alignments', 'score']:
+            print('    %s: %s' % (attr, getattr(record.descriptions[i], attr)))
+        print('  alignment %d:' % (i + 1))
+        for attr in 'accession', 'hit_def', 'hit_id', 'length', 'title':
+            print('    %s: %s' % (attr, getattr(alignment, attr)))
+        print('    HSPs (%d in total):' % len(alignment.hsps))
         for hspIndex, hsp in enumerate(alignment.hsps, start=1):
-            print("      hsp %d:" % hspIndex)
-            printHSP(hsp, "        ")
+            print('      hsp %d:' % hspIndex)
+            printHSP(hsp, '        ')
```

### Comparing `dark-matter-4.0.84/dark/blast/score.py` & `dark-matter-4.0.9/dark/blast/score.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,43 +17,47 @@
 """
 
 from math import log
 
 _LOG2 = log(2.0)
 
 
-def bitScoreToEValue(bitScore, dbSize, dbSequenceCount, queryLength, lengthAdjustment):
+def bitScoreToEValue(bitScore, dbSize, dbSequenceCount, queryLength,
+                     lengthAdjustment):
     """
     Convert a bit score to an e-value.
 
     @param bitScore: The C{float} bit score to convert.
     @param dbSize: The C{int} total size of the database (i.e., the sum of
         the lengths of all sequences in the BLAST database).
     @param dbSequenceCount: The C{int} number of sequences in the database.
     @param queryLength: The C{int} length of the query.
     @param lengthAdjustment: The C{int} length adjustment (BLAST XML output
         calls this the Statistics_hsp-len).
     @return: A C{float} e-value.
     """
-    effectiveDbSize = (dbSize - dbSequenceCount * lengthAdjustment) * (
-        queryLength - lengthAdjustment
+    effectiveDbSize = (
+        (dbSize - dbSequenceCount * lengthAdjustment) *
+        (queryLength - lengthAdjustment)
     )
     return effectiveDbSize * (2.0 ** (-1.0 * bitScore))
 
 
-def eValueToBitScore(eValue, dbSize, dbSequenceCount, queryLength, lengthAdjustment):
+def eValueToBitScore(eValue, dbSize, dbSequenceCount, queryLength,
+                     lengthAdjustment):
     """
     Convert an e-value to a bit score.
 
     @param eValue: The C{float} e-value to convert.
     @param dbSize: The C{int} total size of the database (i.e., the sum of
         the lengths of all sequences in the BLAST database).
     @param dbSequenceCount: The C{int} number of sequences in the database.
     @param queryLength: The C{int} length of the query.
     @param lengthAdjustment: The C{int} length adjustment (BLAST XML output
         calls this the Statistics_hsp-len).
     @return: A C{float} bit score.
     """
-    effectiveDbSize = (dbSize - dbSequenceCount * lengthAdjustment) * (
-        queryLength - lengthAdjustment
+    effectiveDbSize = (
+        (dbSize - dbSequenceCount * lengthAdjustment) *
+        (queryLength - lengthAdjustment)
     )
     return -1.0 * (log(eValue / effectiveDbSize) / _LOG2)
```

### Comparing `dark-matter-4.0.84/dark/bowtie2.py` & `dark-matter-4.0.9/dark/bowtie2.py`

 * *Files 7% similar despite different names*

```diff
@@ -3,39 +3,32 @@
 import os
 from os.path import join
 import requests
 
 from dark.process import Executor
 
 
-class Bowtie2:
+class Bowtie2(object):
     """
     Run Bowtie2.
     """
 
-    def __init__(
-        self,
-        executor=None,
-        threads=None,
-        verboseFp=None,
-        dryRun=False,
-        reference=None,
-        tempdir=None,
-        tmpChmod=None,
-    ):
+    def __init__(self, executor=None, threads=None, verboseFp=None,
+                 dryRun=False, reference=None, tempdir=None,
+                 tmpChmod=None):
         self._executor = executor or Executor(dryRun)
         if dryRun:
-            self.tempdir = tempdir or "/tmp/xxx"
+            self.tempdir = tempdir or '/tmp/xxx'
         else:
-            self.tempdir = mkdtemp(prefix="bt2-", dir=tempdir)
+            self.tempdir = mkdtemp(prefix='bt2-', dir=tempdir)
             if tmpChmod:
-                self._executor.execute(f"chmod {tmpChmod} {self.tempdir}")
-        self._samFile = join(self.tempdir, "result.sam")
-        self._bamFile = join(self.tempdir, "result.bam")
-        self._indexFile = join(self.tempdir, "index")
+                self._executor.execute(f'chmod {tmpChmod} {self.tempdir}')
+        self._samFile = join(self.tempdir, 'result.sam')
+        self._bamFile = join(self.tempdir, 'result.bam')
+        self._indexFile = join(self.tempdir, 'index')
         self._verboseFp = verboseFp
         self._indexCalled = self._samExists = self._bamExists = False
         self.nThreads = threads or multiprocessing.cpu_count()
         self._reference = reference
 
     def buildIndex(self, index):
         """
@@ -43,355 +36,312 @@
         """
         if os.path.exists(index):
             # Check if this is a pre-existing bowtie2 index. Look for and
             # remove a bowtie2 suffix, if any (otherwise bowtie2 will
             # complain). We do things this way to allow a user to use TAB
             # completion on the command line to give them the full path to
             # any bowtie index file.
-            for suffix in ("1.bt2 2.bt2 3.bt2 4.bt2 rev.1.bt2 rev.2.bt2").split():
-                suffix = "." + suffix
+            for suffix in ('1.bt2 2.bt2 3.bt2 4.bt2 rev.1.bt2 '
+                           'rev.2.bt2').split():
+                suffix = '.' + suffix
                 if index.endswith(suffix):
-                    self._indexFile = index[: -len(suffix)]
-                    self._report(
-                        "Using pre-existing Bowtie2 index %r." % self._indexFile
-                    )
+                    self._indexFile = index[:-len(suffix)]
+                    self._report('Using pre-existing Bowtie2 index %r.' %
+                                 self._indexFile)
                     break
             else:
                 # Assume a FASTA file and make an index.
                 self._indexFile = self._makeIndexFromFastaFile(index)
         else:
             # Not a filename. So either the start of the path to a bowtie2
             # index or else an accession number.
-            if os.path.exists(index + ".1.bt2"):
-                self._report("Using pre-existing Bowtie2 index %r." % index)
+            if os.path.exists(index + '.1.bt2'):
+                self._report('Using pre-existing Bowtie2 index %r.' % index)
                 self._indexFile = index
             else:
                 # Assume an accession number.
                 self._indexFile = self._makeIndexFromAccession(index)
 
         self._indexCalled = True
 
-    def align(
-        self,
-        bowtie2Args="--no-unal",
-        fastq1=None,
-        fastq2=None,
-        threads=None,
-        discardSAM=False,
-        readGroup="orig",
-        sampleName="orig",
-    ):
+    def align(self, bowtie2Args='--no-unal', fastq1=None, fastq2=None,
+              threads=None, discardSAM=False, readGroup='orig',
+              sampleName='orig'):
         """
         Run Bowtie2.
         """
         if not self._indexCalled:
-            raise ValueError("buildIndex() has not yet been called.")
+            raise ValueError('buildIndex() has not yet been called.')
 
-        self._report("Aligning with Bowtie2.")
+        self._report('Aligning with Bowtie2.')
 
         nThreads = threads or self.nThreads
-        samFile = "/dev/null" if discardSAM else self._samFile
+        samFile = '/dev/null' if discardSAM else self._samFile
 
         if fastq1 and fastq2:
             self._executor.execute(
                 "bowtie2 %s --threads %d --rg-id '%s' --rg 'SM:%s' -x '%s' "
-                "-1 '%s' -2 '%s' > '%s'"
-                % (
-                    bowtie2Args,
-                    nThreads,
-                    readGroup,
-                    sampleName,
-                    self._indexFile,
-                    fastq1,
-                    fastq2,
-                    samFile,
-                )
-            )
+                "-1 '%s' -2 '%s' > '%s'" % (
+                    bowtie2Args, nThreads, readGroup, sampleName,
+                    self._indexFile, fastq1, fastq2, samFile))
         elif fastq1:
             self._executor.execute(
                 "bowtie2 %s --threads %d --rg-id '%s' --rg 'SM:%s' -x '%s' "
-                "-U '%s' > '%s'"
-                % (
-                    bowtie2Args,
-                    nThreads,
-                    readGroup,
-                    sampleName,
-                    self._indexFile,
-                    fastq1,
-                    samFile,
-                )
-            )
+                "-U '%s' > '%s'" % (
+                    bowtie2Args, nThreads, readGroup, sampleName,
+                    self._indexFile, fastq1, samFile))
         else:
-            raise ValueError("At least fastq1 must be passed.")
+            raise ValueError('At least fastq1 must be passed.')
 
         self._samExists = True
 
     def _report(self, mesg):
         """
         Print a progress message.
         """
         if self._verboseFp:
             print(mesg, file=self._verboseFp)
 
-    def makeBAM(self, samtoolsViewArgs=""):
+    def makeBAM(self, samtoolsViewArgs=''):
         """
         Convert the SAM to BAM.
         """
         # The following will raise if there is no SAM file.
         self._SAMorBAM()
-        self._report("Converting SAM to BAM.")
+        self._report('Converting SAM to BAM.')
         self._executor.execute(
-            "samtools view -b %s '%s' > '%s'"
-            % (samtoolsViewArgs, self._samFile, self._bamFile)
-        )
+            "samtools view -b %s '%s' > '%s'" %
+            (samtoolsViewArgs, self._samFile, self._bamFile))
         self._bamExists = True
 
     def _SAMorBAM(self):
         """
         Do we have a SAM or BAM file available?
         """
         if self._bamExists:
-            return "BAM"
+            return 'BAM'
         elif self._samExists:
-            return "SAM"
+            return 'SAM'
         else:
-            raise ValueError("bowtie2() has not yet been called.")
+            raise ValueError('bowtie2() has not yet been called.')
 
     def outputFile(self):
         """
         The name of the output file.
         """
         if self._bamExists:
             return self._bamFile
         elif self._samExists:
             return self._samFile
         else:
-            raise ValueError("bowtie2() has not yet been called.")
+            raise ValueError('bowtie2() has not yet been called.')
 
     def indexBAM(self):
         """
         Index the BAM file.
         """
         which = self._SAMorBAM()
 
-        if which != "BAM":
-            raise ValueError("makeBAM() has not yet been called.")
+        if which != 'BAM':
+            raise ValueError('makeBAM() has not yet been called.')
 
-        self._report("Indexing BAM.")
+        self._report('Indexing BAM.')
         self._executor.execute("samtools index '%s'" % self._bamFile)
 
     def sort(self, byName=False):
         """
         Sort the BAM or SAM.
         """
         which = self._SAMorBAM()
-        self._report("Sorting %s (by %s)." % (which, "name" if byName else "coord"))
-        inFile = self._bamFile if which == "BAM" else self._samFile
-        sortedFile = join(self.tempdir, "result-sorted." + which.lower())
+        self._report('Sorting %s (by %s).' % (
+            which, 'name' if byName else 'coord'))
+        inFile = self._bamFile if which == 'BAM' else self._samFile
+        sortedFile = join(self.tempdir, 'result-sorted.' + which.lower())
         self._executor.execute(
-            "samtools sort %s'%s' > '%s'"
-            % ("-n " if byName else "", inFile, sortedFile)
-        )
+            "samtools sort %s'%s' > '%s'" % (
+                '-n ' if byName else '', inFile, sortedFile))
         self._executor.execute("mv '%s' '%s'" % (sortedFile, inFile))
 
     def removePrimers(self, bedFile):
         """
         Removes primers specified in the bed file
         """
         which = self._SAMorBAM()
 
-        if which != "BAM":
-            raise ValueError("makeBAM() has not yet been called.")
+        if which != 'BAM':
+            raise ValueError('makeBAM() has not yet been called.')
 
         self._report("removing primers specified in %s" % bedFile)
         tempTrimmedBamPrefix = "%s.trimmed" % self._bamFile
         self._executor.execute(
-            "ivar trim -b '%s' -p '%s' -i '%s' -q 20 -m 30 -s 4 -e"
-            % (bedFile, tempTrimmedBamPrefix, self._bamFile)
-        )
-        self._executor.execute(
-            "mv '%s'.bam '%s'" % (tempTrimmedBamPrefix, self._bamFile)
-        )
+            "ivar trim -b '%s' -p '%s' -i '%s' -q 20 -m 30 -s 4 -e" %
+            (bedFile, tempTrimmedBamPrefix, self._bamFile))
+        self._executor.execute("mv '%s'.bam '%s'" %
+                               (tempTrimmedBamPrefix, self._bamFile))
 
     def markDuplicatesPicard(self, picardFile):
         """
         Use Picard to mark duplicates.
         """
         which = self._SAMorBAM()
-        self._report("Marking duplicates with Picard.")
+        self._report('Marking duplicates with Picard.')
 
-        inFile = self._bamFile if which == "BAM" else self._samFile
-        tempFile = join(self.tempdir, "picard-duplicates." + which.lower())
-        tempErrFile = join(self.tempdir, "picard.errs")
+        inFile = self._bamFile if which == 'BAM' else self._samFile
+        tempFile = join(self.tempdir, 'picard-duplicates.' + which.lower())
+        tempErrFile = join(self.tempdir, 'picard.errs')
 
         self._executor.execute(
-            "java -Xmn2g -Xms2g -Xmx2g -jar %s "
-            "MarkDuplicates I='%s' O='%s' M=/dev/null >'%s' 2>&1"
-            % (picardFile, inFile, tempFile, tempErrFile)
-        )
+            'java -Xmn2g -Xms2g -Xmx2g -jar %s '
+            "MarkDuplicates I='%s' O='%s' M=/dev/null >'%s' 2>&1" %
+            (picardFile, inFile, tempFile, tempErrFile))
 
         self._executor.execute("mv '%s' '%s'" % (tempFile, inFile))
 
     def markDuplicatesGATK(self, threads=None):
         """
         Use GATK to mark duplicates.
         """
         nThreads = threads or self.nThreads
         which = self._SAMorBAM()
-        self._report("Marking duplicates with GATK.")
+        self._report('Marking duplicates with GATK.')
 
-        inFile = self._bamFile if which == "BAM" else self._samFile
-        tempFile = join(self.tempdir, "gatk-duplicates." + which.lower())
+        inFile = self._bamFile if which == 'BAM' else self._samFile
+        tempFile = join(self.tempdir, 'gatk-duplicates.' + which.lower())
 
         self._executor.execute(
-            "gatk MarkDuplicatesSpark "
-            "-I '%s' -O '%s' --conf spark.executor.cores=%d"
-            % (inFile, tempFile, nThreads)
-        )
+            'gatk MarkDuplicatesSpark '
+            "-I '%s' -O '%s' --conf spark.executor.cores=%d" %
+            (inFile, tempFile, nThreads))
 
         self._executor.execute("mv '%s' '%s'" % (tempFile, inFile))
 
     def callHaplotypesGATK(self, picardJar, vcfFile=None, referenceFasta=None):
         """
         Use GATK to call haplotypes.
         """
         which = self._SAMorBAM()
-        self._report("Calling haplotypes with GATK.")
+        self._report('Calling haplotypes with GATK.')
 
-        inFile = self._bamFile if which == "BAM" else self._samFile
-        vcfFile = vcfFile or join(self.tempdir, "output.vcf.gz")
+        inFile = self._bamFile if which == 'BAM' else self._samFile
+        vcfFile = vcfFile or join(self.tempdir, 'output.vcf.gz')
 
         if referenceFasta is None:
             if self._reference:
-                self._report("Using %s as a reference." % self._reference)
+                self._report('Using %s as a reference.' % self._reference)
                 referenceFasta = self._reference
             else:
-                raise ValueError(
-                    "No reference was passed, given to the "
-                    "Bowtie2 __init__, or used in buildIndex."
-                )
+                raise ValueError('No reference was passed, given to the '
+                                 'Bowtie2 __init__, or used in buildIndex.')
 
-        indexFile = referenceFasta + ".fai"
+        indexFile = referenceFasta + '.fai'
         if os.path.exists(indexFile):
             removeIndex = False
         else:
             removeIndex = True
             self._executor.execute("samtools faidx '%s'" % referenceFasta)
 
-        if referenceFasta.lower().endswith(".fasta"):
-            dictFile = referenceFasta[: -len(".fasta")] + ".dict"
+        if referenceFasta.lower().endswith('.fasta'):
+            dictFile = referenceFasta[:-len('.fasta')] + '.dict'
         else:
-            dictFile = referenceFasta + ".dict"
+            dictFile = referenceFasta + '.dict'
 
         if os.path.exists(dictFile):
             removeDict = False
         else:
             removeDict = True
             self._executor.execute(
-                "java -jar '%s' CreateSequenceDictionary R='%s' O='%s'"
-                % (picardJar, referenceFasta, dictFile)
-            )
+                "java -jar '%s' CreateSequenceDictionary R='%s' O='%s'" %
+                (picardJar, referenceFasta, dictFile))
 
         self._executor.execute(
-            "gatk --java-options -Xmx4g HaplotypeCaller "
+            'gatk --java-options -Xmx4g HaplotypeCaller '
             "--reference '%s' "
             "--input '%s' "
             "--output '%s' "
             "--sample-ploidy 1 "
             "--dont-use-soft-clipped-bases true "
-            "-ERC GVCF" % (referenceFasta, inFile, vcfFile)
-        )
+            '-ERC GVCF' %
+            (referenceFasta, inFile, vcfFile))
 
         if removeIndex:
             self._executor.execute("rm '%s'" % indexFile)
 
         if removeDict:
             self._executor.execute("rm '%s'" % dictFile)
 
     def callHaplotypesBcftools(self, vcfFile=None, referenceFasta=None):
         """
         Use bcftools call to call haplotypes.
         """
         which = self._SAMorBAM()
-        self._report("Calling haplotypes with bcftools call.")
+        self._report('Calling haplotypes with bcftools call.')
 
-        inFile = self._bamFile if which == "BAM" else self._samFile
-        vcfFile = vcfFile or join(self.tempdir, "output.vcf.gz")
+        inFile = self._bamFile if which == 'BAM' else self._samFile
+        vcfFile = vcfFile or join(self.tempdir, 'output.vcf.gz')
 
         if referenceFasta is None:
             if self._reference:
-                self._report("Using %s as a reference." % self._reference)
+                self._report('Using %s as a reference.' % self._reference)
                 referenceFasta = self._reference
             else:
-                raise ValueError(
-                    "No reference was passed, given to the "
-                    "Bowtie2 __init__, or used in buildIndex."
-                )
+                raise ValueError('No reference was passed, given to the '
+                                 'Bowtie2 __init__, or used in buildIndex.')
 
         self._executor.execute(
             'bcftools mpileup --max-depth 5000 -Ou -f "%s" "%s" | '
-            'bcftools call --ploidy 1 -mv -Oz -o "%s"'
-            % (referenceFasta, inFile, vcfFile)
-        )
+            'bcftools call --ploidy 1 -mv -Oz -o "%s"' %
+            (referenceFasta, inFile, vcfFile))
 
-        self._executor.execute(f"bcftools index --force {vcfFile!r}")
+        self._executor.execute('bcftools index %s' % vcfFile)
 
     def removeDuplicates(self):
         """
         Use samtools to remove marked duplicates.
         """
         which = self._SAMorBAM()
-        self._report("Removing marked duplicates.")
+        self._report('Removing marked duplicates.')
 
-        inFile = self._bamFile if which == "BAM" else self._samFile
-        tempFile = join(self.tempdir, "non-duplicates." + which.lower())
+        inFile = self._bamFile if which == 'BAM' else self._samFile
+        tempFile = join(self.tempdir, 'non-duplicates.' + which.lower())
 
-        # See the comment on the testRemoveDuplicates test in
-        # ../test/test_bowtie2.py regarding there being two spaces in the
-        # samtools command below if we are not producing BAM.  If you
-        # change spacing here you will also need to change that test.
-        bArg = "-b" if which == "BAM" else ""
         self._executor.execute(
-            "samtools view %s -F 1024 '%s' > '%s'" % (bArg, inFile, tempFile)
-        )
+            "samtools view -b -F 1024 '%s' > '%s'" % (inFile, tempFile))
         self._executor.execute("mv '%s' '%s'" % (tempFile, inFile))
 
     def _makeIndexFromFastaFile(self, fastaFilename):
-        index = join(self.tempdir, "index")
+        index = join(self.tempdir, 'index')
 
-        self._report("Building Bowtie2 index from %s." % fastaFilename)
-        self._executor.execute(
-            "bowtie2-build --quiet '%s' '%s'" % (fastaFilename, index)
-        )
+        self._report('Building Bowtie2 index from %s.' % fastaFilename)
+        self._executor.execute("bowtie2-build --quiet '%s' '%s'" %
+                               (fastaFilename, index))
 
         if self._reference is None:
-            self._report("Will use this FASTA file as the reference (if needed).")
+            self._report('Will use this FASTA file as the reference '
+                         '(if needed).')
             self._reference = fastaFilename
 
         return index
 
     def _makeIndexFromAccession(self, accessionId):
-        fastaFilename = join(self.tempdir, accessionId + ".fasta")
-        index = join(self.tempdir, "index")
+        fastaFilename = join(self.tempdir, accessionId + '.fasta')
+        index = join(self.tempdir, 'index')
 
-        self._report("Downloading FASTA for accession %s from NCBI." % accessionId)
+        self._report('Downloading FASTA for accession %s from NCBI.' %
+                     accessionId)
 
-        URL = (
-            "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"
-            "db=nucleotide&id=%s&rettype=fasta&retmode=text" % accessionId
-        )
+        URL = ('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?'
+               'db=nucleotide&id=%s&rettype=fasta&retmode=text' % accessionId)
 
         if not self._executor.dryRun:
-            with open(fastaFilename, "w") as fp:
-                print(requests.get(URL).text.rstrip("\n"), file=fp)
+            with open(fastaFilename, 'w') as fp:
+                print(requests.get(URL).text.rstrip('\n'), file=fp)
 
-        self._report("Building bowtie2 index for %s." % accessionId)
-        self._executor.execute(
-            "bowtie2-build --quiet '%s' '%s'" % (fastaFilename, index)
-        )
+        self._report('Building bowtie2 index for %s.' % accessionId)
+        self._executor.execute("bowtie2-build --quiet '%s' '%s'" %
+                               (fastaFilename, index))
 
         return index
 
     def close(self):
         """
         Clean up.
         """
```

### Comparing `dark-matter-4.0.84/dark/btop.py` & `dark-matter-4.0.9/dark/btop.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-from dark.cigar import CINS_STR, CDEL_STR, CMATCH_STR, CEQUAL_STR, CDIFF_STR
+from dark.cigar import CINS, CDEL, CMATCH, CEQUAL, CDIFF
 
 
 def parseBtop(btopString):
     """
     Parse a BTOP string.
 
     The format is described at https://www.ncbi.nlm.nih.gov/books/NBK279682/
@@ -15,48 +15,45 @@
     isdigit = str.isdigit
     value = None
     queryLetter = None
     for offset, char in enumerate(btopString):
         if isdigit(char):
             if queryLetter is not None:
                 raise ValueError(
-                    "BTOP string %r has a query letter %r at offset %d with "
-                    "no corresponding subject letter"
-                    % (btopString, queryLetter, offset - 1)
-                )
+                    'BTOP string %r has a query letter %r at offset %d with '
+                    'no corresponding subject letter' %
+                    (btopString, queryLetter, offset - 1))
             value = int(char) if value is None else value * 10 + int(char)
         else:
             if value is not None:
                 yield value
                 value = None
                 queryLetter = char
             else:
                 if queryLetter is None:
                     queryLetter = char
                 else:
-                    if queryLetter == "-" and char == "-":
+                    if queryLetter == '-' and char == '-':
                         raise ValueError(
-                            "BTOP string %r has two consecutive gaps at "
-                            "offset %d" % (btopString, offset - 1)
-                        )
+                            'BTOP string %r has two consecutive gaps at '
+                            'offset %d' % (btopString, offset - 1))
                     elif queryLetter == char:
                         raise ValueError(
-                            "BTOP string %r has two consecutive identical %r "
-                            "letters at offset %d" % (btopString, char, offset - 1)
-                        )
+                            'BTOP string %r has two consecutive identical %r '
+                            'letters at offset %d' %
+                            (btopString, char, offset - 1))
                     yield (queryLetter, char)
                     queryLetter = None
 
     if value is not None:
         yield value
     elif queryLetter is not None:
         raise ValueError(
-            "BTOP string %r has a trailing query letter %r with "
-            "no corresponding subject letter" % (btopString, queryLetter)
-        )
+            'BTOP string %r has a trailing query letter %r with '
+            'no corresponding subject letter' % (btopString, queryLetter))
 
 
 def countGaps(btopString):
     """
     Count the query and subject gaps in a BTOP string.
 
     @param btopString: A C{str} BTOP sequence.
@@ -65,16 +62,16 @@
     @return: A 2-tuple of C{int}s, with the (query, subject) gaps counts as
         found in C{btopString}.
     """
     queryGaps = subjectGaps = 0
     for countOrMismatch in parseBtop(btopString):
         if isinstance(countOrMismatch, tuple):
             queryChar, subjectChar = countOrMismatch
-            queryGaps += int(queryChar == "-")
-            subjectGaps += int(subjectChar == "-")
+            queryGaps += int(queryChar == '-')
+            subjectGaps += int(subjectChar == '-')
 
     return (queryGaps, subjectGaps)
 
 
 def btop2cigar(btopString, concise=False, aa=False):
     """
     Convert a BTOP string to a CIGAR string.
@@ -91,50 +88,49 @@
         they refer to a number of amino acids matching.
     @raise ValueError: If L{parseBtop} finds an error in C{btopString} or
         if C{aa} and C{concise} are both C{True}.
     @return: A generator that yields C{str} pieces of a CIGAR string. Use
         ''.join(btopString(...)) to get a complete CIGAR string.
     """
     if aa and concise:
-        raise ValueError("aa and concise cannot both be True")
+        raise ValueError('aa and concise cannot both be True')
 
     thisLength = thisOperation = currentLength = currentOperation = None
 
     for item in parseBtop(btopString):
         if isinstance(item, int):
             thisLength = item
-            thisOperation = CEQUAL_STR if concise else CMATCH_STR
+            thisOperation = CEQUAL if concise else CMATCH
         else:
             thisLength = 1
             query, reference = item
-            if query == "-":
+            if query == '-':
                 # The query has a gap. That means that in matching the
                 # query to the reference a deletion is needed in the
                 # reference.
-                assert reference != "-"
-                thisOperation = CDEL_STR
-            elif reference == "-":
+                assert reference != '-'
+                thisOperation = CDEL
+            elif reference == '-':
                 # The reference has a gap. That means that in matching the
                 # query to the reference an insertion is needed in the
                 # reference.
-                thisOperation = CINS_STR
+                thisOperation = CINS
             else:
                 # A substitution was needed.
                 assert query != reference
-                thisOperation = CDIFF_STR if concise else CMATCH_STR
+                thisOperation = CDIFF if concise else CMATCH
 
         if thisOperation == currentOperation:
             currentLength += thisLength
         else:
             if currentOperation:
-                yield "%d%s" % (
-                    (3 * currentLength) if aa else currentLength,
-                    currentOperation,
-                )
+                yield '%d%s' % ((3 * currentLength) if aa else currentLength,
+                                currentOperation)
             currentLength, currentOperation = thisLength, thisOperation
 
     # We reached the end of the BTOP string. If there was an operation
     # underway, emit it.  The 'if' here should only be needed to catch the
     # case where btopString was empty.
-    assert currentOperation or btopString == ""
+    assert currentOperation or btopString == ''
     if currentOperation:
-        yield "%d%s" % ((3 * currentLength) if aa else currentLength, currentOperation)
+        yield '%d%s' % ((3 * currentLength) if aa else currentLength,
+                        currentOperation)
```

### Comparing `dark-matter-4.0.84/dark/civ/graphics.py` & `dark-matter-4.0.9/dark/civ/graphics.py`

 * *Files 14% similar despite different names*

```diff
@@ -2,22 +2,41 @@
 from copy import deepcopy
 from stat import S_ISDIR
 from math import ceil
 from time import ctime, time
 from textwrap import fill
 from os.path import join
 
-import matplotlib
+try:
+    import matplotlib
+    if not os.environ.get('DISPLAY'):
+        # Use non-interactive Agg backend
+        matplotlib.use('Agg')
+    import matplotlib.pyplot as plt
+except ImportError:
+    import platform
+    if platform.python_implementation() == 'PyPy':
+        # PyPy doesn't have a version of matplotlib. Make fake classes and
+        # a Line2D function that raises if used. This allows us to use
+        # other 'dark' code that happens to import dark.civ.graphics but
+        # which does not use the functions that rely on matplotlib.
+        class plt(object):
+            def __getattr__(self, _):
+                raise NotImplementedError(
+                    'matplotlib is not supported under pypy')
 
-if not os.environ.get("DISPLAY"):
-    # Use non-interactive Agg backend
-    matplotlib.use("Agg")
-import matplotlib.pyplot as plt
-from matplotlib.lines import Line2D
-from matplotlib import gridspec
+        gridspec = patches = plt
+
+        def Line2D(*args, **kwargs):
+            raise NotImplementedError('matplotlib is not supported under pypy')
+    else:
+        raise
+else:
+    from matplotlib.lines import Line2D
+    from matplotlib import gridspec
 
 from dark.dimension import dimensionalIterator
 from dark.html import NCBISequenceLinkURL
 from dark.civ.html import AlignmentPanelHTMLWriter
 from dark.intervals import ReadIntervals
 from dark.features import ProteinFeatureAdder, NucleotideFeatureAdder
 from dark.intervals import OffsetAdjuster
@@ -37,34 +56,23 @@
 
 # The default base of the logarithm to use when logLinearXAxis is used to
 # produce an alignment graph.
 DEFAULT_LOG_LINEAR_X_AXIS_BASE = 1.1
 
 
 def report(msg):
-    print("%s: %s" % (ctime(time()), msg))
+    print('%s: %s' % (ctime(time()), msg))
 
 
-def alignmentGraph(
-    titlesAlignments,
-    title,
-    accession,
-    addQueryLines=True,
-    showFeatures=True,
-    logLinearXAxis=False,
-    logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
-    rankScores=False,
-    createFigure=True,
-    showFigure=True,
-    readsAx=None,
-    imageFile=None,
-    quiet=False,
-    idList=False,
-    xRange="subject",
-):
+def alignmentGraph(titlesAlignments, title, accession, addQueryLines=True,
+                   showFeatures=True, logLinearXAxis=False,
+                   logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE, rankScores=False,
+                   createFigure=True, showFigure=True,
+                   readsAx=None, imageFile=None, quiet=False, idList=False,
+                   xRange='subject'):
     """
     Align a set of matching reads against a BLAST or DIAMOND hit.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param title: A C{str} sequence title that was matched. We plot the
         reads that hit this title.
     @param accession: The C{str} accession number of the matched title.
@@ -91,15 +99,16 @@
         of read identifiers that should be colored in the respective color.
     @param xRange: set to either 'subject' or 'reads' to indicate the range of
         the X axis.
     """
 
     startTime = time()
 
-    assert xRange in ("subject", "reads"), 'xRange must be either "subject" or "reads".'
+    assert xRange in ('subject', 'reads'), (
+        'xRange must be either "subject" or "reads".')
 
     if createFigure:
         width = 20
         figure = plt.figure(figsize=(width, 20))
 
     createdReadsAx = readsAx is None
 
@@ -125,43 +134,41 @@
     except AttributeError:
         pass
     else:
         adjuster(titleAlignments)
 
     if rankScores:
         reverse = titlesAlignments.scoreClass is not HigherIsBetterScore
-        for rank, hsp in enumerate(
-            sorted(titleAlignments.hsps(), reverse=reverse), start=1
-        ):
+        for rank, hsp in enumerate(sorted(titleAlignments.hsps(),
+                                   reverse=reverse), start=1):
             hsp.score.score = rank
 
     if logLinearXAxis:
         readIntervals = ReadIntervals(titleAlignments.subjectLength)
         # Examine all HSPs so we can build an offset adjuster.
         for hsp in titleAlignments.hsps():
             readIntervals.add(hsp.readStartInSubject, hsp.readEndInSubject)
         # Now adjust offsets in all HSPs.
         offsetAdjuster = OffsetAdjuster(readIntervals, base=logBase)
         for hsp in titleAlignments.hsps():
             offsetAdjuster.adjustHSP(hsp)
         # A function for adjusting other offsets, below.
         adjustOffset = offsetAdjuster.adjustOffset
     else:
-
         def adjustOffset(offset):
             return offset
 
     # It would be more efficient to only walk through all HSPs once and
     # compute these values all at once, but for now this is simple and clear.
     maxY = int(ceil(titleAlignments.bestHsp().score.score))
     minY = int(titleAlignments.worstHsp().score.score)
     maxX = max(hsp.readEndInSubject for hsp in titleAlignments.hsps())
     minX = min(hsp.readStartInSubject for hsp in titleAlignments.hsps())
 
-    if xRange == "subject":
+    if xRange == 'subject':
         # We'll display a graph for the full subject range. Adjust X axis
         # min/max to make sure we cover at least zero to the sequence length.
         maxX = max(titleAlignments.subjectLength, maxX)
         minX = min(0, minX)
 
     # Swap min & max Y values, if needed, as it's possible we are dealing
     # with LSPs but that the score adjuster made numerically greater values
@@ -190,89 +197,84 @@
 
     # Add light grey vertical rectangles to show the logarithmic gaps. Add
     # these first so that reads will be plotted on top of them. Only draw
     # gaps that are more than SMALLEST_LOGGED_GAP_TO_DISPLAY pixels wide as
     # we could have millions of tiny gaps for a bacteria and drawing them
     # all will be slow and only serves to make the entire background grey.
     if logLinearXAxis and len(offsetAdjuster.adjustments()) < 100:
-        for intervalType, interval in readIntervals.walk():
+        for (intervalType, interval) in readIntervals.walk():
             if intervalType == ReadIntervals.EMPTY:
                 adjustedStart = adjustOffset(interval[0])
                 adjustedStop = adjustOffset(interval[1])
                 width = adjustedStop - adjustedStart
                 if width >= SMALLEST_LOGGED_GAP_TO_DISPLAY:
-                    readsAx.axvspan(adjustedStart, adjustedStop, color="#f4f4f4")
+                    readsAx.axvspan(adjustedStart, adjustedStop,
+                                    color='#f4f4f4')
     else:
         # Add horizontal lines for all the query sequences. These will be the
         # grey 'whiskers' in the plots once we (below) draw the matched part
         # on top of part of them.
         if addQueryLines:
             for hsp in titleAlignments.hsps():
                 y = hsp.score.score
-                line = Line2D(
-                    [hsp.readStartInSubject, hsp.readEndInSubject],
-                    [y, y],
-                    color="#aaaaaa",
-                )
+                line = Line2D([hsp.readStartInSubject, hsp.readEndInSubject],
+                              [y, y], color='#aaaaaa')
                 readsAx.add_line(line)
 
         # Add the horizontal BLAST alignment lines.
 
         # If an idList is given set things up to look up read colors.
         readColor = {}
         if idList:
             for color, reads in idList.items():
                 for read in reads:
                     if read in readColor:
-                        raise ValueError(
-                            "Read %s is specified multiple times in idList" % read
-                        )
+                        raise ValueError('Read %s is specified multiple '
+                                         'times in idList' % read)
                     else:
                         readColor[read] = color
 
         # Draw the matched region.
         for titleAlignment in titleAlignments:
             readId = titleAlignment.read.id
             for hsp in titleAlignment.hsps:
                 y = hsp.score.score
-                line = Line2D(
-                    [hsp.subjectStart, hsp.subjectEnd],
-                    [y, y],
-                    color=readColor.get(readId, "blue"),
-                )
+                line = Line2D([hsp.subjectStart, hsp.subjectEnd], [y, y],
+                              color=readColor.get(readId, 'blue'))
                 readsAx.add_line(line)
 
     if showFeatures:
         if subjectIsNucleotides:
             featureAdder = NucleotideFeatureAdder()
         else:
             featureAdder = ProteinFeatureAdder()
 
-        features = featureAdder.add(featureAx, title, minX, maxX, adjustOffset)
+        features = featureAdder.add(featureAx, title, minX, maxX,
+                                    adjustOffset)
 
         # If there are features and there weren't too many of them, add
         # vertical feature lines to the reads and ORF axes.
         if features and not featureAdder.tooManyFeaturesToPlot:
             for feature in features:
                 start = feature.start
                 end = feature.end
                 color = feature.color
                 readsAx.axvline(x=start, color=color)
-                readsAx.axvline(x=end, color="#cccccc")
+                readsAx.axvline(x=end, color='#cccccc')
     else:
         features = None
 
     # We'll return some information we've gathered.
     result = {
-        "adjustOffset": adjustOffset,
-        "features": features,
-        "minX": minX,
-        "maxX": maxX,
-        "minY": minY,
-        "maxY": maxY,
+        'adjustOffset': adjustOffset,
+        'features': features,
+        'minX': minX,
+        'maxX': maxX,
+        'minY': minY,
+        'maxY': maxY,
     }
 
     # Allow the class of titlesAlignments to add to the plot, if it has a
     # method for doing so.
     try:
         adjuster = readsAlignments.adjustPlot
     except AttributeError:
@@ -281,64 +283,53 @@
         adjuster(readsAx)
 
     # Titles, axis, etc.
     if createFigure:
         readCount = titleAlignments.readCount()
         hspCount = titleAlignments.hspCount()
         figure.suptitle(
-            "%s (%s)\nLength %d %s, %d read%s, %d HSP%s."
-            % (
-                fill(titleAlignments.subjectTitle, 80),
-                accession,
+            '%s (%s)\nLength %d %s, %d read%s, %d HSP%s.' %
+            (
+                fill(titleAlignments.subjectTitle, 80), accession,
                 titleAlignments.subjectLength,
-                "nt" if subjectIsNucleotides else "aa",
-                readCount,
-                "" if readCount == 1 else "s",
-                hspCount,
-                "" if hspCount == 1 else "s",
+                'nt' if subjectIsNucleotides else 'aa',
+                readCount, '' if readCount == 1 else 's',
+                hspCount, '' if hspCount == 1 else 's'
             ),
-            fontsize=20,
-        )
+            fontsize=20)
 
     # Add a title and y-axis label, but only if we made the reads axes.
     if createdReadsAx:
-        readsAx.set_title("Read alignments", fontsize=20)
+        readsAx.set_title('Read alignments', fontsize=20)
         ylabel = readsAlignments.params.scoreTitle
         if rankScores:
-            ylabel += " rank"
+            ylabel += ' rank'
         plt.ylabel(ylabel, fontsize=17)
 
     # Set the x-axis limits.
     readsAx.set_xlim([minX - 1, maxX + 1])
 
     readsAx.set_ylim([0, int(maxY * Y_AXIS_UPPER_PADDING)])
     readsAx.grid()
     if createFigure:
         if showFigure:
             plt.show()
         if imageFile:
             figure.savefig(imageFile)
     stop = time()
     if not quiet:
-        report("Graph generated in %.3f mins." % ((stop - startTime) / 60.0))
+        report('Graph generated in %.3f mins.' % ((stop - startTime) / 60.0))
 
     return result
 
 
-def alignmentPanel(
-    titlesAlignments,
-    sortOn="maxScore",
-    idList=False,
-    equalizeXAxes=False,
-    xRange="subject",
-    logLinearXAxis=False,
-    rankScores=False,
-    showFeatures=True,
-    logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
-):
+def alignmentPanel(titlesAlignments, sortOn='maxScore', idList=False,
+                   equalizeXAxes=False, xRange='subject', logLinearXAxis=False,
+                   rankScores=False, showFeatures=True,
+                   logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE):
     """
     Produces a rectangular panel of graphs that each contain an alignment graph
     against a given sequence.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param sortOn: The attribute to sort subplots on. Either "maxScore",
         "medianScore", "readCount", "length", or "title".
@@ -356,156 +347,124 @@
         title to be their rank (worst to best).
     @param showFeatures: If C{True}, look online for features of the subject
         sequences.
     @raise ValueError: If C{outputDir} exists but is not a directory or if
         C{xRange} is not "subject" or "reads".
     """
 
-    if xRange not in ("subject", "reads"):
+    if xRange not in ('subject', 'reads'):
         raise ValueError('xRange must be either "subject" or "reads".')
 
     start = time()
     titles = titlesAlignments.sortTitles(sortOn)
     cols = 5
     rows = int(len(titles) / cols) + (0 if len(titles) % cols == 0 else 1)
     figure, ax = plt.subplots(rows, cols, squeeze=False)
     allGraphInfo = {}
     coords = dimensionalIterator((rows, cols))
 
-    report(
-        "Plotting %d titles in %dx%d grid, sorted on %s"
-        % (len(titles), rows, cols, sortOn)
-    )
+    report('Plotting %d titles in %dx%d grid, sorted on %s' %
+           (len(titles), rows, cols, sortOn))
 
     for i, title in enumerate(titles):
         titleAlignments = titlesAlignments[title]
         row, col = next(coords)
-        report("%d: %s %s" % (i, title, NCBISequenceLinkURL(title, "")))
+        report('%d: %s %s' % (i, title, NCBISequenceLinkURL(title, '')))
 
         # Add a small plot to the alignment panel.
         graphInfo = alignmentGraph(
-            titlesAlignments,
-            title,
-            addQueryLines=True,
-            showFeatures=showFeatures,
-            rankScores=rankScores,
-            logLinearXAxis=logLinearXAxis,
-            logBase=logBase,
-            createFigure=False,
-            showFigure=False,
-            readsAx=ax[row][col],
-            quiet=True,
-            idList=idList,
-            xRange=xRange,
-        )
+            titlesAlignments, title, addQueryLines=True,
+            showFeatures=showFeatures, rankScores=rankScores,
+            logLinearXAxis=logLinearXAxis, logBase=logBase,
+            createFigure=False, showFigure=False,
+            readsAx=ax[row][col], quiet=True, idList=idList, xRange=xRange)
 
         allGraphInfo[title] = graphInfo
         readCount = titleAlignments.readCount()
         hspCount = titleAlignments.hspCount()
 
         # Make a short title for the small panel blue plot, ignoring any
         # leading NCBI gi / accession numbers.
-        if title.startswith("gi|") and title.find(" ") > -1:
-            shortTitle = title.split(" ", 1)[1][:40]
+        if title.startswith('gi|') and title.find(' ') > -1:
+            shortTitle = title.split(' ', 1)[1][:40]
         else:
             shortTitle = title[:40]
 
-        plotTitle = "%d: %s\nLength %d, %d read%s, %d HSP%s." % (
-            i,
-            shortTitle,
-            titleAlignments.subjectLength,
-            readCount,
-            "" if readCount == 1 else "s",
-            hspCount,
-            "" if hspCount == 1 else "s",
-        )
+        plotTitle = ('%d: %s\nLength %d, %d read%s, %d HSP%s.' % (
+            i, shortTitle, titleAlignments.subjectLength,
+            readCount, '' if readCount == 1 else 's',
+            hspCount, '' if hspCount == 1 else 's'))
 
         if hspCount:
             if rankScores:
-                plotTitle += "\nY axis is ranked score"
+                plotTitle += '\nY axis is ranked score'
             else:
-                plotTitle += "\nmax %.2f, median %.2f" % (
+                plotTitle += '\nmax %.2f, median %.2f' % (
                     titleAlignments.bestHsp().score.score,
-                    titleAlignments.medianScore(),
-                )
+                    titleAlignments.medianScore())
 
         ax[row][col].set_title(plotTitle, fontsize=10)
 
-    maxX = max(graphInfo["maxX"] for graphInfo in allGraphInfo.values())
-    minX = min(graphInfo["minX"] for graphInfo in allGraphInfo.values())
-    maxY = max(graphInfo["maxY"] for graphInfo in allGraphInfo.values())
-    minY = min(graphInfo["minY"] for graphInfo in allGraphInfo.values())
+    maxX = max(graphInfo['maxX'] for graphInfo in allGraphInfo.values())
+    minX = min(graphInfo['minX'] for graphInfo in allGraphInfo.values())
+    maxY = max(graphInfo['maxY'] for graphInfo in allGraphInfo.values())
+    minY = min(graphInfo['minY'] for graphInfo in allGraphInfo.values())
 
     # Post-process graphs to adjust axes, etc.
 
     coords = dimensionalIterator((rows, cols))
     for title in titles:
         titleAlignments = titlesAlignments[title]
         row, col = next(coords)
         a = ax[row][col]
         a.set_ylim([0, int(maxY * Y_AXIS_UPPER_PADDING)])
         if equalizeXAxes:
             a.set_xlim([minX, maxX])
         a.set_yticks([])
         a.set_xticks([])
 
-        if xRange == "subject" and minX < 0:
+        if xRange == 'subject' and minX < 0:
             # Add a vertical line at x=0 so we can see the 'whiskers' of
             # reads that extend to the left of the sequence we're aligning
             # against.
-            a.axvline(x=0, color="#cccccc")
+            a.axvline(x=0, color='#cccccc')
 
         # Add a line on the right of each sub-plot so we can see where the
         # sequence ends (as all panel graphs have the same width and we
         # otherwise couldn't tell).
         sequenceLen = titleAlignments.subjectLength
         if logLinearXAxis:
-            sequenceLen = allGraphInfo[title]["adjustOffset"](sequenceLen)
-        a.axvline(x=sequenceLen, color="#cccccc")
+            sequenceLen = allGraphInfo[title]['adjustOffset'](sequenceLen)
+        a.axvline(x=sequenceLen, color='#cccccc')
 
     # Hide the final panel graphs (if any) that have no content. We do this
     # because the panel is a rectangular grid and some of the plots at the
     # end of the last row may be unused.
     for row, col in coords:
-        ax[row][col].axis("off")
+        ax[row][col].axis('off')
 
     # plt.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.93,
     # wspace=0.1, hspace=None)
     plt.subplots_adjust(hspace=0.4)
-    figure.suptitle(
-        "X: %d to %d, Y (%s): %d to %d"
-        % (
-            minX,
-            maxX,
-            titlesAlignments.readsAlignments.params.scoreTitle,
-            int(minY),
-            int(maxY),
-        ),
-        fontsize=20,
-    )
+    figure.suptitle('X: %d to %d, Y (%s): %d to %d' %
+                    (minX, maxX,
+                     titlesAlignments.readsAlignments.params.scoreTitle,
+                     int(minY), int(maxY)), fontsize=20)
     figure.set_size_inches(5 * cols, 3 * rows, forward=True)
     figure.show()
     stop = time()
-    report("Alignment panel generated in %.3f mins." % ((stop - start) / 60.0))
+    report('Alignment panel generated in %.3f mins.' % ((stop - start) / 60.0))
 
 
-def alignmentPanelHTML(
-    titlesAlignments,
-    proteinGenomeDB,
-    sortOn="maxScore",
-    outputDir=None,
-    idList=False,
-    equalizeXAxes=False,
-    xRange="subject",
-    logLinearXAxis=False,
-    logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
-    rankScores=False,
-    showFeatures=True,
-    subjectType="protein",
-):
+def alignmentPanelHTML(titlesAlignments, proteinGenomeDB, sortOn='maxScore',
+                       outputDir=None, idList=False, equalizeXAxes=False,
+                       xRange='subject', logLinearXAxis=False,
+                       logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
+                       rankScores=False, showFeatures=True,
+                       subjectType='protein'):
     """
     Produces an HTML index file in C{outputDir} and a collection of alignment
     graphs and FASTA files to summarize the information in C{titlesAlignments}.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param proteinGenomeDB: A L{dark.civ.proteins.SqliteIndex} instance.
     @param sortOn: The attribute to sort subplots on. Either "maxScore",
@@ -529,61 +488,50 @@
     @param subjectType: A C{str} indicating whether the matched subjects are
         'protein' or 'genome'. This is used to determine what accession number
         to extract from the matched title.
     @raise TypeError: If C{outputDir} is C{None}.
     @raise ValueError: If C{outputDir} is None or exists but is not a
         directory or if C{xRange} is not "subject" or "reads".
     """
-    if subjectType not in ("protein", "genome"):
+    if subjectType not in ('protein', 'genome'):
         raise ValueError('subjectType must be either "protein" or "genome".')
 
-    if xRange not in ("subject", "reads"):
+    if xRange not in ('subject', 'reads'):
         raise ValueError('xRange must be either "subject" or "reads".')
 
     if equalizeXAxes:
-        raise NotImplementedError("This feature is not yet implemented.")
+        raise NotImplementedError('This feature is not yet implemented.')
 
     titles = titlesAlignments.sortTitles(sortOn)
 
     if os.access(outputDir, os.F_OK):
         # outputDir exists. Check it's a directory.
         if not S_ISDIR(os.stat(outputDir).st_mode):
-            raise ValueError("%r is not a directory." % outputDir)
+            raise ValueError('%r is not a directory.' % outputDir)
     else:
         if outputDir is None:
-            raise ValueError("The outputDir needs to be specified.")
+            raise ValueError('The outputDir needs to be specified.')
         else:
             os.mkdir(outputDir)
 
     htmlWriter = AlignmentPanelHTMLWriter(outputDir, titlesAlignments)
 
-    getAccession = (
-        proteinGenomeDB.proteinAccession
-        if subjectType == "protein"
-        else proteinGenomeDB.genomeAccession
-    )
+    getAccession = (proteinGenomeDB.proteinAccession
+                    if subjectType == 'protein'
+                    else proteinGenomeDB.genomeAccession)
 
     for title in titles:
         accession = getAccession(title)
-        imageBasename = accession + ".png"
+        imageBasename = accession + '.png'
         imageFile = join(outputDir, imageBasename)
         graphInfo = alignmentGraph(
-            titlesAlignments,
-            title,
-            accession,
-            addQueryLines=True,
-            showFeatures=showFeatures,
-            rankScores=rankScores,
-            logLinearXAxis=logLinearXAxis,
-            logBase=logBase,
-            showFigure=False,
-            imageFile=imageFile,
-            quiet=True,
-            idList=idList,
-            xRange=xRange,
-        )
+            titlesAlignments, title, accession, addQueryLines=True,
+            showFeatures=showFeatures, rankScores=rankScores,
+            logLinearXAxis=logLinearXAxis, logBase=logBase,
+            showFigure=False, imageFile=imageFile,
+            quiet=True, idList=idList, xRange=xRange)
 
         # Close the image plot to make sure memory is flushed.
         plt.close()
         htmlWriter.addImage(imageBasename, accession, title, graphInfo)
 
     htmlWriter.close()
```

### Comparing `dark-matter-4.0.84/dark/civ/html.py` & `dark-matter-4.0.9/dark/civ/html.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,212 +1,198 @@
+from __future__ import print_function
+
 from os.path import join
 
 from dark.fastq import FastqReads
 from dark.html import NCBISequenceLinkURL
 
 
-class AlignmentPanelHTMLWriter:
+class AlignmentPanelHTMLWriter(object):
     """
     Produces HTML details of a rectangular panel of graphs that each
     contain an alignment graph against a given sequence. This is
     supplementary output info for the AlignmentPanel class in graphics.py.
 
     @param outputDir: The C{str} directory to write files into.
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     """
-
     def __init__(self, outputDir, titlesAlignments):
         self._outputDir = outputDir
         self._titlesAlignments = titlesAlignments
         self._images = []
 
     def addImage(self, imageBasename, accession, title, graphInfo):
-        self._images.append(
-            {
-                "accession": accession,
-                "graphInfo": graphInfo,
-                "imageBasename": imageBasename,
-                "title": title,
-            }
-        )
+        self._images.append({
+            'accession': accession,
+            'graphInfo': graphInfo,
+            'imageBasename': imageBasename,
+            'title': title
+        })
 
     def close(self):
-        with open(join(self._outputDir, "index.html"), "w") as fp:
+        with open(join(self._outputDir, 'index.html'), 'w') as fp:
             self._writeHeader(fp)
             self._writeBody(fp)
             self._writeFooter(fp)
-        with open(join(self._outputDir, "style.css"), "w") as fp:
+        with open(join(self._outputDir, 'style.css'), 'w') as fp:
             self._writeCSS(fp)
 
     def _writeHeader(self, fp):
-        fp.write(
-            """\
+        fp.write("""\
 <html>
   <head>
     <title>Read alignments for %d matched subjects</title>
     <link rel="stylesheet" type="text/css" href="style.css">
   </head>
   <body>
     <div id="content">
-        """
-            % len(self._images)
-        )
+        """ % len(self._images))
 
     def _writeBody(self, fp):
-        fp.write(
-            "<h1>Read alignments for %d matched subjects</h1>\n" % len(self._images)
-        )
+        fp.write('<h1>Read alignments for %d matched subjects</h1>\n' %
+                 len(self._images))
 
         # Write out an alignment panel as a table.
         cols = 6
-        fp.write("<table><tbody>\n")
+        fp.write('<table><tbody>\n')
 
         for i, image in enumerate(self._images):
-            title = image["title"]
-            accession = image["accession"]
+            title = image['title']
+            accession = image['accession']
             if i % cols == 0:
-                fp.write("<tr>\n")
+                fp.write('<tr>\n')
 
             fp.write(
                 '<td><a id="small_%s"></a><a href="#big_%s"><img src="%s" '
-                'class="thumbnail"/></a></td>\n'
-                % (accession, accession, image["imageBasename"])
-            )
+                'class="thumbnail"/></a></td>\n' %
+                (accession, accession, image['imageBasename']))
 
             if i % cols == cols - 1:
-                fp.write("</tr>")
+                fp.write('</tr>')
 
         # Add empty cells to the final table row, and close the row, if
         # necessary.
         if i % cols < cols - 1:
             while i % cols < cols - 1:
-                fp.write("<td>&nbsp;</td>\n")
+                fp.write('<td>&nbsp;</td>\n')
                 i += 1
-            fp.write("</tr>\n")
+            fp.write('</tr>\n')
 
-        fp.write("</tbody></table>\n")
+        fp.write('</tbody></table>\n')
 
         # Write out the full images with additional detail.
         for i, image in enumerate(self._images):
-            title = image["title"]
-            accession = image["accession"]
+            title = image['title']
+            accession = image['accession']
             titleAlignments = self._titlesAlignments[title]
-            graphInfo = image["graphInfo"]
+            graphInfo = image['graphInfo']
             readFormat = self._writeReads(image)
-            fp.write(
-                """
+            fp.write("""
       <a id="big_%s"></a>
       <h3>%d: %s</h3>
       <p>
             Length: %d.
             Read count: %d.
             HSP count: %d.
             <a href="%s.%s">%s</a>.
             <a href="#small_%s">Top panel.</a>
 """
-                % (
-                    accession,
-                    i,
-                    title,
-                    titleAlignments.subjectLength,
-                    titleAlignments.readCount(),
-                    titleAlignments.hspCount(),
-                    accession,
-                    readFormat,
-                    readFormat,
-                    accession,
-                )
-            )
+                     % (accession,
+                        i, title,
+                        titleAlignments.subjectLength,
+                        titleAlignments.readCount(),
+                        titleAlignments.hspCount(),
+                        accession, readFormat, readFormat,
+                        accession))
 
             url = NCBISequenceLinkURL(title)
             if url:
                 fp.write('<a href="%s" target="_blank">NCBI</a>.' % url)
 
             # Write out feature information.
-            if graphInfo["features"] is None:
+            if graphInfo['features'] is None:
                 # Feature lookup was False (or we were offline).
                 pass
-            elif len(graphInfo["features"]) == 0:
-                fp.write("There were no features.")
+            elif len(graphInfo['features']) == 0:
+                fp.write('There were no features.')
             else:
-                fp.write('<a href="%s">Features</a>' % self._writeFeatures(i, image))
+                fp.write('<a href="%s">Features</a>' %
+                         self._writeFeatures(i, image))
 
             # Write out the titles that this title invalidated due to its
             # read set.
             readSetFilter = self._titlesAlignments.readSetFilter
             if readSetFilter:
                 invalidated = readSetFilter.invalidates(title)
                 if invalidated:
                     nInvalidated = len(invalidated)
-                    fp.write(
-                        "<br/>This title invalidated %d other%s due to "
-                        "its read set:<ul>"
-                        % (nInvalidated, "" if nInvalidated == 1 else "s")
-                    )
+                    fp.write('<br/>This title invalidated %d other%s due to '
+                             'its read set:<ul>'
+                             % (nInvalidated,
+                                '' if nInvalidated == 1 else 's'))
                     for title in invalidated:
-                        fp.write("<li>%s</li>" % title)
-                    fp.write("</ul>")
+                        fp.write('<li>%s</li>' % title)
+                    fp.write('</ul>')
 
-            fp.write('</p><img src="%s" class="full-size"/>' % image["imageBasename"])
+            fp.write('</p><img src="%s" class="full-size"/>' %
+                     image['imageBasename'])
 
     def _writeFooter(self, fp):
-        fp.write(
-            """\
+        fp.write("""\
     </div>
   </body>
 </html>
-"""
-        )
+""")
 
     def _writeCSS(self, fp):
-        fp.write(
-            """\
+        fp.write("""\
 #content {
   width: 95%;
   margin: auto;
 }
 img.thumbnail {
   height: 300px;
 }
 img.full-size {
   height: 900px;
 }
-"""
-        )
+""")
 
     def _writeReads(self, image):
         """
         Write a FASTA or FASTQ file containing the set of reads that hit a
         sequence.
 
         @param image: A member of self._images.
         @return: A C{str}, either 'fasta' or 'fastq' indicating the format
             of the reads in C{self._titlesAlignments}.
         """
-        if isinstance(self._titlesAlignments.readsAlignments.reads, FastqReads):
-            format_ = "fastq"
+        if isinstance(self._titlesAlignments.readsAlignments.reads,
+                      FastqReads):
+            format_ = 'fastq'
         else:
-            format_ = "fasta"
-        filename = join(self._outputDir, "%s.%s" % (image["accession"], format_))
-        titleAlignments = self._titlesAlignments[image["title"]]
-        with open(filename, "w") as fp:
+            format_ = 'fasta'
+        filename = join(self._outputDir,
+                        '%s.%s' % (image['accession'], format_))
+        titleAlignments = self._titlesAlignments[image['title']]
+        with open(filename, 'w') as fp:
             for titleAlignment in titleAlignments:
                 fp.write(titleAlignment.read.toString(format_))
         return format_
 
     def _writeFeatures(self, image):
         """
         Write a text file containing the features as a table.
 
         @param image: A member of self._images.
         @return: The C{str} features file name - just the base name, not
             including the path to the file.
         """
-        basename = image["accession"] + "-features.txt"
+        basename = image['accession'] + '-features.txt'
         filename = join(self._outputDir, basename)
-        featureList = image["graphInfo"]["features"]
+        featureList = image['graphInfo']['features']
         # Note that the following (deliberately) creates an empty features
         # file if there were no features.
-        with open(filename, "w") as fp:
+        with open(filename, 'w') as fp:
             for feature in featureList:
-                fp.write("%s\n\n" % feature.feature)
+                fp.write('%s\n\n' % feature.feature)
         return basename
```

### Comparing `dark-matter-4.0.84/dark/civ/proteins.py` & `dark-matter-4.0.9/dark/civ/proteins.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+from __future__ import print_function
+
 import os
 import re
 import sqlite3
 import sys
 import numpy as np
 from Bio import SeqIO
 from cachetools import LRUCache, cachedmethod
@@ -18,44 +20,39 @@
 from dark.errors import DatabaseDuplicationError
 from dark.fasta import FastaReads
 from dark.fastq import FastqReads
 from dark.filter import TitleFilter
 from dark.genbank import getCDSInfo, getSourceInfo
 from dark.html import NCBISequenceLinkURL, NCBISequenceLink, readCountText
 from dark.reads import Reads
-from dark.sqlite3 import sqliteConnect
 from dark.taxonomy import (
-    lineageTaxonomyLinks,
-    Hierarchy,
-    LineageElement,
-    isAllowedTaxonomicRank,
-)
-from dark.utils import asHandle
+    # isDNAVirus, isRNAVirus, formatLineage,
+    lineageTaxonomyLinks, Hierarchy,
+    LineageElement)
 
 
-class PathogenSampleFiles:
+class PathogenSampleFiles(object):
     """
     Maintain a cache of FASTA/FASTQ file names for the samples that contain a
     given pathogen, create de-duplicated (by read id) FASTA/FASTQ files
     for each pathogen/sample pair, provide functions to write out index files
     of samples numbers (which are generated here in C{self.add}),
     and provide a filename lookup function for pathogen/sample combinations
     or just pathogen accessions by themselves.
 
     @param proteinGrouper: An instance of C{ProteinGrouper}.
     @param format_: A C{str}, either 'fasta' or 'fastq' indicating the format
         of the files containing the reads matching proteins.
     @raise ValueError: If C{format_} is unknown.
     """
-
-    def __init__(self, proteinGrouper, format_="fasta"):
+    def __init__(self, proteinGrouper, format_='fasta'):
         self._proteinGrouper = proteinGrouper
-        if format_ in ("fasta", "fastq"):
+        if format_ in ('fasta', 'fastq'):
             self._format = format_
-            self._readsClass = FastaReads if format_ == "fasta" else FastqReads
+            self._readsClass = FastaReads if format_ == 'fasta' else FastqReads
         else:
             raise ValueError("format_ must be either 'fasta' or 'fastq'.")
         self._pathogens = {}
         self._samples = {}
         self._readsFilenames = {}
 
     def add(self, genomeAccession, sampleName):
@@ -73,31 +70,29 @@
         """
         sampleIndex = self._samples.setdefault(sampleName, len(self._samples))
 
         try:
             return self._readsFilenames[(genomeAccession, sampleIndex)]
         except KeyError:
             reads = Reads()
-            for proteinMatch in self._proteinGrouper.genomeAccessions[genomeAccession][
-                sampleName
-            ]["proteins"].values():
-                for read in self._readsClass(proteinMatch["readsFilename"]):
+            for proteinMatch in self._proteinGrouper.genomeAccessions[
+                    genomeAccession][sampleName]['proteins'].values():
+                for read in self._readsClass(proteinMatch['readsFilename']):
                     reads.add(read)
             saveFilename = join(
-                proteinMatch["outDir"],
-                "pathogen-%s-sample-%d.%s"
-                % (genomeAccession, sampleIndex, self._format),
-            )
+                proteinMatch['outDir'],
+                'pathogen-%s-sample-%d.%s' % (genomeAccession, sampleIndex,
+                                              self._format))
             reads.filter(removeDuplicatesById=True)
             nReads = reads.save(saveFilename, format_=self._format)
             # Save the unique read count into self._proteinGrouper
-            self._proteinGrouper.genomeAccessions[genomeAccession][sampleName][
-                "uniqueReadCount"
-            ] = nReads
-            self._readsFilenames[(genomeAccession, sampleIndex)] = saveFilename
+            self._proteinGrouper.genomeAccessions[
+                genomeAccession][sampleName]['uniqueReadCount'] = nReads
+            self._readsFilenames[
+                (genomeAccession, sampleIndex)] = saveFilename
             return saveFilename
 
     def lookup(self, genomeAccession, sampleName):
         """
         Look up a pathogen accession number, sample name combination and get
         its FASTA/FASTQ file name.
 
@@ -107,34 +102,30 @@
 
         @param genomeAccession: A C{str} pathogen accession number.
         @param sampleName: A C{str} sample name.
         @raise KeyError: If the pathogen accession number or sample name have
             not been seen, either individually or in combination.
         @return: A C{str} filename retrieved from self._readsFilenames
         """
-        return self._readsFilenames[(genomeAccession, self._samples[sampleName])]
+        return self._readsFilenames[
+            (genomeAccession, self._samples[sampleName])]
 
     def writeSampleIndex(self, fp):
         """
         Write a file of sample indices and names, sorted by index.
 
         @param fp: A file-like object, opened for writing.
         """
-        print(
-            "\n".join(
-                "%d %s" % (index, name)
-                for (index, name) in sorted(
-                    (index, name) for (name, index) in self._samples.items()
-                )
-            ),
-            file=fp,
-        )
+        print('\n'.join(
+            '%d %s' % (index, name) for (index, name) in
+            sorted((index, name) for (name, index) in self._samples.items())
+        ), file=fp)
 
 
-class ProteinGrouper:
+class ProteinGrouper(object):
     """
     Group matched proteins by the pathogen they come from.
 
     @param proteinGenomeDatabase: A connection to an Sqlite3 database
         holding protein and genome information, as built by
         C{make-protein-database.py}.
     @param assetDir: The C{str} directory name where
@@ -162,47 +153,38 @@
         refseq database and RVDB.
     @param pathogenDataDir: The C{str} directory where per-pathogen information
         (e.g., collected reads across all samples) should be written. Will be
         created (in C{self.toHTML}) if it doesn't exist.
     @raise ValueError: If C{format_} is unknown.
     """
 
-    VIRALZONE = "https://viralzone.expasy.org/search?query="
-    ICTV = "https://talk.ictvonline.org/search-124283882/?q="
-    READCOUNT_MARKER = "*READ-COUNT*"
-    READ_AND_HSP_COUNT_STR_SEP = "/"
-
-    def __init__(
-        self,
-        proteinGenomeDatabase,
-        taxonomyDatabase,
-        assetDir="out",
-        sampleName=None,
-        sampleNameRegex=None,
-        format_="fasta",
-        saveReadLengths=False,
-        titleRegex=None,
-        negativeTitleRegex=None,
-        pathogenDataDir="pathogen-data",
-    ):
+    VIRALZONE = 'https://viralzone.expasy.org/search?query='
+    ICTV = 'https://talk.ictvonline.org/search-124283882/?q='
+    READCOUNT_MARKER = '*READ-COUNT*'
+    READ_AND_HSP_COUNT_STR_SEP = '/'
+
+    def __init__(self, proteinGenomeDatabase, taxonomyDatabase, assetDir='out',
+                 sampleName=None, sampleNameRegex=None, format_='fasta',
+                 saveReadLengths=False, titleRegex=None,
+                 negativeTitleRegex=None, pathogenDataDir='pathogen-data'):
         self._db = proteinGenomeDatabase
         self._taxdb = taxonomyDatabase
         self._assetDir = assetDir
         self._sampleName = sampleName
-        self._sampleNameRegex = re.compile(sampleNameRegex) if sampleNameRegex else None
-        if format_ in ("fasta", "fastq"):
+        self._sampleNameRegex = (re.compile(sampleNameRegex) if sampleNameRegex
+                                 else None)
+        if format_ in ('fasta', 'fastq'):
             self._format = format_
         else:
             raise ValueError("format_ must be either 'fasta' or 'fastq'.")
         self._saveReadLengths = saveReadLengths
 
         if titleRegex or negativeTitleRegex:
             self.titleFilter = TitleFilter(
-                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex
-            )
+                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex)
         else:
             self.titleFilter = None
 
         self._pathogenDataDir = pathogenDataDir
 
         # genomeAccessions will be a dict of dicts of dicts. The first
         # two keys will be a pathogen accession and a sample name. The
@@ -214,37 +196,31 @@
         self.sampleNames = {}
         self.pathogenSampleFiles = PathogenSampleFiles(self, format_=format_)
 
     def _title(self, pathogenType):
         """
         Create a title summarizing the pathogens and samples.
 
-        @param pathogenType: A C{str}, either 'viral', 'bacterial' or
-            'generic'.
+        @param pathogenType: A C{str}, either 'viral' or 'bacterial'.
         @return: A C{str} title.
         """
 
-        assert pathogenType in ("bacterial", "viral", "generic")
+        assert pathogenType in ('viral', 'bacterial')
 
         nPathogens = len(self.genomeAccessions)
         nSamples = len(self.sampleNames)
 
-        if pathogenType == "bacterial":
-            what = "bacterium" if nPathogens == 1 else "bacteria"
-        elif pathogenType == "viral":
-            what = "virus%s" % ("" if nPathogens == 1 else "es")
+        if pathogenType == 'bacterial':
+            what = 'bacterium' if nPathogens == 1 else 'bacteria'
         else:
-            what = "pathogen%s" % ("" if nPathogens == 1 else "es")
+            what = 'virus%s' % ('' if nPathogens == 1 else 'es')
 
-        return "Proteins from %d %s were found in %d sample%s." % (
-            nPathogens,
-            what,
-            nSamples,
-            "" if nSamples == 1 else "s",
-        )
+        return (
+            'Proteins from %d %s were found in %d sample%s.' %
+            (nPathogens, what, nSamples, '' if nSamples == 1 else 's'))
 
     def addFile(self, filename, fp):
         """
         Read and record protein information for a sample.
 
         @param filename: A C{str} file name.
         @param fp: An open file pointer to read the file's data from.
@@ -260,26 +236,19 @@
             else:
                 sampleName = filename
         else:
             sampleName = filename
 
         outDir = join(dirname(filename), self._assetDir)
 
-        self.sampleNames[sampleName] = join(outDir, "index.html")
+        self.sampleNames[sampleName] = join(outDir, 'index.html')
 
         for index, proteinLine in enumerate(fp):
-            (
-                coverage,
-                medianScore,
-                bestScore,
-                readCount,
-                hspCount,
-                proteinLength,
-                longName,
-            ) = proteinLine.split(None, 6)
+            (coverage, medianScore, bestScore, readCount, hspCount,
+             proteinLength, longName) = proteinLine.split(None, 6)
 
             proteinInfo = self._db.findProtein(longName)
             if proteinInfo is None:
                 try:
                     accession = self._db.proteinAccession(longName)
                 except IndexError:
                     accession = longName
@@ -299,240 +268,213 @@
                 # issuing a warning would risk silently being in a situation
                 # where nothing at all matched, e.g., due to passing an
                 # incorrect database name. This error happens infrequently and
                 # IMO it's better that we cause an error, force the user
                 # (usually me, unfortunately) to investigate, clean up
                 # properly, and re-run.
                 raise ValueError(
-                    "Could not find protein info for accession number %r "
-                    "(extracted from %r). In the past, this hard-to-debug "
-                    "(hence this long message!) error has resulted from using "
-                    "a new genome/protein database to process results that "
-                    "were generated based on an earlier version of the "
-                    "database, in which case proteins that were present then "
-                    "are not now in the database." % (accession, longName)
-                )
-            proteinName = proteinInfo["product"] or proteinInfo["gene"] or "unknown"
-            proteinAccession = proteinInfo["accession"]
+                    'Could not find protein info for accession number %r '
+                    '(extracted from %r). In the past, this hard-to-debug '
+                    '(hence this long message!) error has resulted from using '
+                    'a new genome/protein database to process results that '
+                    'were generated based on an earlier version of the '
+                    'database, in which case proteins that were present then '
+                    'are not now in the database.' % (accession, longName))
+            proteinName = (proteinInfo['product'] or proteinInfo['gene'] or
+                           'unknown')
+            proteinAccession = proteinInfo['accession']
 
             genomeInfo = self._db.findGenome(longName)
-            genomeName = genomeInfo["name"]
-            genomeAccession = genomeInfo["accession"]
+            genomeName = genomeInfo['name']
+            genomeAccession = genomeInfo['accession']
 
             # Ignore genomes with names we don't want.
-            if (
-                self.titleFilter
-                and self.titleFilter.accept(genomeName) == TitleFilter.REJECT
-            ):
+            if (self.titleFilter and self.titleFilter.accept(
+                    genomeName) == TitleFilter.REJECT):
                 continue
 
             if sampleName not in self.genomeAccessions[genomeAccession]:
                 self.genomeAccessions[genomeAccession][sampleName] = {
-                    "proteins": {},
-                    "uniqueReadCount": None,
+                    'proteins': {},
+                    'uniqueReadCount': None,
                 }
 
-            proteins = self.genomeAccessions[genomeAccession][sampleName]["proteins"]
+            proteins = self.genomeAccessions[
+                genomeAccession][sampleName]['proteins']
 
             # We should only receive one line of information for a given
             # genome/sample/protein combination.
             if proteinAccession in proteins:
                 raise ValueError(
-                    "Protein %r already seen for genome %r (%s) sample %r."
-                    % (proteinAccession, genomeName, genomeAccession, sampleName)
-                )
-
-            readsFilename = join(outDir, "%s.%s" % (proteinAccession, self._format))
-
-            if longName.startswith(
-                SqliteIndexWriter.SEQUENCE_ID_PREFIX
-                + SqliteIndexWriter.SEQUENCE_ID_SEPARATOR
-            ):
+                    'Protein %r already seen for genome %r (%s) sample %r.' %
+                    (proteinAccession, genomeName, genomeAccession,
+                     sampleName))
+
+            readsFilename = join(outDir,
+                                 '%s.%s' % (proteinAccession, self._format))
+
+            if longName.startswith(SqliteIndexWriter.SEQUENCE_ID_PREFIX +
+                                   SqliteIndexWriter.SEQUENCE_ID_SEPARATOR):
                 proteinURL = NCBISequenceLinkURL(longName, field=2)
                 genomeURL = NCBISequenceLinkURL(longName, field=4)
             else:
                 proteinURL = genomeURL = None
 
             proteinInfo = proteins[proteinAccession] = {
-                "accession": proteinAccession,
-                "bestScore": float(bestScore),
-                "bluePlotFilename": join(outDir, "%s.png" % proteinAccession),
-                "coverage": float(coverage),
-                "readsFilename": readsFilename,
-                "hspCount": int(hspCount),
-                "index": index,
-                "medianScore": float(medianScore),
-                "outDir": outDir,
-                "proteinLength": int(proteinLength),
-                "proteinName": proteinName,
-                "proteinURL": proteinURL,
-                "genomeURL": genomeURL,
-                "readCount": int(readCount),
+                'accession': proteinAccession,
+                'bestScore': float(bestScore),
+                'bluePlotFilename': join(outDir, '%s.png' % proteinAccession),
+                'coverage': float(coverage),
+                'readsFilename': readsFilename,
+                'hspCount': int(hspCount),
+                'index': index,
+                'medianScore': float(medianScore),
+                'outDir': outDir,
+                'proteinLength': int(proteinLength),
+                'proteinName': proteinName,
+                'proteinURL': proteinURL,
+                'genomeURL': genomeURL,
+                'readCount': int(readCount),
             }
 
-            if proteinInfo["readCount"] == proteinInfo["hspCount"]:
-                proteinInfo["readAndHspCountStr"] = readCount
+            if proteinInfo['readCount'] == proteinInfo['hspCount']:
+                proteinInfo['readAndHspCountStr'] = readCount
             else:
-                proteinInfo["readAndHspCountStr"] = "%s%s%s" % (
-                    readCount,
-                    self.READ_AND_HSP_COUNT_STR_SEP,
-                    hspCount,
-                )
+                proteinInfo['readAndHspCountStr'] = '%s%s%s' % (
+                    readCount, self.READ_AND_HSP_COUNT_STR_SEP, hspCount)
 
             if self._saveReadLengths:
-                readsClass = FastaReads if self._format == "fasta" else FastqReads
-                proteins[proteinName]["readLengths"] = tuple(
-                    len(read) for read in readsClass(readsFilename)
-                )
+                readsClass = (FastaReads if self._format == 'fasta'
+                              else FastqReads)
+                proteins[proteinName]['readLengths'] = tuple(
+                    len(read) for read in readsClass(readsFilename))
 
     def _computeUniqueReadCounts(self):
         """
         Add all pathogen / sample combinations to self.pathogenSampleFiles.
 
         This will make all de-duplicated (by id) FASTA/FASTQ files and store
         the number of de-duplicated reads into C{self.genomeAccessions}.
         """
         for genomeAccession, samples in self.genomeAccessions.items():
             for sampleName in samples:
                 self.pathogenSampleFiles.add(genomeAccession, sampleName)
 
-    def toStr(self, title=None, preamble=None, pathogenType="viral"):
+    def toStr(self, title=None, preamble=None, pathogenType='viral'):
         """
         Produce a string representation of the pathogen summary.
 
         @param title: The C{str} title for the output.
         @param preamble: The C{str} descriptive preamble, or C{None} if no
             preamble is needed.
-        @param pathogenType: A C{str}, either 'viral', 'bacterial' or
-            'generic'.
+        @param pathogenType: A C{str}, either 'viral' or 'bacterial'.
 
         @return: A C{str} suitable for printing.
         """
         # Note that the string representation contains much less
         # information than the HTML summary. E.g., it does not contain the
         # unique (de-duplicated, by id) read count, since that is only computed
         # when we are making combined FASTA files of reads matching a
         # pathogen.
 
-        assert pathogenType in ("viral", "bacterial", "generic")
+        assert pathogenType in ('viral', 'bacterial')
 
-        title = title or "Summary of %s." % (
-            "bacteria"
-            if pathogenType == "bacterial"
-            else ("viruses" if pathogenType == "viral" else "pathogens")
-        )
+        title = title or 'Summary of %s.' % (
+            'bacteria' if pathogenType == 'bacterial' else 'viruses')
 
-        readCountGetter = itemgetter("readCount")
+        readCountGetter = itemgetter('readCount')
         result = []
         append = result.append
 
-        result.extend((title, ""))
+        result.extend((title, ''))
         if preamble:
-            result.extend((preamble, ""))
-        result.extend((self._title(pathogenType), ""))
+            result.extend((preamble, ''))
+        result.extend((self._title(pathogenType), ''))
 
         for genomeAccession, samples in self.genomeAccessions.items():
             genomeInfo = self._db.findGenome(genomeAccession)
-            genomeName = genomeInfo["name"]
+            genomeName = genomeInfo['name']
             sampleCount = len(samples)
-            append(
-                "%s (in %d sample%s)"
-                % (genomeName, sampleCount, "" if sampleCount == 1 else "s")
-            )
+            append('%s (in %d sample%s)' %
+                   (genomeName,
+                    sampleCount, '' if sampleCount == 1 else 's'))
             for sampleName in sorted(samples):
-                proteins = samples[sampleName]["proteins"]
+                proteins = samples[sampleName]['proteins']
                 proteinCount = len(proteins)
                 totalReads = sum(readCountGetter(p) for p in proteins.values())
-                append(
-                    "  %s (%d protein%s, %d read%s)"
-                    % (
-                        sampleName,
-                        proteinCount,
-                        "" if proteinCount == 1 else "s",
-                        totalReads,
-                        "" if totalReads == 1 else "s",
-                    )
-                )
+                append('  %s (%d protein%s, %d read%s)' %
+                       (sampleName,
+                        proteinCount, '' if proteinCount == 1 else 's',
+                        totalReads, '' if totalReads == 1 else 's'))
                 for proteinName in sorted(proteins):
                     append(
-                        "    %(coverage).2f\t%(medianScore).2f\t"
-                        "%(bestScore).2f\t%(readAndHspCountStr)3s\t"
-                        "%(proteinName)s" % proteins[proteinName]
-                    )
-            append("")
+                        '    %(coverage).2f\t%(medianScore).2f\t'
+                        '%(bestScore).2f\t%(readAndHspCountStr)3s\t'
+                        '%(proteinName)s'
+                        % proteins[proteinName])
+            append('')
 
-        return "\n".join(result)
+        return '\n'.join(result)
 
     def _genomeName(self, genomeAccession):
         """
         Get the name of a genome, given its accession number.
 
         @param genomeAccession: A C{str} pathogen accession number.
         @return: A C{str} genome name.
         """
-        return self._db.findGenome(genomeAccession)["organism"]
+        return self._db.findGenome(genomeAccession)['organism']
 
     def _makeSampleSorter(self):
         """
         Make a function to sort sample names with, using the 3rd
         underscore-separated field of each name as an integer, if possible.
         """
         # Note: we could do this without the allSampleNamesHaveIntThirdField
         # variable by defining a function in the 'except' clause and adding an
         # 'else' to the 'for' loop, but that causes flake8 to complain that the
         # unused _key function (in the except) has been redefined (in the
         # else).
         allSampleNamesHaveIntThirdField = True
         for sampleName in self.sampleNames:
             try:
-                int(sampleName.split("_", maxsplit=3)[2])
+                int(sampleName.split('_', maxsplit=3)[2])
             except (IndexError, ValueError):
                 allSampleNamesHaveIntThirdField = False
                 break
 
         if allSampleNamesHaveIntThirdField:
-
             def _key(sampleName):
-                return int(sampleName.split("_", maxsplit=3)[2])
-
+                return int(sampleName.split('_', maxsplit=3)[2])
         else:
-
             def _key(sampleName):
                 return sampleName
 
         self.sampleSort = partial(sorted, key=_key)
 
-    def toHTML(
-        self,
-        pathogenPanelFilename=None,
-        readCountColors=None,
-        minProteinFraction=0.0,
-        minProteinCount=0,
-        pathogenType="viral",
-        title=None,
-        preamble=None,
-        sampleIndexFilename=None,
-        omitVirusLinks=False,
-        bootstrapTreeviewDir=None,
-    ):
+    def toHTML(self, pathogenPanelFilename=None, readCountColors=None,
+               minProteinFraction=0.0, minProteinCount=0,
+               pathogenType='viral', title=None, preamble=None,
+               sampleIndexFilename=None, omitVirusLinks=False,
+               bootstrapTreeviewDir=None):
         """
         Produce an HTML string representation of the pathogen summary.
 
         @param pathogenPanelFilename: If not C{None}, a C{str} filename to
             write a pathogen panel PNG image to.
         @param readCountColors: Either a C{dark.colors.colorsForCounts}
             instance or C{None} for no read count coloring.
         @param minProteinFraction: The C{float} minimum fraction of proteins
             in a pathogen that must be matched by a sample in order for that
             pathogen to be displayed for that sample.
         @param minProteinCount: The C{int} minimum number of proteins
             in a pathogen that must be matched by a sample in order for that
             pathogen to be displayed for that sample.
         @param pathogenType: A C{str} giving the type of the pathogen involved,
-            either 'bacterial', 'viral', or 'generic'.
+            either 'bacterial' or 'viral'.
         @param title: The C{str} title for the HTML page or C{None} to get a
             default generic title depending on whether a viral or bacterial
             database was matched against.
         @param preamble: The C{str} descriptive preamble for the HTML page, or
             C{None} if no preamble is needed.
         @param sampleIndexFilename: A C{str} filename to write a sample index
             file to. Lines in the file will have an integer index, a space, and
@@ -540,125 +482,112 @@
         @param omitVirusLinks: If C{True}, links to ICTV and ViralZone will be
             omitted in output.
         @param bootstrapTreeviewDir: A C{str} giving the directory where the
             bootstrap-treeview JS and CSS files may be found. Or C{None} if no
             bootstrap-treeview output should be generated.
         @return: An HTML C{str} suitable for printing.
         """
-        if pathogenType == "bacterial":
-            singular, plural = "bacterium", "bacteria"
-        elif pathogenType == "viral":
-            singular, plural = "virus", "viruses"
-        elif pathogenType == "generic":
-            singular, plural = "pathogen", "pathogens"
+        if pathogenType == 'bacterial':
+            singular, plural = 'bacterium', 'bacteria'
+        elif pathogenType == 'viral':
+            singular, plural = 'virus', 'viruses'
         else:
             raise ValueError(
                 "Unrecognized pathogenType argument: %r. Value must be either "
-                "'bacterial', 'viral', or 'generic'." % pathogenType
-            )
+                "'bacterial' or 'viral'." % pathogenType)
 
         if not exists(self._pathogenDataDir):
             os.mkdir(self._pathogenDataDir)
 
-        title = title or "Summary of " + plural
+        title = title or 'Summary of ' + plural
 
         self._makeSampleSorter()
         self._computeUniqueReadCounts()
 
         if sampleIndexFilename:
-            with open(sampleIndexFilename, "w") as fp:
+            with open(sampleIndexFilename, 'w') as fp:
                 self.pathogenSampleFiles.writeSampleIndex(fp)
 
         # Figure out if we have to delete some pathogens because the number
         # or fraction of its proteins that we have matches for is too low.
         if minProteinFraction > 0.0 or minProteinCount > 0:
             toDelete = defaultdict(list)
             for genomeAccession in self.genomeAccessions:
                 genomeInfo = self._db.findGenome(genomeAccession)
-                pathogenProteinCount = genomeInfo["proteinCount"]
+                pathogenProteinCount = genomeInfo['proteinCount']
                 assert pathogenProteinCount > 0
                 for s in self.genomeAccessions[genomeAccession]:
-                    sampleProteinCount = len(
-                        self.genomeAccessions[genomeAccession][s]["proteins"]
-                    )
+                    sampleProteinCount = len(self.genomeAccessions[
+                        genomeAccession][s]['proteins'])
                     if sampleProteinCount < minProteinCount:
                         toDelete[genomeAccession].append(s)
                     else:
                         sampleProteinFraction = (
-                            sampleProteinCount / pathogenProteinCount
-                        )
+                            sampleProteinCount / pathogenProteinCount)
                         if sampleProteinFraction < minProteinFraction:
                             toDelete[genomeAccession].append(s)
 
             for genomeAccession, samples in toDelete.items():
                 for sample in samples:
                     del self.genomeAccessions[genomeAccession][sample]
 
         genomeAccessions = sorted(
-            (
-                genomeAccession
-                for genomeAccession in self.genomeAccessions
-                if len(self.genomeAccessions[genomeAccession]) > 0
-            ),
-            key=self._genomeName,
-        )
+            (genomeAccession for genomeAccession in self.genomeAccessions
+             if len(self.genomeAccessions[genomeAccession]) > 0),
+            key=self._genomeName)
         nPathogenNames = len(genomeAccessions)
 
         sampleNames = self.sampleSort(self.sampleNames)
 
         # Be very careful with commas in the following! Long lines that
         # should be continued unbroken must not end with a comma.
         result = [
-            "<html>",
-            "<head>",
-            "<title>",
+            '<html>',
+            '<head>',
+            '<title>',
             title,
-            "</title>",
+            '</title>',
             '<meta charset="UTF-8">',
+
             '<link rel="stylesheet"',
             'href="https://stackpath.bootstrapcdn.com/bootstrap/'
             '3.4.1/css/bootstrap.min.css"',
             'integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5z'
             'CYotlSAcp1+c8xmyTe9GYg1l9a69psu"',
             'crossorigin="anonymous">',
         ]
 
         if bootstrapTreeviewDir:
             result.append(
                 '<link rel="stylesheet" href="%s/bootstrap-treeview.min.css">'
-                % bootstrapTreeviewDir
-            )
+                % bootstrapTreeviewDir)
 
-        result.extend(
-            [
-                "</head>",
-                "<body>",
-                "<script",
-                'src="https://code.jquery.com/jquery-3.4.1.min.js"',
-                'integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="',
-                'crossorigin="anonymous"></script>',
-                "<script",
-                'src="https://stackpath.bootstrapcdn.com/bootstrap/'
-                '3.4.1/js/bootstrap.min.js"',
-                'integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5b'
-                'ApTppSuUkhZXN0VxHd"',
-                'crossorigin="anonymous"></script>',
-            ]
-        )
+        result.extend([
+            '</head>',
+            '<body>',
+            '<script',
+            'src="https://code.jquery.com/jquery-3.4.1.min.js"',
+            'integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="',
+            'crossorigin="anonymous"></script>',
+
+            '<script',
+            'src="https://stackpath.bootstrapcdn.com/bootstrap/'
+            '3.4.1/js/bootstrap.min.js"',
+            'integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5b'
+            'ApTppSuUkhZXN0VxHd"',
+            'crossorigin="anonymous"></script>'])
 
         if bootstrapTreeviewDir:
             result.append(
                 '<script src="%s/bootstrap-treeview.min.js"></script>'
-                % bootstrapTreeviewDir
-            )
+                % bootstrapTreeviewDir)
 
-        result.extend(
-            [
-                "<style>",
-                """\
+        result.extend([
+            '<style>',
+            '''\
             body {
                 margin-left: 2%;
                 margin-right: 2%;
             }
             hr {
                 display: block;
                 margin-top: 0.5em;
@@ -714,667 +643,559 @@
             }
             .stats {
                 font-family: "Courier New", Courier, monospace;
                 white-space: pre;
             }
             .protein-list {
                 margin-top: 2px;
-            }""",
-                "</style>",
-                "</head>",
-                "<body>",
-            ]
-        )
+            }''',
+            '</style>',
+            '</head>',
+            '<body>',
+        ])
 
         append = result.append
 
         proteinFieldsDescription = self._help(readCountColors, result)
 
-        append("<h2>%s</h2>" % title)
+        append('<h2>%s</h2>' % title)
         append(self._title(pathogenType))
         if preamble:
             append(preamble)
 
         if minProteinFraction > 0.0:
-            append("<p>")
+            append('<p>')
             percent = minProteinFraction * 100.0
             if nPathogenNames < len(self.genomeAccessions):
                 if nPathogenNames == 1:
-                    append(
-                        "Pathogen protein fraction filtering has been "
-                        "applied, so information on only 1 pathogen is "
-                        "displayed. This is the only pathogen for which at "
-                        "least one sample matches at least %.2f%% of the "
-                        "pathogen proteins." % percent
-                    )
+                    append('Pathogen protein fraction filtering has been '
+                           'applied, so information on only 1 pathogen is '
+                           'displayed. This is the only pathogen for which at '
+                           'least one sample matches at least %.2f%% of the '
+                           'pathogen proteins.' % percent)
                 else:
-                    append(
-                        "Pathogen protein fraction filtering has been "
-                        "applied, so information on only %d pathogens is "
-                        "displayed. These are the only pathogens for which "
-                        "at least one sample matches at least %.2f%% of "
-                        "the pathogen proteins." % (nPathogenNames, percent)
-                    )
+                    append('Pathogen protein fraction filtering has been '
+                           'applied, so information on only %d pathogens is '
+                           'displayed. These are the only pathogens for which '
+                           'at least one sample matches at least %.2f%% of '
+                           'the pathogen proteins.' % (nPathogenNames,
+                                                       percent))
             else:
-                append(
-                    "Pathogen protein fraction filtering was applied, "
-                    "but all pathogens have at least %.2f%% of their "
-                    "proteins matched by at least one sample." % percent
-                )
-            append("</p>")
+                append('Pathogen protein fraction filtering was applied, '
+                       'but all pathogens have at least %.2f%% of their '
+                       'proteins matched by at least one sample.' % percent)
+            append('</p>')
 
         if pathogenPanelFilename and genomeAccessions:
             self.pathogenPanel(pathogenPanelFilename)
-            append("<p>")
-            append(
-                '<a href="%s">Panel showing read count per pathogen, '
-                "per sample.</a>" % pathogenPanelFilename
-            )
-            append(
-                "Red vertical bars indicate samples with an unusually "
-                "high read count."
-            )
-            append("</p>")
+            append('<p>')
+            append('<a href="%s">Panel showing read count per pathogen, '
+                   'per sample.</a>' % pathogenPanelFilename)
+            append('Red vertical bars indicate samples with an unusually '
+                   'high read count.')
+            append('</p>')
 
         result.extend(proteinFieldsDescription)
 
         append('<p style="margin-top: 10px;">Global: ')
-        append(
-            '<button type="button" class="btn btn-default btn-sm" '
-            'id="expand-all-button">Expand all</button>'
-        )
-
-        append(
-            '<button type="button" class="btn btn-default btn-sm" '
-            'id="collapse-all-button">Collapse all</button>'
-        )
-        append("</p>")
+        append('<button type="button" class="btn btn-default btn-sm" '
+               'id="expand-all-button">Expand all</button>')
 
-        append(
-            """
+        append('<button type="button" class="btn btn-default btn-sm" '
+               'id="collapse-all-button">Collapse all</button>')
+        append('</p>')
+
+        append('''
         <script>
         $("#expand-all-button").click(function(){
             $(".collapse").collapse("show");
         });
         $("#collapse-all-button").click(function(){
             $(".collapse").collapse("hide");
         });
         </script>
-        """
-        )
+        ''')
 
-        append("<h2>Indices</h2>")
+        append('<h2>Indices</h2>')
         self._sampleIndex(sampleNames, result)
         self._pathogenIndex(genomeAccessions, result, singular, plural)
 
         self._samplesToHTML(
-            result,
-            pathogenType,
-            omitVirusLinks,
-            sampleNames,
-            readCountColors,
-            singular,
-            plural,
-        )
+            result, pathogenType, omitVirusLinks, sampleNames, readCountColors,
+            singular, plural)
 
         self._pathogensToHTML(
-            result,
-            pathogenType,
-            genomeAccessions,
-            omitVirusLinks,
-            readCountColors,
-            bootstrapTreeviewDir,
-            plural,
-        )
-
-        append("</body>")
-        append("</html>")
-
-        return "\n".join(result)
-
-    def _samplesToHTML(
-        self,
-        result,
-        pathogenType,
-        omitVirusLinks,
-        sampleNames,
-        readCountColors,
-        singular,
-        plural,
-    ):
+            result, pathogenType, genomeAccessions, omitVirusLinks,
+            readCountColors, bootstrapTreeviewDir, plural)
+
+        append('</body>')
+        append('</html>')
+
+        return '\n'.join(result)
+
+    def _samplesToHTML(self, result, pathogenType, omitVirusLinks,
+                       sampleNames, readCountColors, singular, plural):
         """
         Write all samples (with pathogens (with proteins)).
         """
         append = result.append
-        append("<h2>Samples</h2>")
+        append('<h2>Samples</h2>')
 
         for sampleName in sampleNames:
             samplePathogenAccessions = sorted(
-                (
-                    accession
-                    for accession in self.genomeAccessions
-                    if sampleName in self.genomeAccessions[accession]
-                ),
-                key=self._genomeName,
-            )
-
-            append("<div>")
-
-            append(
-                '<button type="button" class="btn btn-default btn-sm" '
-                'data-toggle="collapse" data-target="#sample-%s-collapse">'
-                '<span class="glyphicon glyphicon-plus"></span></button>' % sampleName
-            )
+                (accession for accession in self.genomeAccessions
+                 if sampleName in self.genomeAccessions[accession]),
+                key=self._genomeName)
+
+            append('<div>')
+
+            append('<button type="button" class="btn btn-default btn-sm" '
+                   'data-toggle="collapse" data-target="#sample-%s-collapse">'
+                   '<span class="glyphicon glyphicon-plus"></span></button>' %
+                   sampleName)
 
             if len(samplePathogenAccessions):
                 append(
                     '<a id="sample-%s"></a>'
                     '<span class="sample"><span class="sample-name">%s</span> '
-                    "matched proteins from %d %s, "
-                    '<a href="%s">panel</a>.</span>'
-                    % (
-                        sampleName,
-                        sampleName,
-                        len(samplePathogenAccessions),
-                        (singular if len(samplePathogenAccessions) == 1 else plural),
-                        self.sampleNames[sampleName],
-                    )
-                )
+                    'matched proteins from %d %s, '
+                    '<a href="%s">panel</a>.</span>' %
+                    (sampleName, sampleName, len(samplePathogenAccessions),
+                     (singular if len(samplePathogenAccessions) == 1
+                      else plural),
+                     self.sampleNames[sampleName]))
             else:
                 append(
                     '<a id="sample-%s"></a>'
                     '<span class="sample">'
                     '<span class="sample-name">%s</span> '
-                    "did not match anything.</span>" % (sampleName, sampleName)
-                )
+                    'did not match anything.</span>' %
+                    (sampleName, sampleName))
                 continue
 
-            append("</div>")
-            append('<div class="collapse" id="sample-%s-collapse">' % sampleName)
+            append('</div>')
+            append('<div class="collapse" id="sample-%s-collapse">' %
+                   sampleName)
 
             for genomeAccession in samplePathogenAccessions:
                 genomeInfo = self._db.findGenome(genomeAccession)
                 readsFileName = self.pathogenSampleFiles.lookup(
-                    genomeAccession, sampleName
-                )
+                    genomeAccession, sampleName)
                 proteins = self.genomeAccessions[genomeAccession][sampleName][
-                    "proteins"
-                ]
-                uniqueReadCount = self.genomeAccessions[genomeAccession][sampleName][
-                    "uniqueReadCount"
-                ]
+                    'proteins']
+                uniqueReadCount = self.genomeAccessions[
+                    genomeAccession][sampleName]['uniqueReadCount']
                 proteinCount = len(proteins)
-                pathogenProteinCount = genomeInfo["proteinCount"]
-                proteinCountStr = "%d/%d protein%s" % (
-                    proteinCount,
-                    pathogenProteinCount,
-                    "" if pathogenProteinCount == 1 else "s",
-                )
+                pathogenProteinCount = genomeInfo['proteinCount']
+                proteinCountStr = '%d/%d protein%s' % (
+                    proteinCount, pathogenProteinCount,
+                    '' if pathogenProteinCount == 1 else 's')
 
-                pathogenLinksHTML = " (%s" % NCBISequenceLink(genomeAccession)
+                pathogenLinksHTML = ' (%s' % NCBISequenceLink(genomeAccession)
 
-                if pathogenType == "viral" and not omitVirusLinks:
-                    quoted = quote(genomeInfo["organism"])
+                if pathogenType == 'viral' and not omitVirusLinks:
+                    quoted = quote(genomeInfo['organism'])
                     pathogenLinksHTML += (
-                        ', <a href="%s%s">ICTV</a>, ' '<a href="%s%s">ViralZone</a>)'
+                        ', <a href="%s%s">ICTV</a>, '
+                        '<a href="%s%s">ViralZone</a>)'
                     ) % (self.ICTV, quoted, self.VIRALZONE, quoted)
                 else:
-                    pathogenLinksHTML += ")"
+                    pathogenLinksHTML += ')'
 
                 append(
                     '<p class="sample indented">'
                     '<a href="#pathogen-%s">%s</a> %s %s, '
-                    '<a href="%s">%d read%s</a>:</p>'
-                    % (
-                        genomeAccession,
-                        genomeInfo["organism"],
-                        pathogenLinksHTML,
-                        proteinCountStr,
-                        readsFileName,
-                        uniqueReadCount,
-                        "" if uniqueReadCount == 1 else "s",
-                    )
-                )
+                    '<a href="%s">%d read%s</a>:</p>' %
+                    (genomeAccession, genomeInfo['organism'],
+                     pathogenLinksHTML, proteinCountStr, readsFileName,
+                     uniqueReadCount, '' if uniqueReadCount == 1 else 's'))
                 append('<ul class="protein-list indented">')
                 for proteinAccession in sorted(proteins):
                     proteinMatch = proteins[proteinAccession]
                     append(
-                        "<li>"
+                        '<li>'
                         '<span class="stats">'
-                        "%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f "
-                        % proteinMatch
-                    )
+                        '%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f '
+                        % proteinMatch)
 
                     self._appendNoSpace(
                         readCountText(
                             readCountColors,
-                            proteinMatch["readCount"],
-                            f"{proteinMatch['readAndHspCountStr']:4s}",
-                        ),
-                        result,
-                    )
+                            proteinMatch['readCount'],
+                            f"{proteinMatch['readAndHspCountStr']:4s}"),
+                        result)
 
                     self._appendNoSpace(
-                        "</span> "
+                        '</span> '
                         '<span class="protein-name">'
-                        "%(proteinName)s"
-                        "</span> "
-                        "(%(proteinLength)d aa," % proteinMatch,
-                        result,
-                    )
-
-                    if proteinMatch["proteinURL"]:
-                        append(
-                            '<a href="%s">%s</a>, '
-                            % (proteinMatch["proteinURL"], proteinMatch["accession"])
-                        )
+                        '%(proteinName)s'
+                        '</span> '
+                        '(%(proteinLength)d aa,'
+                        % proteinMatch, result)
+
+                    if proteinMatch['proteinURL']:
+                        append('<a href="%s">%s</a>, ' % (
+                            proteinMatch['proteinURL'],
+                            proteinMatch['accession']))
 
                     append(
                         '<a href="%(bluePlotFilename)s">blue plot</a>, '
-                        '<a href="%(readsFilename)s">reads</a>)' % proteinMatch
-                    )
+                        '<a href="%(readsFilename)s">reads</a>)'
+                        % proteinMatch)
 
-                    append("</li>")
+                    append('</li>')
 
-                append("</ul>")
-            append("</div>")
+                append('</ul>')
+            append('</div>')
 
-    def _pathogensToHTML(
-        self,
-        result,
-        pathogenType,
-        genomeAccessions,
-        omitVirusLinks,
-        readCountColors,
-        bootstrapTreeviewDir,
-        plural,
-    ):
+    def _pathogensToHTML(self, result, pathogenType, genomeAccessions,
+                         omitVirusLinks, readCountColors,
+                         bootstrapTreeviewDir, plural):
         """
         Write all pathogens (with samples (with proteins)).
         """
         append = result.append
-        append("<h2>%s</h2>" % plural.title())
+        append('<h2>%s</h2>' % plural.title())
 
         if bootstrapTreeviewDir:
             # A <div> to hold the taxonomy tree.
             append('<div id="tree"></div>')
 
         taxonomyHierarchy = Hierarchy()
 
         for genomeAccession in genomeAccessions:
             samples = self.genomeAccessions[genomeAccession]
             sampleCount = len(samples)
             genomeInfo = self._db.findGenome(genomeAccession)
-            pathogenProteinCount = genomeInfo["proteinCount"]
+            pathogenProteinCount = genomeInfo['proteinCount']
 
-            lineage = (
-                None
-                if genomeInfo["taxonomyId"] is None
-                else self._taxdb.lineage(genomeInfo["taxonomyId"])
-            )
+            lineage = (None if genomeInfo['taxonomyId'] is None
+                       else self._taxdb.lineage(genomeInfo['taxonomyId']))
 
             if lineage:
                 taxonomyHierarchy.add(lineage, genomeAccession)
-                lineageHTML = ", ".join(lineageTaxonomyLinks(lineage))
+                lineageHTML = ', '.join(lineageTaxonomyLinks(lineage))
             else:
-                lineageHTML = ""
+                lineageHTML = ''
 
-            pathogenLinksHTML = " %s, %s" % (
-                genomeInfo["databaseName"],
-                NCBISequenceLink(genomeAccession),
-            )
+            pathogenLinksHTML = ' %s, %s' % (
+                genomeInfo['databaseName'],
+                NCBISequenceLink(genomeAccession))
 
-            if pathogenType == "viral" and not omitVirusLinks:
-                quoted = quote(genomeInfo["organism"])
+            if pathogenType == 'viral' and not omitVirusLinks:
+                quoted = quote(genomeInfo['organism'])
                 pathogenLinksHTML += (
                     ', <a href="%s%s">ICTV</a>, <a href="%s%s">ViralZone</a>.'
                 ) % (self.ICTV, quoted, self.VIRALZONE, quoted)
             else:
-                pathogenLinksHTML += "."
+                pathogenLinksHTML += '.'
 
-            proteinCountStr = " %d protein%s" % (
-                pathogenProteinCount,
-                "" if pathogenProteinCount == 1 else "s",
-            )
+            proteinCountStr = (' %d protein%s' %
+                               (pathogenProteinCount,
+                                '' if pathogenProteinCount == 1 else 's'))
 
             pathogenReadsFilename = join(
                 self._pathogenDataDir,
-                "pathogen-%s.%s" % (genomeAccession, self._format),
-            )
+                'pathogen-%s.%s' % (genomeAccession, self._format))
 
-            pathogenReadsFp = open(pathogenReadsFilename, "w")
+            pathogenReadsFp = open(pathogenReadsFilename, 'w')
             pathogenReadCount = 0
 
-            append("<div>")  # Button and following summary.
+            append('<div>')  # Button and following summary.
 
-            append(
-                '<button type="button" class="btn btn-default btn-sm" '
-                'data-toggle="collapse" '
-                'data-target="#pathogen-%s-collapse">'
-                '<span class="glyphicon glyphicon-plus"></span></button>'
-                % genomeAccession.replace(".", "-")
-            )
+            append('<button type="button" class="btn btn-default btn-sm" '
+                   'data-toggle="collapse" '
+                   'data-target="#pathogen-%s-collapse">'
+                   '<span class="glyphicon glyphicon-plus"></span></button>' %
+                   genomeAccession.replace('.', '-'))
 
             append(
                 '<a id="pathogen-%s"></a>'
                 '<span class="pathogen">'
                 '<span class="pathogen-name">%s</span> '
                 '<span class="host">(%s)</span>'
-                "<br/>%d nt, %s, "
-                "matched by %d sample%s, "
+                '<br/>%d nt, %s, '
+                'matched by %d sample%s, '
                 '%s <a href="%s">reads</a> in total. '
-                "%s"
+                '%s'
                 '<br/><span class="taxonomy">Taxonomy: %s.</span>'
-                "</span>"
-                % (
-                    genomeAccession,
-                    genomeInfo["organism"],
-                    genomeInfo.get("host") or "unknown host",
-                    genomeInfo["length"],
-                    proteinCountStr,
-                    sampleCount,
-                    "" if sampleCount == 1 else "s",
-                    self.READCOUNT_MARKER,
-                    pathogenReadsFilename,
-                    pathogenLinksHTML,
-                    lineageHTML,
-                )
-            )
+                '</span>' %
+                (genomeAccession,
+                 genomeInfo['organism'],
+                 genomeInfo.get('host') or 'unknown host',
+                 genomeInfo['length'],
+                 proteinCountStr,
+                 sampleCount, '' if sampleCount == 1 else 's',
+                 self.READCOUNT_MARKER, pathogenReadsFilename,
+                 pathogenLinksHTML,
+                 lineageHTML))
 
             # Remember where we are in the output result so we can fill in
             # the total read count once we have processed all samples for
             # this pathogen. Not nice, I know.
             pathogenReadCountLineIndex = len(result) - 1
 
-            append("</div>")  # End of button summary.
+            append('</div>')  # End of button summary.
 
-            append(
-                '<div class="collapse" id="pathogen-%s-collapse">'
-                % genomeAccession.replace(".", "-")
-            )
+            append('<div class="collapse" id="pathogen-%s-collapse">' %
+                   genomeAccession.replace('.', '-'))
 
             for sampleName in self.sampleSort(samples):
                 readsFileName = self.pathogenSampleFiles.lookup(
-                    genomeAccession, sampleName
-                )
+                    genomeAccession, sampleName)
 
                 # Copy the read data from the per-sample reads for this
                 # pathogen into the per-pathogen file of reads.
                 with open(readsFileName) as readsFp:
                     while True:
                         data = readsFp.read(4096)
                         if data:
                             pathogenReadsFp.write(data)
                         else:
                             break
 
-                proteins = samples[sampleName]["proteins"]
+                proteins = samples[sampleName]['proteins']
                 proteinCount = len(proteins)
-                uniqueReadCount = samples[sampleName]["uniqueReadCount"]
+                uniqueReadCount = samples[sampleName]['uniqueReadCount']
                 pathogenReadCount += uniqueReadCount
-                proteinCountHTML = "%d protein%s, " % (
-                    proteinCount,
-                    "" if proteinCount == 1 else "s",
-                )
+                proteinCountHTML = '%d protein%s, ' % (
+                    proteinCount, '' if proteinCount == 1 else 's')
 
                 append(
                     '<p class="sample indented">'
                     'Sample <a href="#sample-%s">%s</a> '
                     '(%s<a href="%s">%d '
-                    'read%s</a>, <a href="%s">panel</a>).</p>'
-                    % (
-                        sampleName,
-                        sampleName,
-                        proteinCountHTML,
-                        readsFileName,
-                        uniqueReadCount,
-                        "" if uniqueReadCount == 1 else "s",
-                        self.sampleNames[sampleName],
-                    )
-                )
+                    'read%s</a>, <a href="%s">panel</a>).</p>' %
+                    (sampleName, sampleName,
+                     proteinCountHTML,
+                     readsFileName,
+                     uniqueReadCount, '' if uniqueReadCount == 1 else 's',
+                     self.sampleNames[sampleName]))
 
                 append('<ul class="protein-list indented">')
                 for proteinName in sorted(proteins):
                     proteinMatch = proteins[proteinName]
                     append(
-                        "<li>"
+                        '<li>'
                         '<span class="stats">'
-                        "%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f "
+                        '%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f '
                         % proteinMatch
                     )
 
                     self._appendNoSpace(
                         readCountText(
                             readCountColors,
-                            proteinMatch["readCount"],
-                            f"{proteinMatch['readAndHspCountStr']:4s}",
-                        ),
-                        result,
-                    )
+                            proteinMatch['readCount'],
+                            f"{proteinMatch['readAndHspCountStr']:4s}"),
+                        result)
 
                     if self._saveReadLengths:
-                        self._appendNoSpace(
-                            " (%s)"
-                            % ", ".join(map(str, sorted(proteinMatch["readLengths"]))),
-                            result,
-                        )
+                        self._appendNoSpace(' (%s)' % ', '.join(
+                            map(str, sorted(proteinMatch['readLengths']))),
+                            result)
 
                     self._appendNoSpace(
-                        "</span> "
+                        '</span> '
                         '<span class="protein-name">'
-                        "%(proteinName)s"
-                        "</span> "
-                        "(%(proteinLength)d aa," % proteinMatch,
-                        result,
-                    )
-
-                    if proteinMatch["proteinURL"]:
-                        append(
-                            '<a href="%s">%s</a>, '
-                            % (proteinMatch["proteinURL"], proteinMatch["accession"])
-                        )
+                        '%(proteinName)s'
+                        '</span> '
+                        '(%(proteinLength)d aa,'
+                        % proteinMatch, result)
+
+                    if proteinMatch['proteinURL']:
+                        append('<a href="%s">%s</a>, ' % (
+                            proteinMatch['proteinURL'],
+                            proteinMatch['accession']))
 
                     append(
                         '<a href="%(bluePlotFilename)s">blue plot</a>, '
-                        '<a href="%(readsFilename)s">reads</a>)' % proteinMatch
-                    )
+                        '<a href="%(readsFilename)s">reads</a>)'
+                        % proteinMatch)
 
-                    append("</li>")
+                    append('</li>')
 
-                append("</ul>")
+                append('</ul>')
 
-            append("</div>")
+            append('</div>')
 
             pathogenReadsFp.close()
 
             # Sanity check there's a read count marker text in our output
             # where we expect it.
             readCountLine = result[pathogenReadCountLineIndex]
             if readCountLine.find(self.READCOUNT_MARKER) == -1:
                 raise ValueError(
-                    "Could not find pathogen read count marker (%s) in result "
-                    "index %d text (%s)."
-                    % (self.READCOUNT_MARKER, pathogenReadCountLineIndex, readCountLine)
-                )
+                    'Could not find pathogen read count marker (%s) in result '
+                    'index %d text (%s).' %
+                    (self.READCOUNT_MARKER, pathogenReadCountLineIndex,
+                     readCountLine))
 
             # Put the read count into the pathogen summary line we wrote
             # earlier, replacing the read count marker with the correct text.
             readCountLine = readCountLine.replace(
-                self.READCOUNT_MARKER, readCountText(readCountColors, pathogenReadCount)
-            )
+                self.READCOUNT_MARKER,
+                readCountText(readCountColors, pathogenReadCount))
             if pathogenReadCount == 1:
                 # Horrible hack to make 'reads' be singular if there's only 1.
                 readCountLine = readCountLine.replace(
-                    '">reads</a> in total.', '">read</a> in total.'
-                )
+                    '">reads</a> in total.', '">read</a> in total.')
 
             result[pathogenReadCountLineIndex] = readCountLine
 
         if bootstrapTreeviewDir:
-            append(
-                """
+            append('''
                 <script>
                 $(document).ready(function(){
                     var tree = %s;
                     $('#tree').treeview({
                         data: tree,
                         enableLinks: true,
                         levels: 0,
                     });
                 });
                 </script>
-            """
-                % taxonomyHierarchy.toJSON()
-            )
+            ''' % taxonomyHierarchy.toJSON())
 
     def _help(self, readCountColors, result):
         append = result.append
 
-        append(
-            """
+        append('''
         <script>
             $(document).ready(function(){
                 $("#help-button").click(function(){
                     var self=$(this);
                     if (self.val() === "Show"){
                         self.val("Hide");
                     }
                     else {
                         self.val("Show");
                     }
                     $("#help-details").toggle();
                 });
             });
         </script>
-        """
-        )
+        ''')
 
         if readCountColors:
             levels = []
-            append("<style>")
+            append('<style>')
             for threshold, color in readCountColors.colors:
                 klass = readCountColors.thresholdToCssName(threshold)
-                append(".%s { color: %s; font-weight: bold; }" % (klass, color))
-                levels.append('<span class="%s">%d</span>' % (klass, threshold))
-            append("</style>")
-            readCountColorLegend = " Color levels: " + ", ".join(reversed(levels)) + "."
+                append('.%s { color: %s; font-weight: bold; }' %
+                       (klass, color))
+                levels.append('<span class="%s">%d</span>' %
+                              (klass, threshold))
+            append('</style>')
+            readCountColorLegend = (
+                ' Color levels: ' + ', '.join(reversed(levels)) + '.')
         else:
-            readCountColorLegend = ""
+            readCountColorLegend = ''
 
         proteinFieldsDescription = [
             'Help: <button type="button" class="btn btn-default btn-sm" '
             'id="help-button">Show</button><br>',
             '<div id="help-details" style="display:none;">',
-            "In all bullet point protein lists below, there are the following "
-            "numeric fields:",
-            "<ol>",
-            "<li>Coverage fraction.</li>",
-            "<li>Median bit score.</li>",
-            "<li>Best bit score.</li>",
-            "<li>Read count (if read and HSP counts differ, ",
-            (
-                'both are given, separated by "%s").%s</li>'
-                % (self.READ_AND_HSP_COUNT_STR_SEP, readCountColorLegend)
-            ),
+            'In all bullet point protein lists below, there are the following '
+            'numeric fields:',
+            '<ol>',
+            '<li>Coverage fraction.</li>',
+            '<li>Median bit score.</li>',
+            '<li>Best bit score.</li>',
+            '<li>Read count (if read and HSP counts differ, ',
+            ('both are given, separated by "%s").%s</li>' %
+             (self.READ_AND_HSP_COUNT_STR_SEP, readCountColorLegend)),
         ]
 
         if self._saveReadLengths:
             proteinFieldsDescription.append(
-                "<li>All read lengths (in parentheses).</li>"
-            )
+                '<li>All read lengths (in parentheses).</li>')
 
-        proteinFieldsDescription.extend(
-            [
-                "</ol>",
-                "</div>",
-            ]
-        )
+        proteinFieldsDescription.extend([
+            '</ol>',
+            '</div>',
+        ])
 
         return proteinFieldsDescription
 
     def _appendNoSpace(self, s, result):
-        assert result, "Cannot append %r to empty result list" % s
+        assert result, ('Cannot append %r to empty result list' % s)
         result[-1] += s
 
     def _sampleIndex(self, sampleNames, result):
         """
         Write a linked table of contents by sample.
         """
         append = result.append
 
         if len(sampleNames) == 1:
-            title = "Sample"
+            title = 'Sample'
         else:
-            title = "Samples (%d)" % len(sampleNames)
+            title = 'Samples (%d)' % len(sampleNames)
 
         append('<p><span class="index-name">%s:</span>' % title)
         append('<span class="index">')
         for count, sampleName in enumerate(sampleNames, start=1):
-            append(
-                '<span class="index-letter">%d</span> '
-                '<a href="#sample-%s">%s</a>' % (count, sampleName, sampleName)
-            )
-            append("&middot;")
+            append('<span class="index-letter">%d</span> '
+                   '<a href="#sample-%s">%s</a>' %
+                   (count, sampleName, sampleName))
+            append('&middot;')
         # Get rid of final middle dot and add a period.
         result.pop()
-        self._appendNoSpace(".", result)
-        append("</span></p>")
+        self._appendNoSpace('.', result)
+        append('</span></p>')
 
     def _pathogenIndex(self, genomeAccessions, result, singular, plural):
         """
         Create a linked table of contents by pathogen.
         """
         append = result.append
 
         if len(genomeAccessions) == 1:
             title = singular.title()
         else:
-            title = "%s (%d)" % (plural.title(), len(genomeAccessions))
+            title = '%s (%d)' % (plural.title(), len(genomeAccessions))
 
         append('<p><span class="index-name">%s:</span>' % title)
         append('<span class="index">')
         lastLetter = None
         for genomeAccession in genomeAccessions:
             genomeInfo = self._db.findGenome(genomeAccession)
-            organism = genomeInfo["organism"]
+            organism = genomeInfo['organism']
             letter = organism[0]
             if letter != lastLetter:
                 append('<span class="index-letter">%s</span>' % letter)
                 lastLetter = letter
-            append(
-                '<a href="#pathogen-%s">%s</a>'
-                % (genomeAccession, genomeInfo["organism"])
-            )
-            append("&middot;")
+            append('<a href="#pathogen-%s">%s</a>' % (genomeAccession,
+                                                      genomeInfo['organism']))
+            append('&middot;')
         # Get rid of final middle dot and add a period.
         result.pop()
-        self._appendNoSpace(".", result)
-        append("</span></p>")
+        self._appendNoSpace('.', result)
+        append('</span></p>')
 
     def _pathogenSamplePlot(self, genomeAccession, sampleNames, ax):
         """
         Make an image of a graph giving pathogen read count (Y axis) versus
         sample id (X axis).
 
         @param genomeAccession: A C{str} pathogen accession number.
         @param sampleNames: A sorted C{list} of sample names.
         @param ax: A matplotlib C{axes} instance.
         """
         readCounts = []
         for sampleName in sampleNames:
             try:
                 readCount = self.genomeAccessions[genomeAccession][sampleName][
-                    "uniqueReadCount"
-                ]
+                    'uniqueReadCount']
             except KeyError:
                 readCount = 0
             readCounts.append(readCount)
 
-        highlight = "r"
-        normal = "gray"
+        highlight = 'r'
+        normal = 'gray'
         sdMultiple = 2.5
         minReadsForHighlighting = 10
         highlighted = []
 
         if len(readCounts) == 1:
             if readCounts[0] > minReadsForHighlighting:
                 color = [highlight]
@@ -1382,18 +1203,16 @@
             else:
                 color = [normal]
         else:
             mean = np.mean(readCounts)
             sd = np.std(readCounts)
             color = []
             for readCount, sampleName in zip(readCounts, sampleNames):
-                if (
-                    readCount > (sdMultiple * sd) + mean
-                    and readCount >= minReadsForHighlighting
-                ):
+                if (readCount > (sdMultiple * sd) + mean and
+                        readCount >= minReadsForHighlighting):
                     color.append(highlight)
                     highlighted.append(sampleName)
                 else:
                     color.append(normal)
 
         nSamples = len(sampleNames)
         x = np.arange(nSamples)
@@ -1401,163 +1220,145 @@
         ax.set_xticks([])
         ax.set_xlim((-0.5, nSamples - 0.5))
         ax.vlines(x, yMin, readCounts, color=color)
 
         genomeInfo = self._db.findGenome(genomeAccession)
 
         if highlighted:
-            title = "%s\nIn red: %s" % (
-                genomeInfo["organism"],
-                fill(", ".join(highlighted), 50),
-            )
+            title = '%s\nIn red: %s' % (
+                genomeInfo['organism'], fill(', '.join(highlighted), 50))
         else:
             # Add a newline to keep the first line of each title at the
             # same place as those titles that have an "In red:" second
             # line.
-            title = genomeInfo["organism"] + "\n"
+            title = genomeInfo['organism'] + '\n'
 
         ax.set_title(title, fontsize=10)
-        ax.tick_params(axis="both", which="major", labelsize=8)
-        ax.tick_params(axis="both", which="minor", labelsize=6)
+        ax.tick_params(axis='both', which='major', labelsize=8)
+        ax.tick_params(axis='both', which='minor', labelsize=6)
 
     def pathogenPanel(self, filename):
         """
         Make a panel of images, with each image being a graph giving pathogen
         de-duplicated (by id) read count (Y axis) versus sample id (X axis).
 
         @param filename: A C{str} file name to write the image to.
         """
         import matplotlib
-
-        matplotlib.use("Agg")
+        matplotlib.use('Agg')
         import matplotlib.pyplot as plt
 
         self._computeUniqueReadCounts()
         genomeAccessions = sorted(self.genomeAccessions)
         sampleNames = sorted(self.sampleNames)
 
         cols = 5
         rows = int(len(genomeAccessions) / cols) + (
-            0 if len(genomeAccessions) % cols == 0 else 1
-        )
+            0 if len(genomeAccessions) % cols == 0 else 1)
         figure, ax = plt.subplots(rows, cols, squeeze=False)
 
         coords = dimensionalIterator((rows, cols))
 
         for genomeAccession in genomeAccessions:
             row, col = next(coords)
-            self._pathogenSamplePlot(genomeAccession, sampleNames, ax[row][col])
+            self._pathogenSamplePlot(genomeAccession, sampleNames,
+                                     ax[row][col])
 
         # Hide the final panel graphs (if any) that have no content. We do
         # this because the panel is a rectangular grid and some of the
         # plots at the end of the last row may be unused.
         for row, col in coords:
-            ax[row][col].axis("off")
+            ax[row][col].axis('off')
 
         figure.suptitle(
-            "Per-sample read count for %d pathogen%s and %d sample%s.\n\n"
-            % (
+            'Per-sample read count for %d pathogen%s and %d sample%s.\n\n' % (
                 len(genomeAccessions),
-                "" if len(genomeAccessions) == 1 else "s",
+                '' if len(genomeAccessions) == 1 else 's',
                 len(sampleNames),
-                "" if len(sampleNames) == 1 else "s",
-            ),
-            fontsize=18,
-        )
+                '' if len(sampleNames) == 1 else 's'),
+            fontsize=18)
         figure.set_size_inches(5.0 * cols, 2.0 * rows, forward=True)
         plt.subplots_adjust(hspace=0.4)
 
-        try:
-            figure.savefig(filename)
-        except ValueError as e:
-            print(
-                f"WARNING! Could not save pathogens panel figure: {e}. "
-                "That file has not been created and therefore the link to it ",
-                "from the results HTML will be broken.",
-                file=sys.stderr,
-            )
+        figure.savefig(filename)
 
 
-class _Genome:
+class _Genome(object):
     """
     Hold genome information, mirroring the attributes of a BioPython
     GenBank record.
 
     @param d: A C{dict} holding genome information (see below).
     """
-
     def __init__(self, d):
-        self.id = d["id"]
-        self.description = d["name"]
-        self.seq = d["sequence"]
+        self.id = d['id']
+        self.description = d['name']
+        self.seq = d['sequence']
         self.annotations = {}
-        self.lineage = [LineageElement(*lineage) for lineage in d.get("lineage", [])]
-        self.features = [_GenomeFeature(f) for f in d["features"]]
+        self.lineage = [LineageElement(*lineage)
+                        for lineage in d.get('lineage', [])]
+        self.features = [_GenomeFeature(f) for f in d['features']]
 
 
-class _GenomeLocation:
+class _GenomeLocation(object):
     """
     Hold genome feature location information, mirroring the attributes of a
     BioPython GenBank record.
 
     @param start: An C{int} start location.
     @param end: An C{int} stop location.
     @param strand: The C{int} strand, either 1 for forward or 0 for reverse.
     """
-
     def __init__(self, start, end, strand):
         self.start = start
         self.end = end
         self.strand = strand
 
     def __str__(self):
-        return "[%d:%d](%s)" % (self.start, self.end, "+" if self.strand == 1 else "-")
+        return '[%d:%d](%s)' % (self.start, self.end,
+                                '+' if self.strand == 1 else '-')
 
 
-class _GenomeFeature:
+class _GenomeFeature(object):
     """
     Hold genome feature information, mirroring the attributes of a BioPython
     GenBank record.
 
     @param d: A C{dict} holding genome feature information.
     """
-
     def __init__(self, d):
-        self.type = d["type"]
-        self.qualifiers = d["qualifiers"]
+        self.type = d['type']
+        self.qualifiers = d['qualifiers']
         self.strand = 1
-        location = d["qualifiers"]["location"]
-        self.location = _GenomeLocation(
-            location["start"], location["stop"], self.strand
-        )
+        location = d['qualifiers']['location']
+        self.location = _GenomeLocation(location['start'], location['stop'],
+                                        self.strand)
 
 
-class SqliteIndexWriter:
+class SqliteIndexWriter(object):
     """
     Create or update an Sqlite3 database holding information about proteins and
     the genomes they come from.
 
     @param dbFilename: A C{str} file name containing an sqlite3 database. If
         the file does not exist it will be created. The special string
         ":memory:" can be used to create an in-memory database.
     @param fastaFp: A file-pointer to which the protein FASTA is written.
     """
-
     PROTEIN_ACCESSION_FIELD = 2
     GENOME_ACCESSION_FIELD = 4
-    SEQUENCE_ID_PREFIX = "civ"
-    SEQUENCE_ID_SEPARATOR = "|"
+    SEQUENCE_ID_PREFIX = 'civ'
+    SEQUENCE_ID_SEPARATOR = '|'
 
     def __init__(self, dbFilename, fastaFp=sys.stdout):
-        self._connection = sqliteConnect(dbFilename)
+        self._connection = sqlite3.connect(dbFilename)
         self._fastaFp = fastaFp
 
         cur = self._connection.cursor()
-        cur.executescript(
-            """
+        cur.executescript('''
             CREATE TABLE IF NOT EXISTS proteins (
                 accession VARCHAR UNIQUE PRIMARY KEY,
                 genomeAccession VARCHAR NOT NULL,
                 sequence VARCHAR NOT NULL,
                 length INTEGER NOT NULL,
                 offsets VARCHAR NOT NULL,
                 forward INTEGER NOT NULL,
@@ -1578,54 +1379,34 @@
                 length INTEGER NOT NULL,
                 proteinCount INTEGER NOT NULL,
                 host VARCHAR,
                 note VARCHAR,
                 taxonomyId INTEGER,
                 databaseName VARCHAR
             );
-            """
-        )
+            ''')
         self._connection.commit()
 
-    def addGenBankFile(
-        self,
-        filename,
-        taxonomyDatabase,
-        dnaOnly=False,
-        rnaOnly=False,
-        allowedTaxonomicRanks=None,
-        minGenomeLength=None,
-        maxGenomeLength=None,
-        excludeExclusiveHosts=None,
-        excludeFungusOnlyViruses=False,
-        excludePlantOnlyViruses=False,
-        databaseName=None,
-        proteinSource="GENBANK",
-        genomeSource="GENBANK",
-        duplicationPolicy="error",
-        logfp=None,
-    ):
+    def addGenBankFile(self, filename, taxonomyDatabase, dnaOnly=False,
+                       rnaOnly=False, minGenomeLength=None,
+                       maxGenomeLength=None, excludeExclusiveHosts=None,
+                       excludeFungusOnlyViruses=False,
+                       excludePlantOnlyViruses=False, databaseName=None,
+                       proteinSource='GENBANK', genomeSource='GENBANK',
+                       duplicationPolicy='error', logfp=None):
         """
         Add proteins from a GenBank file.
 
         @param filename: A C{str} file name, with the file in GenBank format
             (see https://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html).
         @param taxonomyDatabase: A taxonomy database. Must be given if
             C{dnaOnly} is C{True} or C{rnaOnly} is C{True} or
             C{excludeExclusiveHosts} is not C{None}.
         @param dnaOnly: If C{True}, only include DNA viruses.
         @param rnaOnly: If C{True}, only include RNA viruses.
-        @param allowedTaxonomicRanks: If not C{None}, a set of case-insensitive
-            name, rank C{str} 2-tuples. E.g.,
-                set((
-                    ("Nidovirales", "order"),
-                    ("Retroviridae", "family"),
-                ))
-            Viruses will be included only if they match at least one of
-            the name, rank pairs.
         @param minGenomeLength: If not C{None}, genomes of a length shorter
             than this should not be added.
         @param maxGenomeLength: If not C{None}, genomes of a length greater
             than this should not be added.
         @param excludeExclusiveHosts: Either C{None} or a set of host types
             that should cause a genome to be excluded if the genome only
             has a single host and it is in C{excludeExclusiveHosts}.
@@ -1653,71 +1434,46 @@
         @return: A tuple containing two C{int}s: the number of genome sequences
             in the added file and the total number of proteins found.
         """
 
         def lineageFetcher(genome):
             return taxonomyDatabase.lineage(genome.id)
 
-        with asHandle(filename) as fp:
+        with open(filename) as fp:
             with self._connection:
-                genomes = SeqIO.parse(fp, "gb")
+                genomes = SeqIO.parse(fp, 'gb')
                 return self._addGenomes(
-                    genomes,
-                    taxonomyDatabase,
-                    lineageFetcher,
-                    dnaOnly=dnaOnly,
-                    rnaOnly=rnaOnly,
-                    allowedTaxonomicRanks=allowedTaxonomicRanks,
+                    genomes, taxonomyDatabase, lineageFetcher,
+                    dnaOnly=dnaOnly, rnaOnly=rnaOnly,
                     minGenomeLength=minGenomeLength,
                     maxGenomeLength=maxGenomeLength,
                     excludeExclusiveHosts=excludeExclusiveHosts,
                     excludeFungusOnlyViruses=excludeFungusOnlyViruses,
                     excludePlantOnlyViruses=excludePlantOnlyViruses,
-                    databaseName=databaseName,
-                    proteinSource=proteinSource,
+                    databaseName=databaseName, proteinSource=proteinSource,
                     genomeSource=genomeSource,
-                    duplicationPolicy=duplicationPolicy,
-                    logfp=logfp,
-                )
-
-    def addJSONFile(
-        self,
-        filename,
-        taxonomyDatabase,
-        dnaOnly=False,
-        rnaOnly=False,
-        allowedTaxonomicRanks=None,
-        minGenomeLength=None,
-        maxGenomeLength=None,
-        excludeExclusiveHosts=None,
-        excludeFungusOnlyViruses=False,
-        excludePlantOnlyViruses=False,
-        databaseName=None,
-        proteinSource="GENBANK",
-        genomeSource="GENBANK",
-        duplicationPolicy="error",
-        logfp=None,
-    ):
+                    duplicationPolicy=duplicationPolicy, logfp=logfp)
+
+    def addJSONFile(self, filename, taxonomyDatabase, dnaOnly=False,
+                    rnaOnly=False, minGenomeLength=None, maxGenomeLength=None,
+                    excludeExclusiveHosts=None,
+                    excludeFungusOnlyViruses=False,
+                    excludePlantOnlyViruses=False,
+                    databaseName=None, proteinSource='GENBANK',
+                    genomeSource='GENBANK', duplicationPolicy='error',
+                    logfp=None):
         """
         Add proteins from a JSON infor file.
 
         @param filename: A C{str} file name, in JSON format.
         @param taxonomyDatabase: A taxonomy database. Must be given if
             C{dnaOnly} is C{True} or C{rnaOnly} is C{True} or
             C{excludeExclusiveHosts} is not C{None}.
         @param dnaOnly: If C{True}, only include DNA viruses.
         @param rnaOnly: If C{True}, only include RNA viruses.
-        @param allowedTaxonomicRanks: If not C{None}, a set of case-insensitive
-            name, rank C{str} 2-tuples. E.g.,
-                set((
-                    ("Nidovirales", "order"),
-                    ("Retroviridae", "family"),
-                ))
-            Viruses will be included only if they match at least one of
-            the name, rank pairs.
         @param minGenomeLength: If not C{None}, genomes of a length shorter
             than this should not be added.
         @param maxGenomeLength: If not C{None}, genomes of a length greater
             than this should not be added.
         @param excludeExclusiveHosts: Either C{None} or a set of host types
             that should cause a genome to be excluded if the genome only
             has a single host and it is in C{excludeExclusiveHosts}.
@@ -1745,77 +1501,50 @@
         @return: A tuple containing two C{int}s: the number of genome sequences
             in the added file and the total number of proteins found.
         """
 
         def lineageFetcher(genome):
             return genome.lineage
 
-        with asHandle(filename) as fp:
+        with open(filename) as fp:
             genome = _Genome(load(fp))
 
         with self._connection:
             return self._addGenomes(
-                [genome],
-                taxonomyDatabase,
-                lineageFetcher,
-                dnaOnly=dnaOnly,
-                rnaOnly=rnaOnly,
-                allowedTaxonomicRanks=None,
+                [genome], taxonomyDatabase, lineageFetcher,
+                dnaOnly=dnaOnly, rnaOnly=rnaOnly,
                 minGenomeLength=minGenomeLength,
                 maxGenomeLength=maxGenomeLength,
                 excludeExclusiveHosts=excludeExclusiveHosts,
                 excludeFungusOnlyViruses=excludeFungusOnlyViruses,
                 excludePlantOnlyViruses=excludePlantOnlyViruses,
-                databaseName=databaseName,
-                proteinSource=proteinSource,
+                databaseName=databaseName, proteinSource=proteinSource,
                 genomeSource=genomeSource,
-                duplicationPolicy=duplicationPolicy,
-                logfp=logfp,
-            )
+                duplicationPolicy=duplicationPolicy, logfp=logfp)
 
     def _addGenomes(
-        self,
-        genomes,
-        taxonomyDatabase,
-        lineageFetcher,
-        dnaOnly=False,
-        rnaOnly=False,
-        allowedTaxonomicRanks=None,
-        minGenomeLength=None,
-        maxGenomeLength=None,
-        excludeExclusiveHosts=None,
-        excludeFungusOnlyViruses=False,
-        excludePlantOnlyViruses=False,
-        databaseName=None,
-        proteinSource="GENBANK",
-        genomeSource="GENBANK",
-        duplicationPolicy="error",
-        logfp=None,
-    ):
+            self, genomes, taxonomyDatabase, lineageFetcher, dnaOnly=False,
+            rnaOnly=False, minGenomeLength=None, maxGenomeLength=None,
+            excludeExclusiveHosts=None, excludeFungusOnlyViruses=False,
+            excludePlantOnlyViruses=False, databaseName=None,
+            proteinSource='GENBANK', genomeSource='GENBANK',
+            duplicationPolicy='error', logfp=None):
         """
         Add a bunch of genomes.
 
         @param genomes: An iterable of genomes. These are either genomes
             returned by BioPython's GenBank parser or instances of C{_Genome}.
         @param taxonomyDatabase: A taxonomy database.
         @param lineageFetcher: A function that takes a genome and returns a
             C{tuple} of the taxonomic categories of the genome. Each
             tuple element is a 3-tuple of (C{int}, C{str}, C{str}) giving a
             taxonomy id a (scientific) name, and the rank (species, genus,
             etc). I.e., as returned by L{dark.taxonomy.LineageFetcher.lineage}.
         @param dnaOnly: If C{True}, only include DNA viruses.
         @param rnaOnly: If C{True}, only include RNA viruses.
-        @param allowedTaxonomicRanks: If not C{None}, a set of case-insensitive
-            name, rank C{str} 2-tuples. E.g.,
-                set((
-                    ("Nidovirales", "order"),
-                    ("Retroviridae", "family"),
-                ))
-            Viruses will be included only if they match at least one of
-            the name, rank pairs.
         @param minGenomeLength: If not C{None}, genomes of a length shorter
             than this should not be added.
         @param maxGenomeLength: If not C{None}, genomes of a length greater
             than this should not be added.
         @param excludeExclusiveHosts: Either C{None} or a set of host types
             that should cause a genome to be excluded if the genome only
             has a single host and it is in C{excludeExclusiveHosts}.
@@ -1841,100 +1570,72 @@
         @raise DatabaseDuplicationError: If a duplicate accession number is
             encountered and C{duplicationPolicy} is 'error'.
         @return: A C{tuple} containing three C{int}s: the number of genome
             sequences examined (for potential addition), the number of genomes
             actually added, and the total number of proteins added.
         """
         assert self.SEQUENCE_ID_SEPARATOR not in proteinSource, (
-            "proteinSource cannot contain %r as that is used as a separator."
-            % self.SEQUENCE_ID_SEPARATOR
-        )
+            'proteinSource cannot contain %r as that is used as a separator.' %
+            self.SEQUENCE_ID_SEPARATOR)
 
         assert self.SEQUENCE_ID_SEPARATOR not in genomeSource, (
-            "genomeSource cannot contain %r as that is used as a separator."
-            % self.SEQUENCE_ID_SEPARATOR
-        )
+            'genomeSource cannot contain %r as that is used as a separator.' %
+            self.SEQUENCE_ID_SEPARATOR)
 
-        assert not (dnaOnly and rnaOnly), "dnaOnly and rnaOnly cannot both be True."
+        assert not (dnaOnly and rnaOnly), (
+            'dnaOnly and rnaOnly cannot both be True.')
 
         examinedGenomeCount = addedGenomeCount = addedProteinCount = 0
 
         for genome in genomes:
             examinedGenomeCount += 1
             source = getSourceInfo(genome, logfp=logfp)
 
             if source is None:
                 # The lack of a source is logged by getSourceInfo.
                 continue
 
             genomeLength = len(str(genome.seq))
 
             if logfp:
-                print("\n%s: %s" % (genome.id, genome.description), file=logfp)
-                print("  length = %d" % genomeLength, file=logfp)
-                print("  Source:", file=logfp)
+                print('\n%s: %s' % (genome.id, genome.description), file=logfp)
+                print('  length = %d' % genomeLength, file=logfp)
+                print('  Source:', file=logfp)
                 for k, v in source.items():
-                    print("    %s = %r" % (k, v), file=logfp)
-                print("  Annotations:", file=logfp)
+                    print('    %s = %r' % (k, v), file=logfp)
+                print('  Annotations:', file=logfp)
                 for k, v in genome.annotations.items():
-                    if k not in ("references", "comment", "structured_comment"):
-                        print("    %s = %r" % (k, v), file=logfp)
+                    if k not in ('references', 'comment',
+                                 'structured_comment'):
+                        print('    %s = %r' % (k, v), file=logfp)
 
             if minGenomeLength is not None and genomeLength < minGenomeLength:
                 if logfp:
-                    print("  Genome too short. Skipping.", file=logfp)
+                    print('  Genome too short. Skipping.', file=logfp)
                 continue
 
             if maxGenomeLength is not None and genomeLength > maxGenomeLength:
                 if logfp:
-                    print("  Genome too long. Skipping.", file=logfp)
+                    print('  Genome too long. Skipping.', file=logfp)
                 continue
 
             try:
                 lineage = lineageFetcher(genome)
             except ValueError as e:
-                print(
-                    "ValueError calling lineage fetcher for %s (%s): %s"
-                    % (genome.id, genome.description, e),
-                    file=logfp,
-                )
+                print('ValueError calling lineage fetcher for %s (%s): %s' %
+                      (genome.id, genome.description, e), file=logfp)
                 lineage = taxonomyId = None
             else:
                 taxonomyId = lineage[0][0]
 
-            if allowedTaxonomicRanks:
-                if lineage:
-                    if not isAllowedTaxonomicRank(allowedTaxonomicRanks, lineage):
-                        if logfp:
-                            print(
-                                "  %s (%s) has an unwanted taxonomic lineage. Skipping."
-                                % (genome.id, genome.description),
-                                file=logfp,
-                            )
-                        continue
-                else:
-                    # We are allowing only certain taxonomic ranks and we
-                    # have no lineage information for this virus. We skip
-                    # it because we cannot confirm that we want it.
-                    if logfp:
-                        print(
-                            "  %s (%s) has no taxonomic lineage information. Skipping."
-                            % (genome.id, genome.description),
-                            file=logfp,
-                        )
-                    continue
-
             if dnaOnly:
-                if not source["mol_type"].endswith("DNA"):
+                if not source['mol_type'].endswith('DNA'):
                     if logfp:
-                        print(
-                            "  %s (%s) is not a DNA virus (mol_type). Skipping."
-                            % (genome.id, genome.description),
-                            file=logfp,
-                        )
+                        print('  %s (%s) is not a DNA virus (mol_type).' %
+                              (genome.id, genome.description), file=logfp)
                     continue
                 # if lineage:
                 #     print('  Lineage:', file=logfp)
                 #     print(formatLineage(lineage, prefix='    '), file=logfp)
                 #     if isDNAVirus(lineage):
                 #         if logfp:
                 #             print('  %s (%s) is a DNA virus.' %
@@ -1949,21 +1650,18 @@
                 # else:
                 #     print('Could not look up taxonomy lineage for %s (%s). '
                 #           'Cannot confirm as DNA.' %
                 #           (genome.id, genome.description), file=logfp)
                 #     continue
 
             if rnaOnly:
-                if not source["mol_type"].endswith("RNA"):
+                if not source['mol_type'].endswith('RNA'):
                     if logfp:
-                        print(
-                            "  %s (%s) is not a RNA virus (mol_type). Skipping."
-                            % (genome.id, genome.description),
-                            file=logfp,
-                        )
+                        print('  %s (%s) is not a RNA virus (mol_type).' %
+                              (genome.id, genome.description), file=logfp)
                     continue
                 # if lineage:
                 #     print('  Lineage:', file=logfp)
                 #     print(formatLineage(lineage, prefix='    '), file=logfp)
                 #     if isRNAVirus(lineage):
                 #         if logfp:
                 #             print('  %s (%s) is an RNA virus.' %
@@ -1979,137 +1677,92 @@
                 #     print('Could not look up taxonomy lineage for %s (%s). '
                 #           'Cannot confirm as RNA. Skipping.' %
                 #           (genome.id, genome.description), file=logfp)
                 #     continue
 
             if excludeFungusOnlyViruses:
                 if lineage is None:
-                    print(
-                        "  Could not look up taxonomy lineage for %s "
-                        "(%s). Cannot confirm as fungus-only virus."
-                        % (genome.id, genome.description),
-                        file=logfp,
-                    )
+                    print('Could not look up taxonomy lineage for %s '
+                          '(%s). Cannot confirm as fungus-only virus. '
+                          'Skipping.' %
+                          (genome.id, genome.description), file=logfp)
                 else:
-                    if taxonomyDatabase.isFungusOnlyVirus(lineage, genome.description):
+                    if taxonomyDatabase.isFungusOnlyVirus(
+                            lineage, genome.description):
                         if logfp:
-                            print(
-                                "  %s (%s) is a fungus-only virus. Skipping."
-                                % (genome.id, genome.description),
-                                file=logfp,
-                            )
+                            print('  %s (%s) is a fungus-only virus.' %
+                                  (genome.id, genome.description), file=logfp)
                         continue
                     else:
                         if logfp:
-                            print(
-                                "  %s (%s) is not a fungus-only virus."
-                                % (genome.id, genome.description),
-                                file=logfp,
-                            )
+                            print('  %s (%s) is not a fungus-only virus.' %
+                                  (genome.id, genome.description), file=logfp)
 
             if excludePlantOnlyViruses:
                 if lineage is None:
-                    print(
-                        "  Could not look up taxonomy lineage for %s "
-                        "(%s). Cannot confirm as plant-only virus. "
-                        "Not skipping." % (genome.id, genome.description),
-                        file=logfp,
-                    )
+                    print('Could not look up taxonomy lineage for %s '
+                          '(%s). Cannot confirm as plant-only virus. '
+                          'Skipping.' %
+                          (genome.id, genome.description), file=logfp)
                 else:
-                    if taxonomyDatabase.isPlantOnlyVirus(lineage, genome.description):
+                    if taxonomyDatabase.isPlantOnlyVirus(
+                            lineage, genome.description):
                         if logfp:
-                            print(
-                                "  %s (%s) is a plant-only virus. Skipping."
-                                % (genome.id, genome.description),
-                                file=logfp,
-                            )
+                            print('  %s (%s) is a plant-only virus.' %
+                                  (genome.id, genome.description), file=logfp)
                         continue
                     else:
                         if logfp:
-                            print(
-                                "  %s (%s) is not a plant-only virus."
-                                % (genome.id, genome.description),
-                                file=logfp,
-                            )
+                            print('  %s (%s) is not a plant-only virus.' %
+                                  (genome.id, genome.description), file=logfp)
 
             if excludeExclusiveHosts:
                 if taxonomyId is None:
-                    print(
-                        "  Could not find taxonomy id for %s (%s). "
-                        "Cannot exclude due to exclusive host criteria."
-                        % (genome.id, genome.description),
-                        file=logfp,
-                    )
+                    print('Could not find taxonomy id for %s (%s). '
+                          'Cannot exclude due to exclusive host criteria.' %
+                          (genome.id, genome.description), file=logfp)
                 else:
                     hosts = taxonomyDatabase.hosts(taxonomyId)
                     if hosts is None:
-                        print(
-                            "  Could not find hosts for %s (%s). Cannot "
-                            "exclude due to exclusive host criteria."
-                            % (genome.id, genome.description),
-                            file=logfp,
-                        )
+                        print('Could not find hosts for %s (%s). Cannot '
+                              'exclude due to exclusive host criteria.' %
+                              (genome.id, genome.description), file=logfp)
                     else:
                         if len(hosts) == 1:
                             host = hosts.pop()
                             if host in excludeExclusiveHosts:
                                 print(
-                                    "  Skipping %s (%s) due to exclusive "
-                                    "host criteria (infects only %s hosts)."
-                                    % (genome.id, genome.description, host),
-                                    file=logfp,
-                                )
+                                    'Excluding %s (%s) due to exclusive '
+                                    'host criteria (infects only %s hosts).' %
+                                    (genome.id, genome.description, host),
+                                    file=logfp)
                                 continue
 
             proteinCount = len(list(self._genomeProteins(genome)))
 
             if self.addGenome(
-                genome,
-                source,
-                taxonomyId,
-                proteinCount,
-                databaseName,
-                duplicationPolicy=duplicationPolicy,
-                logfp=logfp,
-            ):
+                    genome, source, taxonomyId, proteinCount, databaseName,
+                    duplicationPolicy=duplicationPolicy, logfp=logfp):
+
                 self.addProteins(
-                    genome,
-                    source,
-                    proteinSource=proteinSource,
+                    genome, source, proteinSource=proteinSource,
                     genomeSource=genomeSource,
-                    duplicationPolicy=duplicationPolicy,
-                    logfp=logfp,
-                )
+                    duplicationPolicy=duplicationPolicy, logfp=logfp)
 
                 addedProteinCount += proteinCount
                 addedGenomeCount += 1
 
-                print(
-                    "  Added %s (%s) with %d protein%s to database."
-                    % (
-                        genome.id,
-                        genome.description,
-                        proteinCount,
-                        "" if proteinCount == 1 else "s",
-                    ),
-                    file=logfp,
-                )
+                print('  Added %s (%s) with %d protein%s to database.' %
+                      (genome.id, genome.description, proteinCount,
+                       '' if proteinCount == 1 else 's'), file=logfp)
 
         return examinedGenomeCount, addedGenomeCount, addedProteinCount
 
-    def addGenome(
-        self,
-        genome,
-        source,
-        taxonomyId,
-        proteinCount,
-        databaseName,
-        duplicationPolicy="error",
-        logfp=None,
-    ):
+    def addGenome(self, genome, source, taxonomyId, proteinCount, databaseName,
+                  duplicationPolicy='error', logfp=None):
         """
         Add information about a genome to the genomes table.
 
         @param genome: A GenBank genome record, as parsed by SeqIO.parse
         @param source: A C{dict} containing genome source information, as
             returned by C{getSourceInfo}.
         @param taxonomyId: Either an C{int} taxonomy id or C{None} if the
@@ -2128,65 +1781,46 @@
             encountered and C{duplicationPolicy} is 'error'.
         @return: C{True} if the genome was added, else C{False}.
         """
         sequence = str(genome.seq)
 
         try:
             self._connection.execute(
-                "INSERT INTO genomes(accession, organism, name, sequence, "
-                "length, proteinCount, host, note, taxonomyId, databaseName) "
-                "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
-                (
-                    genome.id,
-                    source["organism"],
-                    genome.description,
-                    sequence,
-                    len(sequence),
-                    proteinCount,
-                    source["host"],
-                    source.get("note"),
-                    taxonomyId,
-                    databaseName,
-                ),
-            )
+                'INSERT INTO genomes(accession, organism, name, sequence, '
+                'length, proteinCount, host, note, taxonomyId, databaseName) '
+                'VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',
+                (genome.id, source['organism'], genome.description,
+                 sequence, len(sequence), proteinCount, source['host'],
+                 source.get('note'), taxonomyId, databaseName))
         except sqlite3.IntegrityError as e:
-            if str(e).find("UNIQUE constraint failed") > -1:
-                if duplicationPolicy == "error":
+            if str(e).find('UNIQUE constraint failed') > -1:
+                if duplicationPolicy == 'error':
                     raise DatabaseDuplicationError(
-                        "Genome information for %r already present in "
-                        "database: %s" % (genome.id, e)
-                    )
-                elif duplicationPolicy == "ignore":
+                        'Genome information for %r already present in '
+                        'database: %s' % (genome.id, e))
+                elif duplicationPolicy == 'ignore':
                     if logfp:
                         print(
-                            "Genome information for %r already present in "
-                            "database. Ignoring: %s" % (genome.id, e),
-                            file=logfp,
-                        )
+                            'Genome information for %r already present in '
+                            'database. Ignoring: %s' % (genome.id, e),
+                            file=logfp)
                     return False
                 else:
                     raise NotImplementedError(
-                        "Unknown duplication policy (%s) found when "
-                        "attempting to insert genome information for %s."
-                        % (duplicationPolicy, genome.id)
-                    )
+                        'Unknown duplication policy (%s) found when '
+                        'attempting to insert genome information for %s.' %
+                        (duplicationPolicy, genome.id))
             else:
                 raise
         else:
             return True
 
-    def addProteins(
-        self,
-        genome,
-        source,
-        proteinSource="GENBANK",
-        genomeSource="GENBANK",
-        duplicationPolicy="error",
-        logfp=None,
-    ):
+    def addProteins(self, genome, source, proteinSource='GENBANK',
+                    genomeSource='GENBANK', duplicationPolicy='error',
+                    logfp=None):
         """
         Add proteins from a Genbank genome record to the proteins database and
         write out their sequences to the proteins FASTA file (in
         C{self._fastaFp}).
 
         @param genome: Either a GenBank genome record, as parsed by
             C{SeqIO.parse} or a C{_Genome} instance (which behaves like the
@@ -2208,61 +1842,38 @@
             progress output to.
         @raise DatabaseDuplicationError: If a duplicate accession number is
             encountered and C{duplicationPolicy} is 'error'.
         """
         genomeLen = len(genome.seq)
 
         for fInfo in self._genomeProteins(genome, logfp=logfp):
+
             # Write FASTA for the protein.
-            seqId = self.SEQUENCE_ID_SEPARATOR.join(
-                (
-                    self.SEQUENCE_ID_PREFIX,
-                    proteinSource,
-                    fInfo["proteinId"],
-                    genomeSource,
-                    genome.id,
-                    fInfo["product"],
-                )
-            )
-
-            print(
-                ">%s [%s]\n%s" % (seqId, source["organism"], fInfo["translation"]),
-                file=self._fastaFp,
-            )
+            seqId = self.SEQUENCE_ID_SEPARATOR.join((
+                self.SEQUENCE_ID_PREFIX,
+                proteinSource, fInfo['proteinId'],
+                genomeSource, genome.id,
+                fInfo['product']))
+
+            print('>%s [%s]\n%s' %
+                  (seqId, source['organism'], fInfo['translation']),
+                  file=self._fastaFp)
 
             self.addProtein(
-                fInfo["proteinId"],
-                genome.id,
-                fInfo["translation"],
-                fInfo["featureLocation"],
-                fInfo["forward"],
-                fInfo["circular"],
-                fInfo["ranges"].distinctRangeCount(genomeLen),
-                gene=fInfo["gene"],
-                note=fInfo["note"],
-                product=fInfo["product"],
-                duplicationPolicy=duplicationPolicy,
-                logfp=logfp,
-            )
-
-    def addProtein(
-        self,
-        accession,
-        genomeAccession,
-        sequence,
-        offsets,
-        forward,
-        circular,
-        rangeCount,
-        gene=None,
-        note=None,
-        product=None,
-        duplicationPolicy="error",
-        logfp=None,
-    ):
+                fInfo['proteinId'], genome.id, fInfo['translation'],
+                fInfo['featureLocation'], fInfo['forward'],
+                fInfo['circular'],
+                fInfo['ranges'].distinctRangeCount(genomeLen),
+                gene=fInfo['gene'], note=fInfo['note'],
+                product=fInfo['product'], duplicationPolicy=duplicationPolicy,
+                logfp=logfp)
+
+    def addProtein(self, accession, genomeAccession, sequence, offsets,
+                   forward, circular, rangeCount, gene=None, note=None,
+                   product=None, duplicationPolicy='error', logfp=None):
         """
         Add information about a protein to the proteins table.
 
         @param accession: A C{str} protein accession id.
         @param genomeAccession: A C{str} genome accession id (the genome to
             which this protein belongs).
         @param sequence: A C{str} protein amino acid sequence.
@@ -2288,121 +1899,99 @@
         @param logfp: If not C{None}, a file pointer to write verbose
             progress output to.
         @raise DatabaseDuplicationError: If a duplicate accession number is
             encountered and C{duplicationPolicy} is 'error'.
         """
         try:
             self._connection.execute(
-                "INSERT INTO proteins("
-                "accession, genomeAccession, sequence, length, offsets, "
-                "forward, circular, rangeCount, gene, note, product) "
-                "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
-                (
-                    accession,
-                    genomeAccession,
-                    sequence,
-                    len(sequence),
-                    offsets,
-                    int(forward),
-                    int(circular),
-                    rangeCount,
-                    gene,
-                    note,
-                    product,
-                ),
-            )
+                'INSERT INTO proteins('
+                'accession, genomeAccession, sequence, length, offsets, '
+                'forward, circular, rangeCount, gene, note, product) '
+                'VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',
+                (accession, genomeAccession, sequence, len(sequence), offsets,
+                 int(forward), int(circular), rangeCount, gene, note, product))
         except sqlite3.IntegrityError as e:
-            if str(e).find("UNIQUE constraint failed") > -1:
-                if duplicationPolicy == "error":
+            if str(e).find('UNIQUE constraint failed') > -1:
+                if duplicationPolicy == 'error':
                     raise DatabaseDuplicationError(
-                        "Protein information for %r already present in "
-                        "database." % accession
-                    )
-                elif duplicationPolicy == "ignore":
+                        'Protein information for %r already present in '
+                        'database.' % accession)
+                elif duplicationPolicy == 'ignore':
                     if logfp:
                         print(
-                            "Protein information for %r already present in "
-                            "database. Ignoring." % accession,
-                            file=logfp,
-                        )
+                            'Protein information for %r already present in '
+                            'database. Ignoring.' % accession, file=logfp)
                 else:
                     raise NotImplementedError(
-                        "Unknown duplication policy (%s) found when "
-                        "attempting to insert protein information for %s."
-                        % (duplicationPolicy, accession)
-                    )
+                        'Unknown duplication policy (%s) found when '
+                        'attempting to insert protein information for %s.' %
+                        (duplicationPolicy, accession))
             else:
                 raise
         else:
             if logfp:
-                print(
-                    "    Protein %s: genome=%s product=%s"
-                    % (accession, genomeAccession, product),
-                    file=logfp,
-                )
+                print('    Protein %s: genome=%s product=%s' % (
+                    accession, genomeAccession, product), file=logfp)
 
     def _genomeProteins(self, genome, logfp=None):
         """
         Get proteins (CDS features) that we can process from a genome, along
         with information extracted from each.
 
         @param genome: A GenBank genome record, as parsed by SeqIO.parse
         @param logfp: If not C{None}, a file pointer to write verbose
             progress output to.
         @return: A generator yielding feature info C{dict}s as returned by
             C{getCDSInfo}.
         """
         for feature in genome.features:
-            if feature.type == "CDS":
+            if feature.type == 'CDS':
                 featureInfo = getCDSInfo(genome, feature)
                 if featureInfo:
                     yield featureInfo
 
     def close(self):
         """
         Create indices on the accesssion ids and close the connection.
         """
         cur = self._connection.cursor()
-        cur.execute(
-            "CREATE UNIQUE INDEX IF NOT EXISTS protein_idx ON proteins(accession)"
-        )
-        cur.execute(
-            "CREATE UNIQUE INDEX IF NOT EXISTS genomes_idx ON genomes(accession)"
-        )
+        cur.execute('CREATE UNIQUE INDEX IF NOT EXISTS protein_idx ON '
+                    'proteins(accession)')
+        cur.execute('CREATE UNIQUE INDEX IF NOT EXISTS genomes_idx ON '
+                    'genomes(accession)')
         self._connection.commit()
         self._connection.close()
         self._connection = None
 
     def __enter__(self):
         return self
 
     def __exit__(self, excType, excValue, traceback):
         self.close()
 
 
-class SqliteIndex:
+class SqliteIndex(object):
     """
     Provide lookup access to an Sqlite3 database holding information about
     proteins and the genomes they come from.
 
     @param dbFilenameOrConnection: Either a C{str} file name containing an
         sqlite3 database as created by C{SqliteIndexWriter} or an already
         open connection to such a database. Note that an already open
         connection will not be closed by self.close().
     @param lookupCacheSize: The C{int} size of the memoization cache
         for the protein and genome lookup functions (each has its own
         memoization cache).
     """
-
     PROTEIN_ACCESSION_FIELD = 2
     GENOME_ACCESSION_FIELD = 4
 
     def __init__(self, dbFilenameOrConnection, lookupCacheSize=1024):
         if isinstance(dbFilenameOrConnection, string_types):
-            self._connection = sqliteConnect(dbFilenameOrConnection)
+            self._connection = sqlite3.connect(dbFilenameOrConnection)
             self._closeConnection = True
         else:
             self._connection = dbFilenameOrConnection
             self._closeConnection = False
         self._connection.row_factory = sqlite3.Row
         self._proteinCache = LRUCache(maxsize=lookupCacheSize)
         self._genomeCache = LRUCache(maxsize=lookupCacheSize)
@@ -2413,49 +2002,48 @@
 
         @param id_: A C{str} sequence id in the form
             'civ|GENBANK|%s|GENBANK|%s|%s [%s]' where the genome accession
             is in the fifth '|'-separated field.
         @raise IndexError: If C{id_} does not have enough |-separated fields.
         @return: The C{str} accession number.
         """
-        return id_.split("|", self.GENOME_ACCESSION_FIELD + 1)[
-            self.GENOME_ACCESSION_FIELD
-        ]
+        return id_.split('|', self.GENOME_ACCESSION_FIELD + 1)[
+            self.GENOME_ACCESSION_FIELD]
 
     def proteinAccession(self, id_):
         """
         Get the protein accession info from a sequence id.
 
         @param id_: A C{str} sequence id in the form
             'civ|GENBANK|%s|GENBANK|%s|%s [%s]' where the protein accession
             is in the third '|'-separated field.
         @raise IndexError: If C{id_} does not have enough |-separated fields.
         @return: The C{str} accession number.
         """
-        return id_.split("|", self.PROTEIN_ACCESSION_FIELD + 1)[
-            self.PROTEIN_ACCESSION_FIELD
-        ]
+        return id_.split('|', self.PROTEIN_ACCESSION_FIELD + 1)[
+            self.PROTEIN_ACCESSION_FIELD]
 
-    @cachedmethod(attrgetter("_genomeCache"))
+    @cachedmethod(attrgetter('_genomeCache'))
     def _findGenome(self, accession):
         """
         Find info about a genome, given an accession number.
 
         @param accession: A C{str} accession number.
         @return: A C{dict} with keys corresponding to the names of the columns
             in the genomes database table, else C{None} if C{id_} cannot be
             found.
         """
-        cur = self.execute("SELECT * FROM genomes WHERE accession = ?", (accession,))
+        cur = self.execute(
+            'SELECT * FROM genomes WHERE accession = ?', (accession,))
         row = cur.fetchone()
 
         if row:
             result = dict(row)
             # TODO: the following line can be removed, I think.
-            result["accession"] = accession
+            result['accession'] = accession
             return result
 
     def findGenome(self, id_):
         """
         Find info about a genome, given a sequence id.
 
         @param id_: A C{str} sequence id. This is either of the form
@@ -2469,33 +2057,34 @@
         try:
             accession = self.genomeAccession(id_)
         except IndexError:
             accession = id_
 
         return self._findGenome(accession)
 
-    @cachedmethod(attrgetter("_proteinCache"))
+    @cachedmethod(attrgetter('_proteinCache'))
     def _findProtein(self, accession):
         """
         Find info about a protein, given an accession number.
 
         @param accession: A C{str} accession number.
         @return: A C{dict} with keys corresponding to the names of the columns
             in the proteins database table, else C{None} if C{id_} cannot be
             found.
         """
-        cur = self.execute("SELECT * FROM proteins WHERE accession = ?", (accession,))
+        cur = self.execute(
+            'SELECT * FROM proteins WHERE accession = ?', (accession,))
         row = cur.fetchone()
         if row:
             result = dict(row)
-            result["forward"] = bool(result["forward"])
-            result["circular"] = bool(result["circular"])
-            result["length"] = int(result["length"])
+            result['forward'] = bool(result['forward'])
+            result['circular'] = bool(result['circular'])
+            result['length'] = int(result['length'])
             # TODO: the following line can be removed, I think.
-            result["accession"] = accession
+            result['accession'] = accession
             return result
 
     def findProtein(self, id_):
         """
         Find info about a protein, given a sequence id.
 
         @param id_: A C{str} sequence id. This is either of the form
@@ -2521,17 +2110,17 @@
         @param cur: An sqlite3 cursor.
         @return: A generator that yields C{dict}s with keys corresponding to
             the names of the columns in the proteins database table.
         """
         while rows:
             for row in rows:
                 result = dict(row)
-                result["forward"] = bool(result["forward"])
-                result["circular"] = bool(result["circular"])
-                result["length"] = int(result["length"])
+                result['forward'] = bool(result['forward'])
+                result['circular'] = bool(result['circular'])
+                result['length'] = int(result['length'])
                 yield result
             rows = cur.fetchmany()
 
     def findProteinsForGenome(self, id_):
         """
         Find all proteins for a genome id.
 
@@ -2545,16 +2134,15 @@
         """
         try:
             accession = self.genomeAccession(id_)
         except IndexError:
             accession = id_
 
         cur = self.execute(
-            "SELECT * FROM proteins WHERE genomeAccession = ?", (accession,)
-        )
+            'SELECT * FROM proteins WHERE genomeAccession = ?', (accession,))
 
         rows = cur.fetchmany()
         if rows:
             return self._yieldProteins(rows, cur)
 
     def execute(self, query, *args):
         """
@@ -2573,24 +2161,24 @@
 
     def proteinCount(self):
         """
         How many proteins are in the database?
 
         @return: An C{int} protein count.
         """
-        cur = self.execute("SELECT COUNT(1) FROM proteins")
+        cur = self.execute('SELECT COUNT(1) FROM proteins')
         return int(cur.fetchone()[0])
 
     def genomeCount(self):
         """
         How many genomes are in the database?
 
         @return: An C{int} genome count.
         """
-        cur = self.execute("SELECT COUNT(1) FROM genomes")
+        cur = self.execute('SELECT COUNT(1) FROM genomes')
         return int(cur.fetchone()[0])
 
     def close(self):
         """
         Close the database connection (if we opened it).
         """
         if self._closeConnection:
```

### Comparing `dark-matter-4.0.84/dark/colors.py` & `dark-matter-4.0.9/dark/colors.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,59 +1,55 @@
 from operator import itemgetter
 
 
-class ColorsForCounts:
+class ColorsForCounts(object):
     """
     Maintain a collection of count thresholds and colors with methods to get a
     color or a CSS name for a count.
 
     @param colors: An C{iterable} of space separated "value color" strings,
         such as ["100 red", "200 rgb(23, 190, 207)", "700 #CF3CF3"]. Or C{None}
         if no colors (other than C{defaultColor}) should be used.
     @param defaultColor: The C{str} color to use for counts that do not reach
         the lowest count threshold for any color in C{colors}.
     @raise ValueError: If an incorrect count/color pair is found in C{colors}.
     """
-
-    def __init__(self, colors, defaultColor="black"):
+    def __init__(self, colors, defaultColor='black'):
         thresholds = set()
         result = []
         if colors:
             for colorInfo in colors:
                 fields = colorInfo.split(None, 1)
                 if len(fields) == 2:
                     threshold, color = fields
                     try:
                         threshold = int(threshold)
                     except ValueError:
                         raise ValueError(
-                            "color arguments must be given as space-separated "
+                            'color arguments must be given as space-separated '
                             'pairs of "count color" where the count is an '
-                            "integer threshold. Your value (%r) was not "
-                            "an integer." % threshold
-                        )
+                            'integer threshold. Your value (%r) was not '
+                            'an integer.' % threshold)
                     if threshold < 0:
                         raise ValueError(
-                            "color arguments must be given as space-separated "
+                            'color arguments must be given as space-separated '
                             'pairs of "count color" where the count is '
-                            "non-negative. Your value (%r) is less than 0." % threshold
-                        )
+                            'non-negative. Your value (%r) is less than 0.' %
+                            threshold)
                     if threshold in thresholds:
                         raise ValueError(
-                            "repeated color argument count (%d)." % threshold
-                        )
+                            'repeated color argument count (%d).' % threshold)
 
                     result.append((threshold, color))
                     thresholds.add(threshold)
                 else:
                     raise ValueError(
-                        "color arguments must be given as space-separated "
+                        'color arguments must be given as space-separated '
                         'pairs of "value color". Your value (%r) does not '
-                        "contain a space." % colorInfo
-                    )
+                        'contain a space.' % colorInfo)
 
             result.sort(key=itemgetter(0), reverse=True)
 
         if not result or result[-1][0] > 0:
             result.append((0, defaultColor))
 
         self.colors = tuple(result)
@@ -63,37 +59,37 @@
         Turn a count threshold into a string that can be used as a CSS
         class name.
 
         @param threshold: The C{int} threshold.
         @raise ValueError: If the threshold is not an C{int}.
         @return: A C{str} CSS class name.
         """
-        return "threshold-%d" % threshold
+        return 'threshold-%d' % threshold
 
     def thresholdForCount(self, count):
         """
         Get the best threshold for a specific count.
 
         @param count: An C{int} count.
         @return: The first C{int} threshold that the given count is at least
             as big as.
         """
-        assert count >= 0, "Count (%d) cannot be negative." % count
+        assert count >= 0, 'Count (%d) cannot be negative.' % count
         for threshold, _ in self.colors:
             if count >= threshold:
                 return threshold
 
-        raise ValueError("This should never happen! Last threshold is not 0?")
+        raise ValueError('This should never happen! Last threshold is not 0?')
 
     def colorForCount(self, count):
         """
         Get the color for a count.
 
         @param count: An C{int} count.
         @return: The C{str} color for the count.
         """
-        assert count >= 0, "Count (%d) cannot be negative." % count
+        assert count >= 0, 'Count (%d) cannot be negative.' % count
         for threshold, color in self.colors:
             if count >= threshold:
                 return color
 
-        raise ValueError("This should never happen! Last threshold is not 0?")
+        raise ValueError('This should never happen! Last threshold is not 0?')
```

### Comparing `dark-matter-4.0.84/dark/diamond/alignments.py` & `dark-matter-4.0.9/dark/diamond/alignments.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 from random import uniform
 from math import log10
 import copy
 
-from dark.alignments import ReadsAlignments, ReadAlignments, ReadsAlignmentsParams
+from dark.alignments import (
+    ReadsAlignments, ReadAlignments, ReadsAlignmentsParams)
 from dark.diamond.conversion import JSONRecordsReader
 from dark.fasta import FastaReads, SqliteIndex
 from dark.reads import AAReadWithX
 from dark.score import HigherIsBetterScore
 from dark.utils import numericallySortFilenames
 
 ZERO_EVALUE_UPPER_RANDOM_INCREMENT = 150
@@ -44,26 +45,19 @@
         to a random (very good) value.
     @raises ValueError: if a file type is not recognized, or if the number of
         reads does not match the number of records found in the DIAMOND result
         files, or if neither (or both) of databaseFilename and
         sqliteDatabaseFilename are given.
     """
 
-    def __init__(
-        self,
-        reads,
-        filenames,
-        databaseFilename=None,
-        databaseDirectory=None,
-        sqliteDatabaseFilename=None,
-        scoreClass=HigherIsBetterScore,
-        sortFilenames=False,
-        randomizeZeroEValues=True,
-    ):
-        if isinstance(filenames, str):
+    def __init__(self, reads, filenames, databaseFilename=None,
+                 databaseDirectory=None, sqliteDatabaseFilename=None,
+                 scoreClass=HigherIsBetterScore, sortFilenames=False,
+                 randomizeZeroEValues=True):
+        if type(filenames) == str:
             filenames = [filenames]
         if sortFilenames:
             self.filenames = numericallySortFilenames(filenames)
         else:
             self.filenames = filenames
 
         self._databaseFilename = databaseFilename
@@ -72,40 +66,37 @@
         self._subjectTitleToSubject = None
         self.randomizeZeroEValues = randomizeZeroEValues
 
         # Prepare diamondTask parameters in order to initialize self.
         self._reader = self._getReader(self.filenames[0], scoreClass)
         diamondTask = self._reader.diamondTask
         diamondParams = copy.deepcopy(self._reader.params)
-        scoreTitle = (
-            "Bit score" if scoreClass is HigherIsBetterScore else "$- log_{10}(e)$"
-        )
+        scoreTitle = ('Bit score' if scoreClass is HigherIsBetterScore
+                      else '$- log_{10}(e)$')
 
         diamondTaskParams = ReadsAlignmentsParams(
-            diamondTask,
-            diamondParams,
+            diamondTask, diamondParams,
             subjectIsNucleotides=False,  # DIAMOND dbs are always protein.
-            scoreTitle=scoreTitle,
-        )
+            scoreTitle=scoreTitle)
 
-        ReadsAlignments.__init__(self, reads, diamondTaskParams, scoreClass=scoreClass)
+        ReadsAlignments.__init__(self, reads, diamondTaskParams,
+                                 scoreClass=scoreClass)
 
     def _getReader(self, filename, scoreClass):
         """
         Obtain a JSON record reader for DIAMOND records.
 
         @param filename: The C{str} file name holding the JSON.
         @param scoreClass: A class to hold and compare scores (see scores.py).
         """
-        if filename.endswith(".json") or filename.endswith(".json.bz2"):
+        if filename.endswith('.json') or filename.endswith('.json.bz2'):
             return JSONRecordsReader(filename, scoreClass)
         else:
             raise ValueError(
-                "Unknown DIAMOND record file suffix for file %r." % filename
-            )
+                'Unknown DIAMOND record file suffix for file %r.' % filename)
 
     def iter(self):
         """
         Extract DIAMOND records and yield C{ReadAlignments} instances.
 
         @return: A generator that yields C{ReadAlignments} instances.
         """
@@ -143,20 +134,20 @@
         """
         if self._subjectTitleToSubject is None:
             if self._databaseFilename is None:
                 # An Sqlite3 database is used to look up subjects.
                 self._subjectTitleToSubject = SqliteIndex(
                     self._sqliteDatabaseFilename,
                     fastaDirectory=self._databaseDirectory,
-                    readClass=AAReadWithX,
-                )
+                    readClass=AAReadWithX)
             else:
                 # Build a dict to look up subjects.
                 titles = {}
-                for read in FastaReads(self._databaseFilename, readClass=AAReadWithX):
+                for read in FastaReads(self._databaseFilename,
+                                       readClass=AAReadWithX):
                     titles[read.id] = read
                 self._subjectTitleToSubject = titles
 
         return self._subjectTitleToSubject[title]
 
     def adjustHspsForPlotting(self, titleAlignments):
         """
@@ -178,30 +169,28 @@
         # from disk again, which is not what's wanted.
         for hsp in titleAlignments.hsps():
             if hsp.score.score == 0.0:
                 zeroHsps.append(hsp)
             else:
                 convertedEValue = -1.0 * log10(hsp.score.score)
                 hsp.score.score = convertedEValue
-                if maxConvertedEValue is None or convertedEValue > maxConvertedEValue:
+                if (maxConvertedEValue is None or
+                        convertedEValue > maxConvertedEValue):
                     maxConvertedEValue = convertedEValue
 
         if zeroHsps:
             # Save values so that we can use them in self.adjustPlot
             self._maxConvertedEValue = maxConvertedEValue
             self._zeroEValueFound = True
 
             # Adjust all zero e-value HSPs to have numerically high values.
             if self.randomizeZeroEValues:
                 for hsp in zeroHsps:
-                    hsp.score.score = (
-                        maxConvertedEValue
-                        + 2
-                        + uniform(0, ZERO_EVALUE_UPPER_RANDOM_INCREMENT)
-                    )
+                    hsp.score.score = (maxConvertedEValue + 2 + uniform(
+                        0, ZERO_EVALUE_UPPER_RANDOM_INCREMENT))
             else:
                 for count, hsp in enumerate(zeroHsps, start=1):
                     hsp.score.score = maxConvertedEValue + count
         else:
             self._zeroEValueFound = False
 
     def adjustPlot(self, readsAx):
@@ -213,10 +202,9 @@
             matplotlib.pyplot.subplot.
         """
         # If we're using bit scores, there's nothing to do.
         if self.scoreClass is HigherIsBetterScore:
             return
 
         if self._zeroEValueFound:
-            readsAx.axhline(
-                y=self._maxConvertedEValue + 0.5, color="#cccccc", linewidth=0.5
-            )
+            readsAx.axhline(y=self._maxConvertedEValue + 0.5, color='#cccccc',
+                            linewidth=0.5)
```

### Comparing `dark-matter-4.0.84/dark/diamond/conversion.py` & `dark-matter-4.0.9/dark/diamond/conversion.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+from __future__ import print_function
+
 import six
 import bz2
 from json import dumps, loads
 from operator import itemgetter
 from collections import Counter
 
 from Bio.File import as_handle
@@ -11,105 +13,98 @@
 from dark.alignments import Alignment, ReadAlignments
 from dark.diamond.hsp import normalizeHSP
 
 # The following are the fields (in the order they are expected on the
 # command line via --outfmt 6) that must be given to DIAMOND blastx to
 # allow its output to be parsed by convert-diamond-to-sam.py (which uses
 # diamondTabularFormatToDicts (below)).
-FIELDS = (
-    "bitscore btop qframe qend full_qqual qlen full_qseq qseqid "
-    "qstart slen sstart stitle"
-)
+FIELDS = ('bitscore btop qframe qend full_qqual qlen full_qseq qseqid '
+          'qstart slen sstart stitle')
 
 # The keys in the following are DIAMOND format 6 field names. The values
 # are one-argument functions that take a string and return an appropriately
 # converted field value.
 #
 # The following fields are taken from the DIAMOND manual v0.9.22 2018-05-11.
 # Fields whose name doesn't appear here will be left as strings.
 DIAMOND_FIELD_CONVERTER = {
-    "bitscore": float,
-    "evalue": float,
-    "frame": int,
-    "gapopen": int,
-    "gaps": int,
-    "identicalCount": lambda nident: None if nident is None else int(nident),
-    "length": int,
-    "mismatch": int,
-    "nident": int,
-    "pident": float,
-    "positive": int,
-    "positiveCount": lambda pos: None if pos is None else int(pos),
-    "ppos": float,
-    "qcovhsp": float,
-    "qend": int,
-    "qframe": int,
-    "qlen": int,
-    "qstart": int,
-    "score": float,
-    "send": int,
-    "slen": int,
-    "sstart": int,
+    'bitscore': float,
+    'evalue': float,
+    'frame': int,
+    'gapopen': int,
+    'gaps': int,
+    'identicalCount': lambda nident: None if nident is None else int(nident),
+    'length': int,
+    'mismatch': int,
+    'nident': int,
+    'pident': float,
+    'positive': int,
+    'positiveCount': lambda pos: None if pos is None else int(pos),
+    'ppos': float,
+    'qcovhsp': float,
+    'qend': int,
+    'qframe': int,
+    'qlen': int,
+    'qstart': int,
+    'score': float,
+    'send': int,
+    'slen': int,
+    'sstart': int,
 }
 
 
-class DiamondTabularFormat:
+class DiamondTabularFormat(object):
     """
     Read/convert DIAMOND TAB-separated format (format #6).
 
     @param fieldNames: A C{list} or C{tuple} of C{str} DIAMOND field names.
         Run 'diamond -help' to see the full list. If C{None}, a default set of
         fields will be used, as compatible with convert-diamond-to-sam.py
     """
-
     def __init__(self, fieldNames=None):
         self._fieldNames = fieldNames or FIELDS.split()
         self._nFields = len(self._fieldNames)
         if not self._nFields:
-            raise ValueError("fieldNames cannot be empty.")
+            raise ValueError('fieldNames cannot be empty.')
 
         c = Counter(self._fieldNames)
         if c.most_common(1)[0][1] > 1:
             raise ValueError(
-                "field names contains duplicated names: %s."
-                % (", ".join(sorted(x[0] for x in c.most_common() if x[1] > 1)))
-            )
+                'field names contains duplicated names: %s.' %
+                (', '.join(sorted(x[0] for x in c.most_common() if x[1] > 1))))
 
         def identity(x):
             return x
 
-        self._convertors = tuple(
-            DIAMOND_FIELD_CONVERTER.get(field, identity) for field in self._fieldNames
-        )
+        self._convertors = tuple(DIAMOND_FIELD_CONVERTER.get(field, identity)
+                                 for field in self._fieldNames)
 
     def diamondFieldsToDict(self, line):
         """
         Convert a line of DIAMOND tabular (--outfmt 6) output to a dictionary
 
         @param line: A C{str} line read from DIAMOND output. This may contain
             a trailing whitespace (including newline and carriage return).
         @raise ValueError: If a line of C{filename} does not have the expected
             number of TAB-separated fields (i.e., len(self._fieldNames)).
         @return: A C{dict} with keys that are the DIAMOND field names, with
             values as converted by the functions set up in __init__.
         """
-        values = line.rstrip().split("\t")
+        values = line.rstrip().split('\t')
 
         if len(values) != self._nFields:
             raise ValueError(
-                "DIAMOND output line had %d field values (expected %d). "
-                "The offending input line was %r." % (len(values), self._nFields, line)
-            )
+                'DIAMOND output line had %d field values (expected %d). '
+                'The offending input line was %r.' %
+                (len(values), self._nFields, line))
 
         return dict(
             (fieldName, func(value))
             for fieldName, func, value in zip(
-                self._fieldNames, self._convertors, values
-            )
-        )
+                self._fieldNames, self._convertors, values))
 
     def diamondTabularFormatToDicts(self, filename):
         """
         Read DIAMOND tabular (--outfmt 6) output and convert lines to
         dictionaries.
 
         @param filename: Either a C{str} file name or an open file pointer.
@@ -119,15 +114,15 @@
             C{diamondFieldsToDict}, above.
         """
         with as_handle(filename) as fp:
             for line in fp:
                 yield self.diamondFieldsToDict(line)
 
 
-class DiamondTabularFormatReader:
+class DiamondTabularFormatReader(object):
     """
     Provide a method that yields parsed tabular records from a file. Store and
     make accessible the global DIAMOND parameters.
 
     Make sure you run DIAMOND with the right output format. You must have run
     with --outfmt 6 and one of the following sets of arguments (in the given
     order):
@@ -147,24 +142,22 @@
     @param filename: A C{str} filename or an open file pointer, containing
         DIAMOND tabular records.
 
     """
 
     def __init__(self, filename):
         self._filename = filename
-        self.application = "DIAMOND"
+        self.application = 'DIAMOND'
         self.params = {
-            "application": self.application,
-            "reference": (
-                "Buchfink et al., Fast and Sensitive Protein "
-                "Alignment using DIAMOND, Nature Methods, 12, 59-60 "
-                "(2015)"
-            ),
-            "task": "blastx",  # TODO: Add support for blastp, if needed.
-            "version": "v0.8.23",
+            'application': self.application,
+            'reference': ('Buchfink et al., Fast and Sensitive Protein '
+                          'Alignment using DIAMOND, Nature Methods, 12, 59-60 '
+                          '(2015)'),
+            'task': 'blastx',  # TODO: Add support for blastp, if needed.
+            'version': 'v0.8.23',
         }
 
     def records(self):
         """
         Parse the DIAMOND output and yield records. This will be used to read
         original DIAMOND output (either from stdin or from a file) to turn the
         DIAMOND results into Python dictionaries that will then be stored in
@@ -175,133 +168,92 @@
         """
         with as_handle(self._filename) as fp:
             previousQtitle = None
             subjectsSeen = {}
             record = {}
             for line in fp:
                 line = line[:-1]
-                fields = line.split("\t")
+                fields = line.split('\t')
                 nFields = len(fields)
 
                 if nFields == 13:
-                    (
-                        qtitle,
-                        stitle,
-                        bitscore,
-                        evalue,
-                        qframe,
-                        qseq,
-                        qstart,
-                        qend,
-                        sseq,
-                        sstart,
-                        send,
-                        slen,
-                        btop,
-                    ) = fields
+                    (qtitle, stitle, bitscore, evalue, qframe, qseq, qstart,
+                     qend, sseq, sstart, send, slen, btop) = fields
                     nident = pident = positive = ppos = None
                 elif nFields == 15:
-                    (
-                        qtitle,
-                        stitle,
-                        bitscore,
-                        evalue,
-                        qframe,
-                        qseq,
-                        qstart,
-                        qend,
-                        sseq,
-                        sstart,
-                        send,
-                        slen,
-                        btop,
-                        nident,
-                        positive,
-                    ) = fields
+                    (qtitle, stitle, bitscore, evalue, qframe, qseq, qstart,
+                     qend, sseq, sstart, send, slen, btop, nident,
+                     positive) = fields
                     pident = ppos = None
                 elif nFields == 17:
-                    (
-                        qtitle,
-                        stitle,
-                        bitscore,
-                        evalue,
-                        qframe,
-                        qseq,
-                        qstart,
-                        qend,
-                        sseq,
-                        sstart,
-                        send,
-                        slen,
-                        btop,
-                        nident,
-                        pident,
-                        positive,
-                        ppos,
-                    ) = fields
+                    (qtitle, stitle, bitscore, evalue, qframe, qseq, qstart,
+                     qend, sseq, sstart, send, slen, btop, nident, pident,
+                     positive, ppos) = fields
                 else:
                     raise ValueError(
-                        "Could not make sense of DIAMOND output. You must use "
-                        "--outfmt 6 with 13, 15, or 17 arguments. See %s for "
-                        "the expected names and order." % __file__
-                    )
+                        'Could not make sense of DIAMOND output. You must use '
+                        '--outfmt 6 with 13, 15, or 17 arguments. See %s for '
+                        'the expected names and order.' % __file__)
 
                 hsp = {
-                    "bits": float(bitscore),
-                    "btop": btop,
-                    "expect": float(evalue),
-                    "frame": int(qframe),
-                    "identicalCount": None if nident is None else int(nident),
-                    "percentIdentical": (None if pident is None else float(pident)),
-                    "positiveCount": (None if positive is None else int(positive)),
-                    "percentPositive": (None if ppos is None else float(ppos)),
-                    "query": qseq,
-                    "query_start": int(qstart),
-                    "query_end": int(qend),
-                    "sbjct": sseq,
-                    "sbjct_start": int(sstart),
-                    "sbjct_end": int(send),
+                    'bits': float(bitscore),
+                    'btop': btop,
+                    'expect': float(evalue),
+                    'frame': int(qframe),
+                    'identicalCount': None if nident is None else int(nident),
+                    'percentIdentical': (
+                        None if pident is None else float(pident)),
+                    'positiveCount': (
+                        None if positive is None else int(positive)),
+                    'percentPositive': (
+                        None if ppos is None else float(ppos)),
+                    'query': qseq,
+                    'query_start': int(qstart),
+                    'query_end': int(qend),
+                    'sbjct': sseq,
+                    'sbjct_start': int(sstart),
+                    'sbjct_end': int(send),
                 }
 
                 if previousQtitle == qtitle:
                     # We have already started accumulating alignments for this
                     # query.
                     if stitle not in subjectsSeen:
                         # We have not seen this subject before, so this is a
                         # new alignment.
                         subjectsSeen.add(stitle)
                         alignment = {
-                            "hsps": [hsp],
-                            "length": int(slen),
-                            "title": stitle,
+                            'hsps': [hsp],
+                            'length': int(slen),
+                            'title': stitle,
                         }
-                        record["alignments"].append(alignment)
+                        record['alignments'].append(alignment)
                     else:
                         # We have already seen this subject, so this is another
                         # HSP in an already existing alignment.
-                        for alignment in record["alignments"]:
-                            if alignment["title"] == stitle:
-                                alignment["hsps"].append(hsp)
+                        for alignment in record['alignments']:
+                            if alignment['title'] == stitle:
+                                alignment['hsps'].append(hsp)
                                 break
                 else:
                     # All alignments for the previous query id (if any)
                     # have been seen.
                     if previousQtitle is not None:
                         yield record
 
                     # Start building up the new record.
                     record = {}
                     subjectsSeen = {stitle}
                     alignment = {
-                        "hsps": [hsp],
-                        "length": int(slen),
-                        "title": stitle,
+                        'hsps': [hsp],
+                        'length': int(slen),
+                        'title': stitle,
                     }
-                    record["alignments"] = [alignment]
-                    record["query"] = qtitle
+                    record['alignments'] = [alignment]
+                    record['query'] = qtitle
 
                     previousQtitle = qtitle
 
             # Yield the last record, if any.
             if record:
                 yield record
 
@@ -311,122 +263,121 @@
         information about the DIAMOND algorithm.
 
         @param fp: A C{str} file pointer to write to.
         @param writeBytes: If C{True}, the JSON will be written out as bytes
             (not strings). This is required when we are writing to a BZ2 file.
         """
         if writeBytes:
-            fp.write(dumps(self.params, sort_keys=True).encode("UTF-8"))
-            fp.write(b"\n")
+            fp.write(dumps(self.params, sort_keys=True).encode('UTF-8'))
+            fp.write(b'\n')
             for record in self.records():
-                fp.write(dumps(record, sort_keys=True).encode("UTF-8"))
-                fp.write(b"\n")
+                fp.write(dumps(record, sort_keys=True).encode('UTF-8'))
+                fp.write(b'\n')
         else:
             fp.write(six.u(dumps(self.params, sort_keys=True)))
-            fp.write(six.u("\n"))
+            fp.write(six.u('\n'))
             for record in self.records():
                 fp.write(six.u(dumps(record, sort_keys=True)))
-                fp.write(six.u("\n"))
+                fp.write(six.u('\n'))
 
 
-class JSONRecordsReader:
+class JSONRecordsReader(object):
     """
     Provide a method that yields JSON records from a file. Store, check, and
     make accessible the DIAMOND parameters.
 
     @param filename: A C{str} filename containing JSON DIAMOND records.
     @param scoreClass: A class to hold and compare scores (see scores.py).
         Default is C{HigherIsBetterScore}, for comparing bit scores. If you
         are using e-values, pass LowerIsBetterScore instead.
     """
-
     def __init__(self, filename, scoreClass=HigherIsBetterScore):
         self._filename = filename
         self._scoreClass = scoreClass
         if scoreClass is HigherIsBetterScore:
             self._hspClass = HSP
         else:
             self._hspClass = LSP
 
         self._open(filename)
-        self.diamondTask = self.params["task"]
+        self.diamondTask = self.params['task']
 
     def _open(self, filename):
         """
         Open the input file. Set self._fp to point to it. Read the first
         line of parameters.
 
         @param filename: A C{str} filename containing JSON DIAMOND records.
         @raise ValueError: if the first line of the file isn't valid JSON,
             if the input file is empty, or if the JSON does not contain an
             'application' key.
         """
-        if filename.endswith(".bz2"):
+        if filename.endswith('.bz2'):
             if six.PY3:
-                self._fp = bz2.open(filename, mode="rt", encoding="UTF-8")
+                self._fp = bz2.open(filename, mode='rt', encoding='UTF-8')
             else:
                 self._fp = bz2.BZ2File(filename)
         else:
             self._fp = open(filename)
 
         line = self._fp.readline()
         if not line:
-            raise ValueError("JSON file %r was empty." % self._filename)
+            raise ValueError('JSON file %r was empty.' % self._filename)
 
         try:
             self.params = loads(line[:-1])
         except ValueError as e:
             raise ValueError(
-                "Could not convert first line of %r to JSON (%s). "
-                "Line is %r." % (self._filename, e, line[:-1])
-            )
+                'Could not convert first line of %r to JSON (%s). '
+                'Line is %r.' % (self._filename, e, line[:-1]))
 
     def _dictToAlignments(self, diamondDict, read):
         """
         Take a dict (made by DiamondTabularFormatReader.records)
         and convert it to a list of alignments.
 
         @param diamondDict: A C{dict}, from records().
         @param read: A C{Read} instance, containing the read that DIAMOND used
             to create this record.
         @return: A C{list} of L{dark.alignment.Alignment} instances.
         """
         alignments = []
-        getScore = itemgetter("bits" if self._hspClass is HSP else "expect")
+        getScore = itemgetter('bits' if self._hspClass is HSP else 'expect')
 
-        for diamondAlignment in diamondDict["alignments"]:
-            alignment = Alignment(diamondAlignment["length"], diamondAlignment["title"])
+        for diamondAlignment in diamondDict['alignments']:
+            alignment = Alignment(diamondAlignment['length'],
+                                  diamondAlignment['title'])
             alignments.append(alignment)
-            for diamondHsp in diamondAlignment["hsps"]:
+            for diamondHsp in diamondAlignment['hsps']:
                 score = getScore(diamondHsp)
-                normalized = normalizeHSP(diamondHsp, len(read), self.diamondTask)
+                normalized = normalizeHSP(diamondHsp, len(read),
+                                          self.diamondTask)
                 hsp = self._hspClass(
                     score,
-                    readStart=normalized["readStart"],
-                    readEnd=normalized["readEnd"],
-                    readStartInSubject=normalized["readStartInSubject"],
-                    readEndInSubject=normalized["readEndInSubject"],
-                    readFrame=diamondHsp["frame"],
-                    subjectStart=normalized["subjectStart"],
-                    subjectEnd=normalized["subjectEnd"],
-                    readMatchedSequence=diamondHsp["query"],
-                    subjectMatchedSequence=diamondHsp["sbjct"],
+                    readStart=normalized['readStart'],
+                    readEnd=normalized['readEnd'],
+                    readStartInSubject=normalized['readStartInSubject'],
+                    readEndInSubject=normalized['readEndInSubject'],
+                    readFrame=diamondHsp['frame'],
+                    subjectStart=normalized['subjectStart'],
+                    subjectEnd=normalized['subjectEnd'],
+                    readMatchedSequence=diamondHsp['query'],
+                    subjectMatchedSequence=diamondHsp['sbjct'],
                     # Use diamondHsp.get on identicalCount, positiveCount,
                     # percentPositive, and percentIdentical because they
                     # were either added in version 2.0.3 or we didn't start
                     # using them until much later and so will not be
                     # present in any of our JSON output generated before
                     # that. Those values will be None when reading those
                     # JSON files, but that's much better than no longer
                     # being able to read all that earlier data.
-                    identicalCount=diamondHsp.get("identicalCount"),
-                    positiveCount=diamondHsp.get("positiveCount"),
-                    percentIdentical=diamondHsp.get("percentIdentical"),
-                    percentPositive=diamondHsp.get("percentPositive"),
-                )
+                    identicalCount=diamondHsp.get('identicalCount'),
+                    positiveCount=diamondHsp.get('positiveCount'),
+                    percentIdentical=diamondHsp.get('percentIdentical'),
+                    percentPositive=diamondHsp.get('percentPositive'))
 
                 alignment.addHsp(hsp)
 
         return alignments
 
     def readAlignments(self, reads):
         """
@@ -447,43 +398,41 @@
 
         try:
             for lineNumber, line in enumerate(self._fp, start=2):
                 try:
                     record = loads(line[:-1])
                 except ValueError as e:
                     raise ValueError(
-                        "Could not convert line %d of %r to JSON (%s). "
-                        "Line is %r." % (lineNumber, self._filename, e, line[:-1])
-                    )
+                        'Could not convert line %d of %r to JSON (%s). '
+                        'Line is %r.' %
+                        (lineNumber, self._filename, e, line[:-1]))
                 else:
-                    recordTitle = record["query"]
+                    recordTitle = record['query']
                     while True:
                         # Iterate through the input reads until we find the
                         # one that matches this DIAMOND record.
                         try:
                             read = next(reads)
                         except StopIteration:
                             raise ValueError(
-                                "Read generator failed to yield a read "
-                                "with id '%s' as found in record number %d "
-                                "during parsing of DIAMOND output file %r."
-                                % (recordTitle, lineNumber - 1, self._filename)
-                            )
+                                'Read generator failed to yield a read '
+                                'with id \'%s\' as found in record number %d '
+                                'during parsing of DIAMOND output file %r.' %
+                                (recordTitle, lineNumber - 1, self._filename))
                         else:
                             # Look for an exact read id / subject title match.
                             # If that doesn't work, allow for the case where
                             # the JSON record has a truncated query (i.e.,
                             # read) id. This covers the situation where a tool
                             # we use (e.g., bwa mem) unconditionally does this
                             # truncation in the output it writes.
-                            if (
-                                read.id == recordTitle
-                                or read.id.split()[0] == recordTitle
-                            ):
-                                alignments = self._dictToAlignments(record, read)
+                            if (read.id == recordTitle or
+                                    read.id.split()[0] == recordTitle):
+                                alignments = self._dictToAlignments(record,
+                                                                    read)
                                 yield ReadAlignments(read, alignments)
                                 break
                             else:
                                 # This is an input read that had no DIAMOND
                                 # matches. So it does not appear in the
                                 # DIAMOND's output. Yield an empty
                                 # ReadAlignments for it.
```

### Comparing `dark-matter-4.0.84/dark/diamond/hsp.py` & `dark-matter-4.0.9/dark/diamond/hsp.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,62 +1,43 @@
+from __future__ import division, print_function
 import sys
 
 from dark.btop import countGaps
 
 
-def _debugPrint(hsp, queryLen, localDict, msg=""):
+def _debugPrint(hsp, queryLen, localDict, msg=''):
     """
     Print debugging information showing the local variables used during
     a call to normalizeHSP and the hsp and then raise an C{AssertionError}.
 
     @param hsp: The HSP C{dict} passed to normalizeHSP.
     @param queryLen: the length of the query sequence.
     @param localDict: A C{dict} of local variables (as produced by locals()).
     @param msg: A C{str} message to raise C{AssertionError} with.
     @raise AssertionError: unconditionally.
     """
-    print("normalizeHSP error:", file=sys.stderr)
-    print("  queryLen: %d" % queryLen, file=sys.stderr)
+    print('normalizeHSP error:', file=sys.stderr)
+    print('  queryLen: %d' % queryLen, file=sys.stderr)
 
-    print("  Original HSP:", file=sys.stderr)
-    for attr in [
-        "bits",
-        "btop",
-        "expect",
-        "frame",
-        "query_end",
-        "query_start",
-        "sbjct",
-        "query",
-        "sbjct_end",
-        "sbjct_start",
-    ]:
-        print("    %s: %r" % (attr, hsp[attr]), file=sys.stderr)
+    print('  Original HSP:', file=sys.stderr)
+    for attr in ['bits', 'btop', 'expect', 'frame', 'query_end', 'query_start',
+                 'sbjct', 'query', 'sbjct_end', 'sbjct_start']:
+        print('    %s: %r' % (attr, hsp[attr]), file=sys.stderr)
 
-    print("  Local variables:", file=sys.stderr)
+    print('  Local variables:', file=sys.stderr)
     for var in sorted(localDict):
-        if var != "hsp":
-            print("    %s: %s" % (var, localDict[var]), file=sys.stderr)
+        if var != 'hsp':
+            print('    %s: %s' % (var, localDict[var]), file=sys.stderr)
 
     raise AssertionError(msg)
 
 
-def _sanityCheck(
-    subjectStart,
-    subjectEnd,
-    queryStart,
-    queryEnd,
-    queryStartInSubject,
-    queryEndInSubject,
-    hsp,
-    queryLen,
-    subjectGaps,
-    queryGaps,
-    localDict,
-):
+def _sanityCheck(subjectStart, subjectEnd, queryStart, queryEnd,
+                 queryStartInSubject, queryEndInSubject, hsp, queryLen,
+                 subjectGaps, queryGaps, localDict):
     """
     Perform some sanity checks on an HSP. Call _debugPrint on any error.
 
     @param subjectStart: The 0-based C{int} start offset of the match in the
         subject.
     @param subjectEnd: The 0-based C{int} end offset of the match in the
         subject.
@@ -72,48 +53,37 @@
     @param subjectGaps: the C{int} number of gaps in the subject.
     @param queryGaps: the C{int} number of gaps in the query.
     @param localDict: A C{dict} of local variables from our caller (as
         produced by locals()).
     """
     # Subject indices must always be ascending.
     if subjectStart >= subjectEnd:
-        _debugPrint(hsp, queryLen, localDict, "subjectStart >= subjectEnd")
+        _debugPrint(hsp, queryLen, localDict, 'subjectStart >= subjectEnd')
 
     subjectMatchLength = subjectEnd - subjectStart
     queryMatchLength = queryEnd - queryStart
 
     # Sanity check that the length of the matches in the subject and query
     # are identical, taking into account gaps in both.
     subjectMatchLengthWithGaps = subjectMatchLength + subjectGaps
     queryMatchLengthWithGaps = queryMatchLength + queryGaps
     if subjectMatchLengthWithGaps != queryMatchLengthWithGaps:
-        _debugPrint(
-            hsp,
-            queryLen,
-            localDict,
-            "Including gaps, subject match length (%d) != Query match "
-            "length (%d)" % (subjectMatchLengthWithGaps, queryMatchLengthWithGaps),
-        )
+        _debugPrint(hsp, queryLen, localDict,
+                    'Including gaps, subject match length (%d) != Query match '
+                    'length (%d)' % (subjectMatchLengthWithGaps,
+                                     queryMatchLengthWithGaps))
 
     if queryStartInSubject > subjectStart:
-        _debugPrint(
-            hsp,
-            queryLen,
-            localDict,
-            "queryStartInSubject (%d) > subjectStart (%d)"
-            % (queryStartInSubject, subjectStart),
-        )
+        _debugPrint(hsp, queryLen, localDict,
+                    'queryStartInSubject (%d) > subjectStart (%d)' %
+                    (queryStartInSubject, subjectStart))
     if queryEndInSubject < subjectEnd:
-        _debugPrint(
-            hsp,
-            queryLen,
-            localDict,
-            "queryEndInSubject (%d) < subjectEnd (%d)"
-            % (queryEndInSubject, subjectEnd),
-        )
+        _debugPrint(hsp, queryLen, localDict,
+                    'queryEndInSubject (%d) < subjectEnd (%d)' %
+                    (queryEndInSubject, subjectEnd))
 
 
 def normalizeHSP(hsp, queryLen, diamondTask):
     """
     Examine an HSP and return information about where the query and subject
     match begins and ends.  Return a dict with keys that allow the query to
     be displayed against the subject. The returned readStartInSubject and
@@ -147,43 +117,43 @@
             readStartInSubject
             readEndInSubject
             subjectStart
             subjectEnd
         The returned offset values are all zero-based.
     """
 
-    queryGaps, subjectGaps = countGaps(hsp["btop"])
+    queryGaps, subjectGaps = countGaps(hsp['btop'])
 
     # Make some variables using Python's standard string indexing (start
     # offset included, end offset not). No calculations in this function
     # are done with the original 1-based HSP variables.
-    queryStart = hsp["query_start"] - 1
-    queryEnd = hsp["query_end"]
-    subjectStart = hsp["sbjct_start"] - 1
-    subjectEnd = hsp["sbjct_end"]
+    queryStart = hsp['query_start'] - 1
+    queryEnd = hsp['query_end']
+    subjectStart = hsp['sbjct_start'] - 1
+    subjectEnd = hsp['sbjct_end']
 
-    queryReversed = hsp["frame"] < 0
+    queryReversed = hsp['frame'] < 0
 
     # Query offsets must be ascending, unless we're looking at blastx output
     # and the query was reversed for the match.
     if queryStart >= queryEnd:
-        if diamondTask == "blastx" and queryReversed:
+        if diamondTask == 'blastx' and queryReversed:
             # Compute new query start and end indices, based on their
             # distance from the end of the string.
             #
             # Above we took one off the start index, so we need to undo
             # that (because the start is actually the end). We didn't take
             # one off the end index, and need to do that now (because the
             # end is actually the start).
             queryStart = queryLen - (queryStart + 1)
             queryEnd = queryLen - (queryEnd - 1)
         else:
-            _debugPrint(hsp, queryLen, locals(), "queryStart >= queryEnd")
+            _debugPrint(hsp, queryLen, locals(), 'queryStart >= queryEnd')
 
-    if diamondTask == "blastx":
+    if diamondTask == 'blastx':
         # In DIAMOND blastx output, subject offsets are based on protein
         # sequence length but queries (and the reported offsets) are
         # nucleotide.  Convert the query offsets to protein because we will
         # plot against the subject (protein).
         #
         # Convert queryLen and the query nucleotide start and end offsets
         # to be valid for the query after translation to AAs. When
@@ -196,42 +166,32 @@
         # frame 2 (i.e., the translation starts from the second nucleotide)
         # will have length 1 as an AA sequence. The first nucleotide is
         # ignored due to the frame and the last two due to there not being
         # enough final nucleotides to make another codon.
         #
         # In the following, the subtraction accounts for the first form of
         # loss and the integer division for the second.
-        initiallyIgnored = abs(hsp["frame"]) - 1
+        initiallyIgnored = abs(hsp['frame']) - 1
         queryLen = (queryLen - initiallyIgnored) // 3
         queryStart = (queryStart - initiallyIgnored) // 3
         queryEnd = (queryEnd - initiallyIgnored) // 3
 
     # unmatchedQueryLeft is the number of query bases that will extend
     # to the left of the start of the subject in our plots.
     unmatchedQueryLeft = queryStart
 
     # Set the query offsets into the subject.
     queryStartInSubject = subjectStart - unmatchedQueryLeft
     queryEndInSubject = queryStartInSubject + queryLen + queryGaps
 
-    _sanityCheck(
-        subjectStart,
-        subjectEnd,
-        queryStart,
-        queryEnd,
-        queryStartInSubject,
-        queryEndInSubject,
-        hsp,
-        queryLen,
-        subjectGaps,
-        queryGaps,
-        locals(),
-    )
+    _sanityCheck(subjectStart, subjectEnd, queryStart, queryEnd,
+                 queryStartInSubject, queryEndInSubject, hsp, queryLen,
+                 subjectGaps, queryGaps, locals())
 
     return {
-        "readStart": queryStart,
-        "readEnd": queryEnd,
-        "readStartInSubject": queryStartInSubject,
-        "readEndInSubject": queryEndInSubject,
-        "subjectStart": subjectStart,
-        "subjectEnd": subjectEnd,
+        'readStart': queryStart,
+        'readEnd': queryEnd,
+        'readStartInSubject': queryStartInSubject,
+        'readEndInSubject': queryEndInSubject,
+        'subjectStart': subjectStart,
+        'subjectEnd': subjectEnd,
     }
```

### Comparing `dark-matter-4.0.84/dark/diamond/run.py` & `dark-matter-4.0.9/dark/diamond/run.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+from __future__ import print_function
+
 import six
 
 from tempfile import mkdtemp
 from shutil import rmtree
 from os.path import join
 from subprocess import CalledProcessError
 
@@ -13,30 +15,29 @@
 def diamondInstalled():
     """
     Test if DIAMOND is installed.
 
     @return: A C{bool}, which is C{True} if DIAMOND seems to be installed.
     """
     try:
-        Executor().execute("diamond help")
+        Executor().execute('diamond help')
     except CalledProcessError:
         return False
     else:
         return True
 
 
-class DiamondExecutor:
+class DiamondExecutor(object):
     """
 
     @param dryRun: If C{True} do not actually execute the DIAMOND commands.
     """
-
-    SUBJECTS_FILENAME = "subjects.fasta"
-    QUERIES_FILENAME = "queries.fasta"
-    OUTPUT_FILENAME = "diamond.tsv"
+    SUBJECTS_FILENAME = 'subjects.fasta'
+    QUERIES_FILENAME = 'queries.fasta'
+    OUTPUT_FILENAME = 'diamond.tsv'
 
     def __init__(self, dryRun=False):
         self._dirty = False
         self._dir = mkdtemp()
         self._subjectsFp = None
         self._subjectsExist = False
         self._executor = Executor(dryRun)
@@ -46,20 +47,21 @@
         Add a subject sequence to the database.
 
         @param subject: A C{dark.reads.Read} instance.
         """
         if self._subjectsFp is None:
             if six.PY3:
                 self._subjectsFp = open(
-                    join(self._dir, self.SUBJECTS_FILENAME), "a", encoding="utf-8"
-                )
+                    join(self._dir, self.SUBJECTS_FILENAME), 'a',
+                    encoding='utf-8')
             else:
-                self._subjectsFp = open(join(self._dir, self.SUBJECTS_FILENAME), "a")
+                self._subjectsFp = open(
+                    join(self._dir, self.SUBJECTS_FILENAME), 'a')
 
-        print(subject.toString("fasta"), end="", file=self._subjectsFp)
+        print(subject.toString('fasta'), end='', file=self._subjectsFp)
         self._subjectsExist = self._dirty = True
 
     def cleanup(self):
         """
         Remove the temporary directory we made.
         """
         if self._subjectsFp:
@@ -75,40 +77,40 @@
         @param fieldNames: An iterable of C{str} field names for DIAMOND
             tabular output (format 6). See diamond help for the names of all
             available fields.
         @return: A generator that yields C{dict}s with keys as in
             C{fieldNames}.
         """
         if not self._subjectsExist:
-            raise ValueError("No subject sequences in the database")
+            raise ValueError('No subject sequences in the database')
 
         with cd(self._dir):
             if self._dirty:
                 self._subjectsFp.close()
                 self._subjectsFp = None
-                self._executor.execute(
-                    "diamond makedb --db database --in %s" % self.SUBJECTS_FILENAME
-                )
+                self._executor.execute('diamond makedb --db database --in %s' %
+                                       self.SUBJECTS_FILENAME)
 
-            with open(self.QUERIES_FILENAME, "w") as fp:
-                count = reads.save(fp, format_="fastq")
+            with open(self.QUERIES_FILENAME, 'w') as fp:
+                count = reads.save(fp, format_='fastq')
 
             if count == 0:
-                raise ValueError("No query sequences were passed")
+                raise ValueError('No query sequences were passed')
 
             fieldNames = fieldNames or FIELDS.split()
 
             self._executor.execute(
-                "diamond blastx --db database --query %s --outfmt 6 %s > %s"
-                % (self.QUERIES_FILENAME, " ".join(fieldNames), self.OUTPUT_FILENAME)
-            )
+                'diamond blastx --db database --query %s --outfmt 6 %s > %s' %
+                (self.QUERIES_FILENAME, ' '.join(fieldNames),
+                 self.OUTPUT_FILENAME))
 
             dtf = DiamondTabularFormat(fieldNames)
 
-            for diamondDict in dtf.diamondTabularFormatToDicts(self.OUTPUT_FILENAME):
+            for diamondDict in dtf.diamondTabularFormatToDicts(
+                    self.OUTPUT_FILENAME):
                 yield diamondDict
 
     def __enter__(self):
         return self
 
     def __exit__(self, excType, excValue, traceback):
         self.cleanup()
```

### Comparing `dark-matter-4.0.84/dark/diamond/sam.py` & `dark-matter-4.0.9/dark/diamond/sam.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,95 +1,91 @@
+from __future__ import print_function
+
 from os import unlink
 from tempfile import TemporaryFile
 from resource import getrlimit, RLIMIT_NOFILE
 
 from dark.btop import btop2cigar
 from dark.diamond.conversion import DiamondTabularFormat
 from dark.fpcache import FilePointerCache
 from dark.reads import DNARead
 from dark.utils import asHandle
 
 
-class SAMWriter:
+class SAMWriter(object):
     """
     A class that collects SAM output lines and writes SAM to a file.
 
     @param ram: If C{True}, do not use a temporary file to hold the non-header
         SAM output. This will run faster but use more memory since all
         non-header SAM output will be stored in RAM and only written out when
         the full header can be determined.
     """
-
     def __init__(self, ram=False):
         self._ram = ram
         self._referenceLengths = {}
 
     def addMatchLine(self, line, genome, fp):
         """
         Add a line of SAM output.
 
         @param line: A C{str} line of valid pre-formatted SAM output.
         @param genome: A C{dict} with information about the (nucleotide) genome
             that the protein in the DIAMOND match comes from. The C{dict} is
             as returned by C{dark.proteins.SqliteIndex.findGenome}.
         @param fp: The file pointer to write the line to.
         """
-        genomeName = genome["accession"]
-        genomeLength = genome["length"]
+        genomeName = genome['accession']
+        genomeLength = genome['length']
         try:
             preexistingLength = self._referenceLengths[genomeName]
         except KeyError:
             self._referenceLengths[genomeName] = genomeLength
         else:
             if preexistingLength != genomeLength:
                 raise ValueError(
-                    "Reference %r passed with length %d but has already been "
-                    "given with a different length (%d)."
-                    % (genomeName, genomeLength, preexistingLength)
-                )
+                    'Reference %r passed with length %d but has already been '
+                    'given with a different length (%d).' %
+                    (genomeName, genomeLength, preexistingLength))
 
         print(line, file=fp)
 
     def save(self, fp, tmpfp=None, headerLines=None):
         """
         Write SAM output to a file.
 
         @param fp: An open file pointer to write the full SAM to.
         @param tmpfp: An open file pointer with the non-header SAM output.
             Only used if C{self._ram} is C{False}
         @param headerLines: An optional iterable of C{str}s SAM header
             lines (with no trailing newlines).
         """
         # Print SAM headers.
-        print(
-            "\n".join(
-                (headerLines or [])
-                + [
-                    "@SQ\tSN:%s\tLN:%d" % (name, self._referenceLengths[name])
-                    for name in sorted(self._referenceLengths)
-                ]
-            ),
-            file=fp,
-        )
+        print('\n'.join(
+            (headerLines or []) +
+            [
+                '@SQ\tSN:%s\tLN:%d' % (name, self._referenceLengths[name])
+                for name in sorted(self._referenceLengths)
+            ]), file=fp)
 
         # Print SAM match lines.
         if self._ram:
             # Trade speed for memory and print the non-header lines one at a
             # time instead of making and printing a potentially massive string
             # with '\n'.join() (although arguably we could just make the single
             # string, seeing as self._ram is True.)
             for line in self._nonHeaderLines:
                 print(line, file=fp)
         else:
             tmpfp.seek(0)
             for line in tmpfp:
-                print(line, end="", file=fp)
+                print(line, end='', file=fp)
 
 
-class _DiamondSAMWriter:
+class _DiamondSAMWriter(object):
     """
     A base class for converting DIAMOND tabular output to SAM.
 
     @param genomesProteins: An open sqlite3 database with information on
         genomes and proteins, as made by the dark-matter
         make-protein-database.py script.
     @param mappingQuality: The mapping quality to use for the SAM MAPQ field
@@ -100,18 +96,16 @@
         non-header SAM output will be stored in RAM and only written out when
         the full header can be determined.
     @param keepDescriptions: If C{True}, do not discard text after the first
         space in query or subject sequence ids. Note that this violates the
         SAM specification, but since SAM files are TAB-separated there may be
         only a small chance this will cause problems downstream.
     """
-
-    def __init__(
-        self, genomesProteins, mappingQuality=255, ram=False, keepDescriptions=False
-    ):
+    def __init__(self, genomesProteins, mappingQuality=255, ram=False,
+                 keepDescriptions=False):
         self._genomesProteins = genomesProteins
         self._mappingQuality = mappingQuality
         self._ram = ram
         self._keepDescriptions = keepDescriptions
         self._strToDiamondDict = DiamondTabularFormat().diamondFieldsToDict
         self._referenceLengths = {}
 
@@ -123,33 +117,31 @@
             output format 6.
         @return: A C{tuple} containing the match C{dict} (from
             C{self._strToDiamondDict}), the protein C{dict} as looked up
             by C{self._genomesProteins.findProtein}, and the genome C{dict}
             as looked up by C{self._genomesProteins.findGenome}.
         """
         match = self._strToDiamondDict(diamondStr)
-        stitle = match["stitle"]
+        stitle = match['stitle']
 
         genomeAccession = self._genomesProteins.genomeAccession(stitle)
         genome = self._genomesProteins.findGenome(genomeAccession)
         if genome is None:
             raise ValueError(
-                "Could not find accession %r in genomes database table."
-                % genomeAccession
-            )
+                'Could not find accession %r in genomes database table.' %
+                genomeAccession)
 
         proteinAccession = self._genomesProteins.proteinAccession(stitle)
         protein = self._genomesProteins.findProtein(proteinAccession)
         if protein is None:
             raise ValueError(
-                "Could not find accession %r in proteins database table."
-                % proteinAccession
-            )
+                'Could not find accession %r in proteins database table.' %
+                proteinAccession)
 
-        self._referenceLengths[genomeAccession] = genome["length"]
+        self._referenceLengths[genomeAccession] = genome['length']
 
         return match, protein, genome
 
     def _SAMLine(self, match, protein, genome):
         """
         Convert DIAMOND match information to a line of SAM file output.
 
@@ -160,19 +152,16 @@
             DIAMOND was for. The C{dict} is as returned by
             C{dark.proteins.SqliteIndex.findProtein}.
         @param genome: A C{dict} with information about the (nucleotide) genome
             that the protein in the DIAMOND match comes from. The C{dict} is
             as returned by C{dark.proteins.SqliteIndex.findGenome}.
         @return: A TAB-separated C{str} line of SAM.
         """
-        qseqid = (
-            match["qseqid"]
-            if self._keepDescriptions
-            else match["qseqid"].split(None, 1)[0]
-        )
+        qseqid = (match['qseqid'] if self._keepDescriptions else
+                  match['qseqid'].split(None, 1)[0])
 
         # from dark.genbank import GenomeRanges
         # ranges = GenomeRanges(protein['offsets'])
 
         # matchStartInGenome = ranges.startInGenome(match)
         # queryStartInGenome = matchStartInGenome - match['qstart'] - 1
         # orientations = ranges.orientations()
@@ -183,93 +172,83 @@
 
         # If the query frame is less than zero, the match was with a
         # translation of the reverse-complemented query. We'll put the
         # reverse complement into the SAM output. This seems to be standard
         # / accepted practice, based on my web searches.  See e.g.,
         # https://www.biostars.org/p/131891/ for what Bowtie2 does and for
         # some comments on this issue for SAM/BAM files in general.
-        if match["qframe"] > 0:
+        if match['qframe'] > 0:
             flag = 0
-            qseq = match["full_qseq"]
-            qqual = match["full_qqual"] or "*"
+            qseq = match['full_qseq']
+            qqual = match['full_qqual'] or '*'
         else:
             flag = 16
-            qseq = DNARead("id", match["full_qseq"]).reverseComplement().sequence
-            qqual = match["full_qqual"][::-1] if match["full_qqual"] else "*"
+            qseq = DNARead('id',
+                           match['full_qseq']).reverseComplement().sequence
+            qqual = match['full_qqual'][::-1] if match['full_qqual'] else '*'
 
         # Make a CIGAR string, including hard-clipped bases at the start and
         # end of the query (DIAMOND outputs a hard-clipped query sequence).
-        startClipCount = match["qstart"] - 1
-        endClipCount = match["qlen"] - match["qend"]
+        startClipCount = match['qstart'] - 1
+        endClipCount = match['qlen'] - match['qend']
 
         assert startClipCount >= 0
-        assert (
-            endClipCount >= 0
-        ), "Query sequence %s has length %d but the qend value is %d" % (
-            qseq,
-            len(match["qseq"]),
-            match["qend"],
-        )
+        assert endClipCount >= 0, (
+            'Query sequence %s has length %d but the qend value is %d' %
+            (qseq, len(match['qseq']), match['qend']))
 
         cigar = (
-            ("%dH" % startClipCount if startClipCount else "")
-            + "".join(btop2cigar(match["btop"], concise=False, aa=True))
-            + ("%dH" % endClipCount if endClipCount else "")
-        )
-
-        return "\t".join(
-            map(
-                str,
-                (
-                    # 1. QNAME
-                    qseqid,
-                    # 2. FLAG
-                    flag,
-                    # 3. RNAME
-                    genome["accession"],
-                    # 4. POS. This needs to be a 1-based offset into the
-                    # nucleotide-equivalent of the DIAMOND subject sequence (which was
-                    # a protein since that is how DIAMOND operates). Because DIAMOND
-                    # gives back a 1-based protein location, we adjust to 0-based,
-                    # multiply by 3 to get to nucleotides, then adjust to 1-based.
-                    3 * (match["sstart"] - 1) + 1,
-                    # 5. MAPQ
-                    self._mappingQuality,
-                    # 6. CIGAR
-                    cigar,
-                    # 7. RNEXT
-                    "*",
-                    # 8. PNEXT
-                    0,
-                    # 9. TLEN
-                    0,
-                    # 10. SEQ
-                    qseq,
-                    # 11. QUAL
-                    qqual,
-                    # 12. Alignment score
-                    "AS:i:%d" % int(match["bitscore"]),
-                ),
-            )
-        )
+            ('%dH' % startClipCount if startClipCount else '') +
+            ''.join(btop2cigar(match['btop'], concise=False, aa=True)) +
+            ('%dH' % endClipCount if endClipCount else ''))
+
+        return '\t'.join(map(str, (
+            # 1. QNAME
+            qseqid,
+            # 2. FLAG
+            flag,
+            # 3. RNAME
+            genome['accession'],
+            # 4. POS. This needs to be a 1-based offset into the
+            # nucleotide-equivalent of the DIAMOND subject sequence (which was
+            # a protein since that is how DIAMOND operates). Because DIAMOND
+            # gives back a 1-based protein location, we adjust to 0-based,
+            # multiply by 3 to get to nucleotides, then adjust to 1-based.
+            3 * (match['sstart'] - 1) + 1,
+            # 5. MAPQ
+            self._mappingQuality,
+            # 6. CIGAR
+            cigar,
+            # 7. RNEXT
+            '*',
+            # 8. PNEXT
+            0,
+            # 9. TLEN
+            0,
+            # 10. SEQ
+            qseq,
+            # 11. QUAL
+            qqual,
+            # 12. Alignment score
+            'AS:i:%d' % int(match['bitscore']))))
 
     def addMatch(self, diamondStr):
         """
         Add information from a row of DIAMOND tabular output.
 
         @param diamondStr: A C{str} with TAB-separated fields from DIAMOND
             output format 6.
         """
-        raise NotImplementedError("addMatch must be implemented by a subclass")
+        raise NotImplementedError('addMatch must be implemented by a subclass')
 
     def save(self, fp):
         """
         Write SAM output to a file.
         """
-        raise NotImplementedError("save must be implemented by a subclass")
+        raise NotImplementedError('save must be implemented by a subclass')
 
 
 class SimpleDiamondSAMWriter(_DiamondSAMWriter):
     """
     Convert DIAMOND tabular output to SAM.
 
     @param genomesProteins: An open sqlite3 database with information on
@@ -283,39 +262,32 @@
         non-header SAM output will be stored in RAM and only written out when
         the full header can be determined.
     @param keepDescriptions: If C{True}, do not discard text after the first
         space in query or subject sequence ids. Note that this violates the
         SAM specification, but since SAM files are TAB-separated there may be
         only a small chance this will cause problems downstream.
     """
-
-    def __init__(
-        self, genomesProteins, mappingQuality=255, ram=False, keepDescriptions=False
-    ):
+    def __init__(self, genomesProteins, mappingQuality=255, ram=False,
+                 keepDescriptions=False):
         _DiamondSAMWriter.__init__(
-            self,
-            genomesProteins,
-            mappingQuality=mappingQuality,
-            ram=ram,
-            keepDescriptions=keepDescriptions,
-        )
-        self._tf = TemporaryFile(mode="w+t", encoding="utf-8")
+            self, genomesProteins, mappingQuality=mappingQuality, ram=ram,
+            keepDescriptions=keepDescriptions)
+        self._tf = TemporaryFile(mode='w+t', encoding='utf-8')
         self._writer = SAMWriter(ram=ram)
 
     def addMatch(self, diamondStr):
         """
         Add information from a row of DIAMOND tabular output.
 
         @param diamondStr: A C{str} with TAB-separated fields from DIAMOND
             output format 6.
         """
         match, protein, genome = self._preprocessMatch(diamondStr)
         self._writer.addMatchLine(
-            self._SAMLine(match, protein, genome), genome, self._tf
-        )
+            self._SAMLine(match, protein, genome), genome, self._tf)
 
     def save(self, filename):
         """
         Write SAM output to a file.
 
         @param filename: A C{str} filename or an already-open file handle.
         """
@@ -350,73 +322,57 @@
     @param fpcMaxsize: An C{int} maximum size for the file pointer cache used
         because SAM output may be being written to an arbitrary number of
         output files so we need to make sure the OS limit on open files is not
         exceeded and that we are not inefficiently constantly re-opening and
         writing single lines to files). If C{None} or C{0} is passed, a size
         of half the maximum number of files will be used.
     """
+    SAM_SUFFIX = '.sam'
+    TMP_SUFFIX = '.tmp'
 
-    SAM_SUFFIX = ".sam"
-    TMP_SUFFIX = ".tmp"
-
-    def __init__(
-        self,
-        genomesProteins,
-        baseFilenameFunc=None,
-        mappingQuality=255,
-        ram=False,
-        keepDescriptions=False,
-        fpcMaxsize=0,
-    ):
+    def __init__(self, genomesProteins, baseFilenameFunc=None,
+                 mappingQuality=255, ram=False, keepDescriptions=False,
+                 fpcMaxsize=0):
         _DiamondSAMWriter.__init__(
-            self,
-            genomesProteins,
-            mappingQuality=mappingQuality,
-            ram=ram,
-            keepDescriptions=keepDescriptions,
-        )
+            self, genomesProteins, mappingQuality=mappingQuality, ram=ram,
+            keepDescriptions=keepDescriptions)
 
         self._writers = {}
         self._baseFilenameFunc = baseFilenameFunc
         self._fpc = FilePointerCache(
             maxsize=(fpcMaxsize or getrlimit(RLIMIT_NOFILE)[0] >> 1),
-            openArgs={"mode": "wt"},
-            reopenArgs={"mode": "at"},
-        )
+            openArgs={'mode': 'wt'}, reopenArgs={'mode': 'at'})
 
     def addMatch(self, diamondStr):
         """
         Add information from a row of DIAMOND tabular output.
 
         @param diamondStr: A C{str} with TAB-separated fields from DIAMOND
             output format 6.
         """
         match, protein, genome = self._preprocessMatch(diamondStr)
-        genomeAccession = genome["accession"]
-        basename = self._baseFilenameFunc(match["stitle"])
+        genomeAccession = genome['accession']
+        basename = self._baseFilenameFunc(match['stitle'])
 
         try:
             writer, _ = self._writers[genomeAccession]
         except KeyError:
             writer = SAMWriter()
             self._writers[genomeAccession] = (writer, basename)
 
-        writer.addMatchLine(
-            self._SAMLine(match, protein, genome),
-            genome,
-            self._fpc.open(basename + self.TMP_SUFFIX),
-        )
+        writer.addMatchLine(self._SAMLine(match, protein, genome), genome,
+                            self._fpc.open(basename + self.TMP_SUFFIX))
 
     def save(self):
         """
         Write SAM output to all files.
         """
         # Close the open file descriptor cache.
         self._fpc.close()
 
         # Write out SAM (including headers) for each reference.
         for writer, basename in self._writers.values():
             tmp = basename + self.TMP_SUFFIX
-            with open(basename + self.SAM_SUFFIX, "wt") as samfp:
+            with open(basename + self.SAM_SUFFIX, 'wt') as samfp:
                 with open(tmp) as tmpfp:
                     writer.save(samfp, tmpfp)
             unlink(tmp)
```

### Comparing `dark-matter-4.0.84/dark/dimension.py` & `dark-matter-4.0.9/dark/dimension.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,13 +1,8 @@
-from typing import Optional, Iterator
-
-
-def dimensionalIterator(
-    dimensions: list[int], maxItems: int = -1, start: Optional[list[int]] = None
-) -> Iterator[tuple[int, ...]]:
+def dimensionalIterator(dimensions, maxItems=-1):
     """
     Given a list of n positive integers, return a generator that yields
     n-tuples of coordinates to 'fill' the dimensions. This is like an
     odometer in a car, but the dimensions do not each have to be 10.
 
     For example: dimensionalIterator((2, 3)) will yield in order
     (0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2). See the tests in
@@ -18,36 +13,22 @@
     infinite series (0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1), ....
 
     maxItems can be used to limit the number of tuples yielded.
     """
     nDimensions = len(dimensions)
     if nDimensions == 0 or maxItems == 0:
         return
-    if any(map(lambda x: x != "*" and x <= 0, dimensions)):
-        raise ValueError("Dimensions not all positive! %r" % (dimensions,))
-
-    if start:
-        if len(start) != len(dimensions):
-            raise ValueError(
-                f"The start list is of length {len(start)}, but "
-                f"the number of dimensions ({len(dimensions)}) differs."
-            )
-        odometer = list(start)
-    else:
-        odometer = [
-            0,
-        ] * nDimensions
-
+    if any(map(lambda x: x != '*' and x <= 0, dimensions)):
+        raise ValueError('Dimensions not all positive! %r' % (dimensions,))
+    odometer = [0, ] * nDimensions
     while maxItems != 0:
         yield tuple(odometer)
         maxItems -= 1
         wheel = nDimensions - 1
-        while (
-            dimensions[wheel] != "*"
-            and odometer[wheel] == dimensions[wheel] - 1
-            and wheel >= 0
-        ):
+        while (dimensions[wheel] != '*' and
+               odometer[wheel] == dimensions[wheel] - 1 and
+               wheel >= 0):
             odometer[wheel] = 0
             wheel -= 1
         if wheel < 0:
             return
         odometer[wheel] += 1
```

### Comparing `dark-matter-4.0.84/dark/distance.py` & `dark-matter-4.0.9/dark/distance.py`

 * *Files 4% similar despite different names*

```diff
@@ -32,16 +32,18 @@
         # Insertion (target grows longer than source):
         current_row = previous_row + 1
 
         # Substitution or matching:
         # Target and source items are aligned, and either
         # are different (cost of 1), or are the same (cost of 0).
         current_row[1:] = np.minimum(
-            current_row[1:], np.add(previous_row[:-1], target != s)
-        )
+            current_row[1:],
+            np.add(previous_row[:-1], target != s))
 
         # Deletion (target grows shorter than source):
-        current_row[1:] = np.minimum(current_row[1:], current_row[0:-1] + 1)
+        current_row[1:] = np.minimum(
+            current_row[1:],
+            current_row[0:-1] + 1)
 
         previous_row = current_row
 
     return previous_row[-1]
```

### Comparing `dark-matter-4.0.84/dark/entrez.py` & `dark-matter-4.0.9/dark/entrez.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 from Bio import Entrez, SeqIO
 from six.moves.urllib_error import URLError
 
-Entrez.email = "tcj25@cam.ac.uk"
+Entrez.email = 'tcj25@cam.ac.uk'
 
 
-def getSequence(title, db="nucleotide"):
+def getSequence(title, db='nucleotide'):
     """
     Get information about a sequence from Genbank.
 
     @param title: A C{str} sequence title from a BLAST hit. Of the form
         'gi|63148399|gb|DQ011818.1| Description...'.
     @param db: The C{str} name of the Entrez database to consult.
 
     NOTE: this uses the network!  Also, there is a 3 requests/second limit
     imposed by NCBI on these requests so be careful or your IP will be banned.
     """
-    titleId = title.split(" ", 1)[0]
+    titleId = title.split(' ', 1)[0]
     try:
-        gi = titleId.split("|")[1]
+        gi = titleId.split('|')[1]
     except IndexError:
         # Assume we have a gi number directly, and make sure it's a string.
         gi = str(titleId)
 
     try:
-        client = Entrez.efetch(db=db, rettype="gb", retmode="text", id=gi)
+        client = Entrez.efetch(db=db, rettype='gb', retmode='text', id=gi)
     except URLError:
         return None
     else:
-        record = SeqIO.read(client, "gb")
+        record = SeqIO.read(client, 'gb')
         client.close()
         return record
```

### Comparing `dark-matter-4.0.84/dark/fasta.py` & `dark-matter-4.0.9/dark/fasta.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,87 +1,81 @@
+from six import PY3
 from hashlib import md5
 import sqlite3
 import os
-from typing import Generator, Iterable, TextIO, Union, Type, Optional, List
 
-from Bio import SeqIO, bgzf  # type: ignore
-from Bio.Seq import Seq
+from Bio import SeqIO, bgzf
 
-from dark.reads import Reads, DNARead, Read
-from dark.sqlite3 import sqliteConnect
+from dark.reads import Reads, DNARead
 from dark.utils import asHandle
 
 
-def fastaToList(fastaFilename) -> list:
-    return list(SeqIO.parse(fastaFilename, "fasta"))
+def fastaToList(fastaFilename):
+    return list(SeqIO.parse(fastaFilename, 'fasta'))
 
 
-def dedupFasta(reads: Reads) -> Generator[Read, None, None]:
+def dedupFasta(reads):
     """
     Remove sequence duplicates (based on sequence) from FASTA.
 
     @param reads: a C{dark.reads.Reads} instance.
     @return: a generator of C{dark.reads.Read} instances with no duplicates.
     """
-    seen: set[bytes] = set()
+    seen = set()
     add = seen.add
-
-    for read in iter(reads):
-        hash_ = md5(read.sequence.encode("UTF-8")).digest()
+    for read in reads:
+        hash_ = md5(read.sequence.encode('UTF-8')).digest()
         if hash_ not in seen:
             add(hash_)
             yield read
 
 
-def dePrefixAndSuffixFasta(
-    sequences: Iterable[Seq],
-) -> Generator[Seq, None, None]:
+def dePrefixAndSuffixFasta(sequences):
     """
     sequences: an iterator producing Bio.Seq sequences.
 
     return: a generator of sequences with no duplicates and no fully contained
         subsequences.
     """
     sequences = sorted(sequences, key=lambda s: len(s.seq), reverse=True)
     seen = set()
     for s in sequences:
         thisSeq = str(s.seq)
-        thisHash = md5(thisSeq.encode("UTF-8")).digest()
+        thisHash = md5(thisSeq.encode('UTF-8')).digest()
         if thisHash not in seen:
             # Add prefixes.
             newHash = md5()
             for nucl in thisSeq:
-                newHash.update(nucl.encode("UTF-8"))
+                newHash.update(nucl.encode('UTF-8'))
                 seen.add(newHash.digest())
             # Add suffixes.
             for start in range(len(thisSeq) - 1):
-                seen.add(md5(thisSeq[start + 1 :].encode("UTF-8")).digest())
+                seen.add(md5(thisSeq[start + 1:].encode('UTF-8')).digest())
             yield s
 
 
-def fastaSubtract(fastaFiles: List[TextIO]) -> Iterable[Seq]:
+def fastaSubtract(fastaFiles):
     """
     Given a list of open file descriptors, each with FASTA content,
     remove the reads found in the 2nd, 3rd, etc files from the first file
     in the list.
 
     @param fastaFiles: a C{list} of FASTA filenames.
     @raises IndexError: if passed an empty list.
-    @return: An iterator producing C{Bio.Seq} instances suitable for
+    @return: An iterator producing C{Bio.SeqRecord} instances suitable for
         writing to a file using C{Bio.SeqIO.write}.
 
     """
     reads = {}
-    fastaFiles = list(fastaFiles)
     firstFile = fastaFiles.pop(0)
-    for seq in SeqIO.parse(firstFile, "fasta"):
+    for seq in SeqIO.parse(firstFile, 'fasta'):
         reads[seq.id] = seq
 
     for fastaFile in fastaFiles:
-        for seq in SeqIO.parse(fastaFile, "fasta"):
+        for seq in SeqIO.parse(fastaFile, 'fasta'):
             # Make sure that reads with the same id have the same sequence.
             if seq.id in reads:
                 assert str(seq.seq) == str(reads[seq.id].seq)
             reads.pop(seq.id, None)
 
     return iter(reads.values())
 
@@ -93,62 +87,55 @@
     @param _files: Either a single C{str} file name or file handle, or a
         C{list} of C{str} file names and/or file handles. Each file or file
         handle must contain sequences in FASTA format.
     @param readClass: The class of read that should be yielded by iter.
     @param upperCase: If C{True}, read sequences will be converted to upper
         case.
     """
-
-    def __init__(
-        self,
-        _files: Union[str, TextIO, Union[list, tuple]],
-        readClass: Type[Read] = DNARead,
-        upperCase: bool = False,
-    ):
+    def __init__(self, _files, readClass=DNARead, upperCase=False):
         self._files = _files if isinstance(_files, (list, tuple)) else [_files]
         self._readClass = readClass
         # TODO: It would be better if upperCase were an argument that could
         # be passed to Reads.__init__ and that could do the uppercasing in
         # its add method (as opposed to using it below in our iter method).
         # In that case, in the iter of this class we'd call self.add on
         # each of the sequences coming from self._file. Or, if we'd already
         # read the file we'd return Reads.iter(self) to re-iterate over the
         # sequences already added from the file.
         self._upperCase = upperCase
-        super().__init__()
+        if PY3:
+            super().__init__()
+        else:
+            Reads.__init__(self)
 
-    def iter(self) -> Generator[Read, None, None]:
+    def iter(self):
         """
         Iterate over the sequences in the files in self.files_, yielding each
         as an instance of the desired read class.
         """
         count = 0
         for _file in self._files:
             with asHandle(_file) as fp:
                 # Duplicate some code here so as not to test
                 # self._upperCase in the loop.
                 if self._upperCase:
-                    for seq in SeqIO.parse(fp, "fasta"):
-                        read = self._readClass(seq.description, str(seq.seq.upper()))
+                    for seq in SeqIO.parse(fp, 'fasta'):
+                        read = self._readClass(seq.description,
+                                               str(seq.seq.upper()))
                         yield read
                         count += 1
                 else:
-                    for seq in SeqIO.parse(fp, "fasta"):
+                    for seq in SeqIO.parse(fp, 'fasta'):
                         read = self._readClass(seq.description, str(seq.seq))
                         yield read
                         count += 1
 
 
-def combineReads(
-    filename: str,
-    sequences: list[str],
-    readClass: Type[Read] = DNARead,
-    upperCase: bool = False,
-    idPrefix: str = "command-line-read-",
-) -> Union[FastaReads, Reads]:
+def combineReads(filename, sequences, readClass=DNARead,
+                 upperCase=False, idPrefix='command-line-read-'):
     """
     Combine FASTA reads from a file and/or sequence strings.
 
     @param filename: A C{str} file name containing FASTA reads.
     @param sequences: A C{list} of C{str} sequences. If a sequence
         contains spaces, the last field (after splitting on spaces) will be
         used as the sequence and the first fields will be used as the sequence
@@ -160,138 +147,128 @@
         sequence number will be appended to this prefix. Note that
         'command-line-read-', the default id prefix, could collide with ids in
         the FASTA file, if given. So output might be ambiguous. That's why we
         allow the caller to specify a custom prefix.
     @return: A C{FastaReads} instance.
     """
     # Read sequences from a FASTA file, if given.
-    reads: Union[FastaReads, Reads]
-
     if filename:
         reads = FastaReads(filename, readClass=readClass, upperCase=upperCase)
     else:
         reads = Reads()
 
     # Add any individually specified subject sequences.
     if sequences:
         for count, sequence in enumerate(sequences, start=1):
             # Try splitting the sequence on its last space and using the
             # first part of the split as the read id. If there's no space,
             # assign a generic id.
-            parts = sequence.rsplit(" ", 1)
+            parts = sequence.rsplit(' ', 1)
             if len(parts) == 2:
                 readId, sequence = parts
             else:
-                readId = "%s%d" % (idPrefix, count)
+                readId = '%s%d' % (idPrefix, count)
             if upperCase:
                 sequence = sequence.upper()
             read = readClass(readId, sequence)
             reads.add(read)
 
     return reads
 
 
-class SqliteIndex:
+class SqliteIndex(object):
     """
     Create an Sqlite3 database holding FASTA sequence ids, file names, and
     offsets for fast random dictionary-like access.
 
     @param dbFilename: A C{str} file name containing an sqlite3 database. If
         the file does not exist it will be created. The special string
         ":memory:" can be used to create an in-memory database.
     @param readClass: The class of read that should be returned by __getitem__.
     @param fastaDirectory: A C{str} directory where the indexed FASTA files
         can be found. If provided, this directory is only used by __getitem__,
         which will combine it with the basename of the files given to
         C{addFile} to locate the FASTA.
     """
-
-    def __init__(
-        self,
-        dbFilename: str,
-        readClass: Type[Read] = DNARead,
-        fastaDirectory: Optional[str] = None,
-    ):
+    def __init__(self, dbFilename, readClass=DNARead, fastaDirectory=None):
         self._readClass = readClass
         self._fastaDirectory = fastaDirectory
-        creating = dbFilename == ":memory:" or not os.path.exists(dbFilename)
-        self._connection: sqlite3.Connection = sqliteConnect(dbFilename)
+        creating = dbFilename == ':memory:' or not os.path.exists(dbFilename)
+        self._connection = sqlite3.connect(dbFilename)
         if creating:
             # Create a new database.
             cur = self._connection.cursor()
-            cur.executescript(
-                """
+            cur.executescript('''
                 CREATE TABLE files (
                     id INTEGER PRIMARY KEY AUTOINCREMENT,
                     name VARCHAR UNIQUE
                 );
 
                 CREATE TABLE sequences (
                     id VARCHAR UNIQUE PRIMARY KEY,
                     fileNumber INTEGER,
                     offset INTEGER
                 );
-            """
-            )
+            ''')
             self._connection.commit()
 
-    def _getFilename(self, fileNumber: int) -> Optional[str]:
+    def _getFilename(self, fileNumber):
         """
         Given a file number, get its name (if any).
 
         @param fileNumber: An C{int} file number.
         @return: A C{str} file name or C{None} if a file with that number
             has not been added.
         """
         cur = self._connection.cursor()
-        cur.execute("SELECT name FROM files WHERE id = ?", (fileNumber,))
+        cur.execute('SELECT name FROM files WHERE id = ?', (fileNumber,))
         row = cur.fetchone()
         if row is None:
             return None
         else:
             return row[0]
 
-    def _getFileNumber(self, filename: str) -> Optional[int]:
+    def _getFileNumber(self, filename):
         """
         Given a file name, get its file number (if any).
 
         @param filename: A C{str} file name.
         @return: An C{int} file number or C{None} if no file with that name
             has been added.
         """
         cur = self._connection.cursor()
-        cur.execute("SELECT id FROM files WHERE name = ?", (filename,))
+        cur.execute('SELECT id FROM files WHERE name = ?', (filename,))
         row = cur.fetchone()
         if row is None:
             return None
         else:
             return row[0]
 
-    def _addFilename(self, filename: str) -> Optional[int]:
+    def _addFilename(self, filename):
         """
         Add a new file name.
 
         @param filename: A C{str} file name.
         @raise ValueError: If a file with this name has already been added.
         @return: The C{int} id of the newly added file.
         """
         cur = self._connection.cursor()
         try:
-            cur.execute("INSERT INTO files(name) VALUES (?)", (filename,))
+            cur.execute('INSERT INTO files(name) VALUES (?)', (filename,))
         except sqlite3.IntegrityError as e:
-            if str(e).find("UNIQUE constraint failed") > -1:
-                raise ValueError("Duplicate file name: %r" % filename)
+            if str(e).find('UNIQUE constraint failed') > -1:
+                raise ValueError('Duplicate file name: %r' % filename)
             else:
                 raise
         else:
             fileNumber = cur.lastrowid
             self._connection.commit()
             return fileNumber
 
-    def addFile(self, filename: str) -> int:
+    def addFile(self, filename):
         """
         Add a new FASTA file of sequences.
 
         @param filename: A C{str} file name, with the file in FASTA format.
             This file must (obviously) exist at indexing time. When __getitem__
             is used to access sequences, it is possible to provide a
             C{fastaDirectory} argument to our C{__init__} to indicate the
@@ -301,144 +278,138 @@
             sqlite database from the shell in one directory and its use
             programmatically from another directory.
         @raise ValueError: If a file with this name has already been added or
             if the file contains a sequence whose id has already been seen.
         @return: The C{int} number of sequences added from the file.
         """
         endswith = filename.lower().endswith
-        if endswith(".bgz") or endswith(".gz"):
+        if endswith('.bgz') or endswith('.gz'):
             useBgzf = True
-        elif endswith(".bz2"):
+        elif endswith('.bz2'):
             raise ValueError(
-                "Compressed FASTA is only supported in BGZF format. Use "
-                "bgzip to compresss your FASTA."
-            )
+                'Compressed FASTA is only supported in BGZF format. Use '
+                'bgzip to compresss your FASTA.')
         else:
             useBgzf = False
 
         fileNumber = self._addFilename(filename)
         connection = self._connection
         count = 0
         try:
             with connection:
                 if useBgzf:
                     try:
-                        fp = bgzf.open(filename, "rb")
+                        fp = bgzf.open(filename, 'rb')
                     except ValueError as e:
-                        if str(e).find("BGZF") > -1:
+                        if str(e).find('BGZF') > -1:
                             raise ValueError(
-                                "Compressed FASTA is only supported in BGZF "
-                                "format. Use the samtools bgzip utility "
-                                "(instead of gzip) to compresss your FASTA."
-                            )
+                                'Compressed FASTA is only supported in BGZF '
+                                'format. Use the samtools bgzip utility '
+                                '(instead of gzip) to compresss your FASTA.')
                         else:
                             raise
                     else:
                         try:
                             for line in fp:
-                                if line[0] == ">":
+                                if line[0] == '>':
                                     count += 1
-                                    id_ = line[1:].rstrip(" \t\n\r")
+                                    id_ = line[1:].rstrip(' \t\n\r')
                                     connection.execute(
-                                        "INSERT INTO sequences(id, "
-                                        "fileNumber, offset) VALUES (?, ?, ?)",
-                                        (id_, fileNumber, fp.tell()),
-                                    )
+                                        'INSERT INTO sequences(id, '
+                                        'fileNumber, offset) VALUES (?, ?, ?)',
+                                        (id_, fileNumber, fp.tell()))
                         finally:
                             fp.close()
                 else:
                     with open(filename) as fp:
                         offset = 0
                         for line in fp:
                             offset += len(line)
-                            if line[0] == ">":
+                            if line[0] == '>':
                                 count += 1
-                                id_ = line[1:].rstrip(" \t\n\r")
+                                id_ = line[1:].rstrip(' \t\n\r')
                                 connection.execute(
-                                    "INSERT INTO sequences(id, fileNumber, "
-                                    "offset) VALUES (?, ?, ?)",
-                                    (id_, fileNumber, offset),
-                                )
+                                    'INSERT INTO sequences(id, fileNumber, '
+                                    'offset) VALUES (?, ?, ?)',
+                                    (id_, fileNumber, offset))
         except sqlite3.IntegrityError as e:
-            if str(e).find("UNIQUE constraint failed") > -1:
+            if str(e).find('UNIQUE constraint failed') > -1:
                 original = self._find(id_)
                 if original is None:
                     # The id must have appeared twice in the current file,
                     # because we could not look it up in the database
                     # (i.e., it was INSERTed but not committed).
                     raise ValueError(
-                        "FASTA sequence id '%s' found twice in file '%s'."
-                        % (id_, filename)
-                    )
+                        "FASTA sequence id '%s' found twice in file '%s'." %
+                        (id_, filename))
                 else:
                     origFilename, _ = original
                     raise ValueError(
                         "FASTA sequence id '%s', found in file '%s', was "
-                        "previously added from file '%s'."
-                        % (id_, filename, origFilename)
-                    )
+                        "previously added from file '%s'." %
+                        (id_, filename, origFilename))
             else:
                 raise
         else:
             return count
 
-    def _find(self, id_: str) -> Optional[tuple[Optional[str], int]]:
+    def _find(self, id_):
         """
         Find the filename and offset of a sequence, given its id.
 
         @param id_: A C{str} sequence id.
         @return: A 2-tuple, containing the C{str} file name and C{int} offset
             within that file of the sequence.
         """
         cur = self._connection.cursor()
-        cur.execute("SELECT fileNumber, offset FROM sequences WHERE id = ?", (id_,))
+        cur.execute(
+            'SELECT fileNumber, offset FROM sequences WHERE id = ?', (id_,))
         row = cur.fetchone()
         if row is None:
             return None
         else:
             return self._getFilename(row[0]), row[1]
 
-    def __getitem__(self, id_: str) -> Read:
+    def __getitem__(self, id_):
         """
         Return a read, given its id.
 
         @param id_: A C{str} sequence id.
         @raise KeyError: If C{id_} is not a known sequence.
         @return: A read of our read class.
         """
         location = self._find(id_)
         if location is None:
-            raise KeyError("Unknown sequence: %r" % id_)
+            raise KeyError('Unknown sequence: %r' % id_)
         else:
             filename, offset = location
             # If a FASTA directory was provided, look for the FASTA files
             # there, otherwise use the filename that was given to addFile.
-            assert filename
             if self._fastaDirectory:
-                filename = os.path.join(
-                    self._fastaDirectory, os.path.basename(filename)
-                )
+                filename = os.path.join(self._fastaDirectory,
+                                        os.path.basename(filename))
 
             endswith = filename.lower().endswith
-            if endswith(".bgz") or endswith(".gz"):
+            if endswith('.bgz') or endswith('.gz'):
                 opener = bgzf.open
             else:
                 opener = open
 
-            sequence = ""
+            sequence = ''
             with opener(filename) as fp:
                 fp.seek(offset)
                 while True:
                     line = fp.readline()
                     if not line:
                         # EOF
                         break
-                    elif line[0] == ">":
+                    elif line[0] == '>':
                         # We found the next sequence identifier.
                         break
                     else:
-                        sequence += line.rstrip("\n\r")
+                        sequence += line.rstrip('\n\r')
 
             return self._readClass(id_, sequence)
 
-    def close(self) -> None:
+    def close(self):
         self._connection.close()
+        self._connection = None
```

### Comparing `dark-matter-4.0.84/dark/fasta_ss.py` & `dark-matter-4.0.9/dark/fasta_ss.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,9 @@
-from Bio import SeqIO  # type: ignore
+from six import PY3
+from Bio import SeqIO
 
 from dark.reads import Reads, SSAARead
 from dark.utils import asHandle
 
 
 class SSFastaReads(Reads):
     """
@@ -26,66 +27,59 @@
         C{list} of C{str} file names and/or file handles. Each file or file
         handle must contain sequences in PDB FASTA format (see above).
     @param readClass: The class of read that should be yielded by iter. This
         must accept 3 C{str} arguments: an id, the sequence, the structure.
     @param upperCase: If C{True}, both read and structure sequences will be
         converted to upper case.
     """
-
     def __init__(self, _files, readClass=SSAARead, upperCase=False):
         self._files = _files if isinstance(_files, (list, tuple)) else [_files]
         self._readClass = readClass
         self._upperCase = upperCase
-        super().__init__()
+        if PY3:
+            super().__init__()
+        else:
+            Reads.__init__(self)
 
     def iter(self):
         """
         Iterate over the sequences in self.file_, yielding each as an
         instance of the desired read class.
 
         @raise ValueError: If the input file has an odd number of records or
             if any sequence has a different length than its predicted
             secondary structure.
         """
         upperCase = self._upperCase
         for _file in self._files:
             with asHandle(_file) as fp:
-                records = SeqIO.parse(fp, "fasta")
+                records = SeqIO.parse(fp, 'fasta')
                 while True:
                     try:
                         record = next(records)
                     except StopIteration:
                         break
                     try:
                         structureRecord = next(records)
                     except StopIteration:
-                        raise ValueError(
-                            "Structure file %r has an odd number of records." % _file
-                        )
+                        raise ValueError('Structure file %r has an odd number '
+                                         'of records.' % _file)
 
                     if len(structureRecord) != len(record):
                         raise ValueError(
-                            "Sequence %r length (%d) is not equal to "
-                            "structure %r length (%d) in input file %r."
-                            % (
-                                record.description,
-                                len(record),
+                            'Sequence %r length (%d) is not equal to '
+                            'structure %r length (%d) in input file %r.' % (
+                                record.description, len(record),
                                 structureRecord.description,
-                                len(structureRecord),
-                                _file,
-                            )
-                        )
+                                len(structureRecord), _file))
 
                     if upperCase:
                         read = self._readClass(
                             record.description,
                             str(record.seq.upper()),
-                            str(structureRecord.seq.upper()),
-                        )
+                            str(structureRecord.seq.upper()))
                     else:
-                        read = self._readClass(
-                            record.description,
-                            str(record.seq),
-                            str(structureRecord.seq),
-                        )
+                        read = self._readClass(record.description,
+                                               str(record.seq),
+                                               str(structureRecord.seq))
 
                     yield read
```

### Comparing `dark-matter-4.0.84/dark/fastq.py` & `dark-matter-4.0.9/dark/fastq.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 from six import PY3
 
-from Bio.SeqIO.QualityIO import FastqGeneralIterator  # type: ignore
+from Bio.SeqIO.QualityIO import FastqGeneralIterator
 
 from dark.reads import Reads, DNARead
 from dark.utils import asHandle
 
 
 class FastqReads(Reads):
     """
     Subclass of L{dark.reads.Reads} providing access to FASTQ reads.
 
     @param _files: Either a single C{str} file name or file handle, or a
         C{list} of C{str} file names and/or file handles. Each file or file
         handle must contain sequences in FASTQ format.
     @param readClass: The class of read that should be yielded by iter.
     """
-
     def __init__(self, _files, readClass=DNARead):
         self._files = _files if isinstance(_files, (list, tuple)) else [_files]
         self.readClass = readClass
         if PY3:
             super().__init__()
         else:
             Reads.__init__(self)
```

### Comparing `dark-matter-4.0.84/dark/features.py` & `dark-matter-4.0.9/dark/features.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,23 +1,34 @@
 import numpy as np
 import os
 
-from typing import Optional, Tuple
-
-import matplotlib
-
-if not os.environ.get("DISPLAY"):
-    # Use non-interactive Agg backend
-    matplotlib.use("Agg")
-from matplotlib import pyplot as plt
+try:
+    import matplotlib
+    if not os.environ.get('DISPLAY'):
+        # Use non-interactive Agg backend
+        matplotlib.use('Agg')
+    from matplotlib import pyplot as plt
+except ImportError:
+    import platform
+    if platform.python_implementation() == 'PyPy':
+        # PyPy doesn't have a version of matplotlib. Make fake classes and
+        # a Line2D function and that raise if used. This allows us to use
+        # other 'dark' code that happens to import dark.mutations but not
+        # use the functions that rely on matplotlib.
+        class plt(object):
+            def __getattr__(self, _):
+                raise NotImplementedError(
+                    'matplotlib is not supported under pypy')
+    else:
+        raise
 
 from dark.entrez import getSequence
 
 
-class Feature:
+class Feature(object):
     """
     An offset-adjusted feature, with start and stop attributes and methods to
     return a textual description and a legend label.
 
     @param feature: A BioPython feature.
     @param subfeature: A C{bool} to indicate if a feature is actually a
         subfeature.
@@ -41,45 +52,36 @@
     def legendLabel(self):
         """
         Provide a textual description of the feature and its qualifiers to be
         used as a label in a plot legend.
 
         @return: A C{str} description of the feature.
         """
-        excludedQualifiers = set(
-            (
-                "codon_start",
-                "db_xref",
-                "protein_id",
-                "region_name",
-                "ribosomal_slippage",
-                "rpt_type",
-                "translation",
-                "transl_except",
-                "transl_table",
-            )
+        excludedQualifiers = set((
+            'codon_start', 'db_xref', 'protein_id', 'region_name',
+            'ribosomal_slippage', 'rpt_type', 'translation', 'transl_except',
+            'transl_table')
         )
         maxValueLength = 30
         result = []
         if self.feature.qualifiers:
             for qualifier in sorted(self.feature.qualifiers):
                 if qualifier not in excludedQualifiers:
-                    value = ", ".join(self.feature.qualifiers[qualifier])
-                    if qualifier == "site_type" and value == "other":
+                    value = ', '.join(self.feature.qualifiers[qualifier])
+                    if qualifier == 'site_type' and value == 'other':
                         continue
                     if len(value) > maxValueLength:
-                        value = value[: maxValueLength - 3] + "..."
-                    result.append("%s: %s" % (qualifier, value))
-        return "%d-%d %s%s.%s" % (
+                        value = value[:maxValueLength - 3] + '...'
+                    result.append('%s: %s' % (qualifier, value))
+        return '%d-%d %s%s.%s' % (
             int(self.feature.location.start),
             int(self.feature.location.end),
             self.feature.type,
-            " (subfeature)" if self.subfeature else "",
-            " " + ", ".join(result) if result else "",
-        )
+            ' (subfeature)' if self.subfeature else '',
+            ' ' + ', '.join(result) if result else '')
 
 
 class FeatureList(list):
     """
     Provide access to a list of L{Feature} objects.
 
     @param title: A C{str} sequence title from a BLAST hit. Of the form
@@ -112,30 +114,31 @@
             # Assign colors to features.
             colormap = plt.cm.coolwarm
             colors = [colormap(i) for i in np.linspace(0.0, 0.99, len(self))]
             for feature, color in zip(self, colors):
                 feature.setColor(color)
 
 
-class _FeatureAdder:
+class _FeatureAdder(object):
     """
     Look up features for a title, and provide a method to add them to a figure
     as well as returning them.
     """
 
     TITLE_FONTSIZE = 16
     FONTSIZE = 20
     MAX_FEATURES_TO_DISPLAY = 50
-    DATABASE = Optional[str]  # Set in subclasses.
-    WANTED_TYPES = Optional[Tuple[str, ...]]  # Set in subclasses.
+    DATABASE = None  # Set in subclasses.
+    WANTED_TYPES = None  # Set in subclasses.
 
     def __init__(self):
         self.tooManyFeaturesToPlot = False
 
-    def add(self, fig, title, minX, maxX, offsetAdjuster=None, sequenceFetcher=None):
+    def add(self, fig, title, minX, maxX, offsetAdjuster=None,
+            sequenceFetcher=None):
         """
         Find the features for a sequence title. If there aren't too many, add
         the features to C{fig}. Return information about the features, as
         described below.
 
         @param fig: A matplotlib figure.
         @param title: A C{str} sequence title from a BLAST hit. Of the form
@@ -149,64 +152,48 @@
             L{dark.entrez.getSequence}.
         @return: If we seem to be offline, return C{None}. Otherwise, return
             a L{FeatureList} instance.
         """
 
         offsetAdjuster = offsetAdjuster or (lambda x: x)
 
-        fig.set_title("Target sequence features", fontsize=self.TITLE_FONTSIZE)
+        fig.set_title('Target sequence features', fontsize=self.TITLE_FONTSIZE)
         fig.set_yticks([])
 
-        features = FeatureList(
-            title, self.DATABASE, self.WANTED_TYPES, sequenceFetcher=sequenceFetcher
-        )
+        features = FeatureList(title, self.DATABASE, self.WANTED_TYPES,
+                               sequenceFetcher=sequenceFetcher)
 
         if features.offline:
-            fig.text(
-                minX + (maxX - minX) / 3.0,
-                0,
-                "You (or Genbank) appear to be offline.",
-                fontsize=self.FONTSIZE,
-            )
+            fig.text(minX + (maxX - minX) / 3.0, 0,
+                     'You (or Genbank) appear to be offline.',
+                     fontsize=self.FONTSIZE)
             fig.axis([minX, maxX, -1, 1])
             return None
 
         # If no interesting features were found, display a message saying
         # so in the figure.  Otherwise, if we don't have too many features
         # to plot, add the feature info to the figure.
         nFeatures = len(features)
         if nFeatures == 0:
             # fig.text(minX + (maxX - minX) / 3.0, 0, 'No features found',
             #          fontsize=self.FONTSIZE)
-            fig.text(
-                0.5,
-                0.5,
-                "No features found",
-                horizontalalignment="center",
-                verticalalignment="center",
-                transform=fig.transAxes,
-                fontsize=self.FONTSIZE,
-            )
+            fig.text(0.5, 0.5, 'No features found',
+                     horizontalalignment='center', verticalalignment='center',
+                     transform=fig.transAxes, fontsize=self.FONTSIZE)
             fig.axis([minX, maxX, -1, 1])
         elif nFeatures <= self.MAX_FEATURES_TO_DISPLAY:
             # Call the method in our subclass to do the figure display.
             self._displayFeatures(fig, features, minX, maxX, offsetAdjuster)
         else:
             self.tooManyFeaturesToPlot = True
             # fig.text(minX + (maxX - minX) / 3.0, 0,
             # 'Too many features to plot.', fontsize=self.FONTSIZE)
-            fig.text(
-                0.5,
-                0.5,
-                "Too many features to plot",
-                horizontalalignment="center",
-                verticalalignment="center",
-                fontsize=self.FONTSIZE,
-                transform=fig.transAxes,
-            )
+            fig.text(0.5, 0.5, 'Too many features to plot',
+                     horizontalalignment='center', verticalalignment='center',
+                     fontsize=self.FONTSIZE, transform=fig.transAxes)
             fig.axis([minX, maxX, -1, 1])
 
         return features
 
     def _displayFeatures(self, fig, features, minX, maxX, offsetAdjuster):
         """
         Add the given C{features} to the figure in C{fig}.
@@ -214,84 +201,68 @@
         @param fig: A matplotlib figure.
         @param features: A C{FeatureList} instance.
         @param minX: The smallest x coordinate.
         @param maxX: The largest x coordinate.
         @param offsetAdjuster: a function for adjusting feature X axis offsets
             for plotting.
         """
-        raise NotImplementedError(
-            "_displayFeatures must be implemented in a subclass."
-        )
+        raise NotImplementedError('_displayFeatures must be implemented in '
+                                  'a subclass.')
 
 
 class ProteinFeatureAdder(_FeatureAdder):
     """
     Subclass L{_FeatureAdder} with a method to add protein features to a
     figure.
     """
-
-    DATABASE = "protein"
-    WANTED_TYPES = ("CDS", "mat_peptide", "rRNA", "Site", "Region")
+    DATABASE = 'protein'
+    WANTED_TYPES = ('CDS', 'mat_peptide', 'rRNA', 'Site', 'Region')
 
     def _displayFeatures(self, fig, features, minX, maxX, offsetAdjuster):
         """
         Add the given C{features} to the figure in C{fig}.
 
         @param fig: A matplotlib figure.
         @param features: A C{FeatureList} instance.
         @param minX: The smallest x coordinate.
         @param maxX: The largest x coordinate.
         @param offsetAdjuster: a function for adjusting feature X axis offsets
             for plotting.
         """
         labels = []
         for index, feature in enumerate(features):
-            fig.plot(
-                [offsetAdjuster(feature.start), offsetAdjuster(feature.end)],
-                [index * -0.2, index * -0.2],
-                color=feature.color,
-                linewidth=2,
-            )
+            fig.plot([offsetAdjuster(feature.start),
+                      offsetAdjuster(feature.end)],
+                     [index * -0.2, index * -0.2], color=feature.color,
+                     linewidth=2)
             labels.append(feature.legendLabel())
 
         # Note that minX and maxX do not need to be adjusted by the offset
         # adjuster. They are the already-adjusted min/max values as
         # computed in computePlotInfo in blast.py
         fig.axis([minX, maxX, (len(features) + 1) * -0.2, 0.2])
 
         if labels:
             # Put a legend above the figure.
             box = fig.get_position()
-            fig.set_position([box.x0, box.y0, box.width, box.height * 0.2])
-            fig.legend(
-                labels,
-                loc="lower center",
-                bbox_to_anchor=(0.5, 1.4),
-                fancybox=True,
-                shadow=True,
-                ncol=2,
-            )
+            fig.set_position([box.x0, box.y0,
+                              box.width, box.height * 0.2])
+            fig.legend(labels, loc='lower center', bbox_to_anchor=(0.5, 1.4),
+                       fancybox=True, shadow=True, ncol=2)
 
 
 class NucleotideFeatureAdder(_FeatureAdder):
     """
     Subclass L{_FeatureAdder} with a method to add nucleotide features to a
     figure.
     """
 
-    DATABASE = "nucleotide"
-    WANTED_TYPES = (
-        "CDS",
-        "LTR",
-        "mat_peptide",
-        "misc_feature",
-        "misc_structure",
-        "repeat_region",
-        "rRNA",
-    )
+    DATABASE = 'nucleotide'
+    WANTED_TYPES = ('CDS', 'LTR', 'mat_peptide', 'misc_feature',
+                    'misc_structure', 'repeat_region', 'rRNA')
 
     def _displayFeatures(self, fig, features, minX, maxX, offsetAdjuster):
         """
         Add the given C{features} to the figure in C{fig}.
 
         @param fig: A matplotlib figure.
         @param features: A C{FeatureList} instance.
@@ -313,34 +284,29 @@
                     y = subfeatureFrame - 0.2
                 else:
                     y = subfeatureFrame
             else:
                 frame = start % 3
                 # If we have a polyprotein, shift it up slightly so we can see
                 # its components below it.
-                product = feature.feature.qualifiers.get("product", [""])[0]
-                if product.lower().find("polyprotein") > -1:
+                product = feature.feature.qualifiers.get('product', [''])[0]
+                if product.lower().find('polyprotein') > -1:
                     y = frame + 0.2
                 else:
                     y = frame
             fig.plot([start, end], [y, y], color=feature.color, linewidth=2)
             labels.append(feature.legendLabel())
 
         # Note that minX and maxX do not need to be adjusted by the offset
         # adjuster. They are the already-adjusted min/max values as
         # computed in computePlotInfo in blast.py
         fig.axis([minX, maxX, -0.5, 2.5])
         fig.set_yticks(np.arange(3))
-        fig.set_ylabel("Frame")
+        fig.set_ylabel('Frame')
 
         if labels:
             # Put a legend above the figure.
             box = fig.get_position()
-            fig.set_position([box.x0, box.y0, box.width, box.height * 0.3])
-            fig.legend(
-                labels,
-                loc="lower center",
-                bbox_to_anchor=(0.5, 2.5),
-                fancybox=True,
-                shadow=True,
-                ncol=2,
-            )
+            fig.set_position([box.x0, box.y0,
+                              box.width, box.height * 0.3])
+            fig.legend(labels, loc='lower center', bbox_to_anchor=(0.5, 2.5),
+                       fancybox=True, shadow=True, ncol=2)
```

### Comparing `dark-matter-4.0.84/dark/fpcache.py` & `dark-matter-4.0.9/dark/fpcache.py`

 * *Files 11% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 
 
 class _FilePointerCache(LFUCache):
     """
     A least-frequently-used file pointer cache class with an eviction method
     that closes open files.
     """
-
     def popitem(self):
         """
         Evict a cache item.
 
         @return: The C{str} name of the evicted file.
         """
         _, (filename, fp) = super().popitem()
@@ -23,29 +22,28 @@
         """
         Close all open files in the cache.
         """
         while self.currsize:
             self.popitem()
 
 
-class FilePointerCache:
+class FilePointerCache(object):
     """
     A file pointer cache class for simultaneously opening multiple files,
     without exceeeding the per-process operating system limit on open file
     handles.
 
     @param maxsize: The C{int} maximum size of the cache.
     @param openArgs: If not C{None}, a C{dict} of keyword arguments to pass to
         open when opening a new file. If C{None}, the file will be opened
         with the default mode ('rt').
     @param reopenArgs: If not C{None}, a C{dict} of keyword arguments to pass
         to open when opening an already existing file. If C{None}, the file
         will be opened with the default mode ('rt').
     """
-
     def __init__(self, maxsize=32, openArgs=None, reopenArgs=None):
         self._openArgs = openArgs or {}
         self._reopenArgs = reopenArgs or {}
         self._filePointerCache = _FilePointerCache(maxsize=maxsize)
         self._lock = RLock()
 
         @cached(self._filePointerCache, lock=self._lock)
```

### Comparing `dark-matter-4.0.84/dark/genbank.py` & `dark-matter-4.0.9/dark/genbank.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from warnings import warn
 
 
-class GenomeRanges:
+class GenomeRanges(object):
     """
     Split and manage a GenBank range string as converted by BioPython.
 
     @param rangeStr: A C{str} indicating the (0-based) genome nucleotide
         offsets covered by a protein. This can have the following example
         forms:
 
@@ -32,73 +32,66 @@
 
             '[11969:12575](-)' => ((11969, 12575, False),)
 
             'join{[126386:126881](-), [125941:126232](+)}' =>
                 ((126386, 126881, False),
                  (125941, 126232, True))
     """
-
     def __init__(self, rangeStr):
-        if rangeStr.startswith("join{") and rangeStr[-1] == "}":
+        if rangeStr.startswith('join{') and rangeStr[-1] == '}':
             join = True
             inner = rangeStr[5:-1]
         else:
             join = False
             inner = rangeStr
 
         ranges = []
-        subRanges = inner.split(", ")
+        subRanges = inner.split(', ')
         nRanges = len(subRanges)
 
         if nRanges == 1 and join:
-            raise ValueError(
-                'Could not parse GenBank range string "%s". '
-                "join{} can only be used with multiple ranges." % rangeStr
-            )
+            raise ValueError('Could not parse GenBank range string "%s". '
+                             'join{} can only be used with multiple ranges.' %
+                             rangeStr)
         elif nRanges > 1 and not join:
-            raise ValueError(
-                'Could not parse GenBank range string "%s". '
-                "Multiple ranges must be wrapped in join{}." % rangeStr
-            )
+            raise ValueError('Could not parse GenBank range string "%s". '
+                             'Multiple ranges must be wrapped in join{}.' %
+                             rangeStr)
 
         for subRange in subRanges:
-            if subRange.endswith("](+)"):
+            if subRange.endswith('](+)'):
                 forward = True
-            elif subRange.endswith("](-)"):
+            elif subRange.endswith('](-)'):
                 forward = False
             else:
-                raise ValueError(
-                    'Could not parse GenBank range string "%s". '
-                    'Range "%s" does not end with ](+) or ](-).' % (rangeStr, subRange)
-                )
-
-            if not subRange.startswith("["):
-                raise ValueError(
-                    'Could not parse GenBank range string "%s". '
-                    'Range "%s" does not start with "[".' % (rangeStr, subRange)
-                )
+                raise ValueError('Could not parse GenBank range string "%s". '
+                                 'Range "%s" does not end with ](+) or ](-).' %
+                                 (rangeStr, subRange))
+
+            if not subRange.startswith('['):
+                raise ValueError('Could not parse GenBank range string "%s". '
+                                 'Range "%s" does not start with "[".' %
+                                 (rangeStr, subRange))
             try:
-                start, stop = subRange[1:-4].split(":")
+                start, stop = subRange[1:-4].split(':')
             except ValueError as e:
-                raise ValueError(
-                    'Could not parse GenBank range string "%s". '
-                    'Original parsing ValueError was "%s".' % (rangeStr, e)
-                )
+                raise ValueError('Could not parse GenBank range string "%s". '
+                                 'Original parsing ValueError was "%s".' %
+                                 (rangeStr, e))
             else:
-                if start.startswith("<"):
+                if start.startswith('<'):
                     start = start[1:]
-                if stop.startswith(">"):
+                if stop.startswith('>'):
                     stop = stop[1:]
                 start, stop = map(int, (start, stop))
                 if start > stop:
                     raise ValueError(
                         'Could not parse GenBank range string "%s". '
-                        "Offset values (%d, %d) cannot decrease."
-                        % (rangeStr, start, stop)
-                    )
+                        'Offset values (%d, %d) cannot decrease.' %
+                        (rangeStr, start, stop))
 
                 ranges.append((start, stop, forward))
 
         self.ranges = self._mergeContiguousRanges(ranges)
         self._nRanges = len(self.ranges)
 
     def _mergeContiguousRanges(self, ranges):
@@ -115,32 +108,32 @@
 
         for index, (start, stop, forward) in enumerate(ranges):
             if lastStart is None:
                 lastStart, lastStop, lastForward = start, stop, forward
             else:
                 if start == lastStop and forward == lastForward:
                     # This range continues the previous one.
-                    warn(
-                        "Contiguous GenBank ranges detected: [%d:%d] "
-                        "followed by [%d:%d]." % (lastStart, lastStop, start, stop)
-                    )
+                    warn('Contiguous GenBank ranges detected: [%d:%d] '
+                         'followed by [%d:%d].' %
+                         (lastStart, lastStop, start, stop))
                     lastStop = stop
                 else:
                     # Emit the range that just got terminated.
                     result.append((lastStart, lastStop, lastForward))
                     # And remember this one.
                     lastStart, lastStop, lastForward = start, stop, forward
 
         # Emit the final range.
         result.append((lastStart, lastStop, lastForward))
 
         return tuple(result)
 
     def __str__(self):
-        return "<%s: %s>" % (self.__class__.__name__, ", ".join(map(str, self.ranges)))
+        return '<%s: %s>' % (
+            self.__class__.__name__, ', '.join(map(str, self.ranges)))
 
     def circular(self, genomeLength):
         """
         Determine whether the offset ranges of a protein in a genome span the
         end of the genome (indicating that the genome may be circular).
 
         @param genomeLength: The C{int} length of the genome.
@@ -187,32 +180,30 @@
             protein.
         @return: The C{int} offset of the start of the DIAMOND match in the
             genome.
         """
 
         # Calculate the start of the match in the genome, given its start in
         # the protein.
-        offsetInGenome = remaining = (match["sstart"] - 1) * 3
+        offsetInGenome = remaining = (match['sstart'] - 1) * 3
 
         for start, stop, _ in self.ranges:
             rangeWidth = stop - start
             if remaining < rangeWidth:
                 # The match starts in this range.
                 return start + remaining
             else:
                 remaining -= rangeWidth
         else:
             raise ValueError(
-                "Starting nucleotide offset %d not found in protein "
-                "nucleotide ranges %s."
-                % (
-                    offsetInGenome,
-                    ", ".join(("(%d, %d)" % (i, j)) for i, j, _ in self.ranges),
-                )
-            )
+                'Starting nucleotide offset %d not found in protein '
+                'nucleotide ranges %s.' %
+                (offsetInGenome,
+                 ', '.join(('(%d, %d)' % (i, j))
+                           for i, j, _ in self.ranges)))
 
     def orientations(self):
         """
         Produce the set of all orientations for our ranges.
 
         @return: A C{set} of C{True} and C{False} range orientations.
         """
@@ -225,15 +216,16 @@
         @param genomeLength: The C{int} length of the genome.
         @return: An C{int} which is the number of ranges that are not
             contiguous with one another.
         """
         return len(self.ranges) - int(self.circular(genomeLength))
 
 
-def getSourceInfo(genome, keys=("host", "note", "organism", "mol_type"), logfp=None):
+def getSourceInfo(genome, keys=('host', 'note', 'organism', 'mol_type'),
+                  logfp=None):
     """
     Extract summary information from a genome source feature.
 
     @param genome: A GenBank genome record, as parsed by SeqIO.parse
     @param keys: An iterable of C{str} keys to extract from the Genbank
         source features.
     @param logfp: If not C{None}, a file pointer to write verbose
@@ -242,64 +234,57 @@
         (if any) found in the source feature (see the return value below
         for detail). Or C{None} if no source feature is found or a source
         feature does not have length 1.
     """
     result = {}
 
     for feature in genome.features:
-        if feature.type == "source":
+        if feature.type == 'source':
             for key in keys:
                 try:
                     values = feature.qualifiers[key]
                 except KeyError:
                     value = None
-                    if key != "note" and logfp:
-                        print(
-                            "Genome %r (accession %s) source info has "
-                            "no %r feature." % (genome.description, genome.id, key),
-                            file=logfp,
-                        )
+                    if key != 'note' and logfp:
+                        print('Genome %r (accession %s) source info has '
+                              'no %r feature.' %
+                              (genome.description, genome.id, key),
+                              file=logfp)
                 else:
                     if len(values) == 1:
                         value = values[0]
 
-                        if key == "mol_type":
-                            assert value[-3:] in ("DNA", "RNA")
+                        if key == 'mol_type':
+                            assert value[-3:] in ('DNA', 'RNA')
 
-                    elif len(values) > 1 and key == "host":
-                        value = ", ".join(values)
+                    elif len(values) > 1 and key == 'host':
+                        value = ', '.join(values)
                     else:
                         if logfp:
-                            print(
-                                "Genome %r (accession %s) has source "
-                                "feature %r with length != 1: %r"
-                                % (genome.description, genome.id, key, values),
-                                file=logfp,
-                            )
+                            print('Genome %r (accession %s) has source '
+                                  'feature %r with length != 1: %r' % (
+                                      genome.description, genome.id, key,
+                                      values), file=logfp)
                         return
 
                 result[key] = value
 
             # Break so no other features are examined; we only want source.
             break
     else:
         if logfp:
-            print(
-                "Genome %r (accession %s) had no source feature! "
-                "Skipping." % (genome.description, genome.id),
-                file=logfp,
-            )
+            print('Genome %r (accession %s) had no source feature! '
+                  'Skipping.' % (genome.description, genome.id), file=logfp)
         return
 
     return result
 
 
-def getCDSInfo(
-    genome, feature, keys=("gene", "note", "product", "protein_id", "translation")
-):
+def getCDSInfo(genome, feature,
+               keys=('gene', 'note', 'product', 'protein_id', 'translation')):
     """
     Extract summary information from a genome CDS feature.
 
     @param genome: A GenBank genome record, as parsed by SeqIO.parse
     @param feature: A feature from a genome, as produced by BioPython's
         GenBank parser.
     @param keys: An iterable of C{str} keys to extract from the Genbank
@@ -308,72 +293,60 @@
         found in the feature (see the return value below for detail).
         Or C{None} if the feature is not of interest or otherwise invalid.
     """
     qualifiers = feature.qualifiers
 
     # Check in advance that all feature qualifiers we're interested in
     # have the right lengths, if they're present.
-    for key in "gene", "note", "product", "protein_id", "translation":
+    for key in 'gene', 'note', 'product', 'protein_id', 'translation':
         if key in qualifiers:
-            assert (
-                len(qualifiers[key]) == 1
-            ), "GenBank qualifier key %s is not length one %r" % (key, qualifiers[key])
+            assert len(qualifiers[key]) == 1, (
+                'GenBank qualifier key %s is not length one %r' %
+                (key, qualifiers[key]))
 
     # A protein id is mandatory.
-    if "protein_id" in qualifiers:
-        proteinId = qualifiers["protein_id"][0]
+    if 'protein_id' in qualifiers:
+        proteinId = qualifiers['protein_id'][0]
     else:
-        if "translation" in qualifiers:
-            warn(
-                "Genome %r (accession %s) has CDS feature with no "
-                "protein_id feature but has a translation! "
-                "Skipping.\nFeature: %s" % (genome.description, genome.id, feature)
-            )
+        if 'translation' in qualifiers:
+            warn('Genome %r (accession %s) has CDS feature with no '
+                 'protein_id feature but has a translation! '
+                 'Skipping.\nFeature: %s' %
+                 (genome.description, genome.id, feature))
         return
 
     # A translated (i.e., amino acid) sequence is mandatory.
-    if "translation" in qualifiers:
-        translation = qualifiers["translation"][0]
+    if 'translation' in qualifiers:
+        translation = qualifiers['translation'][0]
     else:
-        warn(
-            "Genome %r (accession %s) has CDS feature with protein "
-            "%r with no translated sequence. Skipping."
-            % (genome.description, genome.id, proteinId)
-        )
+        warn('Genome %r (accession %s) has CDS feature with protein '
+             '%r with no translated sequence. Skipping.' %
+             (genome.description, genome.id, proteinId))
         return
 
     featureLocation = str(feature.location)
 
     # Make sure the feature's location string can be parsed.
     try:
         ranges = GenomeRanges(featureLocation)
     except ValueError as e:
-        warn(
-            "Genome %r  (accession %s) contains unparseable CDS "
-            "location for protein %r. Skipping. Error: %s"
-            % (genome.description, genome.id, proteinId, e)
-        )
+        warn('Genome %r  (accession %s) contains unparseable CDS '
+             'location for protein %r. Skipping. Error: %s' %
+             (genome.description, genome.id, proteinId, e))
         return
     else:
         # Does the protein span the end of the genome? This indicates a
         # circular genome.
         circular = int(ranges.circular(len(genome.seq)))
 
     if feature.location.start >= feature.location.end:
-        warn(
-            "Genome %r (accession %s) contains feature with start "
-            "(%d) >= stop (%d). Skipping.\nFeature: %s"
-            % (
-                genome.description,
-                genome.id,
-                feature.location.start,
-                feature.location.end,
-                feature,
-            )
-        )
+        warn('Genome %r (accession %s) contains feature with start '
+             '(%d) >= stop (%d). Skipping.\nFeature: %s' %
+             (genome.description, genome.id, feature.location.start,
+              feature.location.end, feature))
         return
 
     strand = feature.strand
     if strand is None:
         # The strands of the protein in the genome are not all the same
         # (see Bio.SeqFeature.CompoundLocation._get_strand).  The
         # protein is formed by the combination of reading one strand in
@@ -386,39 +359,37 @@
         # This situation makes turning DIAMOND protein output into
         # SAM very complicated because a match on such a protein
         # cannot be stored as a SAM linear alignment. It instead
         # requires a multi-line 'supplementary' alignment. The code
         # and tests for that are more complex than I want to deal
         # with at the moment, just for the sake of one protein in a
         # frog herpesvirus.
-        warn(
-            "Genome %s (accession %s) has protein %r with mixed "
-            "orientation!" % (genome.description, genome.id, proteinId)
-        )
+        warn('Genome %s (accession %s) has protein %r with mixed '
+             'orientation!' % (genome.description, genome.id,
+                               proteinId))
         return
     elif strand == 0:
         # This never occurs for proteins corresponding to genomes in
         # the RVDB database C-RVDBv15.1.
-        warn(
-            "Genome %r (accession %s) has protein %r with feature "
-            "with strand of zero!" % (genome.description, genome.id, proteinId)
-        )
+        warn('Genome %r (accession %s) has protein %r with feature '
+             'with strand of zero!' %
+             (genome.description, genome.id, proteinId))
         return
     else:
         assert strand in (1, -1)
         forward = strand == 1
         # Make sure the strand agrees with the orientations in the
         # string BioPython makes out of the locations.
         assert ranges.orientations() == {forward}
 
     return {
-        "circular": circular,
-        "featureLocation": featureLocation,
-        "forward": forward,
-        "gene": qualifiers.get("gene", [""])[0],
-        "note": qualifiers.get("note", [""])[0],
-        "product": qualifiers.get("product", ["UNKNOWN"])[0],
-        "proteinId": proteinId,
-        "ranges": ranges,
-        "strand": strand,
-        "translation": translation,
+        'circular': circular,
+        'featureLocation': featureLocation,
+        'forward': forward,
+        'gene': qualifiers.get('gene', [''])[0],
+        'note': qualifiers.get('note', [''])[0],
+        'product': qualifiers.get('product', ['UNKNOWN'])[0],
+        'proteinId': proteinId,
+        'ranges': ranges,
+        'strand': strand,
+        'translation': translation,
     }
```

### Comparing `dark-matter-4.0.84/dark/genomes.py` & `dark-matter-4.0.9/dark/genomes.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,27 +2,27 @@
 
 from dark.errors import NoSuchGenomeError
 from dark.genbank import GenomeRanges
 from dark.reads import DNARead
 from dark.sam import samfile
 
 
-class GenomeProteinInfo:
+class GenomeProteinInfo(object):
     """
     Hold information about the proteins in a genome and how they are matched
     by reads in SAM files.
 
     @param accession: The C{str} accession number of a genome.
     @param proteinGenomeDB: A L{dark.civ.proteins.SqliteIndex} instance.
     @param checkTranslations: If C{True}, check that the protein sequences
         that area supposed to have come from the genome can be obtained by
         translating the corresponding region of the genome.
     """
-
-    def __init__(self, genomeAccession, proteinGenomeDB, checkTranslations=True):
+    def __init__(self, genomeAccession, proteinGenomeDB,
+                 checkTranslations=True):
         self.genomeAccession = genomeAccession
         self.proteinGenomeDB = proteinGenomeDB
         # self.proteins is keyed by protein accession number.
         self.proteins = {}
         self.coveredProteins = set()
         # self.offsets is keyed by genome offset, values are dicts that
         # contain a list of protein accession numbers that overlap that
@@ -35,35 +35,34 @@
         # not.
         self.coveredOffsetCount = Counter()
         self.samFiles = []
         self.readIdsMatchingGenome = set()
 
         self.genome = proteinGenomeDB.findGenome(genomeAccession)
         if self.genome is None:
-            raise NoSuchGenomeError(
-                "Reference %r not found in protein/genome "
-                "database." % genomeAccession
-            )
+            raise NoSuchGenomeError('Reference %r not found in protein/genome '
+                                    'database.' % genomeAccession)
 
         for protein in proteinGenomeDB.findProteinsForGenome(genomeAccession):
-            proteinAccession = protein["accession"]
+            proteinAccession = protein['accession']
             self.proteins[proteinAccession] = protein
 
-            ranges = GenomeRanges(protein["offsets"]).ranges
+            ranges = GenomeRanges(protein['offsets']).ranges
             # print('Protein accession', proteinAccession)
             # print(ranges)
 
-            for start, stop, forward in ranges:
+            for (start, stop, forward) in ranges:
                 for offset in range(start, stop):
                     if offset not in self.offsets:
                         self.offsets[offset] = {
-                            "proteinAccessions": set(),
-                            "readIds": set(),
+                            'proteinAccessions': set(),
+                            'readIds': set(),
                         }
-                    self.offsets[offset]["proteinAccessions"].add(proteinAccession)
+                    self.offsets[offset]['proteinAccessions'].add(
+                        proteinAccession)
 
             if checkTranslations:
                 self._checkTranslation(self.genome, ranges, protein)
 
     def _checkTranslation(self, genome, ranges, protein):
         """
         Make sure all protein sequences supposed to be in the genome can in
@@ -74,27 +73,27 @@
             C{dark.civ.proteins.SqliteIndex.findGenome.
         @param ranges: A C{list} of (start, stop, forward) nucleotide ranges
             for the protein in the genome.
         @param protein: A C{dict} with protein information from our sqlite3
             protein/genome database, as returned by
             C{dark.civ.proteins.SqliteIndex.findProtein.
         """
-        proteinSequence = protein["sequence"] + "*"
+        proteinSequence = protein['sequence'] + '*'
 
         # print('protein name', protein['product'], 'ranges', ranges)
-        sequence = "".join(
-            [genome["sequence"][start:stop] for (start, stop, _) in ranges]
-        )
+        sequence = ''.join([genome['sequence'][start:stop]
+                            for (start, stop, _) in ranges])
 
-        genomeRead = DNARead("id", sequence)
+        genomeRead = DNARead('id', sequence)
         translations = list(genomeRead.translations())
-        index = 0 if protein["forward"] else 3
+        index = 0 if protein['forward'] else 3
         if translations[index].sequence != proteinSequence:
             # TODO: improve this error to show what actually went wrong.
-            raise ValueError("Could not translate genome range to get protein sequence")
+            raise ValueError(
+                'Could not translate genome range to get protein sequence')
 
     def addSAM(self, filename, filterAlignment=None):
         """
         Read a SAM file and add information about the reads that match our
         reference id.
 
         @param filename: A C{str} SAM filename.
@@ -103,30 +102,31 @@
         """
         self.samFiles.append(filename)
         referenceId = self.genomeAccession
         with samfile(filename) as sam:
             for column in sam.pileup():
                 for read in column.pileups:
                     alignment = read.alignment
-                    if alignment.reference_name == referenceId and (
-                        filterAlignment is None or filterAlignment(alignment)
-                    ):
+                    if (alignment.reference_name == referenceId and
+                            (filterAlignment is None or
+                             filterAlignment(alignment))):
                         readId = alignment.query_name
                         self.readIdsMatchingGenome.add(readId)
                         offset = column.reference_pos
                         self.coveredOffsetCount[offset] += 1
 
                         try:
                             offsetInfo = self.offsets[offset]
                         except KeyError:
                             pass
                         else:
                             # This offset corresponds to one or more proteins.
-                            self.coveredProteins.update(offsetInfo["proteinAccessions"])
-                            offsetInfo["readIds"].add(readId)
+                            self.coveredProteins.update(
+                                offsetInfo['proteinAccessions'])
+                            offsetInfo['readIds'].add(readId)
 
     def proteinCoverageInfo(self, proteinAccession, minReadOffsetCount=None):
         """
         Calculate coverage information for a protein.
 
         @param proteinAccession: A C{str} accession number.
         @param minReadOffsetCount: An C{int}, specifying the minimum number of
@@ -153,73 +153,69 @@
         if minReadOffsetCount is not None and minReadOffsetCount < 2:
             # A minimum of zero or one is equivalent to not giving a value.
             minReadOffsetCount = None
 
         if minReadOffsetCount:
             readOffsetCounts = Counter()
 
-        proteinRanges = GenomeRanges(protein["offsets"]).ranges
+        proteinRanges = GenomeRanges(protein['offsets']).ranges
 
         # Do an initial pass across all the offsets of the protein to see
         # which reads intersect and where. We will then do a second pass in
         # which we ignore reads that do not sufficiently overlap.
-        for start, stop, forward in proteinRanges:
+        for (start, stop, forward) in proteinRanges:
             proteinLength += stop - start
             for offset in range(start, stop):
                 assert offset not in offsetsSeen
                 offsetsSeen.add(offset)
-                readIds = self.offsets[offset]["readIds"]
+                readIds = self.offsets[offset]['readIds']
                 if readIds and minReadOffsetCount:
                     readOffsetCounts.update(readIds)
 
         # Sanity check that the sum of the range lengths is the same as the
         # overall length given in the database.
         #
         # The +3 in the following is because the database holds the AA
         # length, not including the stop codon. But the database range
         # covers the stop codon.
-        dbProteinLength = self.proteins[proteinAccession]["length"] * 3 + 3
+        dbProteinLength = self.proteins[proteinAccession]['length'] * 3 + 3
         if proteinLength != dbProteinLength:
             raise ValueError(
-                "Sum of protein database ranges (%d) does not agree with "
-                "database protein length (%d) for protein %s!"
-                % (proteinLength, dbProteinLength, proteinAccession)
-            )
+                'Sum of protein database ranges (%d) does not agree with '
+                'database protein length (%d) for protein %s!' %
+                (proteinLength, dbProteinLength, proteinAccession))
 
         # If we are not reporting reads whose overlapping offset count is
         # too low, make a set of such reads.
         if minReadOffsetCount:
-            unwanted = set(
-                readId
-                for readId in readOffsetCounts
-                if readOffsetCounts[readId] < minReadOffsetCount
-            )
+            unwanted = set(readId for readId in readOffsetCounts
+                           if readOffsetCounts[readId] < minReadOffsetCount)
         else:
             unwanted = set()
 
         # Second pass, in which we ignore unwanted (i.e., insufficiently
         # overlapping) reads.
-        for start, stop, forward in proteinRanges:
+        for (start, stop, forward) in proteinRanges:
             for offset in range(start, stop):
-                readIds = set(self.offsets[offset]["readIds"]) - unwanted
+                readIds = set(self.offsets[offset]['readIds']) - unwanted
                 if readIds:
                     allReadIds.update(readIds)
                     coveredOffsets += 1
                     totalBases += len(readIds)
 
         return {
-            "coveredOffsets": coveredOffsets,
-            "totalBases": totalBases,
-            "ntLength": proteinLength,
-            "readIds": allReadIds,
+            'coveredOffsets': coveredOffsets,
+            'totalBases': totalBases,
+            'ntLength': proteinLength,
+            'readIds': allReadIds,
         }
 
     def readIdsForAllProteins(self):
         """
         Get the set of read ids for reads matching any protein at all.
 
         @return: A C{set} of C{str} read ids.
         """
         result = set()
         for offsetInfo in self.offsets.values():
-            result.update(offsetInfo["readIds"])
+            result.update(offsetInfo['readIds'])
         return result
```

### Comparing `dark-matter-4.0.84/dark/graphics.py` & `dark-matter-4.0.9/dark/graphics.py`

 * *Files 7% similar despite different names*

```diff
@@ -2,23 +2,41 @@
 from copy import deepcopy
 from stat import S_ISDIR
 from math import ceil
 from collections import defaultdict
 from time import ctime, time
 from textwrap import fill
 
-import matplotlib
+try:
+    import matplotlib
+    if not os.environ.get('DISPLAY'):
+        # Use non-interactive Agg backend
+        matplotlib.use('Agg')
+    import matplotlib.pyplot as plt
+except ImportError:
+    import platform
+    if platform.python_implementation() == 'PyPy':
+        # PyPy doesn't have a version of matplotlib. Make fake classes and
+        # a Line2D function that raises if used. This allows us to use
+        # other 'dark' code that happens to import dark.graphics but which
+        # does not use the functions that rely on matplotlib.
+        class plt(object):
+            def __getattr__(self, _):
+                raise NotImplementedError(
+                    'matplotlib is not supported under pypy')
 
-if not os.environ.get("DISPLAY"):
-    # Use non-interactive Agg backend
-    matplotlib.use("Agg")
-
-import matplotlib.pyplot as plt
-from matplotlib.lines import Line2D
-from matplotlib import gridspec, patches
+        gridspec = patches = plt
+
+        def Line2D(*args, **kwargs):
+            raise NotImplementedError('matplotlib is not supported under pypy')
+    else:
+        raise
+else:
+    from matplotlib.lines import Line2D
+    from matplotlib import gridspec, patches
 
 import numpy as np
 
 from dark.aa import propertiesForSequence, clustersForSequence
 from dark.baseimage import BaseImage
 from dark.dimension import dimensionalIterator
 from dark.html import AlignmentPanelHTMLWriter, NCBISequenceLinkURL
@@ -26,52 +44,36 @@
 from dark.features import ProteinFeatureAdder, NucleotideFeatureAdder
 from dark import orfs
 from dark.intervals import OffsetAdjuster
 from dark.score import HigherIsBetterScore
 
 
 QUERY_COLORS = {
-    "A": (1.0, 0.0, 0.0),  # Red.
-    "C": (0.0, 0.0, 1.0),  # Blue.
-    "G": (0.0, 1.0, 0.0),  # Green.
-    "N": (1.0, 0.0, 1.0),  # Purple.
-    "T": (1.0, 0.8, 0.0),  # Orange.
-    "gap": (0.2, 0.2, 0.2),  # Almost black.
-    "match": (0.9, 0.9, 0.9),  # Almost white.
-    "*": (0.9, 0.9, 0.9),  # Almost white.
+    'A': (1.0, 0.0, 0.0),  # Red.
+    'C': (0.0, 0.0, 1.0),  # Blue.
+    'G': (0.0, 1.0, 0.0),  # Green.
+    'N': (1.0, 0.0, 1.0),  # Purple.
+    'T': (1.0, 0.8, 0.0),  # Orange.
+    'gap': (0.2, 0.2, 0.2),  # Almost black.
+    'match': (0.9, 0.9, 0.9),  # Almost white.
+    '*': (0.9, 0.9, 0.9),  # Almost white.
 }
 
 DEFAULT_BASE_COLOR = (0.5, 0.5, 0.5)  # Grey
 
 # From http://www.randalolson.com/2014/06/28/how-to-make-beautiful-data-\
 # visualizations-in-python-with-matplotlib/
 #
 # These are the "Tableau 20" colors as RGB.
-TABLEAU20: list[tuple[float, float, float]] = [
-    (31, 119, 180),
-    (174, 199, 232),
-    (255, 127, 14),
-    (255, 187, 120),
-    (44, 160, 44),
-    (152, 223, 138),
-    (214, 39, 40),
-    (255, 152, 150),
-    (148, 103, 189),
-    (197, 176, 213),
-    (140, 86, 75),
-    (196, 156, 148),
-    (227, 119, 194),
-    (247, 182, 210),
-    (127, 127, 127),
-    (199, 199, 199),
-    (188, 189, 34),
-    (219, 219, 141),
-    (23, 190, 207),
-    (158, 218, 229),
-]
+TABLEAU20 = [
+    (31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),
+    (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),
+    (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),
+    (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),
+    (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]
 
 # Scale the above RGB values to the [0, 1] range, the format matplotlib
 # accepts.
 for i in range(len(TABLEAU20)):
     r, g, b = TABLEAU20[i]
     TABLEAU20[i] = (r / 255.0, g / 255.0, b / 255.0)
 
@@ -88,35 +90,23 @@
 
 # The default base of the logarithm to use when logLinearXAxis is used to
 # produce an alignment graph.
 DEFAULT_LOG_LINEAR_X_AXIS_BASE = 1.1
 
 
 def report(msg):
-    print("%s: %s" % (ctime(time()), msg))
+    print('%s: %s' % (ctime(time()), msg))
 
 
-def alignmentGraph(
-    titlesAlignments,
-    title,
-    addQueryLines=True,
-    showFeatures=True,
-    logLinearXAxis=False,
-    logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
-    rankScores=False,
-    colorQueryBases=False,
-    createFigure=True,
-    showFigure=True,
-    readsAx=None,
-    imageFile=None,
-    quiet=False,
-    idList=False,
-    xRange="subject",
-    showOrfs=True,
-):
+def alignmentGraph(titlesAlignments, title, addQueryLines=True,
+                   showFeatures=True, logLinearXAxis=False,
+                   logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE, rankScores=False,
+                   colorQueryBases=False, createFigure=True, showFigure=True,
+                   readsAx=None, imageFile=None, quiet=False, idList=False,
+                   xRange='subject', showOrfs=True):
     """
     Align a set of matching reads against a BLAST or DIAMOND hit.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param title: A C{str} sequence title that was matched. We plot the
         reads that hit this title.
     @param addQueryLines: if C{True}, draw query lines in full (these will then
@@ -146,15 +136,16 @@
     @param xRange: set to either 'subject' or 'reads' to indicate the range of
         the X axis.
     @param showOrfs: If C{True}, open reading frames will be displayed.
     """
 
     startTime = time()
 
-    assert xRange in ("subject", "reads"), 'xRange must be either "subject" or "reads".'
+    assert xRange in ('subject', 'reads'), (
+        'xRange must be either "subject" or "reads".')
 
     if createFigure:
         width = 20
         figure = plt.figure(figsize=(width, 20))
 
     createdReadsAx = readsAx is None
 
@@ -197,43 +188,41 @@
     except AttributeError:
         pass
     else:
         adjuster(titleAlignments)
 
     if rankScores:
         reverse = titlesAlignments.scoreClass is not HigherIsBetterScore
-        for rank, hsp in enumerate(
-            sorted(titleAlignments.hsps(), reverse=reverse), start=1
-        ):
+        for rank, hsp in enumerate(sorted(titleAlignments.hsps(),
+                                   reverse=reverse), start=1):
             hsp.score.score = rank
 
     if logLinearXAxis:
         readIntervals = ReadIntervals(titleAlignments.subjectLength)
         # Examine all HSPs so we can build an offset adjuster.
         for hsp in titleAlignments.hsps():
             readIntervals.add(hsp.readStartInSubject, hsp.readEndInSubject)
         # Now adjust offsets in all HSPs.
         offsetAdjuster = OffsetAdjuster(readIntervals, base=logBase)
         for hsp in titleAlignments.hsps():
             offsetAdjuster.adjustHSP(hsp)
         # A function for adjusting other offsets, below.
         adjustOffset = offsetAdjuster.adjustOffset
     else:
-
         def adjustOffset(offset):
             return offset
 
     # It would be more efficient to only walk through all HSPs once and
     # compute these values all at once, but for now this is simple and clear.
     maxY = int(ceil(titleAlignments.bestHsp().score.score))
     minY = int(titleAlignments.worstHsp().score.score)
     maxX = max(hsp.readEndInSubject for hsp in titleAlignments.hsps())
     minX = min(hsp.readStartInSubject for hsp in titleAlignments.hsps())
 
-    if xRange == "subject":
+    if xRange == 'subject':
         # We'll display a graph for the full subject range. Adjust X axis
         # min/max to make sure we cover at least zero to the sequence length.
         maxX = max(titleAlignments.subjectLength, maxX)
         minX = min(0, minX)
 
     # Swap min & max Y values, if needed, as it's possible we are dealing
     # with LSPs but that the score adjuster made numerically greater values
@@ -262,29 +251,30 @@
 
     # Add light grey vertical rectangles to show the logarithmic gaps. Add
     # these first so that reads will be plotted on top of them. Only draw
     # gaps that are more than SMALLEST_LOGGED_GAP_TO_DISPLAY pixels wide as
     # we could have millions of tiny gaps for a bacteria and drawing them
     # all will be slow and only serves to make the entire background grey.
     if logLinearXAxis and len(offsetAdjuster.adjustments()) < 100:
-        for intervalType, interval in readIntervals.walk():
+        for (intervalType, interval) in readIntervals.walk():
             if intervalType == ReadIntervals.EMPTY:
                 adjustedStart = adjustOffset(interval[0])
                 adjustedStop = adjustOffset(interval[1])
                 width = adjustedStop - adjustedStart
                 if width >= SMALLEST_LOGGED_GAP_TO_DISPLAY:
-                    readsAx.axvspan(adjustedStart, adjustedStop, color="#f4f4f4")
+                    readsAx.axvspan(adjustedStart, adjustedStop,
+                                    color='#f4f4f4')
 
     if colorQueryBases:
         # Color each query by its bases.
         xScale = 3
         yScale = 2
         baseImage = BaseImage(
-            maxX - minX, maxY - minY + (1 if rankScores else 0), xScale, yScale
-        )
+            maxX - minX, maxY - minY + (1 if rankScores else 0),
+            xScale, yScale)
         for alignment in titleAlignments:
             for hsp in alignment.hsps:
                 y = hsp.score.score - minY
                 # If the product of the subject and read frame values is +ve,
                 # then they're either both +ve or both -ve, so we just use the
                 # read as is. Otherwise, we need to reverse complement it.
                 if hsp.subjectFrame * hsp.readFrame > 0:
@@ -313,158 +303,142 @@
 
                 # 3. Right part:
                 # Using hsp.readEndInSubject - hsp.subjectEnd to calculate the
                 # length of the right part leads to the part being too long.
                 # The number of gaps needs to be subtracted to get the right
                 # length.
                 origQuery = hsp.readMatchedSequence.upper()
-                rightRange = (
-                    hsp.readEndInSubject - hsp.subjectEnd - origQuery.count("-")
-                )
+                rightRange = (hsp.readEndInSubject - hsp.subjectEnd -
+                              origQuery.count('-'))
 
                 # 1. Left part.
                 xOffset = readStartInSubject - minX
                 queryOffset = 0
                 for queryIndex in range(leftRange):
-                    color = QUERY_COLORS.get(
-                        query[queryOffset + queryIndex], DEFAULT_BASE_COLOR
-                    )
+                    color = QUERY_COLORS.get(query[queryOffset + queryIndex],
+                                             DEFAULT_BASE_COLOR)
                     baseImage.set(xOffset + queryIndex, y, color)
 
                 # 2. Match part.
                 xOffset = hsp.subjectStart - minX
                 xIndex = 0
                 queryOffset = hsp.subjectStart - hsp.readStartInSubject
                 origSubject = hsp.subjectMatchedSequence
                 for matchIndex in range(middleRange):
-                    if origSubject[matchIndex] == "-":
+                    if origSubject[matchIndex] == '-':
                         # A gap in the subject was needed to match the query.
                         # In our graph we keep the subject the same even in the
                         # case where BLAST opened gaps in it, so we compensate
                         # for the gap in the subject by not showing this base
                         # of the query.
                         pass
                     else:
                         if origSubject[matchIndex] == origQuery[matchIndex]:
                             # The query matched the subject at this location.
                             # Matching bases are all colored in the same
                             # 'match' color.
-                            color = QUERY_COLORS["match"]
+                            color = QUERY_COLORS['match']
                         else:
-                            if origQuery[matchIndex] == "-":
+                            if origQuery[matchIndex] == '-':
                                 # A gap in the query. All query gaps get the
                                 # same 'gap' color.
-                                color = QUERY_COLORS["gap"]
+                                color = QUERY_COLORS['gap']
                             else:
                                 # Query doesn't match subject (and is not a
                                 # gap).
-                                color = QUERY_COLORS.get(
-                                    origQuery[matchIndex], DEFAULT_BASE_COLOR
-                                )
+                                color = QUERY_COLORS.get(origQuery[matchIndex],
+                                                         DEFAULT_BASE_COLOR)
                         baseImage.set(xOffset + xIndex, y, color)
                         xIndex += 1
 
                 # 3. Right part.
                 xOffset = hsp.subjectEnd - minX
                 backQuery = query[-rightRange:].upper()
                 for queryIndex in range(rightRange):
-                    color = QUERY_COLORS.get(backQuery[queryIndex], DEFAULT_BASE_COLOR)
+                    color = QUERY_COLORS.get(backQuery[queryIndex],
+                                             DEFAULT_BASE_COLOR)
                     baseImage.set(xOffset + queryIndex, y, color)
 
-        readsAx.imshow(
-            baseImage.data,
-            aspect="auto",
-            origin="lower",
-            interpolation="nearest",
-            extent=[minX, maxX, minY, maxY],
-        )
+        readsAx.imshow(baseImage.data, aspect='auto', origin='lower',
+                       interpolation='nearest',
+                       extent=[minX, maxX, minY, maxY])
     else:
         # Add horizontal lines for all the query sequences. These will be the
         # grey 'whiskers' in the plots once we (below) draw the matched part
         # on top of part of them.
         if addQueryLines:
             for hsp in titleAlignments.hsps():
                 y = hsp.score.score
-                line = Line2D(
-                    [hsp.readStartInSubject, hsp.readEndInSubject],
-                    [y, y],
-                    color="#aaaaaa",
-                )
+                line = Line2D([hsp.readStartInSubject, hsp.readEndInSubject],
+                              [y, y], color='#aaaaaa')
                 readsAx.add_line(line)
 
         # Add the horizontal BLAST alignment lines.
 
         # If an idList is given set things up to look up read colors.
         readColor = {}
         if idList:
             for color, reads in idList.items():
                 for read in reads:
                     if read in readColor:
-                        raise ValueError(
-                            "Read %s is specified multiple times in idList" % read
-                        )
+                        raise ValueError('Read %s is specified multiple '
+                                         'times in idList' % read)
                     else:
                         readColor[read] = color
 
         # Draw the matched region.
         for titleAlignment in titleAlignments:
             readId = titleAlignment.read.id
             for hsp in titleAlignment.hsps:
                 y = hsp.score.score
-                line = Line2D(
-                    [hsp.subjectStart, hsp.subjectEnd],
-                    [y, y],
-                    color=readColor.get(readId, "blue"),
-                )
+                line = Line2D([hsp.subjectStart, hsp.subjectEnd], [y, y],
+                              color=readColor.get(readId, 'blue'))
                 readsAx.add_line(line)
 
     if showOrfs:
         subject = readsAlignments.getSubjectSequence(title)
         orfs.addORFs(orfAx, subject.sequence, minX, maxX, adjustOffset)
-        orfs.addReversedORFs(
-            orfReversedAx,
-            subject.reverseComplement().sequence,
-            minX,
-            maxX,
-            adjustOffset,
-        )
+        orfs.addReversedORFs(orfReversedAx,
+                             subject.reverseComplement().sequence,
+                             minX, maxX, adjustOffset)
 
     if showFeatures:
         if subjectIsNucleotides:
             featureAdder = NucleotideFeatureAdder()
         else:
             featureAdder = ProteinFeatureAdder()
 
-        features = featureAdder.add(featureAx, title, minX, maxX, adjustOffset)
+        features = featureAdder.add(featureAx, title, minX, maxX,
+                                    adjustOffset)
 
         # If there are features and there weren't too many of them, add
         # vertical feature lines to the reads and ORF axes.
         if features and not featureAdder.tooManyFeaturesToPlot:
             for feature in features:
                 start = feature.start
                 end = feature.end
                 color = feature.color
                 readsAx.axvline(x=start, color=color)
-                readsAx.axvline(x=end, color="#cccccc")
+                readsAx.axvline(x=end, color='#cccccc')
                 if showOrfs:
                     orfAx.axvline(x=start, color=color)
-                    orfAx.axvline(x=end, color="#cccccc")
+                    orfAx.axvline(x=end, color='#cccccc')
                     orfReversedAx.axvline(x=start, color=color)
-                    orfReversedAx.axvline(x=end, color="#cccccc")
+                    orfReversedAx.axvline(x=end, color='#cccccc')
     else:
         features = None
 
     # We'll return some information we've gathered.
     result = {
-        "adjustOffset": adjustOffset,
-        "features": features,
-        "minX": minX,
-        "maxX": maxX,
-        "minY": minY,
-        "maxY": maxY,
+        'adjustOffset': adjustOffset,
+        'features': features,
+        'minX': minX,
+        'maxX': maxX,
+        'minY': minY,
+        'maxY': maxY,
     }
 
     # Allow the class of titlesAlignments to add to the plot, if it has a
     # method for doing so.
     try:
         adjuster = readsAlignments.adjustPlot
     except AttributeError:
@@ -473,63 +447,53 @@
         adjuster(readsAx)
 
     # Titles, axis, etc.
     if createFigure:
         readCount = titleAlignments.readCount()
         hspCount = titleAlignments.hspCount()
         figure.suptitle(
-            "%s\nLength %d %s, %d read%s, %d HSP%s."
-            % (
+            '%s\nLength %d %s, %d read%s, %d HSP%s.' %
+            (
                 fill(titleAlignments.subjectTitle, 80),
                 titleAlignments.subjectLength,
-                "nt" if subjectIsNucleotides else "aa",
-                readCount,
-                "" if readCount == 1 else "s",
-                hspCount,
-                "" if hspCount == 1 else "s",
+                'nt' if subjectIsNucleotides else 'aa',
+                readCount, '' if readCount == 1 else 's',
+                hspCount, '' if hspCount == 1 else 's'
             ),
-            fontsize=20,
-        )
+            fontsize=20)
 
     # Add a title and y-axis label, but only if we made the reads axes.
     if createdReadsAx:
-        readsAx.set_title("Read alignments", fontsize=20)
+        readsAx.set_title('Read alignments', fontsize=20)
         ylabel = readsAlignments.params.scoreTitle
         if rankScores:
-            ylabel += " rank"
+            ylabel += ' rank'
         plt.ylabel(ylabel, fontsize=17)
 
     # Set the x-axis limits.
     readsAx.set_xlim([minX - 1, maxX + 1])
 
     readsAx.set_ylim([0, int(maxY * Y_AXIS_UPPER_PADDING)])
     readsAx.grid()
     if createFigure:
         if showFigure:
             plt.show()
         if imageFile:
             figure.savefig(imageFile)
     stop = time()
     if not quiet:
-        report("Graph generated in %.3f mins." % ((stop - startTime) / 60.0))
+        report('Graph generated in %.3f mins.' % ((stop - startTime) / 60.0))
 
     return result
 
 
-def alignmentPanel(
-    titlesAlignments,
-    sortOn="maxScore",
-    idList=False,
-    equalizeXAxes=False,
-    xRange="subject",
-    logLinearXAxis=False,
-    rankScores=False,
-    showFeatures=True,
-    logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
-):
+def alignmentPanel(titlesAlignments, sortOn='maxScore', idList=False,
+                   equalizeXAxes=False, xRange='subject', logLinearXAxis=False,
+                   rankScores=False, showFeatures=True,
+                   logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE):
     """
     Produces a rectangular panel of graphs that each contain an alignment graph
     against a given sequence.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param sortOn: The attribute to sort subplots on. Either "maxScore",
         "medianScore", "readCount", "length", or "title".
@@ -547,157 +511,124 @@
         title to be their rank (worst to best).
     @param showFeatures: If C{True}, look online for features of the subject
         sequences.
     @raise ValueError: If C{outputDir} exists but is not a directory or if
         C{xRange} is not "subject" or "reads".
     """
 
-    if xRange not in ("subject", "reads"):
+    if xRange not in ('subject', 'reads'):
         raise ValueError('xRange must be either "subject" or "reads".')
 
     start = time()
     titles = titlesAlignments.sortTitles(sortOn)
     cols = 5
     rows = int(len(titles) / cols) + (0 if len(titles) % cols == 0 else 1)
     figure, ax = plt.subplots(rows, cols, squeeze=False)
     allGraphInfo = {}
     coords = dimensionalIterator((rows, cols))
 
-    report(
-        "Plotting %d titles in %dx%d grid, sorted on %s"
-        % (len(titles), rows, cols, sortOn)
-    )
+    report('Plotting %d titles in %dx%d grid, sorted on %s' %
+           (len(titles), rows, cols, sortOn))
 
     for i, title in enumerate(titles):
         titleAlignments = titlesAlignments[title]
         row, col = next(coords)
-        report("%d: %s %s" % (i, title, NCBISequenceLinkURL(title, "")))
+        report('%d: %s %s' % (i, title, NCBISequenceLinkURL(title, '')))
 
         # Add a small plot to the alignment panel.
         graphInfo = alignmentGraph(
-            titlesAlignments,
-            title,
-            addQueryLines=True,
-            showFeatures=showFeatures,
-            rankScores=rankScores,
-            logLinearXAxis=logLinearXAxis,
-            logBase=logBase,
-            colorQueryBases=False,
-            createFigure=False,
-            showFigure=False,
-            readsAx=ax[row][col],
-            quiet=True,
-            idList=idList,
-            xRange=xRange,
-            showOrfs=False,
-        )
+            titlesAlignments, title, addQueryLines=True,
+            showFeatures=showFeatures, rankScores=rankScores,
+            logLinearXAxis=logLinearXAxis, logBase=logBase,
+            colorQueryBases=False, createFigure=False, showFigure=False,
+            readsAx=ax[row][col], quiet=True, idList=idList, xRange=xRange,
+            showOrfs=False)
 
         allGraphInfo[title] = graphInfo
         readCount = titleAlignments.readCount()
         hspCount = titleAlignments.hspCount()
 
         # Make a short title for the small panel blue plot, ignoring any
         # leading NCBI gi / accession numbers.
-        if title.startswith("gi|") and title.find(" ") > -1:
-            shortTitle = title.split(" ", 1)[1][:40]
+        if title.startswith('gi|') and title.find(' ') > -1:
+            shortTitle = title.split(' ', 1)[1][:40]
         else:
             shortTitle = title[:40]
 
-        plotTitle = "%d: %s\nLength %d, %d read%s, %d HSP%s." % (
-            i,
-            shortTitle,
-            titleAlignments.subjectLength,
-            readCount,
-            "" if readCount == 1 else "s",
-            hspCount,
-            "" if hspCount == 1 else "s",
-        )
+        plotTitle = ('%d: %s\nLength %d, %d read%s, %d HSP%s.' % (
+            i, shortTitle, titleAlignments.subjectLength,
+            readCount, '' if readCount == 1 else 's',
+            hspCount, '' if hspCount == 1 else 's'))
 
         if hspCount:
             if rankScores:
-                plotTitle += "\nY axis is ranked score"
+                plotTitle += '\nY axis is ranked score'
             else:
-                plotTitle += "\nmax %.2f, median %.2f" % (
+                plotTitle += '\nmax %.2f, median %.2f' % (
                     titleAlignments.bestHsp().score.score,
-                    titleAlignments.medianScore(),
-                )
+                    titleAlignments.medianScore())
 
         ax[row][col].set_title(plotTitle, fontsize=10)
 
-    maxX = max(graphInfo["maxX"] for graphInfo in allGraphInfo.values())
-    minX = min(graphInfo["minX"] for graphInfo in allGraphInfo.values())
-    maxY = max(graphInfo["maxY"] for graphInfo in allGraphInfo.values())
-    minY = min(graphInfo["minY"] for graphInfo in allGraphInfo.values())
+    maxX = max(graphInfo['maxX'] for graphInfo in allGraphInfo.values())
+    minX = min(graphInfo['minX'] for graphInfo in allGraphInfo.values())
+    maxY = max(graphInfo['maxY'] for graphInfo in allGraphInfo.values())
+    minY = min(graphInfo['minY'] for graphInfo in allGraphInfo.values())
 
     # Post-process graphs to adjust axes, etc.
 
     coords = dimensionalIterator((rows, cols))
     for title in titles:
         titleAlignments = titlesAlignments[title]
         row, col = next(coords)
         a = ax[row][col]
         a.set_ylim([0, int(maxY * Y_AXIS_UPPER_PADDING)])
         if equalizeXAxes:
             a.set_xlim([minX, maxX])
         a.set_yticks([])
         a.set_xticks([])
 
-        if xRange == "subject" and minX < 0:
+        if xRange == 'subject' and minX < 0:
             # Add a vertical line at x=0 so we can see the 'whiskers' of
             # reads that extend to the left of the sequence we're aligning
             # against.
-            a.axvline(x=0, color="#cccccc")
+            a.axvline(x=0, color='#cccccc')
 
         # Add a line on the right of each sub-plot so we can see where the
         # sequence ends (as all panel graphs have the same width and we
         # otherwise couldn't tell).
         sequenceLen = titleAlignments.subjectLength
         if logLinearXAxis:
-            sequenceLen = allGraphInfo[title]["adjustOffset"](sequenceLen)
-        a.axvline(x=sequenceLen, color="#cccccc")
+            sequenceLen = allGraphInfo[title]['adjustOffset'](sequenceLen)
+        a.axvline(x=sequenceLen, color='#cccccc')
 
     # Hide the final panel graphs (if any) that have no content. We do this
     # because the panel is a rectangular grid and some of the plots at the
     # end of the last row may be unused.
     for row, col in coords:
-        ax[row][col].axis("off")
+        ax[row][col].axis('off')
 
     # plt.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.93,
     # wspace=0.1, hspace=None)
     plt.subplots_adjust(hspace=0.4)
-    figure.suptitle(
-        "X: %d to %d, Y (%s): %d to %d"
-        % (
-            minX,
-            maxX,
-            titlesAlignments.readsAlignments.params.scoreTitle,
-            int(minY),
-            int(maxY),
-        ),
-        fontsize=20,
-    )
+    figure.suptitle('X: %d to %d, Y (%s): %d to %d' %
+                    (minX, maxX,
+                     titlesAlignments.readsAlignments.params.scoreTitle,
+                     int(minY), int(maxY)), fontsize=20)
     figure.set_size_inches(5 * cols, 3 * rows, forward=True)
     figure.show()
     stop = time()
-    report("Alignment panel generated in %.3f mins." % ((stop - start) / 60.0))
+    report('Alignment panel generated in %.3f mins.' % ((stop - start) / 60.0))
 
 
-def alignmentPanelHTML(
-    titlesAlignments,
-    sortOn="maxScore",
-    outputDir=None,
-    idList=False,
-    equalizeXAxes=False,
-    xRange="subject",
-    logLinearXAxis=False,
-    logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
-    rankScores=False,
-    showFeatures=True,
-    showOrfs=True,
-):
+def alignmentPanelHTML(titlesAlignments, sortOn='maxScore',
+                       outputDir=None, idList=False, equalizeXAxes=False,
+                       xRange='subject', logLinearXAxis=False,
+                       logBase=DEFAULT_LOG_LINEAR_X_AXIS_BASE,
+                       rankScores=False, showFeatures=True, showOrfs=True):
     """
     Produces an HTML index file in C{outputDir} and a collection of alignment
     graphs and FASTA files to summarize the information in C{titlesAlignments}.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param sortOn: The attribute to sort subplots on. Either "maxScore",
         "medianScore", "readCount", "length", or "title".
@@ -719,19 +650,19 @@
         sequences.
     @param showOrfs: If C{True}, open reading frames will be displayed.
     @raise TypeError: If C{outputDir} is C{None}.
     @raise ValueError: If C{outputDir} is None or exists but is not a
         directory or if C{xRange} is not "subject" or "reads".
     """
 
-    if xRange not in ("subject", "reads"):
+    if xRange not in ('subject', 'reads'):
         raise ValueError('xRange must be either "subject" or "reads".')
 
     if equalizeXAxes:
-        raise NotImplementedError("This feature is not yet implemented.")
+        raise NotImplementedError('This feature is not yet implemented.')
 
     titles = titlesAlignments.sortTitles(sortOn)
 
     if os.access(outputDir, os.F_OK):
         # outputDir exists. Check it's a directory.
         if not S_ISDIR(os.stat(outputDir).st_mode):
             raise ValueError("%r is not a directory." % outputDir)
@@ -744,43 +675,32 @@
     htmlWriter = AlignmentPanelHTMLWriter(outputDir, titlesAlignments)
 
     for i, title in enumerate(titles):
         # titleAlignments = titlesAlignments[title]
 
         # If we are writing data to a file too, create a separate file with
         # a plot (this will be linked from the summary HTML).
-        imageBasename = "%d.png" % i
-        imageFile = "%s/%s" % (outputDir, imageBasename)
+        imageBasename = '%d.png' % i
+        imageFile = '%s/%s' % (outputDir, imageBasename)
         graphInfo = alignmentGraph(
-            titlesAlignments,
-            title,
-            addQueryLines=True,
-            showFeatures=showFeatures,
-            rankScores=rankScores,
-            logLinearXAxis=logLinearXAxis,
-            logBase=logBase,
-            colorQueryBases=False,
-            showFigure=False,
-            imageFile=imageFile,
-            quiet=True,
-            idList=idList,
-            xRange=xRange,
-            showOrfs=showOrfs,
-        )
+            titlesAlignments, title, addQueryLines=True,
+            showFeatures=showFeatures, rankScores=rankScores,
+            logLinearXAxis=logLinearXAxis, logBase=logBase,
+            colorQueryBases=False, showFigure=False, imageFile=imageFile,
+            quiet=True, idList=idList, xRange=xRange, showOrfs=showOrfs)
 
         # Close the image plot to make sure memory is flushed.
         plt.close()
         htmlWriter.addImage(imageBasename, title, graphInfo)
 
     htmlWriter.close()
 
 
-def scoreGraph(
-    titlesAlignments, find=None, showTitles=False, figureWidth=5, figureHeight=5
-):
+def scoreGraph(titlesAlignments, find=None, showTitles=False, figureWidth=5,
+               figureHeight=5):
     """
     NOTE: This function has probably bit rotted (but only a little).
 
     Produce a rectangular panel of graphs, each of which shows sorted scores
     for a title. Matches against a certain sequence title, as determined by
     C{find}, (see below) are highlighted.
 
@@ -792,16 +712,15 @@
     @param figureWidth: The C{float} width of the figure, in inches.
     @param figureHeight: The C{float} height of the figure, in inches.
     """
     maxScore = None
     maxHsps = 0
     cols = 5
     rows = int(len(titlesAlignments) / cols) + (
-        0 if len(titlesAlignments) % cols == 0 else 1
-    )
+        0 if len(titlesAlignments) % cols == 0 else 1)
     f, ax = plt.subplots(rows, cols)
     coords = dimensionalIterator((rows, cols))
 
     for title in titlesAlignments:
         titleAlignments = titlesAlignments[title]
         row, col = next(coords)
         hspCount = titleAlignments.hspCount()
@@ -820,17 +739,17 @@
         if scores:
             max_ = max(scores)
             if maxScore is None or max_ > maxScore:
                 maxScore = max_
             x = np.arange(0, len(scores))
             a.plot(x, scores)
         if highlightX:
-            a.plot(highlightX, highlightY, "ro")
+            a.plot(highlightX, highlightY, 'ro')
         if showTitles:
-            a.set_title("%s" % title, fontsize=10)
+            a.set_title('%s' % title, fontsize=10)
 
     # Adjust all plots to have the same dimensions.
     coords = dimensionalIterator((rows, cols))
     for _ in range(len(titlesAlignments)):
         row, col = next(coords)
         a = ax[row][col]
         a.axis([0, maxHsps, 0, maxScore])
@@ -838,52 +757,52 @@
         a.set_yticks([])
         a.set_xticks([])
 
     # Hide the final panel graphs (if any) that have no content. We do this
     # because the panel is a rectangular grid and some of the plots at the
     # end of the last row may be unused.
     for row, col in coords:
-        ax[row][col].axis("off")
+        ax[row][col].axis('off')
 
-    plt.subplots_adjust(
-        left=0.01, bottom=0.01, right=0.99, top=0.93, wspace=0.1, hspace=None
-    )
-    f.suptitle("max HSPs %d, max score %f" % (maxHsps, maxScore))
+    plt.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.93,
+                        wspace=0.1, hspace=None)
+    f.suptitle('max HSPs %d, max score %f' % (maxHsps, maxScore))
     f.set_size_inches(figureWidth, figureHeight, forward=True)
     # f.savefig('scores.png')
     plt.show()
 
 
 def scatterAlign(seq1, seq2, window=7):
     """
     Visually align two sequences.
     """
     d1 = defaultdict(list)
     d2 = defaultdict(list)
-    for seq, section_dict in [(seq1, d1), (seq2, d2)]:
+    for (seq, section_dict) in [(seq1, d1), (seq2, d2)]:
         for i in range(len(seq) - window):
-            section = seq[i : i + window]
+            section = seq[i:i + window]
             section_dict[section].append(i)
     matches = set(d1).intersection(d2)
-    print("%i unique matches" % len(matches))
+    print('%i unique matches' % len(matches))
     x = []
     y = []
     for section in matches:
         for i in d1[section]:
             for j in d2[section]:
                 x.append(i)
                 y.append(j)
     # plt.cla()  # clear any prior graph
     plt.gray()
     plt.scatter(x, y)
     plt.xlim(0, len(seq1) - window)
     plt.ylim(0, len(seq2) - window)
-    plt.xlabel("length %i bp" % (len(seq1)))
-    plt.ylabel("length %i bp" % (len(seq2)))
-    plt.title("Dot plot using window size %i\n(allowing no mis-matches)" % window)
+    plt.xlabel('length %i bp' % (len(seq1)))
+    plt.ylabel('length %i bp' % (len(seq2)))
+    plt.title('Dot plot using window size %i\n(allowing no mis-matches)' %
+              window)
     plt.show()
 
 
 def plotAAProperties(sequence, propertyNames, showLines=True, showFigure=True):
     """
     Plot amino acid property values for a sequence.
 
@@ -899,32 +818,31 @@
     @raise ValueError: If an unknown property is given in C{propertyNames}.
     @return: The return value from calling dark.aa.propertiesForSequence:
         a C{dict} keyed by (lowercase) property name, with values that are
         C{list}s of the corresponding property value according to sequence
         position.
     """
     MISSING_AA_VALUE = -1.1
-    propertyValues = propertiesForSequence(
-        sequence, propertyNames, missingAAValue=MISSING_AA_VALUE
-    )
+    propertyValues = propertiesForSequence(sequence, propertyNames,
+                                           missingAAValue=MISSING_AA_VALUE)
     if showFigure:
         legend = []
         x = np.arange(0, len(sequence))
         plot = plt.plot if showLines else plt.scatter
 
         for index, propertyName in enumerate(propertyValues):
             color = TABLEAU20[index]
             plot(x, propertyValues[propertyName], color=color)
             legend.append(patches.Patch(color=color, label=propertyName))
 
         plt.legend(handles=legend, loc=(0, 1.1))
         plt.xlim(-0.2, len(sequence) - 0.8)
         plt.ylim(min(MISSING_AA_VALUE, -1.1), 1.1)
-        plt.xlabel("Sequence index")
-        plt.ylabel("Property value")
+        plt.xlabel('Sequence index')
+        plt.ylabel('Property value')
         plt.title(sequence.id)
         plt.show()
 
     return propertyValues
 
 
 def plotAAClusters(sequence, propertyNames, showLines=True, showFigure=True):
@@ -943,17 +861,16 @@
     @raise ValueError: If an unknown property is given in C{propertyNames}.
     @return: The return value from calling dark.aa.clustersForSequence:
         a C{dict} keyed by (lowercase) property name, with values that are
         C{list}s of the corresponding property value according to sequence
         position.
     """
     MISSING_AA_VALUE = 0
-    propertyClusters = clustersForSequence(
-        sequence, propertyNames, missingAAValue=MISSING_AA_VALUE
-    )
+    propertyClusters = clustersForSequence(sequence, propertyNames,
+                                           missingAAValue=MISSING_AA_VALUE)
     if showFigure:
         minCluster = 1
         maxCluster = -1
         legend = []
         x = np.arange(0, len(sequence))
         plot = plt.plot if showLines else plt.scatter
 
@@ -971,13 +888,13 @@
             if propertyMaxCluster > maxCluster:
                 maxCluster = propertyMaxCluster
 
         plt.legend(handles=legend, loc=(0, 1.1))
         plt.xlim(-0.2, len(sequence) - 0.8)
         plt.ylim(minCluster - 0.5, maxCluster + 0.5)
         plt.yticks(range(maxCluster + 1))
-        plt.xlabel("Sequence index")
-        plt.ylabel("Property cluster number")
+        plt.xlabel('Sequence index')
+        plt.ylabel('Property cluster number')
         plt.title(sequence.id)
         plt.show()
 
     return propertyClusters
```

### Comparing `dark-matter-4.0.84/dark/hsp.py` & `dark-matter-4.0.9/dark/hsp.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from functools import total_ordering
 
 from dark.score import HigherIsBetterScore, LowerIsBetterScore
 
 
 @total_ordering
-class _Base:
+class _Base(object):
     """
     Holds information about a matching region from a read alignment.
 
     You should not use this class directly. Use one of its subclasses,
     either HSP or LSP, depending on whether you want numerically higher
     scores to be considered better (HSP) or worse (LSP).
 
@@ -61,32 +61,20 @@
     @param positiveCount: The C{int} number of positions at which the subject
         and query had a positive score in the scoring matrix used during
         matching (this is probably only different from the C{identicalCount}
         when matching amino acids (i.e., not nucleotides).
     @param percentIdentical: A C{float} percentage (i.e., ranging from 0.0 to
         100.0, NOT a fraction) of amino acids that were identical in the match.
     """
-
-    def __init__(
-        self,
-        readStart=None,
-        readEnd=None,
-        readStartInSubject=None,
-        readEndInSubject=None,
-        readFrame=None,
-        subjectStart=None,
-        subjectEnd=None,
-        subjectFrame=None,
-        readMatchedSequence=None,
-        subjectMatchedSequence=None,
-        identicalCount=None,
-        percentIdentical=None,
-        positiveCount=None,
-        percentPositive=None,
-    ):
+    def __init__(self, readStart=None, readEnd=None, readStartInSubject=None,
+                 readEndInSubject=None, readFrame=None, subjectStart=None,
+                 subjectEnd=None, subjectFrame=None, readMatchedSequence=None,
+                 subjectMatchedSequence=None, identicalCount=None,
+                 percentIdentical=None, positiveCount=None,
+                 percentPositive=None):
         self.readStart = readStart
         self.readEnd = readEnd
         self.readStartInSubject = readStartInSubject
         self.readEndInSubject = readEndInSubject
         self.readFrame = readFrame
         self.subjectStart = subjectStart
         self.subjectEnd = subjectEnd
@@ -116,28 +104,28 @@
     def toDict(self):
         """
         Get information about the HSP/LSP as a dictionary.
 
         @return: A C{dict} representation of the HSP/LSP.
         """
         return {
-            "readStart": self.readStart,
-            "readEnd": self.readEnd,
-            "readStartInSubject": self.readStartInSubject,
-            "readEndInSubject": self.readEndInSubject,
-            "readFrame": self.readFrame,
-            "subjectStart": self.subjectStart,
-            "subjectEnd": self.subjectEnd,
-            "subjectFrame": self.subjectFrame,
-            "readMatchedSequence": self.readMatchedSequence,
-            "subjectMatchedSequence": self.subjectMatchedSequence,
-            "identicalCount": self.identicalCount,
-            "percentIdentical": self.percentIdentical,
-            "positiveCount": self.positiveCount,
-            "percentPositive": self.percentPositive,
+            'readStart': self.readStart,
+            'readEnd': self.readEnd,
+            'readStartInSubject': self.readStartInSubject,
+            'readEndInSubject': self.readEndInSubject,
+            'readFrame': self.readFrame,
+            'subjectStart': self.subjectStart,
+            'subjectEnd': self.subjectEnd,
+            'subjectFrame': self.subjectFrame,
+            'readMatchedSequence': self.readMatchedSequence,
+            'subjectMatchedSequence': self.subjectMatchedSequence,
+            'identicalCount': self.identicalCount,
+            'percentIdentical': self.percentIdentical,
+            'positiveCount': self.positiveCount,
+            'percentPositive': self.percentPositive,
         }
 
 
 class HSP(_Base):
     """
     Holds information about a high-scoring pair from a read alignment.
     Comparisons are done as for BLAST or DIAMOND bit scores (higher is better).
@@ -152,15 +140,15 @@
     def toDict(self):
         """
         Get information about the HSP as a dictionary.
 
         @return: A C{dict} representation of the HSP.
         """
         result = _Base.toDict(self)
-        result["score"] = self.score.score
+        result['score'] = self.score.score
         return result
 
 
 class LSP(_Base):
     """
     Holds information about a low-scoring pair from a read alignment.
     Comparisons are done as for BLAST or DIAMOND e-values (smaller is better).
@@ -175,9 +163,9 @@
     def toDict(self):
         """
         Get information about the LSP as a dictionary.
 
         @return: A C{dict} representation of the LSP.
         """
         result = _Base.toDict(self)
-        result["score"] = self.score.score
+        result['score'] = self.score.score
         return result
```

### Comparing `dark-matter-4.0.84/dark/html.py` & `dark-matter-4.0.9/dark/html.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,16 @@
-from IPython.display import HTML  # type: ignore
+from __future__ import print_function
+
+from IPython.display import HTML
 from six.moves.urllib.parse import quote
 
 from dark.fastq import FastqReads
 
 
-def NCBISequenceLinkURL(title, field=None, delim="|"):
+def NCBISequenceLinkURL(title, field=None, delim='|'):
     """
     Given a sequence title, like
         "acc|GENBANK|AY516849.1|GENBANK|42768646 Homo sapiens",
     return the URL of a link to the info page at NCBI.
 
     @param title: The C{str} sequence title to produce a link URL for.
     @param field: The C{int} field number to use (as delimited by C{delim})
@@ -20,36 +22,34 @@
     if field is None:
         ref = title
     else:
         try:
             ref = title.split(delim)[field]
         except IndexError:
             raise IndexError(
-                "Could not extract field %d from sequence title %r" % (field, title)
-            )
-    return "http://www.ncbi.nlm.nih.gov/nuccore/" + quote(ref)
+                'Could not extract field %d from sequence title %r' %
+                (field, title))
+    return 'http://www.ncbi.nlm.nih.gov/nuccore/' + quote(ref)
 
 
-def NCBISequenceLink(title, field=None, delim="|"):
+def NCBISequenceLink(title, field=None, delim='|'):
     """
     Given a sequence title, like
         "acc|GENBANK|AY516849.1|GENBANK|42768646 Homo sapiens",
     return an HTML <A> tag displaying a link to the info page at NCBI.
 
     @param title: The C{str} sequence title to produce a link URL for.
     @param field: The C{int} field number to use (as delimited by C{delim})
         or C{None} if no field splitting should be done.
     @param delim: The C{str} to split the title on (if C{field} is not
         C{None}).
     @return: A C{str} HTML <A> tag.
     """
     return '<a href="%s" target="_blank">%s</a>' % (
-        NCBISequenceLinkURL(title, field, delim),
-        title,
-    )
+        NCBISequenceLinkURL(title, field, delim), title)
 
 
 def _sortHTML(titlesAlignments, by, limit=None):
     """
     Return an C{IPython.display.HTML} object with the alignments sorted by the
     given attribute.
 
@@ -63,285 +63,266 @@
     out = []
     for i, title in enumerate(titlesAlignments.sortTitles(by), start=1):
         if limit is not None and i > limit:
             break
         titleAlignments = titlesAlignments[title]
         link = NCBISequenceLink(title, title)
         out.append(
-            "%3d: reads=%d, len=%d, max=%s median=%s<br/>"
-            "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;%s"
-            % (
-                i,
-                titleAlignments.readCount(),
-                titleAlignments.subjectLength,
-                titleAlignments.bestHsp().score.score,
-                titleAlignments.medianScore(),
-                link,
-            )
-        )
-    return HTML("<pre>" + "<br/>".join(out) + "</pre>")
+            '%3d: reads=%d, len=%d, max=%s median=%s<br/>'
+            '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;%s' %
+            (i, titleAlignments.readCount(), titleAlignments.subjectLength,
+             titleAlignments.bestHsp().score.score,
+             titleAlignments.medianScore(), link))
+    return HTML('<pre>' + '<br/>'.join(out) + '</pre>')
 
 
 def summarizeTitlesByTitle(titlesAlignments, limit=None):
     """
     Sort match titles by title
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param limit: An C{int} limit on the number of results to show.
     @return: An C{IPython.display.HTML} instance with match titles sorted by
         title.
     """
-    return _sortHTML(titlesAlignments, "title", limit)
+    return _sortHTML(titlesAlignments, 'title', limit)
 
 
 def summarizeTitlesByCount(titlesAlignments, limit=None):
     """
     Sort match titles by read count.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param limit: An C{int} limit on the number of results to show.
     @return: An C{IPython.display.HTML} instance with match titles sorted by
         read count.
     """
-    return _sortHTML(titlesAlignments, "readCount", limit)
+    return _sortHTML(titlesAlignments, 'readCount', limit)
 
 
 def summarizeTitlesByLength(titlesAlignments, limit=None):
     """
     Sort match titles by sequence length.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param limit: An C{int} limit on the number of results to show.
     @return: An C{IPython.display.HTML} instance with match titles sorted by
         sequence length.
     """
-    return _sortHTML(titlesAlignments, "length", limit)
+    return _sortHTML(titlesAlignments, 'length', limit)
 
 
 def summarizeTitlesByMaxScore(titlesAlignments, limit=None):
     """
     Sort hit titles by maximum score.
 
     @param titlesAlignments: A L{dark.blast.BlastMatchs} instance.
     @param limit: An C{int} limit on the number of results to show.
     @return: An C{IPython.display.HTML} instance with hit titles sorted by
         max score.
     """
-    return _sortHTML(titlesAlignments, "maxScore", limit)
+    return _sortHTML(titlesAlignments, 'maxScore', limit)
 
 
 def summarizeTitlesByMedianScore(titlesAlignments, limit=None):
     """
     Sort match titles by median score.
 
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     @param limit: An C{int} limit on the number of results to show.
     @return: An C{IPython.display.HTML} instance with match titles sorted by
         median score.
     """
-    return _sortHTML(titlesAlignments, "medianScore", limit)
+    return _sortHTML(titlesAlignments, 'medianScore', limit)
 
 
-class AlignmentPanelHTMLWriter:
+class AlignmentPanelHTMLWriter(object):
     """
     Produces HTML details of a rectangular panel of graphs that each
     contain an alignment graph against a given sequence. This is
     supplementary output info for the AlignmentPanel class in graphics.py.
 
     @param outputDir: The C{str} directory to write files into.
     @param titlesAlignments: A L{dark.titles.TitlesAlignments} instance.
     """
-
     def __init__(self, outputDir, titlesAlignments):
         self._outputDir = outputDir
         self._titlesAlignments = titlesAlignments
         self._images = []
 
     def addImage(self, imageBasename, title, graphInfo):
-        self._images.append(
-            {"graphInfo": graphInfo, "imageBasename": imageBasename, "title": title}
-        )
+        self._images.append({
+            'graphInfo': graphInfo,
+            'imageBasename': imageBasename,
+            'title': title
+        })
 
     def close(self):
-        with open("%s/index.html" % self._outputDir, "w") as fp:
+        with open('%s/index.html' % self._outputDir, 'w') as fp:
             self._writeHeader(fp)
             self._writeBody(fp)
             self._writeFooter(fp)
-        with open("%s/style.css" % self._outputDir, "w") as fp:
+        with open('%s/style.css' % self._outputDir, 'w') as fp:
             self._writeCSS(fp)
 
     def _writeHeader(self, fp):
-        fp.write(
-            """\
+        fp.write("""\
 <html>
   <head>
     <title>Read alignments for %d matched subjects</title>
     <link rel="stylesheet" type="text/css" href="style.css">
   </head>
   <body>
     <div id="content">
-        """
-            % len(self._images)
-        )
+        """ % len(self._images))
 
     def _writeBody(self, fp):
-        fp.write(
-            "<h1>Read alignments for %d matched subjects</h1>\n" % len(self._images)
-        )
+        fp.write('<h1>Read alignments for %d matched subjects</h1>\n' %
+                 len(self._images))
 
         # Write out an alignment panel as a table.
         cols = 6
-        fp.write("<table><tbody>\n")
+        fp.write('<table><tbody>\n')
 
         for i, image in enumerate(self._images):
-            title = image["title"]
+            title = image['title']
 
             if i % cols == 0:
-                fp.write("<tr>\n")
+                fp.write('<tr>\n')
 
             fp.write(
                 '<td><a id="small_%d"></a><a href="#big_%d"><img src="%s" '
-                'class="thumbnail"/></a></td>\n' % (i, i, image["imageBasename"])
-            )
+                'class="thumbnail"/></a></td>\n' %
+                (i, i, image['imageBasename']))
 
             if i % cols == cols - 1:
-                fp.write("</tr>")
+                fp.write('</tr>')
 
         # Add empty cells to the final table row, and close the row, if
         # necessary.
         if i % cols < cols - 1:
             while i % cols < cols - 1:
-                fp.write("<td>&nbsp;</td>\n")
+                fp.write('<td>&nbsp;</td>\n')
                 i += 1
-            fp.write("</tr>\n")
+            fp.write('</tr>\n')
 
-        fp.write("</tbody></table>\n")
+        fp.write('</tbody></table>\n')
 
         # Write out the full images with additional detail.
         for i, image in enumerate(self._images):
-            title = image["title"]
+            title = image['title']
             titleAlignments = self._titlesAlignments[title]
-            graphInfo = image["graphInfo"]
+            graphInfo = image['graphInfo']
             readFormat = self._writeFASTA(i, image)
-            fp.write(
-                """
+            fp.write("""
       <a id="big_%d"></a>
       <h3>%d: %s</h3>
       <p>
             Length: %d.
             Read count: %d.
             HSP count: %d.
             <a href="%d.%s">%s</a>.
             <a href="#small_%d">Top panel.</a>
 """
-                % (
-                    i,
-                    i,
-                    title,
-                    titleAlignments.subjectLength,
-                    titleAlignments.readCount(),
-                    titleAlignments.hspCount(),
-                    i,
-                    readFormat,
-                    readFormat,
-                    i,
-                )
-            )
+                     % (i, i, title,
+                        titleAlignments.subjectLength,
+                        titleAlignments.readCount(),
+                        titleAlignments.hspCount(), i, readFormat, readFormat,
+                        i))
 
             url = NCBISequenceLinkURL(title)
             if url:
                 fp.write('<a href="%s" target="_blank">NCBI</a>.' % url)
 
             # Write out feature information.
-            if graphInfo["features"] is None:
+            if graphInfo['features'] is None:
                 # Feature lookup was False (or we were offline).
                 pass
-            elif len(graphInfo["features"]) == 0:
-                fp.write("There were no features.")
+            elif len(graphInfo['features']) == 0:
+                fp.write('There were no features.')
             else:
-                fp.write('<a href="%s">Features</a>' % self._writeFeatures(i, image))
+                fp.write('<a href="%s">Features</a>' %
+                         self._writeFeatures(i, image))
 
             # Write out the titles that this title invalidated due to its
             # read set.
             readSetFilter = self._titlesAlignments.readSetFilter
             if readSetFilter:
                 invalidated = readSetFilter.invalidates(title)
                 if invalidated:
                     nInvalidated = len(invalidated)
-                    fp.write(
-                        "<br/>This title invalidated %d other%s due to "
-                        "its read set:<ul>"
-                        % (nInvalidated, "" if nInvalidated == 1 else "s")
-                    )
+                    fp.write('<br/>This title invalidated %d other%s due to '
+                             'its read set:<ul>'
+                             % (nInvalidated,
+                                '' if nInvalidated == 1 else 's'))
                     for title in invalidated:
-                        fp.write("<li>%s</li>" % title)
-                    fp.write("</ul>")
+                        fp.write('<li>%s</li>' % title)
+                    fp.write('</ul>')
 
-            fp.write('</p><img src="%s" class="full-size"/>' % image["imageBasename"])
+            fp.write(
+                '</p><img src="%s" class="full-size"/>' %
+                image['imageBasename'])
 
     def _writeFooter(self, fp):
-        fp.write(
-            """\
+        fp.write("""\
     </div>
   </body>
 </html>
-"""
-        )
+""")
 
     def _writeCSS(self, fp):
-        fp.write(
-            """\
+        fp.write("""\
 #content {
   width: 95%;
   margin: auto;
 }
 img.thumbnail {
   height: 300px;
 }
 img.full-size {
   height: 900px;
 }
-"""
-        )
+""")
 
     def _writeFASTA(self, i, image):
         """
         Write a FASTA file containing the set of reads that hit a sequence.
 
         @param i: The number of the image in self._images.
         @param image: A member of self._images.
         @return: A C{str}, either 'fasta' or 'fastq' indicating the format
             of the reads in C{self._titlesAlignments}.
         """
-        if isinstance(self._titlesAlignments.readsAlignments.reads, FastqReads):
-            format_ = "fastq"
+        if isinstance(self._titlesAlignments.readsAlignments.reads,
+                      FastqReads):
+            format_ = 'fastq'
         else:
-            format_ = "fasta"
-        filename = "%s/%d.%s" % (self._outputDir, i, format_)
-        titleAlignments = self._titlesAlignments[image["title"]]
-        with open(filename, "w") as fp:
+            format_ = 'fasta'
+        filename = '%s/%d.%s' % (self._outputDir, i, format_)
+        titleAlignments = self._titlesAlignments[image['title']]
+        with open(filename, 'w') as fp:
             for titleAlignment in titleAlignments:
                 fp.write(titleAlignment.read.toString(format_))
         return format_
 
     def _writeFeatures(self, i, image):
         """
         Write a text file containing the features as a table.
 
         @param i: The number of the image in self._images.
         @param image: A member of self._images.
         @return: The C{str} features file name - just the base name, not
             including the path to the file.
         """
-        basename = "features-%d.txt" % i
-        filename = "%s/%s" % (self._outputDir, basename)
-        featureList = image["graphInfo"]["features"]
-        with open(filename, "w") as fp:
+        basename = 'features-%d.txt' % i
+        filename = '%s/%s' % (self._outputDir, basename)
+        featureList = image['graphInfo']['features']
+        with open(filename, 'w') as fp:
             for feature in featureList:
-                fp.write("%s\n\n" % feature.feature)
+                fp.write('%s\n\n' % feature.feature)
         return basename
 
 
 def readCountText(readCountColors, count, linkText=None):
     """
     Produce colored read count text.
 
@@ -351,12 +332,11 @@
     @param linkText: A C{str} for the HTML link text. If C{None}, the
         count will be used.
     @return: An HTML span C{str} colored according to the read count,
         or just the string of the count if no color information is given.
     """
     if readCountColors:
         _class = readCountColors.thresholdToCssName(
-            readCountColors.thresholdForCount(count)
-        )
+            readCountColors.thresholdForCount(count))
         return f'<span class="{_class}">{count}</span>'
     else:
         return linkText or str(count)
```

### Comparing `dark-matter-4.0.84/dark/intervals.py` & `dark-matter-4.0.9/dark/intervals.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from math import log
 from collections import Counter
 
 
-class ReadIntervals:
+class ReadIntervals(object):
     """
     Hold information about the set of reads that match a subject.
 
     @param targetLength: The C{int} length of the target sequence that the
         reads are against.
     """
 
@@ -77,51 +77,52 @@
 
         @return: The C{float} fraction of a subject matched by its reads.
         """
         if self._targetLength == 0:
             return 0.0
 
         coverage = 0
-        for intervalType, (start, end) in self.walk():
+        for (intervalType, (start, end)) in self.walk():
             if intervalType == self.FULL:
                 # Adjust start and end to ignore areas where the read falls
                 # outside the target.
-                coverage += min(end, self._targetLength) - max(0, start)
+                coverage += (min(end, self._targetLength) - max(0, start))
         return float(coverage) / self._targetLength
 
     def coverageCounts(self):
         """
         For each location in the subject, return a count of how many times that
         location is covered by a read.
 
         @return: a C{Counter} where the keys are the C{int} locations on the
             subject and the value is the number of times the location is
             covered by a read.
         """
         coverageCounts = Counter()
         for start, end in self._intervals:
-            coverageCounts.update(range(max(0, start), min(self._targetLength, end)))
+            coverageCounts.update(range(max(0, start),
+                                        min(self._targetLength, end)))
         return coverageCounts
 
 
-class OffsetAdjuster:
+class OffsetAdjuster(object):
     """
     A class that knows how to adjust the offsets in a normalized HSP according
     to the overall set of reads being plotted.
 
     @param intervals: An instance of L{ReadIntervals}.
     @param base: The C{float} logarithmic base to use when adjusting empty
         spaces in the hit sequence.
     """
 
     def __init__(self, intervals=None, base=2.0):
         self._adjustments = []  # Pairs of (X offset, adjustment).
         if intervals:
             divisor = log(base)
-            for intervalType, (start, stop) in intervals.walk():
+            for (intervalType, (start, stop)) in intervals.walk():
                 if intervalType == ReadIntervals.EMPTY:
                     width = stop - start
                     logWidth = log(width) / divisor
                     self._adjustments.append((stop, width - logWidth))
 
     def adjustments(self):
         """
@@ -137,15 +138,15 @@
         Calculate the total reduction for a given X axis offset.
 
         @param offset: The C{int} offset.
         @return: The total C{float} reduction that should be made for this
             offset.
         """
         reduction = 0
-        for thisOffset, thisReduction in self._adjustments:
+        for (thisOffset, thisReduction) in self._adjustments:
             if offset >= thisOffset:
                 reduction += thisReduction
             else:
                 break
         return reduction
 
     def adjustOffset(self, offset):
@@ -160,14 +161,13 @@
     def adjustHSP(self, hsp):
         """
         Adjust the read and subject start and end offsets in an HSP.
 
         @param hsp: a L{dark.hsp.HSP} or L{dark.hsp.LSP} instance.
         """
         reduction = self._reductionForOffset(
-            min(hsp.readStartInSubject, hsp.subjectStart)
-        )
+            min(hsp.readStartInSubject, hsp.subjectStart))
 
         hsp.readEndInSubject = hsp.readEndInSubject - reduction
         hsp.readStartInSubject = hsp.readStartInSubject - reduction
         hsp.subjectEnd = hsp.subjectEnd - reduction
         hsp.subjectStart = hsp.subjectStart - reduction
```

### Comparing `dark-matter-4.0.84/dark/ipynb.py` & `dark-matter-4.0.9/dark/ipynb.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,45 +1,23 @@
 # Import and make available things that are convenient to have around in
 # iPythonNotebook following 'from dark.ipynb import *'.
 
 from .fasta import FastaReads
 from .blast.alignments import BlastReadsAlignments
 from .titles import titleCounts, TitlesAlignments
 from .html import (
-    summarizeTitlesByLength,
-    summarizeTitlesByMaxScore,
-    summarizeTitlesByMedianScore,
-    summarizeTitlesByCount,
-    summarizeTitlesByTitle,
-)
+    summarizeTitlesByLength, summarizeTitlesByMaxScore,
+    summarizeTitlesByMedianScore, summarizeTitlesByCount,
+    summarizeTitlesByTitle)
 from .graphics import alignmentGraph, alignmentPanel, scoreGraph
 
 # Keep pyflakes quiet by pretending to make use of all our imports.
-_ = (
-    FastaReads,
-    BlastReadsAlignments,
-    titleCounts,
-    TitlesAlignments,
-    summarizeTitlesByLength,
-    summarizeTitlesByMaxScore,
-    summarizeTitlesByMedianScore,
-    summarizeTitlesByCount,
-    summarizeTitlesByTitle,
-    alignmentGraph,
-    alignmentPanel,
-    scoreGraph,
-)
+_ = (FastaReads, BlastReadsAlignments, titleCounts, TitlesAlignments,
+     summarizeTitlesByLength, summarizeTitlesByMaxScore,
+     summarizeTitlesByMedianScore, summarizeTitlesByCount,
+     summarizeTitlesByTitle, alignmentGraph, alignmentPanel, scoreGraph)
 
 __all__ = [
-    "FastaReads",
-    "BlastReadsAlignments",
-    "titleCounts",
-    "TitlesAlignments",
-    "summarizeTitlesByLength",
-    "summarizeTitlesByMaxScore",
-    "summarizeTitlesByMedianScore",
-    "summarizeTitlesByCount",
-    "summarizeTitlesByTitle",
-    "alignmentGraph",
-    "alignmentPanel",
-    "scoreGraph",
-]
+    'FastaReads', 'BlastReadsAlignments', 'titleCounts', 'TitlesAlignments',
+    'summarizeTitlesByLength', 'summarizeTitlesByMaxScore',
+    'summarizeTitlesByMedianScore', 'summarizeTitlesByCount',
+    'summarizeTitlesByTitle', 'alignmentGraph', 'alignmentPanel', 'scoreGraph']
```

### Comparing `dark-matter-4.0.84/dark/mutations.py` & `dark-matter-4.0.9/dark/mutations.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,17 +1,30 @@
 import os
 from collections import defaultdict
 import numpy as np
 
-import matplotlib
-
-if not os.environ.get("DISPLAY"):
-    # Use non-interactive Agg backend
-    matplotlib.use("Agg")
-import matplotlib.pyplot as plt
+try:
+    import matplotlib
+    if not os.environ.get('DISPLAY'):
+        # Use non-interactive Agg backend
+        matplotlib.use('Agg')
+    import matplotlib.pyplot as plt
+except ImportError:
+    import platform
+    if platform.python_implementation() == 'PyPy':
+        # PyPy doesn't have a version of matplotlib. Make a fake
+        # class that raises if it is used. This allows us to use other
+        # 'dark' code that happens to import dark.mutations but not use the
+        # functions that rely on matplotlib.
+        class plt(object):
+            def __getattr__(self, _):
+                raise NotImplementedError(
+                    'matplotlib is not supported under pypy')
+    else:
+        raise
 
 from random import choice, uniform
 
 from dark import ncbidb
 
 
 def basePlotter(blastHits, title):
@@ -24,106 +37,97 @@
 
     @param blastHits: A L{dark.blast.BlastHits} instance.
     @param title: A C{str} sequence title that was matched by BLAST. We plot
         the reads that matched this title.
     """
     result = []
     params = blastHits.plotParams
-    assert params is not None, (
-        "Oops, it looks like you forgot to run computePlotInfo."
-    )
+    assert params is not None, ('Oops, it looks like you forgot to run '
+                                'computePlotInfo.')
 
     sequence = ncbidb.getSequence(title, blastHits.records.blastDb)
     subject = sequence.seq
-    gi = title.split("|")[1]
-    sub = "%s\t \t \t%s" % (gi, subject)
+    gi = title.split('|')[1]
+    sub = '%s\t \t \t%s' % (gi, subject)
     result.append(sub)
 
-    plotInfo = blastHits.titles[title]["plotInfo"]
-    assert plotInfo is not None, (
-        "Oops, it looks like you forgot to run computePlotInfo."
-    )
+    plotInfo = blastHits.titles[title]['plotInfo']
+    assert plotInfo is not None, ('Oops, it looks like you forgot to run '
+                                  'computePlotInfo.')
 
-    items = plotInfo["items"]
+    items = plotInfo['items']
     count = 0
     for item in items:
         count += 1
-        hsp = item["hsp"]
-        queryTitle = blastHits.fasta[item["readNum"]].id
+        hsp = item['hsp']
+        queryTitle = blastHits.fasta[item['readNum']].id
         # If the product of the subject and query frame values is +ve,
         # then they're either both +ve or both -ve, so we just use the
         # query as is. Otherwise, we need to reverse complement it.
-        if item["frame"]["subject"] * item["frame"]["query"] > 0:
-            query = blastHits.fasta[item["readNum"]].seq
+        if item['frame']['subject'] * item['frame']['query'] > 0:
+            query = blastHits.fasta[item['readNum']].seq
             reverse = False
         else:
             # One of the subject or query has negative sense.
-            query = blastHits.fasta[item["readNum"]].reverse_complement().seq
+            query = blastHits.fasta[
+                item['readNum']].reverse_complement().seq
             reverse = True
         query = query.upper()
-        queryStart = hsp["queryStart"]
-        subjectStart = hsp["subjectStart"]
-        queryEnd = hsp["queryEnd"]
-        subjectEnd = hsp["subjectEnd"]
+        queryStart = hsp['queryStart']
+        subjectStart = hsp['subjectStart']
+        queryEnd = hsp['queryEnd']
+        subjectEnd = hsp['subjectEnd']
 
         # Before comparing the read to the subject, make a string of the
         # same length as the subject, which contains the read and
         # has ' ' where the read does not match.
         # 3 parts need to be taken into account:
         # 1) the left offset (if the query doesn't stick out to the left)
         # 2) the query. if the frame is -1, it has to be reversed.
         # The query consists of 3 parts: left, middle (control for gaps)
         # 3) the right offset
 
         # Do part 1) and 2).
         if queryStart < 0:
             # The query is sticking out to the left.
-            leftQuery = ""
+            leftQuery = ''
             if subjectStart == 0:
                 # The match starts at the first base of the subject.
-                middleLeftQuery = ""
+                middleLeftQuery = ''
             else:
                 # The match starts into the subject.
                 # Determine the length of the not matching query
                 # part to the left.
                 leftOffset = -1 * queryStart
                 rightOffset = subjectStart + leftOffset
                 middleLeftQuery = query[leftOffset:rightOffset]
         else:
             # The query is not sticking out to the left
             # make the left offset.
-            leftQuery = queryStart * " "
+            leftQuery = queryStart * ' '
 
             leftQueryOffset = subjectStart - queryStart
             middleLeftQuery = query[:leftQueryOffset]
 
         # Do part 3).
         # Disregard gaps in subject while adding.
-        matchQuery = item["origHsp"].query
-        matchSubject = item["origHsp"].sbjct
+        matchQuery = item['origHsp'].query
+        matchSubject = item['origHsp'].sbjct
         index = 0
-        mid = ""
+        mid = ''
         for item in range(len(matchQuery)):
-            if matchSubject[index] != " ":
+            if matchSubject[index] != ' ':
                 mid += matchQuery[index]
             index += 1
         # if the query has been reversed, turn the matched part around
         if reverse:
-            rev = ""
+            rev = ''
             toReverse = mid
-            reverseDict = {
-                " ": " ",
-                "-": "-",
-                "A": "T",
-                "T": "A",
-                "C": "G",
-                "G": "C",
-                ".": ".",
-                "N": "N",
-            }
+            reverseDict = {' ': ' ', '-': '-', 'A': 'T', 'T': 'A',
+                           'C': 'G', 'G': 'C', '.': '.', 'N': 'N'}
             for item in toReverse:
                 newItem = reverseDict[item]
                 rev += newItem
             mid = rev[::-1]
 
         middleQuery = middleLeftQuery + mid
 
@@ -138,126 +142,89 @@
         offset = len(subject) - len(read)
         # if the read is sticking out to the right
         # chop it off
         if offset < 0:
             read = read[:offset]
         # if it's not sticking out, fill the space with ' '
         elif offset > 0:
-            read += offset * " "
+            read += offset * ' '
 
         # compare the subject and the read, make a string
         # called 'comparison', which contains a '.' if the bases
         # are equal and the letter of the read if they are not.
-        comparison = ""
+        comparison = ''
         for readBase, subjectBase in zip(read, subject):
-            if readBase == " ":
-                comparison += " "
+            if readBase == ' ':
+                comparison += ' '
             elif readBase == subjectBase:
-                comparison += "."
+                comparison += '.'
             elif readBase != subjectBase:
                 comparison += readBase
             index += 1
-        que = "%s \t %s" % (queryTitle, comparison)
+        que = '%s \t %s' % (queryTitle, comparison)
         result.append(que)
 
         # sanity checks
-        assert len(comparison) == len(subject), "%d != %d" % (
-            len(comparison),
-            len(subject),
-        )
+        assert (len(comparison) == len(subject)), (
+            '%d != %d' % (len(comparison), len(subject)))
 
         index = 0
-        if comparison[index] == " ":
+        if comparison[index] == ' ':
             index += 1
         else:
             start = index - 1
-            assert start == queryStart or start == -1, "%s != %s or %s != -1" % (
-                start,
-                queryStart,
-                start,
-            )
+            assert (start == queryStart or start == -1), (
+                '%s != %s or %s != -1' % (start, queryStart, start))
 
     return result
 
 
 def getAPOBECFrequencies(dotAlignment, orig, new, pattern):
     """
     Gets mutation frequencies if they are in a certain pattern.
 
     @param dotAlignment: result from calling basePlotter
     @param orig: A C{str}, naming the original base
     @param new: A C{str}, what orig was mutated to
     @param pattern: A C{str}m which pattern we're looking for
         (must be one of 'cPattern', 'tPattern')
     """
-    cPattern = [
-        "ACA",
-        "ACC",
-        "ACG",
-        "ACT",
-        "CCA",
-        "CCC",
-        "CCG",
-        "CCT",
-        "GCA",
-        "GCC",
-        "GCG",
-        "GCT",
-        "TCA",
-        "TCC",
-        "TCG",
-        "TCT",
-    ]
-    tPattern = [
-        "ATA",
-        "ATC",
-        "ATG",
-        "ATT",
-        "CTA",
-        "CTC",
-        "CTG",
-        "CTT",
-        "GTA",
-        "GTC",
-        "GTG",
-        "GTT",
-        "TTA",
-        "TTC",
-        "TTG",
-        "TTT",
-    ]
+    cPattern = ['ACA', 'ACC', 'ACG', 'ACT', 'CCA', 'CCC', 'CCG', 'CCT',
+                'GCA', 'GCC', 'GCG', 'GCT', 'TCA', 'TCC', 'TCG', 'TCT']
+    tPattern = ['ATA', 'ATC', 'ATG', 'ATT', 'CTA', 'CTC', 'CTG', 'CTT',
+                'GTA', 'GTC', 'GTG', 'GTT', 'TTA', 'TTC', 'TTG', 'TTT']
     # choose the right pattern
-    if pattern == "cPattern":
+    if pattern == 'cPattern':
         patterns = cPattern
-        middleBase = "C"
+        middleBase = 'C'
     else:
         patterns = tPattern
-        middleBase = "T"
+        middleBase = 'T'
     # generate the freqs dict with the right pattern
     freqs = defaultdict(int)
     for pattern in patterns:
         freqs[pattern] = 0
     # get the subject sequence from dotAlignment
-    subject = dotAlignment[0].split("\t")[3]
+    subject = dotAlignment[0].split('\t')[3]
     # exclude the subject from the dotAlignment, so just the queries
     # are left over
     queries = dotAlignment[1:]
     for item in queries:
-        query = item.split("\t")[1]
+        query = item.split('\t')[1]
         index = 0
         for queryBase in query:
             qBase = query[index]
             sBase = subject[index]
             if qBase == new and sBase == orig:
                 try:
                     plusSb = subject[index + 1]
                     minusSb = subject[index - 1]
                 except IndexError:
-                    plusSb = "end"
-                motif = "%s%s%s" % (minusSb, middleBase, plusSb)
+                    plusSb = 'end'
+                motif = '%s%s%s' % (minusSb, middleBase, plusSb)
                 if motif in freqs:
                     freqs[motif] += 1
             index += 1
 
     return freqs
 
 
@@ -270,49 +237,41 @@
     the frequencies.
 
     @param blastHits: A L{dark.blast.BlastHits} instance.
     """
     allFreqs = {}
     for title in blastHits.titles:
         allFreqs[title] = {
-            "C>A": {},
-            "C>G": {},
-            "C>T": {},
-            "T>A": {},
-            "T>C": {},
-            "T>G": {},
+            'C>A': {},
+            'C>G': {},
+            'C>T': {},
+            'T>A': {},
+            'T>C': {},
+            'T>G': {},
         }
         basesPlotted = basePlotter(blastHits, title)
         for mutation in allFreqs[title]:
             orig = mutation[0]
             new = mutation[2]
-            if orig == "C":
-                pattern = "cPattern"
+            if orig == 'C':
+                pattern = 'cPattern'
             else:
-                pattern = "tPattern"
+                pattern = 'tPattern'
             freqs = getAPOBECFrequencies(basesPlotted, orig, new, pattern)
             allFreqs[title][mutation] = freqs
-        numberOfReads = len(blastHits.titles[title]["plotInfo"]["items"])
-        allFreqs[title]["numberOfReads"] = numberOfReads
-        allFreqs[title]["bitScoreMax"] = blastHits.titles[title]["plotInfo"][
-            "bitScoreMax"
-        ]
+        numberOfReads = len(blastHits.titles[title]['plotInfo']['items'])
+        allFreqs[title]['numberOfReads'] = numberOfReads
+        allFreqs[title]['bitScoreMax'] = blastHits.titles[
+            title]['plotInfo']['bitScoreMax']
     return allFreqs
 
 
-def makeFrequencyGraph(
-    allFreqs,
-    title,
-    substitution,
-    pattern,
-    color="blue",
-    createFigure=True,
-    showFigure=True,
-    readsAx=False,
-):
+def makeFrequencyGraph(allFreqs, title, substitution, pattern,
+                       color='blue', createFigure=True, showFigure=True,
+                       readsAx=False):
     """
     For a title, make a graph showing the frequencies.
 
     @param allFreqs: result from getCompleteFreqs
     @param title: A C{str}, title of virus of which frequencies should be
         plotted.
     @param substitution: A C{str}, which substitution should be plotted;
@@ -320,81 +279,49 @@
     @param pattern: A C{str}, which pattern we're looking for ( must be
         one of 'cPattern', 'tPattern')
     @param color: A C{str}, color of bars.
     @param createFigure: If C{True}, create a figure.
     @param showFigure: If C{True}, show the created figure.
     @param readsAx: If not None, use this as the subplot for displaying reads.
     """
-    cPattern = [
-        "ACA",
-        "ACC",
-        "ACG",
-        "ACT",
-        "CCA",
-        "CCC",
-        "CCG",
-        "CCT",
-        "GCA",
-        "GCC",
-        "GCG",
-        "GCT",
-        "TCA",
-        "TCC",
-        "TCG",
-        "TCT",
-    ]
-    tPattern = [
-        "ATA",
-        "ATC",
-        "ATG",
-        "ATT",
-        "CTA",
-        "CTC",
-        "CTG",
-        "CTT",
-        "GTA",
-        "GTC",
-        "GTG",
-        "GTT",
-        "TTA",
-        "TTC",
-        "TTG",
-        "TTT",
-    ]
+    cPattern = ['ACA', 'ACC', 'ACG', 'ACT', 'CCA', 'CCC', 'CCG', 'CCT',
+                'GCA', 'GCC', 'GCG', 'GCT', 'TCA', 'TCC', 'TCG', 'TCT']
+    tPattern = ['ATA', 'ATC', 'ATG', 'ATT', 'CTA', 'CTC', 'CTG', 'CTT',
+                'GTA', 'GTC', 'GTG', 'GTT', 'TTA', 'TTC', 'TTG', 'TTT']
 
     # choose the right pattern
-    if pattern == "cPattern":
+    if pattern == 'cPattern':
         patterns = cPattern
     else:
         patterns = tPattern
 
     fig = plt.figure(figsize=(10, 10))
     ax = readsAx or fig.add_subplot(111)
     # how many bars
     N = 16
     ind = np.arange(N)
     width = 0.4
     # make a list in the right order, so that it can be plotted easily
-    divisor = allFreqs[title]["numberOfReads"]
+    divisor = allFreqs[title]['numberOfReads']
     toPlot = allFreqs[title][substitution]
     index = 0
     data = []
     for item in patterns:
         newData = toPlot[patterns[index]] / divisor
         data.append(newData)
         index += 1
     # create the bars
     ax.bar(ind, data, width, color=color)
     maxY = np.max(data) + 5
     # axes and labels
     if createFigure:
-        title = title.split("|")[4][:50]
-        ax.set_title("%s \n %s" % (title, substitution), fontsize=20)
+        title = title.split('|')[4][:50]
+        ax.set_title('%s \n %s' % (title, substitution), fontsize=20)
         ax.set_ylim(0, maxY)
-        ax.set_ylabel("Absolute Number of Mutations", fontsize=16)
+        ax.set_ylabel('Absolute Number of Mutations', fontsize=16)
         ax.set_xticks(ind + width)
         ax.set_xticklabels(patterns, rotation=45, fontsize=8)
     if createFigure is False:
         ax.set_xticks(ind + width)
         ax.set_xticklabels(patterns, rotation=45, fontsize=0)
     else:
         if showFigure:
@@ -406,149 +333,107 @@
     """
     For a title, make a graph showing the frequencies.
 
     @param allFreqs: result from getCompleteFreqs
     @param patientName: A C{str}, title for the panel
     """
     titles = sorted(
-        iter(allFreqs), key=lambda title: (allFreqs[title]["bitScoreMax"], title)
-    )
+        iter(allFreqs),
+        key=lambda title: (allFreqs[title]['bitScoreMax'], title))
 
     origMaxY = 0
     cols = 6
     rows = len(allFreqs)
     figure, ax = plt.subplots(rows, cols, squeeze=False)
-    substitutions = ["C>A", "C>G", "C>T", "T>A", "T>C", "T>G"]
-    colors = ["blue", "black", "red", "yellow", "green", "orange"]
+    substitutions = ['C>A', 'C>G', 'C>T', 'T>A', 'T>C', 'T>G']
+    colors = ['blue', 'black', 'red', 'yellow', 'green', 'orange']
 
     for i, title in enumerate(titles):
         for index in range(6):
             for subst in allFreqs[str(title)]:
                 substitution = substitutions[index]
-                print(i, index, title, "substitution", substitutions[index])
-                if substitution[0] == "C":
-                    pattern = "cPattern"
+                print(i, index, title, 'substitution', substitutions[index])
+                if substitution[0] == 'C':
+                    pattern = 'cPattern'
                 else:
-                    pattern = "tPattern"
-                maxY = makeFrequencyGraph(
-                    allFreqs,
-                    title,
-                    substitution,
-                    pattern,
-                    color=colors[index],
-                    createFigure=False,
-                    showFigure=False,
-                    readsAx=ax[i][index],
-                )
+                    pattern = 'tPattern'
+                maxY = makeFrequencyGraph(allFreqs, title, substitution,
+                                          pattern, color=colors[index],
+                                          createFigure=False, showFigure=False,
+                                          readsAx=ax[i][index])
                 if maxY > origMaxY:
                     origMaxY = maxY
 
             # add title for individual plot.
             # if used for other viruses, this will have to be adapted.
             if index == 0:
-                gi = title.split("|")[1]
-                titles = title.split(" ")
+                gi = title.split('|')[1]
+                titles = title.split(' ')
                 try:
-                    typeIndex = titles.index("type")
+                    typeIndex = titles.index('type')
                 except ValueError:
-                    typeNumber = "gi: %s" % gi
+                    typeNumber = 'gi: %s' % gi
                 else:
                     typeNumber = titles[typeIndex + 1]
 
-                ax[i][index].set_ylabel(
-                    (
-                        "Type %s \n maxBitScore: %s"
-                        % (typeNumber, allFreqs[title]["bitScoreMax"])
-                    ),
-                    fontsize=10,
-                )
+                ax[i][index].set_ylabel(('Type %s \n maxBitScore: %s' % (
+                    typeNumber, allFreqs[title]['bitScoreMax'])), fontsize=10)
             # add xAxis tick labels
             if i == 0:
                 ax[i][index].set_title(substitution, fontsize=13)
             if i == len(allFreqs) - 1 or i == (len(allFreqs) - 1) / 2:
                 if index < 3:
-                    pat = [
-                        "ACA",
-                        "ACC",
-                        "ACG",
-                        "ACT",
-                        "CCA",
-                        "CCC",
-                        "CCG",
-                        "CCT",
-                        "GCA",
-                        "GCC",
-                        "GCG",
-                        "GCT",
-                        "TCA",
-                        "TCC",
-                        "TCG",
-                        "TCT",
-                    ]
+                    pat = ['ACA', 'ACC', 'ACG', 'ACT', 'CCA', 'CCC', 'CCG',
+                           'CCT', 'GCA', 'GCC', 'GCG', 'GCT', 'TCA', 'TCC',
+                           'TCG', 'TCT']
                 else:
-                    pat = [
-                        "ATA",
-                        "ATC",
-                        "ATG",
-                        "ATT",
-                        "CTA",
-                        "CTC",
-                        "CTG",
-                        "CTT",
-                        "GTA",
-                        "GTC",
-                        "GTG",
-                        "GTT",
-                        "TTA",
-                        "TTC",
-                        "TTG",
-                        "TTT",
-                    ]
+                    pat = ['ATA', 'ATC', 'ATG', 'ATT', 'CTA', 'CTC', 'CTG',
+                           'CTT', 'GTA', 'GTC', 'GTG', 'GTT', 'TTA', 'TTC',
+                           'TTG', 'TTT']
                 ax[i][index].set_xticklabels(pat, rotation=45, fontsize=8)
 
     # make Y-axis equal
     for i, title in enumerate(allFreqs):
         for index in range(6):
             a = ax[i][index]
             a.set_ylim([0, origMaxY])
     # add title of whole panel
-    figure.suptitle("Mutation Signatures in %s" % patientName, fontsize=20)
+    figure.suptitle('Mutation Signatures in %s' % patientName, fontsize=20)
     figure.set_size_inches(5 * cols, 3 * rows, forward=True)
     figure.show()
 
     return allFreqs
 
 
-def mutateString(original, n, replacements="acgt"):
+def mutateString(original, n, replacements='acgt'):
     """
     Mutate C{original} in C{n} places with chars chosen from C{replacements}.
 
     @param original: The original C{str} to mutate.
     @param n: The C{int} number of locations to mutate.
     @param replacements: The C{str} of replacement letters.
 
     @return: A new C{str} with C{n} places of C{original} mutated.
     @raises ValueError: if C{n} is too high, or C{replacement} contains
         duplicates, or if no replacement can be made at a certain locus
         because C{replacements} is of length one, or if C{original} is of
         zero length.
     """
     if not original:
-        raise ValueError("Empty original string passed.")
+        raise ValueError('Empty original string passed.')
 
     if n > len(original):
-        raise ValueError(
-            "Cannot make %d mutations in a string of length %d" % (n, len(original))
-        )
+        raise ValueError('Cannot make %d mutations in a string of length %d' %
+                         (n, len(original)))
 
     if len(replacements) != len(set(replacements)):
-        raise ValueError("Replacement string contains duplicates")
+        raise ValueError('Replacement string contains duplicates')
 
     if len(replacements) == 1 and original.find(replacements) != -1:
-        raise ValueError("Impossible replacement")
+        raise ValueError('Impossible replacement')
 
     result = list(original)
     length = len(original)
 
     for offset in range(length):
         if uniform(0.0, 1.0) < float(n) / (length - offset):
             # Mutate.
@@ -557,8 +442,8 @@
                 if new != result[offset]:
                     result[offset] = new
                     break
             n -= 1
             if n == 0:
                 break
 
-    return "".join(result)
+    return ''.join(result)
```

### Comparing `dark-matter-4.0.84/dark/ncbidb.py` & `dark-matter-4.0.9/dark/ncbidb.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,16 @@
 import subprocess
 from io import StringIO
 from Bio import SeqIO
 
 
-def getSequence(title, db="nt"):
+def getSequence(title, db='nt'):
     """
     @param title: A C{str} sequence title from a BLAST hit. Of the form
         'gi|63148399|gb|DQ011818.1| Description...'.
     @param db: the C{str} name of the BLAST database to search.
     @return: A C{SeqIO.read} instance.
     """
-    titleId = title.split(" ", 1)[0]
+    titleId = title.split(' ', 1)[0]
     fasta = subprocess.check_output(
-        ["blastdbcmd", "-entry", titleId, "-db", db]
-    ).decode("ascii")
-    return SeqIO.read(StringIO(fasta), "fasta")
+        ['blastdbcmd', '-entry', titleId, '-db', db]).decode('ascii')
+    return SeqIO.read(StringIO(fasta), 'fasta')
```

### Comparing `dark-matter-4.0.84/dark/orfs.py` & `dark-matter-4.0.9/dark/orfs.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 import numpy as np
 
-START_CODONS = set(["ATG"])
-STOP_CODONS = set(["TAA", "TAG", "TGA"])
+START_CODONS = set(['ATG'])
+STOP_CODONS = set(['TAA', 'TAG', 'TGA'])
 
 
 def findCodons(seq, codons):
     """
     Find all instances of the codons in 'codons' in the given sequence.
 
     seq: A Bio.Seq.Seq instance.
     codons: A set of codon strings.
 
     Return: a generator yielding matching codon offsets.
     """
     seqLen = len(seq)
     start = 0
     while start < seqLen:
-        triplet = str(seq[start : start + 3])
+        triplet = str(seq[start:start + 3])
         if triplet in codons:
             yield start
         start = start + 3
 
 
 def addORFs(fig, seq, minX, maxX, offsetAdjuster):
     """
@@ -30,68 +30,49 @@
     maxX: the largest x coordinate.
     featureEndpoints: an array of features as returned by addFeatures (may be
         empty).
     offsetAdjuster: a function to adjust feature X axis offsets for plotting.
     """
     for frame in range(3):
         target = seq[frame:]
-        for codons, codonType, color in (
-            (START_CODONS, "start", "green"),
-            (STOP_CODONS, "stop", "red"),
-        ):
+        for (codons, codonType, color) in (
+                (START_CODONS, 'start', 'green'),
+                (STOP_CODONS, 'stop', 'red')):
             offsets = list(map(offsetAdjuster, findCodons(target, codons)))
             if offsets:
-                fig.plot(
-                    offsets,
-                    np.tile(frame, len(offsets)),
-                    marker=".",
-                    markersize=4,
-                    color=color,
-                    linestyle="None",
-                )
+                fig.plot(offsets, np.tile(frame, len(offsets)), marker='.',
+                         markersize=4, color=color, linestyle='None')
 
     fig.axis([minX, maxX, -1, 3])
     fig.set_yticks(np.arange(3))
-    fig.set_ylabel("Frame", fontsize=17)
-    fig.set_title(
-        "Subject start (%s) and stop (%s) codons"
-        % (", ".join(sorted(START_CODONS)), ", ".join(sorted(STOP_CODONS))),
-        fontsize=20,
-    )
+    fig.set_ylabel('Frame', fontsize=17)
+    fig.set_title('Subject start (%s) and stop (%s) codons' % (
+        ', '.join(sorted(START_CODONS)), ', '.join(sorted(STOP_CODONS))),
+        fontsize=20)
 
 
 def addReversedORFs(fig, seq, minX, maxX, offsetAdjuster):
     """
     fig is a matplotlib figure.
     seq is a Bio.Seq.Seq (the reverse complement of the sequence we're
         plotting against).
     minX: the smallest x coordinate.
     maxX: the largest x coordinate.
     offsetAdjuster: a function to adjust feature X axis offsets for plotting.
     """
     for frame in range(3):
         target = seq[frame:]
-        for codons, codonType, color in (
-            (START_CODONS, "start", "green"),
-            (STOP_CODONS, "stop", "red"),
-        ):
-            offsets = [
-                maxX - offsetAdjuster(offset) for offset in findCodons(target, codons)
-            ]
+        for (codons, codonType, color) in (
+                (START_CODONS, 'start', 'green'),
+                (STOP_CODONS, 'stop', 'red')):
+            offsets = [maxX - offsetAdjuster(offset)
+                       for offset in findCodons(target, codons)]
             if offsets:
-                fig.plot(
-                    offsets,
-                    np.tile(frame, len(offsets)),
-                    marker=".",
-                    markersize=4,
-                    color=color,
-                    linestyle="None",
-                )
+                fig.plot(offsets, np.tile(frame, len(offsets)), marker='.',
+                         markersize=4, color=color, linestyle='None')
 
     fig.axis([minX, maxX, -1, 3])
     fig.set_yticks(np.arange(3))
-    fig.set_ylabel("Frame", fontsize=17)
-    fig.set_title(
-        "Reversed subject start (%s) and stop (%s) codons"
-        % (", ".join(sorted(START_CODONS)), ", ".join(sorted(STOP_CODONS))),
-        fontsize=20,
-    )
+    fig.set_ylabel('Frame', fontsize=17)
+    fig.set_title('Reversed subject start (%s) and stop (%s) codons' %
+                  (', '.join(sorted(START_CODONS)),
+                   ', '.join(sorted(STOP_CODONS))), fontsize=20)
```

### Comparing `dark-matter-4.0.84/dark/process.py` & `dark-matter-4.0.9/dark/process.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,32 @@
+from __future__ import division, print_function
+
 import six
 from time import time, ctime
 
 from subprocess import PIPE, CalledProcessError
-
 if six.PY3:
     from subprocess import run
 else:
     from subprocess import check_call
 
 
-class Executor:
+class Executor(object):
     """
     Log and execute shell commands.
 
     @param dryRun: If C{True}, do not execute commands, just log them.
         This sets the default and can be overidden for a specific command
         by passing C{dryRun} to the C{execute} method.
     """
-
     def __init__(self, dryRun=False):
         self.dryRun = dryRun
-        self.log = ["# Executor created at %s. Dry run = %s." % (ctime(time()), dryRun)]
+        self.log = [
+            '# Executor created at %s. Dry run = %s.' % (ctime(time()), dryRun)
+        ]
 
     def dryRun(self):
         """
         Is this a dry run?
 
         @return: A Boolean indicating whether this is a dry run.
         """
@@ -53,79 +55,61 @@
         @raise CalledProcessError: If the command results in an error.
         @return: A C{CompletedProcess} instance. This has attributes such as
             C{returncode}, C{stdout}, and C{stderr}. See pydoc subprocess.
             If C{dryRun} is C{True}, C{None} is returned.
         """
         if isinstance(command, six.string_types):
             # Can't have newlines in a command given to the shell.
-            strCommand = command = command.replace("\n", " ").strip()
+            strCommand = command = command.replace('\n', ' ').strip()
             shell = True
         else:
-            strCommand = " ".join(command)
+            strCommand = ' '.join(command)
             shell = False
 
         dryRun = self.dryRun if dryRun is None else dryRun
 
         if dryRun:
-            self.log.append("$ " + strCommand)
+            self.log.append('$ ' + strCommand)
             return
 
         start = time()
-        self.log.extend(
-            [
-                "# Start command (shell=%s) at %s" % (shell, ctime(start)),
-                "$ " + strCommand,
-            ]
-        )
+        self.log.extend([
+            '# Start command (shell=%s) at %s' % (shell, ctime(start)),
+            '$ ' + strCommand,
+        ])
 
         if six.PY3:
             try:
-                result = run(
-                    command,
-                    check=True,
-                    stdout=PIPE,
-                    stderr=PIPE,
-                    shell=shell,
-                    universal_newlines=True,
-                    **kwargs
-                )
+                result = run(command, check=True, stdout=PIPE, stderr=PIPE,
+                             shell=shell, universal_newlines=True, **kwargs)
             except CalledProcessError as e:
                 if callable(useStderr):
                     useStderr = useStderr(e)
                 if useStderr:
                     import sys
-
-                    print("CalledProcessError:", e, file=sys.stderr)
-                    print("STDOUT:\n%s" % e.stdout, file=sys.stderr)
-                    print("STDERR:\n%s" % e.stderr, file=sys.stderr)
+                    print('CalledProcessError:', e, file=sys.stderr)
+                    print('STDOUT:\n%s' % e.stdout, file=sys.stderr)
+                    print('STDERR:\n%s' % e.stderr, file=sys.stderr)
                 raise
         else:
             try:
-                result = check_call(
-                    command,
-                    stdout=PIPE,
-                    stderr=PIPE,
-                    shell=shell,
-                    universal_newlines=True,
-                    **kwargs
-                )
+                result = check_call(command, stdout=PIPE, stderr=PIPE,
+                                    shell=shell, universal_newlines=True,
+                                    **kwargs)
             except CalledProcessError as e:
                 if callable(useStderr):
                     useStderr = useStderr(e)
                 if useStderr:
                     import sys
-
-                    print("CalledProcessError:", e, file=sys.stderr)
-                    print("Return code: %s" % e.returncode, file=sys.stderr)
-                    print("Output:\n%s" % e.output, file=sys.stderr)
+                    print('CalledProcessError:', e, file=sys.stderr)
+                    print('Return code: %s' % e.returncode, file=sys.stderr)
+                    print('Output:\n%s' % e.output, file=sys.stderr)
                 raise
 
         stop = time()
-        elapsed = stop - start
-        self.log.extend(
-            [
-                "# Stop command at %s" % ctime(stop),
-                "# Elapsed = %f seconds" % elapsed,
-            ]
-        )
+        elapsed = (stop - start)
+        self.log.extend([
+            '# Stop command at %s' % ctime(stop),
+            '# Elapsed = %f seconds' % elapsed,
+        ])
 
         return result
```

### Comparing `dark-matter-4.0.84/dark/proteins.py` & `dark-matter-4.0.9/dark/proteins.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+from __future__ import print_function, division
+
 import os
 from collections import defaultdict, Counter
 import numpy as np
 from os.path import dirname, exists, join
 from operator import itemgetter
 import re
 from six.moves.urllib.parse import quote
@@ -29,20 +31,20 @@
 # name has nested [...] sections, as in this example:
 #
 #   gi|224808893|ref|YP_002643049.1| replication-associated protein [Tomato
 #   leaf curl Nigeria virus-[Nigeria:2006]]
 #
 # I decided not to worry about nested [...] sections (there are only 2
 # instances that I know of).
-_PATHOGEN_RE = re.compile(r"^(.*)\[([^\]]+)\]$")
+_PATHOGEN_RE = re.compile(r'^(.*)\[([^\]]+)\]$')
 
 # The pathogen name assigned to proteins whose id strings cannot be parsed
 # for a pathogen name (see previous comment).  Do not use '<', '>' or any
 # other HTML special chars in the following.
-_NO_PATHOGEN_NAME = "[no pathogen name found in sequence id]"
+_NO_PATHOGEN_NAME = '[no pathogen name found in sequence id]'
 
 
 def splitNames(names):
     """
     Split a sequence id string like "Protein name [pathogen name]" into two
     pieces using the final square brackets to delimit the pathogen name.
 
@@ -81,34 +83,33 @@
                 _, pathogenName = splitNames(protein.id)
                 if pathogenName != _NO_PATHOGEN_NAME:
                     result[pathogenName] += 1
 
     return result
 
 
-class PathogenSampleFiles:
+class PathogenSampleFiles(object):
     """
     Maintain a cache of FASTA/FASTQ file names for the samples that contain a
     given pathogen, create de-duplicated (by read id) FASTA/FASTQ files
     for each pathogen/sample pair, provide functions to write out index files
     of sample and pathogen numbers (which are generated here in C{self.add}),
     and provide a filename lookup function for pathogen/sample combinations
     or just pathogen names by themselves.
 
     @param proteinGrouper: An instance of C{ProteinGrouper}.
     @param format_: A C{str}, either 'fasta' or 'fastq' indicating the format
         of the files containing the reads matching proteins.
     @raise ValueError: If C{format_} is unknown.
     """
-
-    def __init__(self, proteinGrouper, format_="fasta"):
+    def __init__(self, proteinGrouper, format_='fasta'):
         self._proteinGrouper = proteinGrouper
-        if format_ in ("fasta", "fastq"):
+        if format_ in ('fasta', 'fastq'):
             self._format = format_
-            self._readsClass = FastaReads if format_ == "fasta" else FastqReads
+            self._readsClass = FastaReads if format_ == 'fasta' else FastqReads
         else:
             raise ValueError("format_ must be either 'fasta' or 'fastq'.")
         self._pathogens = {}
         self._samples = {}
         self._readsFilenames = {}
 
     def add(self, pathogenName, sampleName):
@@ -120,36 +121,35 @@
 
         @param pathogenName: A C{str} pathogen name.
         @param sampleName: A C{str} sample name.
         @return: A C{str} giving the FASTA/FASTQ file name holding all the
             reads (without duplicates, by id) from the sample that matched the
             proteins in the given pathogen.
         """
-        pathogenIndex = self._pathogens.setdefault(pathogenName, len(self._pathogens))
+        pathogenIndex = self._pathogens.setdefault(pathogenName,
+                                                   len(self._pathogens))
         sampleIndex = self._samples.setdefault(sampleName, len(self._samples))
 
         try:
             return self._readsFilenames[(pathogenIndex, sampleIndex)]
         except KeyError:
             reads = Reads()
-            for proteinMatch in self._proteinGrouper.pathogenNames[pathogenName][
-                sampleName
-            ]["proteins"].values():
-                for read in self._readsClass(proteinMatch["readsFilename"]):
+            for proteinMatch in self._proteinGrouper.pathogenNames[
+                    pathogenName][sampleName]['proteins'].values():
+                for read in self._readsClass(proteinMatch['readsFilename']):
                     reads.add(read)
             saveFilename = join(
-                proteinMatch["outDir"],
-                "pathogen-%d-sample-%d.%s" % (pathogenIndex, sampleIndex, self._format),
-            )
+                proteinMatch['outDir'],
+                'pathogen-%d-sample-%d.%s' % (pathogenIndex, sampleIndex,
+                                              self._format))
             reads.filter(removeDuplicatesById=True)
             nReads = reads.save(saveFilename, format_=self._format)
             # Save the unique read count into self._proteinGrouper
-            self._proteinGrouper.pathogenNames[pathogenName][sampleName][
-                "uniqueReadCount"
-            ] = nReads
+            self._proteinGrouper.pathogenNames[
+                pathogenName][sampleName]['uniqueReadCount'] = nReads
             self._readsFilenames[(pathogenIndex, sampleIndex)] = saveFilename
             return saveFilename
 
     def lookup(self, pathogenName, sampleName):
         """
         Look up a pathogen name, sample name combination and get its
         FASTA/FASTQ file name and unique read count.
@@ -170,53 +170,43 @@
 
     def writeSampleIndex(self, fp):
         """
         Write a file of sample indices and names, sorted by index.
 
         @param fp: A file-like object, opened for writing.
         """
-        print(
-            "\n".join(
-                "%d %s" % (index, name)
-                for (index, name) in sorted(
-                    (index, name) for (name, index) in self._samples.items()
-                )
-            ),
-            file=fp,
-        )
+        print('\n'.join(
+            '%d %s' % (index, name) for (index, name) in
+            sorted((index, name) for (name, index) in self._samples.items())
+        ), file=fp)
 
     def writePathogenIndex(self, fp):
         """
         Write a file of pathogen indices and names, sorted by index.
 
         @param fp: A file-like object, opened for writing.
         """
-        print(
-            "\n".join(
-                "%d %s" % (index, name)
-                for (index, name) in sorted(
-                    (index, name) for (name, index) in self._pathogens.items()
-                )
-            ),
-            file=fp,
-        )
+        print('\n'.join(
+            '%d %s' % (index, name) for (index, name) in
+            sorted((index, name) for (name, index) in self._pathogens.items())
+        ), file=fp)
 
     def pathogenIndex(self, pathogenName):
         """
         Get the index for a pathogen.
 
         @param pathogenName: A C{str} pathogen name.
         @raise KeyError: If the named pathogen is unknown.
         @return: An C{int} giving the index for the pathogen (as set in
             self.add).
         """
         return self._pathogens[pathogenName]
 
 
-class ProteinGrouper:
+class ProteinGrouper(object):
     """
     Group matched proteins by the pathogen they come from.
 
     @param assetDir: The C{str} directory name where
         C{noninteractive-alignment-panel.py} put its HTML, blue plot and
         alignment panel images, and FASTA or FASTQ files. This must be relative
         to the filenames that will later be passed to C{addFile}.
@@ -247,50 +237,43 @@
         refseq database and RVDB.
     @param pathogenDataDir: The C{str} directory where per-pathogen information
         (e.g., collected reads across all samples) should be written. Will be
         created (in C{self.toHTML}) if it doesn't exist.
     @raise ValueError: If C{format_} is unknown.
     """
 
-    VIRALZONE = "https://viralzone.expasy.org/search?query="
-    ICTV = "https://talk.ictvonline.org/search-124283882/?q="
-    READCOUNT_MARKER = "*READ-COUNT*"
-    READ_AND_HSP_COUNT_STR_SEP = "/"
-
-    def __init__(
-        self,
-        assetDir="out",
-        sampleName=None,
-        sampleNameRegex=None,
-        format_="fasta",
-        proteinFastaFilenames=None,
-        saveReadLengths=False,
-        titleRegex=None,
-        negativeTitleRegex=None,
-        pathogenDataDir="pathogen-data",
-    ):
+    VIRALZONE = 'https://viralzone.expasy.org/search?query='
+    ICTV = 'https://talk.ictvonline.org/search-124283882/?q='
+    READCOUNT_MARKER = '*READ-COUNT*'
+    READ_AND_HSP_COUNT_STR_SEP = '/'
+
+    def __init__(self, assetDir='out', sampleName=None, sampleNameRegex=None,
+                 format_='fasta', proteinFastaFilenames=None,
+                 saveReadLengths=False, titleRegex=None,
+                 negativeTitleRegex=None, pathogenDataDir='pathogen-data'):
         self._assetDir = assetDir
         self._sampleName = sampleName
-        self._sampleNameRegex = re.compile(sampleNameRegex) if sampleNameRegex else None
-        if format_ in ("fasta", "fastq"):
+        self._sampleNameRegex = (re.compile(sampleNameRegex) if sampleNameRegex
+                                 else None)
+        if format_ in ('fasta', 'fastq'):
             self._format = format_
         else:
             raise ValueError("format_ must be either 'fasta' or 'fastq'.")
         self._saveReadLengths = saveReadLengths
 
         if titleRegex or negativeTitleRegex:
             self.titleFilter = TitleFilter(
-                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex
-            )
+                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex)
         else:
             self.titleFilter = None
 
         self._pathogenDataDir = pathogenDataDir
 
-        self._pathogenProteinCount = getPathogenProteinCounts(proteinFastaFilenames)
+        self._pathogenProteinCount = getPathogenProteinCounts(
+            proteinFastaFilenames)
 
         # pathogenNames will be a dict of dicts of dicts. The first two keys
         # will be a pathogen name and a sample name. The final dict will
         # contain 'proteins' (a list of dicts) and 'uniqueReadCount' (an int).
         self.pathogenNames = {}
         # sampleNames is keyed by sample name and will have values that hold
         # the sample's alignment panel index.html file.
@@ -299,20 +282,20 @@
 
     def _title(self):
         """
         Create a title summarizing the pathogens and samples.
 
         @return: A C{str} title.
         """
-        return "Overall, proteins from %d pathogen%s were found in %d sample%s." % (
-            len(self.pathogenNames),
-            "" if len(self.pathogenNames) == 1 else "s",
-            len(self.sampleNames),
-            "" if len(self.sampleNames) == 1 else "s",
-        )
+        return (
+            'Overall, proteins from %d pathogen%s were found in %d sample%s.' %
+            (len(self.pathogenNames),
+             '' if len(self.pathogenNames) == 1 else 's',
+             len(self.sampleNames),
+             '' if len(self.sampleNames) == 1 else 's'))
 
     def addFile(self, filename, fp):
         """
         Read and record protein information for a sample.
 
         @param filename: A C{str} file name.
         @param fp: An open file pointer to read the file's data from.
@@ -328,180 +311,153 @@
             else:
                 sampleName = filename
         else:
             sampleName = filename
 
         outDir = join(dirname(filename), self._assetDir)
 
-        self.sampleNames[sampleName] = join(outDir, "index.html")
+        self.sampleNames[sampleName] = join(outDir, 'index.html')
 
         for index, proteinLine in enumerate(fp):
             proteinLine = proteinLine[:-1]
-            (
-                coverage,
-                medianScore,
-                bestScore,
-                readCount,
-                hspCount,
-                proteinLength,
-                names,
-            ) = proteinLine.split(None, 6)
+            (coverage, medianScore, bestScore, readCount, hspCount,
+             proteinLength, names) = proteinLine.split(None, 6)
 
             proteinName, pathogenName = splitNames(names)
 
             # Ignore pathogens with names we don't want.
-            if (
-                self.titleFilter
-                and self.titleFilter.accept(pathogenName) == TitleFilter.REJECT
-            ):
+            if (self.titleFilter and self.titleFilter.accept(
+                    pathogenName) == TitleFilter.REJECT):
                 continue
 
             if pathogenName not in self.pathogenNames:
                 self.pathogenNames[pathogenName] = {}
 
             if sampleName not in self.pathogenNames[pathogenName]:
                 self.pathogenNames[pathogenName][sampleName] = {
-                    "proteins": {},
-                    "uniqueReadCount": None,
+                    'proteins': {},
+                    'uniqueReadCount': None,
                 }
 
-            proteins = self.pathogenNames[pathogenName][sampleName]["proteins"]
+            proteins = self.pathogenNames[pathogenName][sampleName]['proteins']
 
             # We should only receive one line of information for a given
             # pathogen/sample/protein combination.
             if proteinName in proteins:
                 raise ValueError(
-                    "Protein %r already seen for pathogen %r sample %r."
-                    % (proteinName, pathogenName, sampleName)
-                )
+                    'Protein %r already seen for pathogen %r sample %r.' %
+                    (proteinName, pathogenName, sampleName))
 
-            readsFilename = join(outDir, "%d.%s" % (index, self._format))
+            readsFilename = join(outDir, '%d.%s' % (index, self._format))
 
-            if proteinName.count("|") < 5:
+            if proteinName.count('|') < 5:
                 # Assume this is an NCBI refseq id, like
                 # YP_009137153.1 uracil glycosylase [Human alphaherpesvirus 2]
                 # with a protein but not a genome accession.
-                proteinURL = NCBISequenceLinkURL(proteinName, field=0, delim=" ")
+                proteinURL = NCBISequenceLinkURL(proteinName, field=0,
+                                                 delim=' ')
                 genomeURL = None
             else:
                 # Assume this is an RVDB id, like
                 # acc|GENBANK|ABJ91970.1|GENBANK|DQ876317|pol protein [HIV]
                 # with both protein and genome accession numbers.
                 proteinURL = NCBISequenceLinkURL(proteinName, field=2)
                 genomeURL = NCBISequenceLinkURL(proteinName, field=4)
 
             proteinInfo = proteins[proteinName] = {
-                "bestScore": float(bestScore),
-                "bluePlotFilename": join(outDir, "%d.png" % index),
-                "coverage": float(coverage),
-                "readsFilename": readsFilename,
-                "hspCount": int(hspCount),
-                "index": index,
-                "medianScore": float(medianScore),
-                "outDir": outDir,
-                "proteinLength": int(proteinLength),
-                "proteinName": proteinName,
-                "proteinURL": proteinURL,
-                "genomeURL": genomeURL,
-                "readCount": int(readCount),
+                'bestScore': float(bestScore),
+                'bluePlotFilename': join(outDir, '%d.png' % index),
+                'coverage': float(coverage),
+                'readsFilename': readsFilename,
+                'hspCount': int(hspCount),
+                'index': index,
+                'medianScore': float(medianScore),
+                'outDir': outDir,
+                'proteinLength': int(proteinLength),
+                'proteinName': proteinName,
+                'proteinURL': proteinURL,
+                'genomeURL': genomeURL,
+                'readCount': int(readCount),
             }
 
-            if proteinInfo["readCount"] == proteinInfo["hspCount"]:
-                proteinInfo["readAndHspCountStr"] = readCount
+            if proteinInfo['readCount'] == proteinInfo['hspCount']:
+                proteinInfo['readAndHspCountStr'] = readCount
             else:
-                proteinInfo["readAndHspCountStr"] = "%s%s%s" % (
-                    readCount,
-                    self.READ_AND_HSP_COUNT_STR_SEP,
-                    hspCount,
-                )
+                proteinInfo['readAndHspCountStr'] = '%s%s%s' % (
+                    readCount, self.READ_AND_HSP_COUNT_STR_SEP, hspCount)
 
             if self._saveReadLengths:
-                readsClass = FastaReads if self._format == "fasta" else FastqReads
-                proteins[proteinName]["readLengths"] = tuple(
-                    len(read) for read in readsClass(readsFilename)
-                )
+                readsClass = (FastaReads if self._format == 'fasta'
+                              else FastqReads)
+                proteins[proteinName]['readLengths'] = tuple(
+                    len(read) for read in readsClass(readsFilename))
 
     def _computeUniqueReadCounts(self):
         """
         Add all pathogen / sample combinations to self.pathogenSampleFiles.
 
         This will make all de-duplicated (by id) FASTA/FASTQ files and store
         the number of de-duplicated reads into C{self.pathogenNames}.
         """
         for pathogenName, samples in self.pathogenNames.items():
             for sampleName in samples:
                 self.pathogenSampleFiles.add(pathogenName, sampleName)
 
-    def toStr(self, title="Summary of pathogens", preamble=None):
+    def toStr(self, title='Summary of pathogens', preamble=None):
         """
         Produce a string representation of the pathogen summary.
 
         @param title: The C{str} title for the output.
         @param preamble: The C{str} descriptive preamble, or C{None} if no
             preamble is needed.
         @return: A C{str} suitable for printing.
         """
         # Note that the string representation contains much less
         # information than the HTML summary. E.g., it does not contain the
         # unique (de-duplicated, by id) read count, since that is only computed
         # when we are making combined FASTA files of reads matching a
         # pathogen.
-        readCountGetter = itemgetter("readCount")
+        readCountGetter = itemgetter('readCount')
         result = []
         append = result.append
 
-        result.extend((title, ""))
+        result.extend((title, ''))
         if preamble:
-            result.extend((preamble, ""))
-        result.extend((self._title(), ""))
+            result.extend((preamble, ''))
+        result.extend((self._title(), ''))
 
         for pathogenName in sorted(self.pathogenNames):
             samples = self.pathogenNames[pathogenName]
             sampleCount = len(samples)
-            append(
-                "%s (in %d sample%s)"
-                % (pathogenName, sampleCount, "" if sampleCount == 1 else "s")
-            )
+            append('%s (in %d sample%s)' %
+                   (pathogenName,
+                    sampleCount, '' if sampleCount == 1 else 's'))
             for sampleName in sorted(samples):
-                proteins = samples[sampleName]["proteins"]
+                proteins = samples[sampleName]['proteins']
                 proteinCount = len(proteins)
                 totalReads = sum(readCountGetter(p) for p in proteins.values())
-                append(
-                    "  %s (%d protein%s, %d read%s)"
-                    % (
-                        sampleName,
-                        proteinCount,
-                        "" if proteinCount == 1 else "s",
-                        totalReads,
-                        "" if totalReads == 1 else "s",
-                    )
-                )
+                append('  %s (%d protein%s, %d read%s)' %
+                       (sampleName,
+                        proteinCount, '' if proteinCount == 1 else 's',
+                        totalReads, '' if totalReads == 1 else 's'))
                 for proteinName in sorted(proteins):
                     append(
-                        "    %(coverage).2f\t%(medianScore).2f\t"
-                        "%(bestScore).2f\t%(readAndHspCountStr)11s\t"
-                        "%(proteinName)s" % proteins[proteinName]
-                    )
-            append("")
-
-        return "\n".join(result)
-
-    def toHTML(
-        self,
-        pathogenPanelFilename=None,
-        minProteinFraction=0.0,
-        minProteinCount=0,
-        pathogenType="viral",
-        title="Summary of pathogens",
-        preamble=None,
-        sampleIndexFilename=None,
-        pathogenIndexFilename=None,
-        omitVirusLinks=False,
-        omitSampleProteinCount=False,
-    ):
+                        '    %(coverage).2f\t%(medianScore).2f\t'
+                        '%(bestScore).2f\t%(readAndHspCountStr)11s\t'
+                        '%(proteinName)s'
+                        % proteins[proteinName])
+            append('')
+
+        return '\n'.join(result)
+
+    def toHTML(self, pathogenPanelFilename=None, minProteinFraction=0.0,
+               minProteinCount=0, pathogenType='viral',
+               title='Summary of pathogens', preamble=None,
+               sampleIndexFilename=None, pathogenIndexFilename=None,
+               omitVirusLinks=False, omitSampleProteinCount=False):
         """
         Produce an HTML string representation of the pathogen summary.
 
         @param pathogenPanelFilename: If not C{None}, a C{str} filename to
             write a pathogen panel PNG image to.
         @param minProteinFraction: The C{float} minimum fraction of proteins
             in a pathogen that must be matched by a sample in order for that
@@ -525,80 +481,75 @@
         @param omitSampleProteinCount: If C{True}, do not display a number of
             matched pathogen proteins for a sample. This should be used when
             those numbers are inaccurate (e.g., when using the unclustered RVDB
             protein database and there are many sequences for the same
             protein).
         @return: An HTML C{str} suitable for printing.
         """
-        if pathogenType not in ("bacterial", "viral"):
+        if pathogenType not in ('bacterial', 'viral'):
             raise ValueError(
                 "Unrecognized pathogenType argument: %r. Value must be either "
-                "'bacterial' or 'viral'." % pathogenType
-            )
+                "'bacterial' or 'viral'." % pathogenType)
 
         if not exists(self._pathogenDataDir):
             os.mkdir(self._pathogenDataDir)
 
         self._computeUniqueReadCounts()
 
         if pathogenPanelFilename:
             self.pathogenPanel(pathogenPanelFilename)
 
         if sampleIndexFilename:
-            with open(sampleIndexFilename, "w") as fp:
+            with open(sampleIndexFilename, 'w') as fp:
                 self.pathogenSampleFiles.writeSampleIndex(fp)
 
         if pathogenIndexFilename:
-            with open(pathogenIndexFilename, "w") as fp:
+            with open(pathogenIndexFilename, 'w') as fp:
                 self.pathogenSampleFiles.writePathogenIndex(fp)
 
         # Figure out if we have to delete some pathogens because the number
         # or fraction of its proteins that we have matches for is too low.
         if minProteinFraction > 0.0 or minProteinCount > 0:
             toDelete = defaultdict(list)
             for genomeAccession in self.genomeAccessions:
                 genomeInfo = self._db.findGenome(genomeAccession)
-                pathogenProteinCount = genomeInfo["proteinCount"]
+                pathogenProteinCount = genomeInfo['proteinCount']
                 assert pathogenProteinCount > 0
                 for s in self.genomeAccessions[genomeAccession]:
-                    sampleProteinCount = len(
-                        self.genomeAccessions[genomeAccession][s]["proteins"]
-                    )
+                    sampleProteinCount = len(self.genomeAccessions[
+                        genomeAccession][s]['proteins'])
                     if sampleProteinCount < minProteinCount:
                         toDelete[genomeAccession].append(s)
                     else:
                         sampleProteinFraction = (
-                            sampleProteinCount / pathogenProteinCount
-                        )
+                            sampleProteinCount / pathogenProteinCount)
                         if sampleProteinFraction < minProteinFraction:
                             toDelete[genomeAccession].append(s)
 
             for genomeAccession, samples in toDelete.items():
                 for sample in samples:
                     del self.genomeAccessions[genomeAccession][sample]
 
         pathogenNames = sorted(
-            pathogenName
-            for pathogenName in self.pathogenNames
-            if len(self.pathogenNames[pathogenName]) > 0
-        )
+            pathogenName for pathogenName in self.pathogenNames
+            if len(self.pathogenNames[pathogenName]) > 0)
         nPathogenNames = len(pathogenNames)
         sampleNames = sorted(self.sampleNames)
 
         result = [
-            "<html>",
-            "<head>",
-            "<title>",
+            '<html>',
+            '<head>',
+            '<title>',
             title,
-            "</title>",
+            '</title>',
             '<meta charset="UTF-8">',
-            "</head>",
-            "<body>",
-            "<style>",
-            """\
+            '</head>',
+            '<body>',
+            '<style>',
+            '''\
             body {
                 margin-left: 2%;
                 margin-right: 2%;
             }
             hr {
                 display: block;
                 margin-top: 0.5em;
@@ -645,426 +596,372 @@
             }
             .stats {
                 font-family: "Courier New", Courier, monospace;
                 white-space: pre;
             }
             .protein-list {
                 margin-top: 2px;
-            }""",
-            "</style>",
-            "</head>",
-            "<body>",
+            }''',
+            '</style>',
+            '</head>',
+            '<body>',
         ]
 
         proteinFieldsDescription = [
-            "<p>",
-            "In all bullet point protein lists below, there are the following "
-            "fields:",
-            "<ol>",
-            "<li>Coverage fraction.</li>",
-            "<li>Median bit score.</li>",
-            "<li>Best bit score.</li>",
-            "<li>Read count (if the HSP count differs, read and HSP ",
-            (
-                'counts are both given, separated by "%s").</li>'
-                % self.READ_AND_HSP_COUNT_STR_SEP
-            ),
-            "<li>Protein length (in amino acids).</li>",
+            '<p>',
+            'In all bullet point protein lists below, there are the following '
+            'fields:',
+            '<ol>',
+            '<li>Coverage fraction.</li>',
+            '<li>Median bit score.</li>',
+            '<li>Best bit score.</li>',
+            '<li>Read count (if the HSP count differs, read and HSP ',
+            ('counts are both given, separated by "%s").</li>' %
+             self.READ_AND_HSP_COUNT_STR_SEP),
+            '<li>Protein length (in amino acids).</li>',
         ]
 
         if self._saveReadLengths:
             proteinFieldsDescription.append(
-                "<li>All read lengths (in parentheses).</li>"
-            )
+                '<li>All read lengths (in parentheses).</li>')
 
-        proteinFieldsDescription.extend(
-            [
-                "<li>Protein name.</li>",
-                "</ol>",
-                "</p>",
-            ]
-        )
+        proteinFieldsDescription.extend([
+            '<li>Protein name.</li>',
+            '</ol>',
+            '</p>',
+        ])
 
         append = result.append
 
-        append("<h1>%s</h1>" % title)
+        append('<h1>%s</h1>' % title)
         if preamble:
-            append("<p>%s</p>" % preamble)
-        append("<p>")
+            append('<p>%s</p>' % preamble)
+        append('<p>')
         append(self._title())
 
         if self._pathogenProteinCount and minProteinFraction:
             percent = minProteinFraction * 100.0
             if nPathogenNames < len(self.pathogenNames):
                 if nPathogenNames == 1:
-                    append(
-                        "Pathogen protein fraction filtering has been "
-                        "applied, so information on only 1 pathogen is "
-                        "displayed. This is the only pathogen for which at "
-                        "least one sample matches at least %.2f%% of the "
-                        "pathogen proteins." % percent
-                    )
+                    append('Pathogen protein fraction filtering has been '
+                           'applied, so information on only 1 pathogen is '
+                           'displayed. This is the only pathogen for which at '
+                           'least one sample matches at least %.2f%% of the '
+                           'pathogen proteins.' % percent)
                 else:
-                    append(
-                        "Pathogen protein fraction filtering has been "
-                        "applied, so information on only %d pathogens is "
-                        "displayed. These are the only pathogens for which "
-                        "at least one sample matches at least %.2f%% of "
-                        "the pathogen proteins." % (nPathogenNames, percent)
-                    )
+                    append('Pathogen protein fraction filtering has been '
+                           'applied, so information on only %d pathogens is '
+                           'displayed. These are the only pathogens for which '
+                           'at least one sample matches at least %.2f%% of '
+                           'the pathogen proteins.' % (nPathogenNames,
+                                                       percent))
             else:
-                append(
-                    "Pathogen protein fraction filtering was applied, "
-                    "but all pathogens have at least %.2f%% of their "
-                    "proteins matched by at least one sample." % percent
-                )
+                append('Pathogen protein fraction filtering was applied, '
+                       'but all pathogens have at least %.2f%% of their '
+                       'proteins matched by at least one sample.' % percent)
 
-        append("</p>")
+        append('</p>')
 
         if pathogenPanelFilename:
-            append("<p>")
-            append(
-                '<a href="%s">Panel showing read count per pathogen, per '
-                "sample.</a>" % pathogenPanelFilename
-            )
-            append(
-                "Red vertical bars indicate samples with an unusually high "
-                "read count."
-            )
-            append("</p>")
+            append('<p>')
+            append('<a href="%s">Panel showing read count per pathogen, per '
+                   'sample.</a>' % pathogenPanelFilename)
+            append('Red vertical bars indicate samples with an unusually high '
+                   'read count.')
+            append('</p>')
 
         result.extend(proteinFieldsDescription)
 
         # Write a linked table of contents by pathogen.
         append('<p><span class="index-name">Pathogen index:</span>')
         append('<span class="index">')
         for pathogenName in pathogenNames:
-            append('<a href="#pathogen-%s">%s</a>' % (pathogenName, pathogenName))
-            append("&middot;")
+            append('<a href="#pathogen-%s">%s</a>' % (pathogenName,
+                                                      pathogenName))
+            append('&middot;')
         # Get rid of final middle dot and add a period.
         result.pop()
-        result[-1] += "."
-        append("</span></p>")
+        result[-1] += '.'
+        append('</span></p>')
 
         # Write a linked table of contents by sample.
         append('<p><span class="index-name">Sample index:</span>')
         append('<span class="index">')
         for sampleName in sampleNames:
             append('<a href="#sample-%s">%s</a>' % (sampleName, sampleName))
-            append("&middot;")
+            append('&middot;')
         # Get rid of final middle dot and add a period.
         result.pop()
-        result[-1] += "."
-        append("</span></p>")
+        result[-1] += '.'
+        append('</span></p>')
 
         # Write all pathogens (with samples (with proteins)).
-        append("<hr>")
-        append("<h1>Pathogens by sample</h1>")
+        append('<hr>')
+        append('<h1>Pathogens by sample</h1>')
 
         for pathogenName in pathogenNames:
             samples = self.pathogenNames[pathogenName]
             sampleCount = len(samples)
             pathogenProteinCount = self._pathogenProteinCount[pathogenName]
-            if pathogenType == "viral" and not omitVirusLinks:
+            if pathogenType == 'viral' and not omitVirusLinks:
                 quoted = quote(pathogenName)
                 pathogenLinksHTML = (
                     ' (<a href="%s%s">ICTV</a>, <a href="%s%s">ViralZone</a>)'
                 ) % (self.ICTV, quoted, self.VIRALZONE, quoted)
             else:
-                pathogenLinksHTML = ""
+                pathogenLinksHTML = ''
 
             if pathogenProteinCount:
-                withStr = " with %d protein%s" % (
-                    pathogenProteinCount,
-                    "" if pathogenProteinCount == 1 else "s",
-                )
+                withStr = (' with %d protein%s' %
+                           (pathogenProteinCount,
+                            '' if pathogenProteinCount == 1 else 's'))
             else:
-                withStr = ""
+                withStr = ''
 
-            pathogenIndex = self.pathogenSampleFiles.pathogenIndex(pathogenName)
+            pathogenIndex = self.pathogenSampleFiles.pathogenIndex(
+                pathogenName)
 
             pathogenReadsFilename = join(
-                self._pathogenDataDir, "pathogen-%d.%s" % (pathogenIndex, self._format)
-            )
+                self._pathogenDataDir,
+                'pathogen-%d.%s' % (pathogenIndex, self._format))
 
-            pathogenReadsFp = open(pathogenReadsFilename, "w")
+            pathogenReadsFp = open(pathogenReadsFilename, 'w')
             pathogenReadCount = 0
 
             append(
                 '<a id="pathogen-%s"></a>'
                 '<p class="pathogen">'
                 '<span class="pathogen-name">%s</span>'
-                "%s %s, "
-                "was matched by %d sample%s "
+                '%s %s, '
+                'was matched by %d sample%s '
                 '(<a href="%s">%s</a> in total):'
-                "</p>"
-                % (
-                    pathogenName,
-                    pathogenName,
-                    pathogenLinksHTML,
-                    withStr,
-                    sampleCount,
-                    "" if sampleCount == 1 else "s",
-                    pathogenReadsFilename,
-                    self.READCOUNT_MARKER,
-                )
-            )
+                '</p>' %
+                (pathogenName,
+                 pathogenName,
+                 pathogenLinksHTML, withStr,
+                 sampleCount, '' if sampleCount == 1 else 's',
+                 pathogenReadsFilename, self.READCOUNT_MARKER))
 
             # Remember where we are in the output result so we can fill in
             # the total read count once we have processed all samples for
             # this pathogen. Not nice, I know.
             pathogenReadCountLineIndex = len(result) - 1
 
             for sampleName in sorted(samples):
                 readsFileName = self.pathogenSampleFiles.lookup(
-                    pathogenName, sampleName
-                )
+                    pathogenName, sampleName)
 
                 # Copy the read data from the per-sample reads for this
                 # pathogen into the per-pathogen file of reads.
                 with open(readsFileName) as readsFp:
                     while True:
                         data = readsFp.read(4096)
                         if data:
                             pathogenReadsFp.write(data)
                         else:
                             break
 
-                proteins = samples[sampleName]["proteins"]
+                proteins = samples[sampleName]['proteins']
                 proteinCount = len(proteins)
-                uniqueReadCount = samples[sampleName]["uniqueReadCount"]
+                uniqueReadCount = samples[sampleName]['uniqueReadCount']
                 pathogenReadCount += uniqueReadCount
 
                 if omitSampleProteinCount:
-                    proteinCountHTML = ""
+                    proteinCountHTML = ''
                 else:
-                    proteinCountHTML = "%d protein%s, " % (
-                        proteinCount,
-                        "" if proteinCount == 1 else "s",
-                    )
+                    proteinCountHTML = '%d protein%s, ' % (
+                        proteinCount, '' if proteinCount == 1 else 's')
 
                 append(
                     '<p class="sample indented">'
                     'Sample <a href="#sample-%s">%s</a> '
                     '(%s<a href="%s">%d de-duplicated (by id) '
-                    'read%s</a>, <a href="%s">panel</a>):</p>'
-                    % (
-                        sampleName,
-                        sampleName,
-                        proteinCountHTML,
-                        readsFileName,
-                        uniqueReadCount,
-                        "" if uniqueReadCount == 1 else "s",
-                        self.sampleNames[sampleName],
-                    )
-                )
+                    'read%s</a>, <a href="%s">panel</a>):</p>' %
+                    (sampleName, sampleName,
+                     proteinCountHTML,
+                     readsFileName,
+                     uniqueReadCount, '' if uniqueReadCount == 1 else 's',
+                     self.sampleNames[sampleName]))
                 append('<ul class="protein-list indented">')
                 for proteinName in sorted(proteins):
                     proteinMatch = proteins[proteinName]
                     append(
-                        "<li>"
+                        '<li>'
                         '<span class="stats">'
-                        "%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f "
-                        "%(readAndHspCountStr)11s %(proteinLength)4d " % proteinMatch
+                        '%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f '
+                        '%(readAndHspCountStr)11s %(proteinLength)4d '
+                        % proteinMatch
                     )
 
                     if self._saveReadLengths:
-                        append(
-                            "(%s) "
-                            % ", ".join(map(str, sorted(proteinMatch["readLengths"])))
-                        )
+                        append('(%s) ' % ', '.join(
+                            map(str, sorted(proteinMatch['readLengths']))))
 
                     append(
-                        "</span> "
+                        '</span> '
                         '<span class="protein-name">'
-                        "%(proteinName)s"
-                        "</span> "
+                        '%(proteinName)s'
+                        '</span> '
                         '(<a href="%(bluePlotFilename)s">blue plot</a>, '
-                        '<a href="%(readsFilename)s">reads</a>' % proteinMatch
-                    )
+                        '<a href="%(readsFilename)s">reads</a>'
+                        % proteinMatch)
 
-                    if proteinMatch["proteinURL"]:
+                    if proteinMatch['proteinURL']:
                         # Append this directly to the last string in result, to
                         # avoid introducing whitespace when we join result
                         # using '\n'.
-                        result[-1] += (
-                            ', <a href="%s">NCBI protein</a>'
-                            % proteinMatch["proteinURL"]
-                        )
+                        result[-1] += (', <a href="%s">NCBI protein</a>' %
+                                       proteinMatch['proteinURL'])
 
-                    if proteinMatch["genomeURL"]:
+                    if proteinMatch['genomeURL']:
                         # Append this directly to the last string in result, to
                         # avoid introducing whitespace when we join result
                         # using '\n'.
-                        result[-1] += (
-                            ', <a href="%s">NCBI genome</a>' % proteinMatch["genomeURL"]
-                        )
-                    result[-1] += ")"
+                        result[-1] += (', <a href="%s">NCBI genome</a>' %
+                                       proteinMatch['genomeURL'])
+                    result[-1] += ')'
 
-                    append("</li>")
+                    append('</li>')
 
-                append("</ul>")
+                append('</ul>')
 
             pathogenReadsFp.close()
 
             # Sanity check there's a read count marker text in our output
             # where we expect it.
             readCountLine = result[pathogenReadCountLineIndex]
             if readCountLine.find(self.READCOUNT_MARKER) == -1:
                 raise ValueError(
-                    "Could not find pathogen read count marker (%s) in result "
-                    "index %d text (%s)."
-                    % (self.READCOUNT_MARKER, pathogenReadCountLineIndex, readCountLine)
-                )
+                    'Could not find pathogen read count marker (%s) in result '
+                    'index %d text (%s).' %
+                    (self.READCOUNT_MARKER, pathogenReadCountLineIndex,
+                     readCountLine))
 
             # Put the read count into the pathogen summary line we wrote
             # earlier, replacing the read count marker with the correct
             # text.
             result[pathogenReadCountLineIndex] = readCountLine.replace(
                 self.READCOUNT_MARKER,
-                "%d read%s"
-                % (pathogenReadCount, "" if pathogenReadCount == 1 else "s"),
-            )
+                '%d read%s' % (pathogenReadCount,
+                               '' if pathogenReadCount == 1 else 's'))
 
         # Write all samples (with pathogens (with proteins)).
-        append("<hr>")
-        append("<h1>Samples by pathogen</h1>")
+        append('<hr>')
+        append('<h1>Samples by pathogen</h1>')
 
         for sampleName in sampleNames:
             samplePathogenNames = [
-                pathName
-                for pathName in self.pathogenNames
-                if sampleName in self.pathogenNames[pathName]
-            ]
+                pathName for pathName in self.pathogenNames
+                if sampleName in self.pathogenNames[pathName]]
 
             if len(samplePathogenNames):
                 append(
                     '<a id="sample-%s"></a>'
                     '<p class="sample">Sample '
                     '<span class="sample-name">%s</span> '
-                    "matched proteins from %d pathogen%s, "
-                    '<a href="%s">panel</a>:</p>'
-                    % (
-                        sampleName,
-                        sampleName,
-                        len(samplePathogenNames),
-                        "" if len(samplePathogenNames) == 1 else "s",
-                        self.sampleNames[sampleName],
-                    )
-                )
+                    'matched proteins from %d pathogen%s, '
+                    '<a href="%s">panel</a>:</p>' %
+                    (sampleName, sampleName, len(samplePathogenNames),
+                     '' if len(samplePathogenNames) == 1 else 's',
+                     self.sampleNames[sampleName]))
             else:
                 append(
                     '<a id="sample-%s"></a>'
                     '<p class="sample">Sample '
                     '<span class="sample-name">%s</span> '
-                    "did not match anything.</p>" % (sampleName, sampleName)
-                )
+                    'did not match anything.</p>' %
+                    (sampleName, sampleName))
                 continue
 
             for pathogenName in sorted(samplePathogenNames):
-                readsFileName = self.pathogenSampleFiles.lookup(
-                    pathogenName, sampleName
-                )
-                proteins = self.pathogenNames[pathogenName][sampleName]["proteins"]
-                uniqueReadCount = self.pathogenNames[pathogenName][sampleName][
-                    "uniqueReadCount"
-                ]
+                readsFileName = self.pathogenSampleFiles.lookup(pathogenName,
+                                                                sampleName)
+                proteins = self.pathogenNames[pathogenName][sampleName][
+                    'proteins']
+                uniqueReadCount = self.pathogenNames[
+                    pathogenName][sampleName]['uniqueReadCount']
                 proteinCount = len(proteins)
                 pathogenProteinCount = self._pathogenProteinCount[pathogenName]
 
                 if pathogenProteinCount:
-                    proteinCountStr = "%d/%d protein%s" % (
-                        proteinCount,
-                        pathogenProteinCount,
-                        "" if pathogenProteinCount == 1 else "s",
-                    )
+                    proteinCountStr = '%d/%d protein%s' % (
+                        proteinCount, pathogenProteinCount,
+                        '' if pathogenProteinCount == 1 else 's')
                 else:
-                    proteinCountStr = "%d protein%s" % (
-                        proteinCount,
-                        "" if proteinCount == 1 else "s",
-                    )
+                    proteinCountStr = '%d protein%s' % (
+                        proteinCount, '' if proteinCount == 1 else 's')
 
                 append(
                     '<p class="sample indented">'
                     '<a href="#pathogen-%s">%s</a> %s, '
-                    '<a href="%s">%d de-duplicated (by id) read%s</a>:</p>'
-                    % (
-                        pathogenName,
-                        pathogenName,
-                        proteinCountStr,
-                        readsFileName,
-                        uniqueReadCount,
-                        "" if uniqueReadCount == 1 else "s",
-                    )
-                )
+                    '<a href="%s">%d de-duplicated (by id) read%s</a>:</p>' %
+                    (pathogenName, pathogenName,
+                     proteinCountStr, readsFileName,
+                     uniqueReadCount, '' if uniqueReadCount == 1 else 's'))
                 append('<ul class="protein-list indented">')
                 for proteinName in sorted(proteins):
                     proteinMatch = proteins[proteinName]
                     append(
-                        "<li>"
+                        '<li>'
                         '<span class="stats">'
-                        "%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f "
-                        "%(readAndHspCountStr)11s %(proteinLength)4d "
-                        "</span> "
+                        '%(coverage).2f %(medianScore)6.2f %(bestScore)6.2f '
+                        '%(readAndHspCountStr)11s %(proteinLength)4d '
+                        '</span> '
                         '<span class="protein-name">'
-                        "%(proteinName)s"
-                        "</span> "
+                        '%(proteinName)s'
+                        '</span> '
                         '(<a href="%(bluePlotFilename)s">blue plot</a>, '
-                        '<a href="%(readsFilename)s">reads</a>' % proteinMatch
-                    )
+                        '<a href="%(readsFilename)s">reads</a>'
+                        % proteinMatch)
 
-                    if proteinMatch["proteinURL"]:
+                    if proteinMatch['proteinURL']:
                         # Append this directly to the last string in result, to
                         # avoid introducing whitespace when we join result
                         # using '\n'.
-                        result[-1] += (
-                            ', <a href="%s">NCBI protein</a>'
-                            % proteinMatch["proteinURL"]
-                        )
+                        result[-1] += (', <a href="%s">NCBI protein</a>' %
+                                       proteinMatch['proteinURL'])
 
-                    if proteinMatch["genomeURL"]:
+                    if proteinMatch['genomeURL']:
                         # Append this directly to the last string in result, to
                         # avoid introducing whitespace when we join result
                         # using '\n'.
-                        result[-1] += (
-                            ', <a href="%s">NCBI genome</a>' % proteinMatch["genomeURL"]
-                        )
+                        result[-1] += (', <a href="%s">NCBI genome</a>' %
+                                       proteinMatch['genomeURL'])
 
-                    result[-1] += ")"
+                    result[-1] += ')'
 
-                    append("</li>")
+                    append('</li>')
 
-                append("</ul>")
+                append('</ul>')
 
-        append("</body>")
-        append("</html>")
+        append('</body>')
+        append('</html>')
 
-        return "\n".join(result)
+        return '\n'.join(result)
 
     def _pathogenSamplePlot(self, pathogenName, sampleNames, ax):
         """
         Make an image of a graph giving pathogen read count (Y axis) versus
         sample id (X axis).
 
         @param pathogenName: A C{str} pathogen name.
         @param sampleNames: A sorted C{list} of sample names.
         @param ax: A matplotlib C{axes} instance.
         """
         readCounts = []
         for i, sampleName in enumerate(sampleNames):
             try:
                 readCount = self.pathogenNames[pathogenName][sampleName][
-                    "uniqueReadCount"
-                ]
+                    'uniqueReadCount']
             except KeyError:
                 readCount = 0
             readCounts.append(readCount)
 
-        highlight = "r"
-        normal = "gray"
+        highlight = 'r'
+        normal = 'gray'
         sdMultiple = 2.5
         minReadsForHighlighting = 10
         highlighted = []
 
         if len(readCounts) == 1:
             if readCounts[0] > minReadsForHighlighting:
                 color = [highlight]
@@ -1072,87 +969,79 @@
             else:
                 color = [normal]
         else:
             mean = np.mean(readCounts)
             sd = np.std(readCounts)
             color = []
             for readCount, sampleName in zip(readCounts, sampleNames):
-                if (
-                    readCount > (sdMultiple * sd) + mean
-                    and readCount >= minReadsForHighlighting
-                ):
+                if (readCount > (sdMultiple * sd) + mean and
+                        readCount >= minReadsForHighlighting):
                     color.append(highlight)
                     highlighted.append(sampleName)
                 else:
                     color.append(normal)
 
         nSamples = len(sampleNames)
         x = np.arange(nSamples)
         yMin = np.zeros(nSamples)
         ax.set_xticks([])
         ax.set_xlim((-0.5, nSamples - 0.5))
         ax.vlines(x, yMin, readCounts, color=color)
         if highlighted:
-            title = "%s\nIn red: %s" % (pathogenName, fill(", ".join(highlighted), 50))
+            title = '%s\nIn red: %s' % (
+                pathogenName, fill(', '.join(highlighted), 50))
         else:
             # Add a newline to keep the first line of each title at the
             # same place as those titles that have an "In red:" second
             # line.
-            title = pathogenName + "\n"
+            title = pathogenName + '\n'
 
         ax.set_title(title, fontsize=10)
-        ax.tick_params(axis="both", which="major", labelsize=8)
-        ax.tick_params(axis="both", which="minor", labelsize=6)
+        ax.tick_params(axis='both', which='major', labelsize=8)
+        ax.tick_params(axis='both', which='minor', labelsize=6)
 
     def pathogenPanel(self, filename):
         """
         Make a panel of images, with each image being a graph giving pathogen
         de-duplicated (by id) read count (Y axis) versus sample id (X axis).
 
         @param filename: A C{str} file name to write the image to.
         """
         import matplotlib
-
-        matplotlib.use("PDF")
+        matplotlib.use('PDF')
         import matplotlib.pyplot as plt
 
         self._computeUniqueReadCounts()
         pathogenNames = sorted(self.pathogenNames)
         sampleNames = sorted(self.sampleNames)
 
         cols = 5
         rows = int(len(pathogenNames) / cols) + (
-            0 if len(pathogenNames) % cols == 0 else 1
-        )
+            0 if len(pathogenNames) % cols == 0 else 1)
         figure, ax = plt.subplots(rows, cols, squeeze=False)
 
         coords = dimensionalIterator((rows, cols))
 
         for i, pathogenName in enumerate(pathogenNames):
             row, col = next(coords)
             self._pathogenSamplePlot(pathogenName, sampleNames, ax[row][col])
 
         # Hide the final panel graphs (if any) that have no content. We do
         # this because the panel is a rectangular grid and some of the
         # plots at the end of the last row may be unused.
         for row, col in coords:
-            ax[row][col].axis("off")
+            ax[row][col].axis('off')
 
         figure.suptitle(
-            (
-                "Per-sample read count for %d pathogen%s and %d sample%s.\n\n"
-                "Sample name%s: %s"
-            )
-            % (
-                len(pathogenNames),
-                "" if len(pathogenNames) == 1 else "s",
-                len(sampleNames),
-                "" if len(sampleNames) == 1 else "s",
-                "" if len(sampleNames) == 1 else "s",
-                fill(", ".join(sampleNames), 50),
-            ),
-            fontsize=20,
-        )
+            ('Per-sample read count for %d pathogen%s and %d sample%s.\n\n'
+             'Sample name%s: %s') % (
+                 len(pathogenNames),
+                 '' if len(pathogenNames) == 1 else 's',
+                 len(sampleNames),
+                 '' if len(sampleNames) == 1 else 's',
+                 '' if len(sampleNames) == 1 else 's',
+                 fill(', '.join(sampleNames), 50)),
+            fontsize=20)
         figure.set_size_inches(5.0 * cols, 2.0 * rows, forward=True)
         plt.subplots_adjust(hspace=0.4)
 
         figure.savefig(filename)
```

### Comparing `dark-matter-4.0.84/dark/reads.py` & `dark-matter-4.0.9/dark/reads.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,216 +1,185 @@
-from __future__ import annotations
-
 import sys
+import six
 import os
 from functools import total_ordering
 from collections import Counter
 from hashlib import md5
 from random import uniform
-from pathlib import Path
-import itertools
-import argparse
-from collections import defaultdict
-from typing import (
-    Callable,
-    Generator,
-    Iterable,
-    List,
-    Literal,
-    Optional,
-    Set,
-    TextIO,
-    Tuple,
-    Union,
-    Dict,
-    Sequence,
-    SupportsIndex,
-)
-
-from Bio.Seq import translate  # type: ignore
-from Bio.Data.IUPACData import ambiguous_dna_complement  # type: ignore
-from Bio.Data.IUPACData import ambiguous_rna_complement  # type: ignore
-
-from dark.aaVars import (
-    START_CODON,
-    STOP_CODONS,
-    AA_LETTERS,
-    PROPERTIES,
-    PROPERTY_DETAILS,
-    NONE,
-)
-from dark.filter import SequenceFilter, TitleFilter
-from dark.hsp import HSP
+
+from Bio.Seq import translate
+from Bio.Data.IUPACData import (
+    ambiguous_dna_complement, ambiguous_rna_complement)
+
+from dark.aa import (
+    AA_LETTERS, NAMES as AA_NAMES, PROPERTIES, PROPERTY_DETAILS, NONE)
+from dark.filter import TitleFilter
 from dark.dna import FloatBaseCounts, AMBIGUOUS, BASES_TO_AMBIGUOUS
 from dark.errors import ReadLengthsNotIdenticalError
 
 
-def _makeComplementTable(complementData: dict) -> Sequence[str]:
-    """
-    Make a sequence complement table.
+if six.PY3:
+    def _makeComplementTable(complementData):
+        """
+        Make a sequence complement table.
+
+        @param complementData: A C{dict} whose keys and values are strings of
+            length one. A key, value pair indicates a substitution that should
+            be performed during complementation.
+        @return: A 256 character string that can be used as a translation table
+            by the C{translate} method of a Python string.
+        """
+        table = list(range(256))
+        for _from, to in complementData.items():
+            table[ord(_from[0].lower())] = ord(to[0].lower())
+            table[ord(_from[0].upper())] = ord(to[0].upper())
+        return ''.join(map(chr, table))
+else:
+    def _makeComplementTable(complementData):
+        """
+        Make a sequence complement table.
+
+        @param complementData: A C{dict} whose keys and values are strings of
+            length one. A key, value pair indicates a substitution that should
+            be performed during complementation.
+        @return: A translation table that can be used by the C{translate}
+            method of a Python2 string.
+        """
+        import string
+
+        fromList = []
+        toList = []
+
+        for _from, to in complementData.items():
+            fromList.append(_from[0].lower())
+            fromList.append(_from[0].upper())
+            toList.append(to[0].lower())
+            toList.append(to[0].upper())
 
-    @param complementData: A C{dict} whose keys and values are strings of
-        length one. A key, value pair indicates a substitution that should
-        be performed during complementation.
-    @return: A 256 character string that can be used as a translation table
-        by the C{translate} method of a Python string.
-    """
-    table = list(range(256))
-    for _from, to in complementData.items():
-        table[ord(_from[0].lower())] = ord(to[0].lower())
-        table[ord(_from[0].upper())] = ord(to[0].upper())
-    return tuple(map(chr, table))
+        return string.maketrans(''.join(fromList), ''.join(toList))
 
 
 @total_ordering
-class Read:
+class Read(object):
     """
     Hold information about a single read.
 
     @param id: A C{str} describing the read.
     @param sequence: A C{str} of sequence information (might be
         nucleotides or proteins).
     @param quality: An optional C{str} of phred quality scores. If not C{None},
         it must be the same length as C{sequence}.
     @raise ValueError: if the length of the quality string (if any) does not
         match the length of the sequence.
     """
+    ALPHABET = None
 
-    ALPHABET: Optional[set] = None
-
-    def __init__(self, id: str, sequence: str, quality: Optional[str] = None):
+    def __init__(self, id, sequence, quality=None):
         if quality is not None and len(quality) != len(sequence):
             raise ValueError(
-                "Invalid read: sequence length (%d) != quality length (%d)"
-                % (len(sequence), len(quality))
-            )
+                'Invalid read: sequence length (%d) != quality length (%d)' %
+                (len(sequence), len(quality)))
 
         self.id = id
         self.sequence = sequence
         self.quality = quality
 
-    def __eq__(self, other: object) -> bool:
-        if isinstance(other, Read):
-            return (
-                self.id == other.id
-                and self.sequence == other.sequence
-                and self.quality == other.quality
-            )
-        else:
-            return NotImplemented
+    def __eq__(self, other):
+        return (self.id == other.id and
+                self.sequence == other.sequence and
+                self.quality == other.quality)
 
-    def __ne__(self, other: object) -> bool:
-        if isinstance(other, Read):
-            return not self == other
-        else:
-            return NotImplemented
+    def __ne__(self, other):
+        return not self == other
 
-    def __lt__(self, other: object) -> bool:
-        if isinstance(other, Read):
-            return (self.id, self.sequence, self.quality) < (
-                other.id,
-                other.sequence,
-                other.quality,
-            )
-        else:
-            return NotImplemented
+    def __lt__(self, other):
+        return ((self.id, self.sequence, self.quality) <
+                (other.id, other.sequence, other.quality))
 
-    def __len__(self) -> int:
+    def __len__(self):
         return len(self.sequence)
 
-    def __hash__(self) -> int:
+    def __hash__(self):
         """
         Calculate a hash key for a read.
 
         @return: The C{int} hash key for the read.
         """
         if self.quality is None:
-            return hash(
-                md5(
-                    self.id.encode("UTF-8") + b"\0" + self.sequence.encode("UTF-8")
-                ).digest()
-            )
+            return hash(md5(self.id.encode('UTF-8') + b'\0' +
+                            self.sequence.encode('UTF-8')).digest())
         else:
-            return hash(
-                md5(
-                    self.id.encode("UTF-8")
-                    + b"\0"
-                    + self.sequence.encode("UTF-8")
-                    + b"\0"
-                    + self.quality.encode("UTF-8")
-                ).digest()
-            )
+            return hash(md5(self.id.encode('UTF-8') + b'\0' +
+                            self.sequence.encode('UTF-8') + b'\0' +
+                            self.quality.encode('UTF-8')).digest())
 
-    def __getitem__(self, item: Union[int, slice]) -> Read:
+    def __getitem__(self, item):
         sequence = self.sequence[item]
         quality = None if self.quality is None else self.quality[item]
         return self.__class__(self.id, sequence, quality)
 
-    def toString(self, format_: str = "fasta") -> str:
+    def toString(self, format_):
         """
         Convert the read to a string format.
 
         @param format_: Either 'fasta', 'fastq' or 'fasta-ss'.
         @raise ValueError: if C{format_} is 'fastq' and the read has no quality
             information, if C{format_} is 'fasta-ss' and the read has no
             structure information, or if an unknown format is requested.
         @return: A C{str} representing the read in the requested format.
         """
-        if format_ == "fasta":
-            return ">%s\n%s\n" % (self.id, self.sequence)
-        elif format_ == "fastq":
+        if format_ == 'fasta':
+            return '>%s\n%s\n' % (self.id, self.sequence)
+        elif format_ == 'fastq':
             if self.quality is None:
-                raise ValueError("Read %r has no quality information" % self.id)
+                raise ValueError('Read %r has no quality information' %
+                                 self.id)
             else:
-                return "@%s\n%s\n+%s\n%s\n" % (
-                    self.id,
-                    self.sequence,
-                    self.id,
-                    self.quality,
-                )
+                return '@%s\n%s\n+%s\n%s\n' % (
+                    self.id, self.sequence, self.id, self.quality)
         else:
-            raise ValueError("Format must be either 'fasta', 'fastq' or 'fasta-ss'.")
+            raise ValueError("Format must be either 'fasta', 'fastq' or "
+                             "'fasta-ss'.")
 
-    def toDict(self) -> dict:
+    def toDict(self):
         """
         Get information about this read in a dictionary.
 
         @return: A C{dict} with keys/values for the attributes of self.
         """
         return {
-            "id": self.id,
-            "sequence": self.sequence,
-            "quality": self.quality,
+            'id': self.id,
+            'sequence': self.sequence,
+            'quality': self.quality,
         }
 
-    def reverse(self) -> Read:
+    def reverse(self):
         """
         Reverse a read (note that this is NOT a reverse complement).
 
         @return: The reversed sequence as an instance of the current class.
         """
         return self.__class__(
             self.id,
             self.sequence[::-1],
-            None if self.quality is None else self.quality[::-1],
-        )
+            None if self.quality is None else self.quality[::-1])
 
     @classmethod
-    def fromDict(cls, d: dict) -> Read:
+    def fromDict(cls, d):
         """
         Create a new instance from attribute values provided in a dictionary.
 
         @param d: A C{dict} with keys/values for the attributes of a new
             instance of this class. Keys 'id' and 'sequence' with C{str} values
             must be provided. A 'quality' C{str} key is optional.
         @return: A new instance of this class, with values taken from C{d}.
         """
-        return cls(d["id"], d["sequence"], d.get("quality"))
+        return cls(d['id'], d['sequence'], d.get('quality'))
 
-    def lowComplexityFraction(self) -> float:
+    def lowComplexityFraction(self):
         """
         What fraction of a read's bases are in low-complexity regions?
         By convention, a region of low complexity is indicated by lowercase
         base letters.
 
         @return: The C{float} representing the fraction of bases in the
             read that are in regions of low complexity.
@@ -218,22 +187,19 @@
         length = len(self)
         if length:
             lowerCount = len(list(filter(str.islower, self.sequence)))
             return float(lowerCount) / length
         else:
             return 0.0
 
-    def walkHSP(
-        self, hsp: HSP, includeWhiskers: bool = True
-    ) -> Generator[Tuple[int, str, bool], None, None]:
+    def walkHSP(self, hsp, includeWhiskers=True):
         """
         Provide information about exactly how a read matches a subject, as
         specified by C{hsp}.
 
-        @param hsp: An C{HSP} instance.
         @param includeWhiskers: If C{True} yield information from the
             (possibly empty) non-matching ends of the read.
         @return: A generator that yields (offset, residue, inMatch) tuples.
             The offset is the offset into the matched subject. The residue is
             the base in the read (which might be '-' to indicate a gap in the
             read was aligned with the subject at this offset). inMatch will be
             C{True} for residues that are part of the HSP match, and C{False}
@@ -251,104 +217,92 @@
             subjectOffset = hsp.readStartInSubject
             while subjectOffset < hsp.subjectStart:
                 yield (subjectOffset, self.sequence[readOffset], False)
                 readOffset += 1
                 subjectOffset += 1
 
         # Match.
-        for subjectOffset, residue in enumerate(
-            hsp.readMatchedSequence, start=hsp.subjectStart
-        ):
+        for subjectOffset, residue in enumerate(hsp.readMatchedSequence,
+                                                start=hsp.subjectStart):
             yield (subjectOffset, residue, True)
 
         # Right whisker.
         if includeWhiskers:
             readOffset = hsp.readEnd
             subjectOffset = hsp.subjectEnd
             while subjectOffset < hsp.readEndInSubject:
                 yield (subjectOffset, self.sequence[readOffset], False)
                 readOffset += 1
                 subjectOffset += 1
 
-    def checkAlphabet(self, count: int = 10) -> set:
+    def checkAlphabet(self, count=10):
         """
         A function which checks whether the sequence in a L{dark.Read} object
         corresponds to its readClass. For AA reads, more testing is done in
         dark.Read.AARead.checkAlphabet.
 
         @param count: An C{int}, indicating how many bases or amino acids at
             the start of the sequence should be considered. If C{None}, all
             bases are checked.
-        @return: A C{set} of the read characters in the first C{count}
-            positions of sequence if these are a subset of the allowed alphabet for this
+        @return: C{True} if the alphabet characters in the first C{count}
+            positions of sequence is a subset of the allowed alphabet for this
             read class, or if the read class has a C{None} alphabet.
         @raise ValueError: If the sequence alphabet is not a subset of the read
             class alphabet.
         """
         if count is None:
             readLetters = set(self.sequence.upper())
         else:
             readLetters = set(self.sequence.upper()[:count])
         # Check if readLetters is a subset of self.ALPHABET.
         if self.ALPHABET is None or readLetters.issubset(self.ALPHABET):
             return readLetters
-        raise ValueError(
-            "Read alphabet (%r) is not a subset of expected "
-            "alphabet (%r) for read class %s."
-            % (
-                "".join(sorted(readLetters)),
-                "".join(sorted(self.ALPHABET)),
-                str(self.__class__.__name__),
-            )
-        )
+        raise ValueError("Read alphabet (%r) is not a subset of expected "
+                         "alphabet (%r) for read class %s." % (
+                             ''.join(sorted(readLetters)),
+                             ''.join(sorted(self.ALPHABET)),
+                             str(self.__class__.__name__)))
 
-    def newFromSites(self, sites: Set[int], exclude: bool = False) -> Read:
+    def newFromSites(self, sites, exclude=False):
         """
         Create a new read from self, with only certain sites.
 
         @param sites: A set of C{int} 0-based sites (i.e., indices) in
             sequences that should be kept. If C{None} (the default), all sites
             are kept.
         @param exclude: If C{True} the C{sites} will be excluded, not
             included.
-        @return: A new C{Read} instance.
         """
-        if sites is None:
-            sites = set(range(len(self)))
-
         if exclude:
             sites = set(range(len(self))) - sites
 
         newSequence = []
         if self.quality:
             newQuality = []
-            for index, (base, quality) in enumerate(zip(self.sequence, self.quality)):
+            for index, (base, quality) in enumerate(zip(self.sequence,
+                                                        self.quality)):
                 if index in sites:
                     newSequence.append(base)
                     newQuality.append(quality)
-            read = self.__class__(self.id, "".join(newSequence), "".join(newQuality))
+            read = self.__class__(self.id, ''.join(newSequence),
+                                  ''.join(newQuality))
         else:
             for index, base in enumerate(self.sequence):
                 if index in sites:
                     newSequence.append(base)
-            read = self.__class__(self.id, "".join(newSequence))
+            read = self.__class__(self.id, ''.join(newSequence))
 
         return read
 
 
 class _NucleotideRead(Read):
     """
     Holds methods to work with nucleotide (DNA and RNA) sequences.
     """
-
-    COMPLEMENT_TABLE: Sequence[Union[str, None]] = [None]
-
-    def translations(
-        self: Union[_NucleotideRead, DNARead, RNARead]
-    ) -> Generator[TranslatedRead, None, None]:
+    def translations(self):
         """
         Yield all six translations of a nucleotide sequence.
 
         @return: A generator that produces six L{TranslatedRead} instances.
         """
         rc = self.reverseComplement().sequence
         for reverseComplemented in False, True:
@@ -358,20 +312,19 @@
                 # skip 0, 1, or 2 initial bases, depending on the frame.
                 # Note that this makes a copy of the sequence, which we can
                 # then safely append 'N' bases to to adjust its length to
                 # be zero mod 3.
                 suffix = seq[frame:]
                 lengthMod3 = len(suffix) % 3
                 if lengthMod3:
-                    suffix += "NN" if lengthMod3 == 1 else "N"
-                yield TranslatedRead(
-                    self, translate(suffix), frame, reverseComplemented
-                )
+                    suffix += ('NN' if lengthMod3 == 1 else 'N')
+                yield TranslatedRead(self, translate(suffix), frame,
+                                     reverseComplemented)
 
-    def reverseComplement(self: Union[_NucleotideRead, DNARead, RNARead]) -> Read:
+    def reverseComplement(self):
         """
         Reverse complement a nucleotide sequence.
 
         @return: The reverse complemented sequence as an instance of the
             current class.
         """
         quality = None if self.quality is None else self.quality[::-1]
@@ -379,112 +332,24 @@
         return self.__class__(self.id, sequence, quality)
 
 
 class DNARead(_NucleotideRead):
     """
     Hold information and methods to work with DNA reads.
     """
-
-    ALPHABET: set = set("ATCG")
+    ALPHABET = set('ATCG')
 
     COMPLEMENT_TABLE = _makeComplementTable(ambiguous_dna_complement)
 
-    def findORF(
-        self,
-        offset: int,
-        forward: bool = True,
-        requireStartCodon: bool = True,
-        allowGaps: bool = True,
-        untranslatable: Optional[Dict[str, str]] = None,
-    ):
-        """
-        Find an ORF that supposedly starts at a specified offset in a read.
-
-        @param offset: The C{int} offset of the start codon.
-        @param forward: If not C{True}, the reverse complement of the sequence
-            should be examined.
-        @param requireStartCodon: If C{True}, the first codon must be a start
-            codon. If it is not, the search is abandoned immediately and the
-            returned dictionary will have zero and C{False} values.
-        @param allowGaps: If C{True}, gaps ('-') will be removed, else a
-            ValueError is raised if there are any gaps in the region of
-            C{self.sequence} that is to be translated.
-        @param untranslatable: A C{dict} with C{str} keys and values. If any of
-            the keys appears in a codon, the corresponding value is added to
-            the translation. This can be used e.g., to make occurrences of '?'
-            translate into '-' or 'X'.
-        @return: A C{dict} with C{str} keys:
-            length (int): the length of the ORF (in amino acids).
-            foundStartCodon (bool): if a start codon was found.
-            foundStopCodon (bool): if a stop codon was found.
-            sequence (str): the ORF nucelotide sequence.
-            translation (str): the amino acid sequence for the ORF.
-        """
-        sequence = self.sequence if forward else self.reverseComplement().sequence
-
-        gapCount = sequence[offset:].count("-")
-        if gapCount:
-            if allowGaps:
-                sequence = sequence[:offset] + sequence[offset:].replace("-", "")
-            else:
-                raise ValueError(
-                    f"At least one gap ('-') character found in read "
-                    f"{self.id!r} from offset {offset} or later."
-                )
-
-        first = True
-        length = 0
-        foundStartCodon = foundStopCodon = False
-        codons = []
-        translation = []
-
-        for index in itertools.count(offset, 3):
-            codon = sequence[index : index + 3]
-            if len(codon) != 3:
-                break
-
-            if first:
-                first = False
-                if codon == START_CODON:
-                    foundStartCodon = True
-                elif requireStartCodon:
-                    break
-
-            if untranslatable:
-                for char, replacement in untranslatable.items():
-                    if char in codon:
-                        translation.append(replacement)
-                        break
-                else:
-                    translation.append(translate(codon))
-            else:
-                translation.append(translate(codon))
-
-            length += 1
-            codons.append(codon)
-
-            if codon in STOP_CODONS:
-                foundStopCodon = True
-                break
-
-        return {
-            "length": length,
-            "foundStartCodon": foundStartCodon,
-            "foundStopCodon": foundStopCodon,
-            "sequence": "".join(codons),
-            "translation": "".join(translation),
-        }
-
 
 class RNARead(_NucleotideRead):
     """
     Hold information and methods to work with RNA reads.
     """
-
-    ALPHABET: set = set("ATCGU")
+    ALPHABET = set('ATCGU')
 
     COMPLEMENT_TABLE = _makeComplementTable(ambiguous_rna_complement)
 
 
 class DNAKozakRead(DNARead):
     """
     Hold information about a Kozak sequence.
@@ -495,114 +360,101 @@
     @param stop: The C{int} stop location of the Kozak sequence (this is a
         Python string index, so the final Kozak sequence character is the one
         before this offset in the sequence.
     @param kozakQuality: A C{float}, giving the percentage of the 5 variable
         locations in the Kozak sequence that match the most frequent Kozak
         nucleotides.
     """
-
-    def __init__(self, originalRead: Read, start: int, stop: int, kozakQuality: float):
+    def __init__(self, originalRead, start, stop, kozakQuality):
         if start < 0:
-            raise ValueError("start offset (%d) less than zero" % start)
+            raise ValueError('start offset (%d) less than zero' % start)
         if stop > len(originalRead):
-            raise ValueError(
-                "stop offset (%d) > original read length (%d)"
-                % (stop, len(originalRead))
-            )
+            raise ValueError('stop offset (%d) > original read length (%d)' %
+                             (stop, len(originalRead)))
         if start > stop:
-            raise ValueError(
-                "start offset (%d) greater than stop offset (%d)" % (start, stop)
-            )
+            raise ValueError('start offset (%d) greater than stop offset (%d)'
+                             % (start, stop))
 
-        newId = "%s-(%d:%d)" % (originalRead.id, start, stop)
+        newId = '%s-(%d:%d)' % (originalRead.id, start, stop)
 
         if originalRead.quality:
-            DNARead.__init__(
-                self,
-                newId,
-                originalRead.sequence[start:stop],
-                originalRead.quality[start:stop],
-            )
+            DNARead.__init__(self, newId, originalRead.sequence[start:stop],
+                             originalRead.quality[start:stop])
         else:
             DNARead.__init__(self, newId, originalRead.sequence[start:stop])
         self.originalRead = originalRead
         self.start = start
         self.stop = stop
         self.kozakQuality = kozakQuality
 
-    def __eq__(self, other: object):
-        if isinstance(other, DNAKozakRead):
-            return (
-                self.id == other.id
-                and self.sequence == other.sequence
-                and self.originalRead == other.originalRead
-                and self.quality == other.quality
-                and self.start == other.start
-                and self.stop == other.stop
-                and self.kozakQuality == other.kozakQuality
-            )
-        else:
-            return NotImplemented
+    def __eq__(self, other):
+        return (self.id == other.id and
+                self.sequence == other.sequence and
+                self.originalRead == other.originalRead and
+                self.quality == other.quality and
+                self.start == other.start and
+                self.stop == other.stop and
+                self.kozakQuality == other.kozakQuality)
 
 
 # Keep a single GOR4 instance that can be used by all AA reads. This saves us
 # from re-scanning the GOR IV secondary structure database every time we make
 # an AARead instance. This will be initialized when it's first needed.
 _GOR4 = None
 
 
 class AARead(Read):
     """
     Hold information and methods to work with AA reads.
     """
-
     ALPHABET = set(AA_LETTERS)
 
-    def checkAlphabet(self, count: int = 10) -> set:
+    def checkAlphabet(self, count=10):
         """
         A function which checks if an AA read really contains amino acids. This
         additional testing is needed, because the letters in the DNA alphabet
         are also in the AA alphabet.
 
         @param count: An C{int}, indicating how many bases or amino acids at
             the start of the sequence should be considered. If C{None}, all
             bases are checked.
-        @return: A C{set} of the alphabet characters in the first C{count}
+        @return: C{True} if the alphabet characters in the first C{count}
             positions of sequence is a subset of the allowed alphabet for this
             read class, or if the read class has a C{None} alphabet.
-        @raise ValueError: If the sequence of self is more than 10 charactere
-            and it looks like DNA has been passed to AARead().
+        @raise ValueError: If a DNA sequence has been passed to AARead().
         """
-        readLetters = super().checkAlphabet(count)
-        if len(self) > 10 and readLetters.issubset(set("ACGT")):
-            raise ValueError(
-                "It looks like a DNA sequence has been passed to AARead()."
-            )
+        if six.PY3:
+            readLetters = super().checkAlphabet(count)
+        else:
+            readLetters = Read.checkAlphabet(self, count)
+        if len(self) > 10 and readLetters.issubset(set('ACGT')):
+            raise ValueError('It looks like a DNA sequence has been passed to '
+                             'AARead().')
         return readLetters
 
-    def properties(self) -> Generator[int, None, None]:
+    def properties(self):
         """
         Translate an amino acid sequence to properties of the form:
         'F': HYDROPHOBIC | AROMATIC.
 
         @return: A generator yielding properties for the residues in the
             current sequence.
         """
         return (PROPERTIES.get(aa, NONE) for aa in self.sequence)
 
-    def propertyDetails(self) -> Generator[Union[dict, int], None, None]:
+    def propertyDetails(self):
         """
         Translate an amino acid sequence to properties. Each property of the
         amino acid gets a value scaled from -1 to 1.
 
-        @return: A generator yielding property dictionaries.
+        @return: A list of property dictionaries.
         """
         return (PROPERTY_DETAILS.get(aa, NONE) for aa in self.sequence)
 
-    def ORFs(self, openORFs: bool = False) -> Generator[AAReadORF, None, None]:
+    def ORFs(self, openORFs=False):
         """
         Find all ORFs in our sequence.
 
         @param openORFs: If C{True} allow ORFs that do not have a start codon
             and/or do not have a stop codon.
         @return: A generator that yields AAReadORF instances that correspond
             to the ORFs found in the AA sequence.
@@ -612,24 +464,25 @@
         # sequence.
         if openORFs:
             ORFStart = 0
             inOpenORF = True  # open on the left
             inORF = False
 
             for index, residue in enumerate(self.sequence):
-                if residue == "*":
+                if residue == '*':
                     if inOpenORF:
                         if index:
                             yield AAReadORF(self, ORFStart, index, True, False)
                         inOpenORF = False
                     elif inORF:
                         if ORFStart != index:
-                            yield AAReadORF(self, ORFStart, index, False, False)
+                            yield AAReadORF(self, ORFStart, index,
+                                            False, False)
                         inORF = False
-                elif residue == "M":
+                elif residue == 'M':
                     if not inOpenORF and not inORF:
                         ORFStart = index + 1
                         inORF = True
 
             # End of sequence. Yield the final ORF, open to the right, if
             # there is one and it has non-zero length.
             length = len(self.sequence)
@@ -639,32 +492,32 @@
                 yield AAReadORF(self, ORFStart, length, False, True)
 
         # Return only closed ORFs.
         else:
             inORF = False
 
             for index, residue in enumerate(self.sequence):
-                if residue == "M":
+                if residue == 'M':
                     if not inORF:
                         inORF = True
                         ORFStart = index + 1
-                elif residue == "*":
+                elif residue == '*':
                     if inORF:
-                        if not ORFStart == index:  # type: ignore (false unboud variable report for ORFStart)
-                            yield AAReadORF(self, ORFStart, index, False, False)  # type: ignore (false unboud variable report for ORFStart)
+                        if not ORFStart == index:
+                            yield AAReadORF(self, ORFStart,
+                                            index, False, False)
                         inORF = False
 
 
 class AAReadWithX(AARead):
     """
     Hold information and methods to work with AA reads with additional
     characters.
     """
-
-    ALPHABET: set[str] = set(AA_LETTERS + ["X"])
+    ALPHABET = set(AA_LETTERS + ['X'])
 
 
 class AAReadORF(AARead):
     """
     Hold information about an ORF from an AA read.
 
     @param originalRead: The original L{AARead} instance in which this ORF
@@ -678,96 +531,79 @@
         start codon was found preceeding this ORF.
     @param openRight: A C{bool}. If C{True}, the ORF potentially ends after
         the sequence given in C{sequence}. I.e., the ORF-detection code
         was in an ORF when it encountered the end of a read (so no stop codon
         was found). If C{False}, a stop codon was found in the read after this
         ORF.
     """
-
-    def __init__(
-        self,
-        originalRead: AARead,
-        start: int,
-        stop: int,
-        openLeft: bool,
-        openRight: bool,
-    ):
+    def __init__(self, originalRead, start, stop, openLeft, openRight):
         if start < 0:
-            raise ValueError("start offset (%d) less than zero" % start)
+            raise ValueError('start offset (%d) less than zero' % start)
         if stop > len(originalRead):
-            raise ValueError(
-                "stop offset (%d) > original read length (%d)"
-                % (stop, len(originalRead))
-            )
+            raise ValueError('stop offset (%d) > original read length (%d)' %
+                             (stop, len(originalRead)))
         if start > stop:
-            raise ValueError(
-                "start offset (%d) greater than stop offset (%d)" % (start, stop)
-            )
-        newId = "%s-%s%d:%d%s" % (
-            originalRead.id,
-            "(" if openLeft else "[",
-            start,
-            stop,
-            ")" if openRight else "]",
-        )
+            raise ValueError('start offset (%d) greater than stop offset (%d)'
+                             % (start, stop))
+        newId = '%s-%s%d:%d%s' % (originalRead.id,
+                                  '(' if openLeft else '[',
+                                  start, stop,
+                                  ')' if openRight else ']')
         if originalRead.quality:
-            AARead.__init__(
-                self,
-                newId,
-                originalRead.sequence[start:stop],
-                originalRead.quality[start:stop],
-            )
+            AARead.__init__(self, newId, originalRead.sequence[start:stop],
+                            originalRead.quality[start:stop])
         else:
             AARead.__init__(self, newId, originalRead.sequence[start:stop])
         self.start = start
         self.stop = stop
         self.openLeft = openLeft
         self.openRight = openRight
 
-    def toDict(self) -> dict:
+    def toDict(self):
         """
         Get information about this read in a dictionary.
 
         @return: A C{dict} with keys/values for the attributes of self.
         """
-        result = super().toDict()
+        if six.PY3:
+            result = super().toDict()
+        else:
+            result = AARead.toDict(self)
 
-        result.update(
-            {
-                "start": self.start,
-                "stop": self.stop,
-                "openLeft": self.openLeft,
-                "openRight": self.openRight,
-            }
-        )
+        result.update({
+            'start': self.start,
+            'stop': self.stop,
+            'openLeft': self.openLeft,
+            'openRight': self.openRight,
+        })
 
         return result
 
     @classmethod
-    def fromDict(cls, d: dict) -> AARead:
+    def fromDict(cls, d):
         """
         Create a new instance from attribute values provided in a dictionary.
 
         @param d: A C{dict} with keys/values for the attributes of a new
             instance of this class. Keys 'id' and 'sequence' with C{str} values
             must be provided. A 'quality' C{str} key is optional. Keys 'start'
             and 'stop' must have C{int} values. Keys 'openLeft' and 'openRight'
             are C{bool}, all keys are as described in the docstring for this
             class.
         @return: A new instance of this class, with values taken from C{d}.
         """
         # Make a dummy instance whose attributes we can set explicitly.
-        new = cls(AARead("", ""), 0, 0, True, True)
-        new.id = d["id"]
-        new.sequence = d["sequence"]
-        new.quality = d.get("quality")
-        new.start = d["start"]
-        new.stop = d["stop"]
-        new.openLeft = d["openLeft"]
-        new.openRight = d["openRight"]
+        new = cls(AARead('', ''), 0, 0, True, True)
+        new.id = d['id']
+        new.sequence = d['sequence']
+        new.quality = d.get('quality')
+        new.start = d['start']
+        new.stop = d['stop']
+        new.openLeft = d['openLeft']
+        new.openRight = d['openRight']
         return new
 
 
 class SSAARead(AARead):
     """
     Hold information to work with AAReads that have secondary structure
     information attached to them.
@@ -775,107 +611,94 @@
     Note that this class (currently) has no quality string associated with it.
 
     @param id: A C{str} describing the read.
     @param sequence: A C{str} of sequence information.
     @param structure: A C{str} of structure information.
     @raise ValueError: If the sequence and structure lengths are not the same.
     """
-
-    def __init__(self, id, sequence: str, structure: str):
-        super().__init__(id, sequence)
+    def __init__(self, id, sequence, structure):
+        if six.PY3:
+            super().__init__(id, sequence)
+        else:
+            AARead.__init__(self, id, sequence)
         self.structure = structure
 
         if len(sequence) != len(structure):
             raise ValueError(
-                "Invalid read: sequence length (%d) != structure length (%d)"
-                % (len(sequence), len(structure))
-            )
-
-    def __eq__(self, other: object) -> bool:
-        if isinstance(other, SSAARead):
-            return (
-                self.id == other.id
-                and self.sequence == other.sequence
-                and self.structure == other.structure
-            )
-        else:
-            return NotImplemented
+                'Invalid read: sequence length (%d) != structure length (%d)' %
+                (len(sequence), len(structure)))
 
-    def __hash__(self) -> int:
+    def __eq__(self, other):
+        return (self.id == other.id and
+                self.sequence == other.sequence and
+                self.structure == other.structure)
+
+    def __hash__(self):
         """
         Calculate a hash key for a read.
 
         @return: The C{int} hash key for the read.
         """
-        return hash(
-            md5(
-                self.id.encode("UTF-8")
-                + b"\0"
-                + self.sequence.encode("UTF-8")
-                + b"\0"
-                + self.structure.encode("UTF-8")
-            ).digest()
-        )
+        return hash(md5(self.id.encode('UTF-8') + b'\0' +
+                        self.sequence.encode('UTF-8') + b'\0' +
+                        self.structure.encode('UTF-8')).digest())
 
-    def __getitem__(self, item: Union[int, slice]) -> SSAARead:
+    def __getitem__(self, item):
         sequence = self.sequence[item]
-        structure = self.structure[item] if self.structure else ""
+        structure = None if self.structure is None else self.structure[item]
         return self.__class__(self.id, sequence, structure)
 
-    def toString(
-        self, format_: str = "fasta-ss", structureSuffix: str = ":structure"
-    ) -> str:
+    def toString(self, format_='fasta-ss', structureSuffix=':structure'):
         """
         Convert the read to a string in PDB format (sequence & structure). This
         consists of two FASTA records, one for the sequence then one for the
         structure.
 
         @param format_: Either 'fasta-ss' or 'fasta'. In the former case, the
             structure information is returned. Otherwise, plain FASTA is
             returned.
         @param structureSuffix: The C{str} suffix to append to the read id
             for the second FASTA record, containing the structure information.
         @raise ValueError: If C{format_} is not 'fasta'.
         @return: A C{str} representing the read sequence and structure in PDB
             FASTA format.
         """
-        if format_ == "fasta-ss":
-            return ">%s\n%s\n>%s%s\n%s\n" % (
-                self.id,
-                self.sequence,
-                self.id,
-                structureSuffix,
-                self.structure,
-            )
+        if format_ == 'fasta-ss':
+            return '>%s\n%s\n>%s%s\n%s\n' % (
+                self.id, self.sequence, self.id, structureSuffix,
+                self.structure)
         else:
-            return super().toString(format_=format_)
+            if six.PY3:
+                return super().toString(format_=format_)
+            else:
+                return AARead.toString(self, format_=format_)
 
     def toDict(self):
         """
         Get information about this read in a dictionary.
 
         @return: A C{dict} with keys/values for the attributes of self.
         """
         return {
-            "id": self.id,
-            "sequence": self.sequence,
-            "structure": self.structure,
+            'id': self.id,
+            'sequence': self.sequence,
+            'structure': self.structure,
         }
 
     @classmethod
     def fromDict(cls, d):
         """
         Create a new instance from attribute values provided in a dictionary.
 
         @param d: A C{dict} with keys/values for the attributes of a new
             instance of this class. Keys 'id', 'sequence', and 'structure'
             with C{str} values must be provided.
         @return: A new instance of this class, with values taken from C{d}.
         """
-        return cls(d["id"], d["sequence"], d["structure"])
+        return cls(d['id'], d['sequence'], d['structure'])
 
     def newFromSites(self, sites, exclude=False):
         """
         Create a new read from self, with only certain sites.
 
         @param sites: A set of C{int} 0-based sites (i.e., indices) in
             sequences that should be kept. If C{None} (the default), all sites
@@ -884,82 +707,77 @@
             included.
         """
         if exclude:
             sites = set(range(len(self))) - sites
 
         newSequence = []
         newStructure = []
-        for index, (base, structure) in enumerate(zip(self.sequence, self.structure)):
+        for index, (base, structure) in enumerate(zip(self.sequence,
+                                                      self.structure)):
             if index in sites:
                 newSequence.append(base)
                 newStructure.append(structure)
-        read = self.__class__(self.id, "".join(newSequence), "".join(newStructure))
+        read = self.__class__(self.id, ''.join(newSequence),
+                              ''.join(newStructure))
 
         return read
 
 
 class SSAAReadWithX(SSAARead):
     """
     Hold information and methods to work with C{SSAARead}s allowing 'X'
     characters to appear in sequences.
     """
-
-    ALPHABET = set(AA_LETTERS + ["X"])
+    ALPHABET = set(AA_LETTERS + ['X'])
 
 
 class TranslatedRead(AARead):
     """
     Hold information about one DNA->AA translation of a Read.
 
     @param originalRead: The original DNA or RNA L{Read} instance from which
         this translation was obtained.
     @param sequence: The C{str} AA translated sequence.
     @param frame: The C{int} frame, either 0, 1, or 2.
     @param reverseComplemented: A C{bool}, C{True} if the original sequence
         must be reverse complemented to obtain this AA sequence.
     """
-
-    def __init__(self, originalRead, sequence, frame, reverseComplemented=False):
+    def __init__(self, originalRead, sequence, frame,
+                 reverseComplemented=False):
         if frame not in (0, 1, 2):
-            raise ValueError("Frame must be 0, 1, or 2")
-        newId = "%s-frame%d%s" % (
-            originalRead.id,
-            frame,
-            "rc" if reverseComplemented else "",
-        )
+            raise ValueError('Frame must be 0, 1, or 2')
+        newId = '%s-frame%d%s' % (originalRead.id, frame,
+                                  'rc' if reverseComplemented else '')
         AARead.__init__(self, newId, sequence)
         self.frame = frame
         self.reverseComplemented = reverseComplemented
 
     def __eq__(self, other):
-        if not isinstance(other, TranslatedRead):
-            return False
-        return (
-            AARead.__eq__(self, other)
-            and self.frame == other.frame
-            and self.reverseComplemented == other.reverseComplemented
-        )
+        return (AARead.__eq__(self, other) and
+                self.frame == other.frame and
+                self.reverseComplemented == other.reverseComplemented)
 
     def __ne__(self, other):
         return not self == other
 
     def toDict(self):
         """
         Get information about this read in a dictionary.
 
         @return: A C{dict} with keys/values for the attributes of self.
         """
-        result = super().toDict()
+        if six.PY3:
+            result = super().toDict()
+        else:
+            result = AARead.toDict(self)
 
-        result.update(
-            {
-                "frame": self.frame,
-                "reverseComplemented": self.reverseComplemented,
-            }
-        )
+        result.update({
+            'frame': self.frame,
+            'reverseComplemented': self.reverseComplemented,
+        })
 
         return result
 
     @classmethod
     def fromDict(cls, d):
         """
         Create a new instance from attribute values provided in a dictionary.
@@ -968,32 +786,32 @@
             instance of this class. Keys 'id' and 'sequence' with C{str} values
             must be provided. A 'quality' C{str} key is optional. Key 'frame'
             must have an C{int} value. Key 'reverseComplemented' must be a
             C{bool}, all keys are as described in the docstring for this class.
         @return: A new instance of this class, with values taken from C{d}.
         """
         # Make a dummy instance whose attributes we can set explicitly.
-        new = cls(AARead("", ""), 0, True)
-        new.id = d["id"]
-        new.sequence = d["sequence"]
-        new.quality = d.get("quality")
-        new.frame = d["frame"]
-        new.reverseComplemented = d["reverseComplemented"]
+        new = cls(AARead('', ''), 0, True)
+        new.id = d['id']
+        new.sequence = d['sequence']
+        new.quality = d.get('quality')
+        new.frame = d['frame']
+        new.reverseComplemented = d['reverseComplemented']
         return new
 
     def maximumORFLength(self, openORFs=True):
         """
         Return the length of the longest (possibly partial) ORF in a translated
         read. The ORF may originate or terminate outside the sequence, which is
         why the length is just a lower bound.
         """
         return max(len(orf) for orf in self.ORFs(openORFs))
 
 
-class ReadFilter:
+class ReadFilter(object):
     """
     Create a function that can be used to filter a set of reads to produce a
     desired subset.
 
     Note: there are many additional filtering options that could be added,
     e.g., on complexity fraction, on GC %, on quality, etc.
 
@@ -1115,97 +933,67 @@
     """
 
     # TODO, when/if needed: make it possible to pass a seed for the RNG
     # when randomSubset or sampleFraction are used. Also possible is to
     # save and restore the state of the RNG and/or to optionally add
     # 'seed=XXX' to the end of the id of the first read, etc.
 
-    def __init__(
-        self,
-        minLength: Optional[int] = None,
-        maxLength: Optional[int] = None,
-        maxNFraction: Optional[float] = None,
-        removeGaps: bool = False,
-        whitelist: Optional[set[str]] = None,
-        blacklist: Optional[set[str]] = None,
-        whitelistFile: Optional[str] = None,
-        blacklistFile: Optional[str] = None,
-        titleRegex: Optional[str] = None,
-        negativeTitleRegex: Optional[str] = None,
-        truncateTitlesAfter: Optional[str] = None,
-        sequenceWhitelist: Optional[set[str]] = None,
-        sequenceBlacklist: Optional[set[str]] = None,
-        sequenceWhitelistFile: Optional[str] = None,
-        sequenceBlacklistFile: Optional[str] = None,
-        sequenceRegex: Optional[str] = None,
-        sequenceNegativeRegex: Optional[str] = None,
-        keepSequences: Optional[set[int]] = None,
-        removeSequences: Optional[set[int]] = None,
-        head: Optional[int] = None,
-        removeDuplicates: bool = False,
-        removeDuplicatesById: bool = False,
-        removeDuplicatesUseMD5: bool = False,
-        removeDescriptions: bool = False,
-        modifier: Optional[Callable[[Read], Union[Read, None]]] = None,
-        randomSubset: Optional[int] = None,
-        trueLength: Optional[int] = None,
-        sampleFraction: Optional[float] = None,
-        sequenceNumbersFile: Optional[str] = None,
-        idLambda: Optional[str] = None,
-        readLambda: Optional[str] = None,
-        keepSites: Optional[set[int]] = None,
-        removeSites: Optional[set[int]] = None,
-        reverse: bool = False,
-        reverseComplement: bool = False,
-    ):
+    def __init__(self, minLength=None, maxLength=None, maxNFraction=None,
+                 removeGaps=False, whitelist=None, blacklist=None,
+                 whitelistFile=None, blacklistFile=None,
+                 titleRegex=None, negativeTitleRegex=None,
+                 truncateTitlesAfter=None, keepSequences=None,
+                 removeSequences=None, head=None,
+                 removeDuplicates=False, removeDuplicatesById=False,
+                 removeDuplicatesUseMD5=False, removeDescriptions=False,
+                 modifier=None, randomSubset=None, trueLength=None,
+                 sampleFraction=None, sequenceNumbersFile=None, idLambda=None,
+                 readLambda=None, keepSites=None, removeSites=None,
+                 reverse=False, reverseComplement=False):
+
         if randomSubset is not None:
             if sampleFraction is not None:
-                raise ValueError(
-                    "randomSubset and sampleFraction cannot be "
-                    "used simultaneously in a filter. Make two "
-                    "read filters instead."
-                )
+                raise ValueError('randomSubset and sampleFraction cannot be '
+                                 'used simultaneously in a filter. Make two '
+                                 'read filters instead.')
 
             if trueLength is None:
-                raise ValueError(
-                    "trueLength must be supplied if randomSubset is specified."
-                )
+                raise ValueError('trueLength must be supplied if randomSubset '
+                                 'is specified.')
 
         self.minLength = minLength
         self.maxLength = maxLength
         self.maxNFraction = maxNFraction
         self.removeGaps = removeGaps
         self.head = head
         self.removeDescriptions = removeDescriptions
         self.modifier = modifier
         self.randomSubset = randomSubset
         self.trueLength = trueLength
 
-        if removeDuplicatesUseMD5 and not (removeDuplicates or removeDuplicatesById):
+        if removeDuplicatesUseMD5 and not (
+                removeDuplicates or removeDuplicatesById):
             raise ValueError(
-                "If you specify removeDuplicatesUseMD5, you need to also use "
-                "one of removeDuplicates or removeDuplicatesById."
-            )
+                'If you specify removeDuplicatesUseMD5, you need to also use '
+                'one of removeDuplicates or removeDuplicatesById.')
         self.removeDuplicates = removeDuplicates
         self.removeDuplicatesById = removeDuplicatesById
         self.removeDuplicatesUseMD5 = removeDuplicatesUseMD5
 
         if keepSequences and removeSequences:
             raise ValueError(
-                "Cannot simultaneously filter using keepSequences and "
-                "removeSequences. Call filter twice in succession instead."
-            )
+                'Cannot simultaneously filter using keepSequences and '
+                'removeSequences. Call filter twice in succession instead.')
         self.keepSequences = keepSequences
         self.removeSequences = removeSequences
 
         if keepSites and removeSites:
             raise ValueError(
-                "Cannot simultaneously filter using keepSites and "
-                "removeSites. Call filter twice in succession instead."
-            )
+                'Cannot simultaneously filter using keepSites and '
+                'removeSites. Call filter twice in succession instead.')
         self.keepSites = keepSites
         self.removeSites = removeSites
 
         if reverseComplement:
             # Make sure reverse is not also set.
             reverse = False
         self.reverse = reverse
@@ -1226,81 +1014,52 @@
             with open(filename) as fp:
                 lastNumber = None
                 for line in fp:
                     n = int(line)
                     if lastNumber is None:
                         if n < 1:
                             raise ValueError(
-                                "First line of sequence number file %r must "
-                                "be at least 1." % filename
-                            )
+                                'First line of sequence number file %r must '
+                                'be at least 1.' % filename)
                         lastNumber = n
                         yield n
                     else:
                         if n > lastNumber:
                             lastNumber = n
                             yield n
                         else:
                             raise ValueError(
-                                "Line number file %r contains non-ascending "
-                                "numbers %d and %d." % (filename, lastNumber, n)
-                            )
+                                'Line number file %r contains non-ascending '
+                                'numbers %d and %d.' %
+                                (filename, lastNumber, n))
 
         self.wantedSequenceNumberGeneratorExhausted = False
         self.nextWantedSequenceNumber = None
 
         if sequenceNumbersFile is not None:
-            self.wantedSequenceNumberGenerator = _wantedSequences(sequenceNumbersFile)
+            self.wantedSequenceNumberGenerator = _wantedSequences(
+                sequenceNumbersFile)
             try:
-                self.nextWantedSequenceNumber = next(self.wantedSequenceNumberGenerator)
+                self.nextWantedSequenceNumber = next(
+                    self.wantedSequenceNumberGenerator)
             except StopIteration:
                 # There was a sequence number file, but it was empty. So no
                 # reads will ever be accepted.
                 self.alwaysFalse = True
 
-        if (
-            whitelist
-            or blacklist
-            or whitelistFile
-            or blacklistFile
-            or titleRegex
-            or negativeTitleRegex
-            or truncateTitlesAfter
-        ):
+        if (whitelist or blacklist or whitelistFile or blacklistFile or
+                titleRegex or negativeTitleRegex or truncateTitlesAfter):
             self.titleFilter = TitleFilter(
-                whitelist=whitelist,
-                blacklist=blacklist,
-                whitelistFile=whitelistFile,
-                blacklistFile=blacklistFile,
-                positiveRegex=titleRegex,
-                negativeRegex=negativeTitleRegex,
-                truncateAfter=truncateTitlesAfter,
-            )
+                whitelist=whitelist, blacklist=blacklist,
+                whitelistFile=whitelistFile, blacklistFile=blacklistFile,
+                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex,
+                truncateAfter=truncateTitlesAfter)
         else:
             self.titleFilter = None
 
-        if (
-            sequenceWhitelist
-            or sequenceBlacklist
-            or sequenceWhitelistFile
-            or sequenceBlacklistFile
-            or sequenceRegex
-            or sequenceNegativeRegex
-        ):
-            self.sequenceFilter = SequenceFilter(
-                whitelist=sequenceWhitelist,
-                blacklist=sequenceBlacklist,
-                whitelistFile=sequenceWhitelistFile,
-                blacklistFile=sequenceBlacklistFile,
-                positiveRegex=sequenceRegex,
-                negativeRegex=sequenceNegativeRegex,
-            )
-        else:
-            self.sequenceFilter = None
-
         if removeDuplicates:
             self.sequencesSeen = set()
 
         if removeDuplicatesById:
             self.idsSeen = set()
 
         if sampleFraction is not None:
@@ -1308,14 +1067,15 @@
                 # The filter method should always return False.
                 self.alwaysFalse = True
             elif sampleFraction == 1.0:
                 # Passing 1.0 can be treated the same as passing no value.
                 # This makes the filter code below simpler.
                 sampleFraction = None
         self.sampleFraction = sampleFraction
+
         self.idLambda = eval(idLambda) if idLambda else None
         self.readLambda = eval(readLambda) if readLambda else None
 
     def filter(self, read):
         """
         Check if a read passes the filter.
 
@@ -1331,103 +1091,96 @@
             return False
 
         if self.nextWantedSequenceNumber is not None:
             if self.readIndex + 1 == self.nextWantedSequenceNumber:
                 # We want this sequence.
                 try:
                     self.nextWantedSequenceNumber = next(
-                        self.wantedSequenceNumberGenerator
-                    )
+                        self.wantedSequenceNumberGenerator)
                 except StopIteration:
                     # The sequence number iterator ran out of sequence
                     # numbers.  We must let the rest of the filtering
                     # continue for the current sequence in case we
                     # throw it out for other reasons (as we might have
                     # done for any of the earlier wanted sequence
                     # numbers).
                     self.wantedSequenceNumberGeneratorExhausted = True
             else:
                 # This sequence isn't one of the ones that's wanted.
                 return False
 
-        if self.sampleFraction is not None and uniform(0.0, 1.0) > self.sampleFraction:
+        if (self.sampleFraction is not None and
+                uniform(0.0, 1.0) > self.sampleFraction):
             # Note that we don't have to worry about the 0.0 or 1.0
             # cases in the above 'if', as they have been dealt with
             # in self.__init__.
             return False
 
         if self.randomSubset is not None:
             if self.yieldCount == self.randomSubset:
                 # The random subset has already been fully returned.
                 # There's no point in going any further through the input.
                 self.alwaysFalse = True
                 return False
-            elif uniform(0.0, 1.0) > (
-                (self.randomSubset - self.yieldCount)
-                / (self.trueLength - self.readIndex)
-            ):
+            elif uniform(0.0, 1.0) > ((self.randomSubset - self.yieldCount) /
+                                      (self.trueLength - self.readIndex)):
                 return False
 
         if self.head is not None and self.readIndex == self.head:
             # We're completely done.
             self.alwaysFalse = True
             return False
 
         readLen = len(read)
-        if (self.minLength is not None and readLen < self.minLength) or (
-            self.maxLength is not None and readLen > self.maxLength
-        ):
+        if ((self.minLength is not None and readLen < self.minLength) or
+                (self.maxLength is not None and readLen > self.maxLength)):
             return False
 
         if self.maxNFraction is not None:
-            nFraction = read.sequence.count("N") / readLen
+            nFraction = read.sequence.count('N') / readLen
             if self.maxNFraction < nFraction:
                 return False
 
         if self.removeGaps:
             if read.quality is None:
-                read = read.__class__(read.id, read.sequence.replace("-", ""))
+                read = read.__class__(read.id, read.sequence.replace('-', ''))
             else:
                 newSequence = []
                 newQuality = []
                 for base, quality in zip(read.sequence, read.quality):
-                    if base != "-":
+                    if base != '-':
                         newSequence.append(base)
                         newQuality.append(quality)
                 read = read.__class__(
-                    read.id, "".join(newSequence), "".join(newQuality)
-                )
+                    read.id, ''.join(newSequence), ''.join(newQuality))
 
-        if self.titleFilter and self.titleFilter.accept(read.id) == TitleFilter.REJECT:
+        if (self.titleFilter and
+                self.titleFilter.accept(read.id) == TitleFilter.REJECT):
             return False
 
-        if (
-            self.sequenceFilter
-            and self.sequenceFilter.accept(read.sequence) == SequenceFilter.REJECT
-        ):
+        if (self.keepSequences is not None and
+                self.readIndex not in self.keepSequences):
             return False
 
-        if self.keepSequences is not None and self.readIndex not in self.keepSequences:
-            return False
-
-        if self.removeSequences is not None and self.readIndex in self.removeSequences:
+        if (self.removeSequences is not None and
+                self.readIndex in self.removeSequences):
             return False
 
         if self.removeDuplicates:
             if self.removeDuplicatesUseMD5:
-                sequence = md5(read.sequence.encode("UTF-8")).digest()
+                sequence = md5(read.sequence.encode('UTF-8')).digest()
             else:
                 sequence = read.sequence
             if sequence in self.sequencesSeen:
                 return False
             self.sequencesSeen.add(sequence)
 
         if self.removeDuplicatesById:
             if self.removeDuplicatesUseMD5:
-                id_ = md5(read.id.encode("UTF-8")).digest()
+                id_ = md5(read.id.encode('UTF-8')).digest()
             else:
                 id_ = read.id
             if id_ in self.idsSeen:
                 return False
             self.idsSeen.add(id_)
 
         if self.modifier:
@@ -1469,61 +1222,59 @@
         self.yieldCount += 1
         return read
 
 
 # Provide a mapping from all read class names to read classes. This can be
 # useful in deserialization.
 readClassNameToClass = {
-    "AARead": AARead,
-    "AAReadORF": AAReadORF,
-    "AAReadWithX": AAReadWithX,
-    "DNARead": DNARead,
-    "RNARead": RNARead,
-    "Read": Read,
-    "SSAARead": SSAARead,
-    "SSAAReadWithX": SSAAReadWithX,
-    "TranslatedRead": TranslatedRead,
+    'AARead': AARead,
+    'AAReadORF': AAReadORF,
+    'AAReadWithX': AAReadWithX,
+    'DNARead': DNARead,
+    'RNARead': RNARead,
+    'Read': Read,
+    'SSAARead': SSAARead,
+    'SSAAReadWithX': SSAAReadWithX,
+    'TranslatedRead': TranslatedRead,
 }
 
-
-def getUnambiguousBases() -> dict[str, set[str]]:
-    _DNA = set("ACGT")
-    _RNA = set("ACGU")
-    _AA = set(AA_LETTERS)
-
-    # Map read class names to the set of unambiguous sequence bases (loosely
-    # speaking).
-    return {
-        "AARead": _AA,
-        "AAReadORF": _AA,
-        "AAReadWithX": _AA,
-        "DNARead": _DNA,
-        "RNARead": _RNA,
-        "Read": _DNA,
-        "SSAARead": _AA,
-        "SSAAReadWithX": _AA,
-        "TranslatedRead": _AA,
-    }
+_DNA = set('ACGT')
+_RNA = set('ACGU')
+_AA = set(AA_NAMES)
+
+# Map read class names to the set of unambiguous sequence bases (loosely
+# speaking).
+unambiguousBases = {
+    'AARead': _AA,
+    'AAReadORF': _AA,
+    'AAReadWithX': _AA,
+    'DNARead': _DNA,
+    'RNARead': _RNA,
+    'Read': _DNA,
+    'SSAARead': _AA,
+    'SSAAReadWithX': _AA,
+    'TranslatedRead': _AA,
+}
 
 
-class Reads:
+class Reads(object):
     """
     Maintain a collection of sequence reads.
 
     @param initialReads: If not C{None}, an iterable of C{Read} (or C{Read}
         subclass) instances.
     """
 
-    def __init__(self, initialReads: Optional[Iterable[Read]] = None) -> None:
+    def __init__(self, initialReads=None):
         self._initialReads = initialReads
-        self._additionalReads: List[Read] = []
-        self._filters: List[Callable] = []
+        self._additionalReads = []
+        self._filters = []
         self._iterated = False
 
-    def filterRead(self, read: Read) -> Union[Literal[False], Read]:
+    def filterRead(self, read):
         """
         Filter a read, according to our set of filters.
 
         @param read: A C{Read} instance or one of its subclasses.
         @return: C{False} if the read fails any of our filters, else the
             C{Read} instance returned by our list of filters.
         """
@@ -1531,23 +1282,23 @@
             filteredRead = filterFunc(read)
             if filteredRead is False:
                 return False
             else:
                 read = filteredRead
         return read
 
-    def add(self, read: Read) -> None:
+    def add(self, read):
         """
         Add a read to this collection of reads.
 
         @param read: A C{Read} instance.
         """
         self._additionalReads.append(read)
 
-    def __iter__(self) -> Generator[Read, None, None]:
+    def __iter__(self):
         """
         Iterate through all the reads.
 
         @return: A generator that yields reads. The returned read types depend
             on the kind of reads that were added to this instance.
         """
         # self._additionalReads is a regular list.
@@ -1571,190 +1322,172 @@
         if isinstance(initialReads, Reads):
             _unfilteredLength += initialReads.unfilteredLength()
         else:
             _unfilteredLength += initialReadsLength
 
         # The value returned by self.iter() may be a Reads instance and/or
         # may not support len().
-        subclassReads: Iterable[Read] = self.iter()
+        subclassReads = self.iter()
         subclassReadsLength = 0
-        for xread in subclassReads:
+        for read in subclassReads:
             subclassReadsLength += 1
-            filteredRead = self.filterRead(xread)
+            filteredRead = self.filterRead(read)
             if filteredRead is not False:
                 yield filteredRead
 
         if isinstance(subclassReads, Reads):
             _unfilteredLength += subclassReads.unfilteredLength()
         else:
             _unfilteredLength += subclassReadsLength
 
         self._unfilteredLength = _unfilteredLength
         self._iterated = True
 
-    def unfilteredLength(self) -> int:
+    def unfilteredLength(self):
         """
         Return the underlying number of reads in C{self}, irrespective of any
         filtering that has been applied.
 
         To obtain the number of reads in a filtered C{Reads} instance, you
         must count the reads yourself as you iterate it.
 
         @raises RuntimeError: If C{self} has not been fully iterated.
         @return: The C{int} number of reads in C{self}.
         """
         if self._iterated:
             return self._unfilteredLength
         else:
             raise RuntimeError(
-                "The unfiltered length of a Reads instance is unknown until "
-                "it has been iterated."
-            )
+                'The unfiltered length of a Reads instance is unknown until '
+                'it has been iterated.')
 
-    def iter(self) -> Union[Generator[Read, None, None], list]:
+    def iter(self):
         """
         Placeholder to allow subclasses to provide reads.
 
         These might be extracted from a file. E.g., the
         C{dark.reads.fasta.FastaReads} class (a subclass of C{Reads})
         overrides this method to provide reads from a file.
 
         @return: An iterable of C{Read} instances.
         """
         return []
 
-    def save(self, filename: Union[str, TextIO], format_: str = "fasta") -> int:
+    def save(self, filename, format_='fasta'):
         """
         Write the reads to C{filename} in the requested format.
 
         @param filename: Either a C{str} file name to save into (the file will
             be overwritten) or an open file descriptor (e.g., sys.stdout).
         @param format_: A C{str} format to save as, either 'fasta', 'fastq' or
             'fasta-ss'.
         @raise ValueError: if C{format_} is 'fastq' and a read with no quality
             is present, or if an unknown format is requested.
         @return: An C{int} giving the number of reads in C{self}.
         """
         format_ = format_.lower()
         count = 0
 
-        if isinstance(filename, (str, Path)):
+        if isinstance(filename, str):
             try:
-                with open(filename, "w") as fp:
-                    for read in iter(self):
+                with open(filename, 'w') as fp:
+                    for read in self:
                         fp.write(read.toString(format_))
                         count += 1
             except ValueError:
                 os.unlink(filename)
                 raise
         else:
             # We have a file-like object.
-            for read in iter(self):
+            for read in self:
                 filename.write(read.toString(format_))
                 count += 1
         return count
 
-    def filter(self, **kwargs) -> Reads:
+    def filter(self, **kwargs):
         """
         Add a filter to this C{Reads} instance.
 
         @param kwargs: Keyword arguments, as accepted by C{ReadFilter}.
         @return: C{self}.
         """
         readFilter = ReadFilter(**kwargs)
         self._filters.append(readFilter.filter)
         return self
 
-    def clearFilters(self) -> Reads:
+    def clearFilters(self):
         """
         Clear all filters on this C{Reads} instance.
 
         @return: C{self}.
         """
         self._filters = []
         return self
 
-    def summarizePosition(self, index: int) -> dict:
+    def summarizePosition(self, index):
         """
         Compute residue counts at a specific sequence index.
 
         @param index: an C{int} index into the sequence.
-        @return: A C{dict} with the count of the reads, the too-short (excluded)
-            sequences, and a Counter instance giving the base/residue counts.
+        @return: A C{dict} with the count of too-short (excluded) sequences,
+            and a Counter instance giving the residue counts.
         """
-        countAtPosition: Counter = Counter()
-        excludedCount = readCount = 0
+        countAtPosition = Counter()
+        excludedCount = 0
 
-        for read in iter(self):
-            readCount += 1
+        for read in self:
             try:
                 countAtPosition[read.sequence[index]] += 1
             except IndexError:
                 excludedCount += 1
 
         return {
-            "excludedCount": excludedCount,
-            "countAtPosition": countAtPosition,
-            "readCount": readCount,
+            'excludedCount': excludedCount,
+            'countAtPosition': countAtPosition
         }
 
-    def sitesMatching(self, targets: set, matchCase: bool, any_: bool) -> set[int]:
+    def sitesMatching(self, targets, matchCase, any_):
         """
         Find sites (i.e., sequence indices) that match a given set of target
         sequence bases.
 
         @param targets: A C{set} of sequence bases to look for.
         @param matchCase: If C{True}, case will be considered in matching.
         @param any_: If C{True}, return sites that match in any read. Else
             return sites that match in all reads.
-        @return: A C{set} of 0-based C{int} sites that indicate where the target
+        @return: A C{set} of 0-based sites that indicate where the target
             bases occur in our reads. An index will be in this set if any of
             our reads has any of the target bases in that location.
         """
         # If case is unimportant, we convert everything (target bases and
         # sequences, as we read them) to lower case.
         if not matchCase:
             targets = set(map(str.lower, targets))
 
-        # result = set() if any_ else None
-        if any_:
-            result: set[int] = set()
-
-        # I am using a 'first' variable here instead of just setting
-        # 'result' to be None and testing that below, because if I let it
-        # be None then mypy complains it is None when I try to add to it.
-        first = True
-
-        for read in iter(self):
+        result = set() if any_ else None
+        for read in self:
             sequence = read.sequence if matchCase else read.sequence.lower()
-            matches = set(
-                index for (index, base) in enumerate(sequence) if base in targets
-            )
+            matches = set(index for (index, base) in enumerate(sequence)
+                          if base in targets)
             if any_:
                 result |= matches
             else:
-                if first:
-                    first = False
+                if result is None:
                     result = matches
                 else:
                     result &= matches
                 # We can exit early if we run out of possible sites.
                 if not result:
                     break
 
         # Make sure we don't return None.
-        # return result or set()
-        return set() if result is None else result
+        return result or set()
 
-    def variableSites(
-        self,
-        confirm: bool = False,
-        homogeneityLevel: float = 1.0,
-        unknownAreAmbiguous: bool = False,
-    ) -> dict:
+    def variableSites(self, confirm=False, homogeneityLevel=1.0,
+                      unknownAreAmbiguous=False):
         """
         Find the variable sites in a set of reads.
 
         @param confirm: If C{True} only return sites where there is confirm
             variation (i.e., ambiguous sites that are compatible with there
             being no variation are not returned).
         @homogeneityLevel: If the frequency of the most-common nucleotide at
@@ -1774,186 +1507,51 @@
         if reads:
             length = len(reads[0].sequence)
             if not all(len(read.sequence) == length for read in reads):
                 raise ReadLengthsNotIdenticalError()
             for site in range(length):
                 counts = FloatBaseCounts(
                     [r.sequence[site] for r in reads],
-                    unknownAreAmbiguous=unknownAreAmbiguous,
-                )
-                if counts.variable(confirm) and not counts.homogeneous(
-                    homogeneityLevel
-                ):
+                    unknownAreAmbiguous=unknownAreAmbiguous)
+                if (counts.variable(confirm) and
+                        not counts.homogeneous(homogeneityLevel)):
                     varSites[site] = counts
 
         return varSites
 
-    def combineReads(self) -> str:
+    def combineReads(self):
         """
         Combine all reads into a single read. Reads must be of equal length.
-        This is "combine" in the sense of making a single consensus sequence
-        but without considering the frequency of the bases at each site.
 
         @return: a C{str} sequence made from combining all reads.
         """
         reads = list(self)
         assert len({len(read) for read in reads}) == 1
 
-        sequence = ""
+        sequence = ''
         for site in range(len(reads[0])):
             bases = set([r.sequence[site] for r in reads])
             if len(bases) == 1:
                 sequence += bases.pop()
-            elif (
-                len(bases) == 2
-                and "N" in bases
-                and bases.intersection({"A", "T", "G", "C"})
-            ):
-                sequence += list(bases.intersection({"A", "T", "G", "C"}))[0]
+            elif (len(bases) == 2 and 'N' in bases and
+                  bases.intersection({'A', 'T', 'G', 'C'})):
+                sequence += list(bases.intersection({'A', 'T', 'G', 'C'}))[0]
             else:
                 nucleotides = set()
                 for base in bases:
                     nucleotides.update(AMBIGUOUS.get(base, set()))
                 try:
-                    sequence += BASES_TO_AMBIGUOUS["".join(sorted(nucleotides))]
+                    sequence += BASES_TO_AMBIGUOUS[''.join(
+                        sorted(nucleotides))]
                 except KeyError:
-                    raise ValueError(
-                        "Unknown DNA base(s): %r" % (nucleotides - set("ACGTN-"))
-                    )
+                    raise ValueError('Unknown DNA base(s): %r' %
+                                     nucleotides - set('ACGTN-'))
 
         return sequence
 
-    def temporalBaseCounts(
-        self,
-        firstPostId: str,
-        minFrequency: Optional[float] = None,
-        maxFrequency: Optional[float] = None,
-        minCount: int = 0,
-        preIds: Optional[Set[str]] = None,
-    ):
-        """
-        Iterate through time-sorted reads, accumulating counts of bases at each
-        offset pre- and post- a specific sequence.
-
-        @param firstPostId: The C{str} id of the first member of the 'post'
-            sequences.
-        @param minFrequency: The C{float} minimum frequency at which a new base
-            is considered interesting and should have its frequency returned.
-        @param maxFrequency: The C{float} maximum frequency at which a new base
-            is considered interesting and should have its frequency returned.
-        @param minCount: The C{int} minimal number of times a new base must be
-            seen to be considered interesting (and to therefore have its
-            frequency returned).
-        @param preIds: If not C{None}, a C{set} of C{str} ids to include in the
-            the early counting (i.e., before seeing firstPostId). If C{None},
-            the sequences of all early ids will be included.
-        @return: A C{dict}, as below.
-        """
-        first = True
-        preBases: dict[int, dict[str, int]] = {}
-        postBases: dict[int, dict[str, int]] = {}
-        preCount = postCount = 0
-        reference = None
-        postIdFound = False
-        preIdsFound = set()
-        _DNA = set("ACGT")
-
-        for genome in iter(self):
-            if first:
-                first = False
-                length = len(genome)
-                reference = genome
-                for offset in range(length):
-                    preBases[offset] = defaultdict(int)
-                    postBases[offset] = defaultdict(int)
-            else:
-                if len(genome) != length:
-                    raise ValueError(
-                        f"Genome {genome.id!r} has length {len(genome)} which "
-                        f"does not match the length of the first input "
-                        f"sequence ({length})."
-                    )
-
-            if genome.id == firstPostId:
-                if postIdFound:
-                    raise ValueError(
-                        f"Delimiting sequence id {firstPostId!r} "
-                        f"found more than once!"
-                    )
-                postIdFound = True
-
-            if postIdFound:
-                bases = postBases
-                postCount += 1
-            else:
-                if preIds:
-                    if genome.id not in preIds:
-                        continue
-                    else:
-                        if genome.id in preIdsFound:
-                            raise ValueError(
-                                f"Pre-id sequence {genome.id!r} "
-                                f"found more than once!"
-                            )
-                        preIdsFound.add(genome.id)
-
-                bases = preBases
-                preCount += 1
-
-            for offset, base in enumerate(genome.sequence):
-                # TODO: Deal with ambiguous codes instead of ignoring them.
-                if base in _DNA:
-                    bases[offset][base] += 1
-
-        if reference is None:
-            raise ValueError("No genomes found.")
-
-        if not postIdFound:
-            raise ValueError(
-                f"The delimiting sequence id {firstPostId!r} " f"was not found."
-            )
-
-        if preIds and preIds != preIdsFound:
-            missing = sorted(preIds - preIdsFound)
-            if len(missing) == 1:
-                raise ValueError(f"Pre-id {missing[0]!r} not found.")
-            else:
-                raise ValueError(
-                    f"{len(missing)} pre-ids " f'({", ".join(missing)}) was not found.'
-                )
-
-        # Look for bases (that occurred in the post-sequences) that are new
-        # (i.e., previously unseen). Calculate their frequencies, and
-        # record frequencies that are in the wanted range.
-        newFrequencies: dict[int, dict[str, float]] = defaultdict(dict)
-        for offset in range(length):
-            newBasesInPost = set(postBases[offset]) - set(preBases[offset])
-            if newBasesInPost:
-                for newBase in newBasesInPost:
-                    baseCount = postBases[offset][newBase]
-                    if baseCount > minCount:
-                        frq = baseCount / postCount
-                        if (minFrequency is None or frq >= minFrequency) and (
-                            maxFrequency is None or frq <= maxFrequency
-                        ):
-                            newFrequencies[offset][newBase] = frq
-
-        return {
-            "reference": reference,
-            "pre": {
-                "bases": preBases,
-                "count": preCount,
-            },
-            "post": {
-                "bases": postBases,
-                "count": postCount,
-                "new": newFrequencies,
-            },
-        }
-
 
 class ReadsInRAM(Reads):
     """
     Maintain a collection of sequence reads in RAM.
 
     @param initialReads: If not C{None}, an iterable of C{Read} (or a C{Read}
         subclass) instances.
@@ -1961,100 +1559,80 @@
 
     # This class provides some C{list} like methods (len and indexing) but
     # is not an actual list or list subclass. That's because we want to inherit
     # the methods of C{Reads}, and I considered it too messy to use double
     # inheritance. If you want a real list, you can just call C{list} on a
     # C{Reads} or C{ReadsInRAM} instance.
 
-    def __init__(self, initialReads: Optional[Iterable[Read]] = None):
-        super().__init__(initialReads)
+    def __init__(self, initialReads=None):
+        if six.PY3:
+            super().__init__(initialReads)
+        else:
+            Reads.__init__(self, initialReads)
 
         # Read all initial reads into memory.
         if initialReads:
             for read in initialReads:
                 self.add(read)
 
         # Set self._iterated to True in case someone calls unfilteredLength
         # (see Reads).
         self._iterated = True
 
-    def __len__(self) -> int:
+    def __len__(self):
         return self._additionalReads.__len__()
 
-    def __getitem__(self, item: SupportsIndex) -> Union[Read, Reads]:
+    def __getitem__(self, item):
         return self._additionalReads.__getitem__(item)
 
-    def __setitem__(self, item: SupportsIndex, value: Read) -> None:
+    def __setitem__(self, item, value):
         return self._additionalReads.__setitem__(item, value)
 
-    def __iter__(self) -> Generator[Read, None, None]:
-        for read in self._additionalReads.__iter__():
-            yield read
+    def __iter__(self):
+        return self._additionalReads.__iter__()
 
 
-def addFASTACommandLineOptions(parser: argparse.ArgumentParser) -> None:
+def addFASTACommandLineOptions(parser):
     """
     Add standard command-line options to an argparse parser.
 
     @param parser: An C{argparse.ArgumentParser} instance.
     """
 
     parser.add_argument(
-        "--fastaFile",
-        type=open,
-        default=sys.stdin,
-        metavar="FILENAME",
-        help=(
-            "The name of the FASTA input file. Standard input will be read "
-            "if no file name is given."
-        ),
-    )
+        '--fastaFile', type=open, default=sys.stdin, metavar='FILENAME',
+        help=('The name of the FASTA input file. Standard input will be read '
+              'if no file name is given.'))
 
     parser.add_argument(
-        "--readClass",
-        default="DNARead",
-        choices=readClassNameToClass,
-        metavar="CLASSNAME",
-        help=(
-            "If specified, give the type of the reads in the input. "
-            "Possible choices: %s." % ", ".join(readClassNameToClass)
-        ),
-    )
+        '--readClass', default='DNARead', choices=readClassNameToClass,
+        metavar='CLASSNAME',
+        help=('If specified, give the type of the reads in the input. '
+              'Possible choices: %s.' % ', '.join(readClassNameToClass)))
 
     # A mutually exclusive group for either --fasta, --fastq, or --fasta-ss
     group = parser.add_mutually_exclusive_group()
 
     group.add_argument(
-        "--fasta",
-        default=False,
-        action="store_true",
-        help="If specified, input will be treated as FASTA. This is the default.",
-    )
+        '--fasta', default=False, action='store_true',
+        help=('If specified, input will be treated as FASTA. This is the '
+              'default.'))
 
     group.add_argument(
-        "--fastq",
-        default=False,
-        action="store_true",
-        help="If specified, input will be treated as FASTQ.",
-    )
+        '--fastq', default=False, action='store_true',
+        help='If specified, input will be treated as FASTQ.')
 
     group.add_argument(
-        "--fasta-ss",
-        dest="fasta_ss",
-        default=False,
-        action="store_true",
-        help=(
-            "If specified, input will be treated as PDB FASTA "
-            "(i.e., regular FASTA with each sequence followed by its "
-            "structure)."
-        ),
-    )
+        '--fasta-ss', dest='fasta_ss', default=False, action='store_true',
+        help=('If specified, input will be treated as PDB FASTA '
+              '(i.e., regular FASTA with each sequence followed by its '
+              'structure).'))
 
 
-def parseFASTACommandLineOptions(args: argparse.Namespace) -> Reads:
+def parseFASTACommandLineOptions(args):
     """
     Examine parsed command-line options and return a Reads instance.
 
     @param args: An argparse namespace, as returned by the argparse
         C{parse_args} function.
     @return: A C{Reads} subclass instance, depending on the type of FASTA file
         given.
@@ -2063,43 +1641,14 @@
     if not (args.fasta or args.fastq or args.fasta_ss):
         args.fasta = True
 
     readClass = readClassNameToClass[args.readClass]
 
     if args.fasta:
         from dark.fasta import FastaReads
-
         return FastaReads(args.fastaFile, readClass=readClass)
     elif args.fastq:
         from dark.fastq import FastqReads
-
         return FastqReads(args.fastaFile, readClass=readClass)
     else:
         from dark.fasta_ss import SSFastaReads
-
         return SSFastaReads(args.fastaFile, readClass=readClass)
-
-
-def getNoCoverageCounts(
-    reads: Iterable[Read], noCoverageChars: Optional[str]
-) -> dict[str, int]:
-    """
-    Get the no-coverage character counts for all reads.
-
-    @param reads: A C{Reads} instance.
-    @param noCoverageChars: A C{str} of sequence characters that indicate
-        no coverage. If empty or C{None}, it is assumed there are no no-coverage
-        characters, so the count for all reads will be zero.
-    @return: A C{dict} keyed by read id, with C{int} number of no-coverage
-        characters in the read sequence.
-    """
-    if noCoverageChars:
-        noCoverageChars = set(noCoverageChars)
-        result = {}
-        for read in reads:
-            result[read.id] = sum(
-                character in noCoverageChars for character in read.sequence
-            )
-    else:
-        result = dict.fromkeys((read.id for read in reads), 0)
-
-    return result
```

### Comparing `dark-matter-4.0.84/dark/sequence.py` & `dark-matter-4.0.9/dark/sequence.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     primer = primer.upper()
     primerLen = len(primer)
     discarded = 0
     offset = seq.find(primer)
 
     while offset > -1:
         offsets.append(discarded + offset)
-        seq = seq[offset + primerLen :]
+        seq = seq[offset + primerLen:]
         discarded += offset + primerLen
         offset = seq.find(primer)
 
     return offsets
 
 
 def findPrimerBidi(primer, seq):
```

### Comparing `dark-matter-4.0.84/dark/simplify.py` & `dark-matter-4.0.9/dark/simplify.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-def simplifyTitle(title: str, target: str) -> str:
+def simplifyTitle(title, target):
     """
     Simplify a given sequence title.  Given a title, look for the first
     occurrence of target anywhere in any of its words. Return a space-separated
     string of the words of the title up to and including the occurrence of the
     target.  Ignore case.
 
     E.g.,
@@ -26,11 +26,11 @@
     targetLen = len(target)
     result = []
 
     for word in title.split():
         if len(word) >= targetLen:
             offset = word.lower().find(target.lower())
             if offset > -1:
-                result.append(word[: offset + targetLen])
+                result.append(word[:offset + targetLen])
                 break
         result.append(word)
-    return " ".join(result)
+    return ' '.join(result)
```

### Comparing `dark-matter-4.0.84/dark/summarize.py` & `dark-matter-4.0.9/dark/summarize.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,59 +1,49 @@
-from typing import Union, Optional
-from io import TextIOWrapper
-from collections import defaultdict
 from Bio import SeqIO
+from collections import defaultdict
 
-from dark.reads import Read
 from dark.utils import median
 
 
-def summarizeReads(
-    file_handle: Union[str, TextIOWrapper], file_type: str
-) -> dict[str, Union[int, float, defaultdict[str, int]]]:
+def summarizeReads(file_handle, file_type):
     """
     open a fasta or fastq file, prints number of of reads,
     average length of read, total number of bases, longest,
     shortest and median read, total number and average of
     individual base (A, T, G, C, N).
     """
-    base_counts: defaultdict[str, int] = defaultdict(int)
+    base_counts = defaultdict(int)
     read_number = 0
     total_length = 0
-    length_list: list[int] = []
+    length_list = []
 
     records = SeqIO.parse(file_handle, file_type)
 
     for record in records:
         total_length += len(record)
         read_number += 1
         length_list.append(len(record))
         for base in record:
             base_counts[base] += 1
 
-    result: dict[str, Union[int, float, defaultdict[str, int]]] = {
+    result = {
         "read_number": read_number,
         "total_length": total_length,
         "average_length": total_length / read_number if read_number > 0 else 0,
         "max_length": max(length_list) if length_list else 0,
         "min_length": min(length_list) if length_list else 0,
         "median_length": median(length_list) if length_list else 0,
-        "base_counts": base_counts,
+        "base_counts": base_counts
     }
 
     return result
 
 
-def sequenceCategoryLengths(
-    read: Read,
-    categories: dict[str, str],
-    defaultCategory: Optional[str] = None,
-    suppressedCategory: str = "...",
-    minLength: int = 1,
-):
+def sequenceCategoryLengths(read, categories, defaultCategory=None,
+                            suppressedCategory='...', minLength=1):
     """
     Summarize the nucleotides or AAs found in a read by assigning each to a
     category and reporting the lengths of the contiguous category classes
     found along the sequence.
 
     @param read: A C{Read} instance or one of its subclasses.
     @param categories: A C{dict} mapping nucleotides or AAs to category.
@@ -74,15 +64,15 @@
     first = True
     currentCategory = None
     currentCount = 0
     suppressing = False
     suppressedCount = 0
 
     if minLength < 1:
-        raise ValueError("minLength must be at least 1")
+        raise ValueError('minLength must be at least 1')
 
     for base in read.sequence:
         thisCategory = get(base, defaultCategory)
         if first:
             first = False
             currentCategory = thisCategory
             currentCount += 1
@@ -93,15 +83,16 @@
                 currentCount += 1
             else:
                 # This is a new category.
                 if currentCount < minLength:
                     # The category region that was just seen will not be
                     # emitted.
                     if suppressing:
-                        # Already suppressing. Suppress the just-seen region too.
+                        # Already suppressing. Suppress the just-seen
+                        # region too.
                         suppressedCount += currentCount
                     else:
                         # Start suppressing.
                         suppressedCount = currentCount
                         suppressing = True
                 else:
                     if suppressing:
```

### Comparing `dark-matter-4.0.84/dark/taxonomy.py` & `dark-matter-4.0.9/dark/taxonomy.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,107 +1,104 @@
-from __future__ import annotations
-
+import sqlite3
 from six import string_types
 from operator import attrgetter
 from cachetools import LRUCache, cachedmethod
 from json import dumps
 import re
 from collections import namedtuple
 from os import environ
-from typing import Optional, Iterable
-import argparse
 
 from dark.database import getDatabaseConnection
-from dark.sqlite3 import sqliteConnect
 
-TAXONOMY_DATABASE_ENV_VAR = "DARK_MATTER_TAXONOMY_DATABASE"
-TAXONOMY_DATABASE_COMMAND_LINE_OPTION = "taxonomyDatabase"
+TAXONOMY_DATABASE_ENV_VAR = 'DARK_MATTER_TAXONOMY_DATABASE'
+TAXONOMY_DATABASE_COMMAND_LINE_OPTION = 'taxonomyDatabase'
 
-LineageElement = namedtuple("LineageElement", ("taxid", "name", "rank"))
+LineageElement = namedtuple('LineageElement', ('taxid', 'name', 'rank'))
 
-# These are name/rank tuples that indicate that a lineage is from an RNA
+# These are rank/name tuples that indicate that a lineage is from an RNA
 # virus.
-RNA_VIRUS_LINEAGE_ELEMENTS = set(
-    (
-        ("Retroviridae", "family"),
-        ("Pseudoviridae", "family"),
-        ("Riboviria", "realm"),
-    )
-)
-
-FUNGUS_ONLY_VIRUS_REGEX = re.compile(r"\b(?:mycovirus)\b", re.I)
+RNA_VIRUS_LINEAGE_ELEMENTS = set((
+    ('family', 'Retroviridae'),
+    ('family', 'Pseudoviridae'),
+    ('realm', 'Riboviria'),
+))
+
+FUNGUS_ONLY_VIRUS_REGEX = re.compile(
+    r'\b(?:mycovirus)\b',
+    re.I)
 
-FUNGUS_ONLY_GENERA: set[str] = set()
+FUNGUS_ONLY_GENERA = {
+}
 
 FUNGUS_ONLY_FAMILIES = {
-    "Chrysoviridae",  # Infects penicillum. E.g., NC_040738.1
-    "Totiviridae",  # Actually infects fungi and protozoa.
+    'Chrysoviridae',  # Infects penicillum. E.g., NC_040738.1
+    'Totiviridae',  # Actually infects fungi and protozoa.
 }
 
 PLANT_ONLY_VIRUS_REGEX = re.compile(
-    r"\b(?:grapevine|mosaic|mottle|blotch virus|viroid|tobacco|"
-    r"tombus|cherry virus|bean endornavirus|coffee ringspot virus|"
-    r"Odontoglossum ringspot virus|hibiscus|Obuda pepper virus|"
-    r"tobamovirus|"
-    r"wheat stripe virus|Lettuce necrotic yellows virus|citrus yellow|"
-    r"Maize fine streak virus|dwarf (fiji)?virus|maize stripe virus|"
-    r"tomato brown rugose fruit virus|turnip vein-clearing virus|"
-    r"chlorotic spot virus)\b",
-    re.I,
-)
+    r'\b(?:grapevine|mosaic|mottle|blotch virus|viroid|tobacco|'
+    r'tombus|cherry virus|bean endornavirus|coffee ringspot virus|'
+    r'Odontoglossum ringspot virus|hibiscus|Obuda pepper virus|'
+    r'tobamovirus|'
+    r'wheat stripe virus|Lettuce necrotic yellows virus|citrus yellow|'
+    r'Maize fine streak virus|dwarf (fiji)?virus|maize stripe virus|'
+    r'tomato brown rugose fruit virus|turnip vein-clearing virus|'
+    r'chlorotic spot virus)\b',
+    re.I)
 
 PLANT_ONLY_GENERA = {
-    "Emaravirus",  # In Bunyavirales.
-    "Idaeovirus",  # Unassigned.
-    "Ourmiavirus",  # In Botourmiaviridae.
-    "Polemovirus",  # Unassigned.
-    "Sobemovirus",  # Unassigned.
-    "Tospovirus",  # (Misclassified?) in Peribunyaviridae (e.g., NC_040742.1)
-    "Umbravirus",  # In Tombusviridae.
-    "Varicosavirus",  # In Rhabdoviridae.
+    'Emaravirus',  # In Bunyavirales.
+    'Idaeovirus',  # Unassigned.
+    'Ourmiavirus',  # In Botourmiaviridae.
+    'Polemovirus',  # Unassigned.
+    'Sobemovirus',  # Unassigned.
+    'Tospovirus',  # (Misclassified?) in Peribunyaviridae (e.g., NC_040742.1)
+    'Umbravirus',  # In Tombusviridae.
+    'Varicosavirus',  # In Rhabdoviridae.
 }
 
 PLANT_ONLY_FAMILIES = {
-    "Aspiviridae",  # (Formerly Ophioviridae) in Serpentovirales.
-    "Avsunviroidae",  # Viroids.
-    "Betaflexiviridae",  # In Tymovirales.
-    "Bromoviridae",  # Unassigned.
-    "Caulimoviridae",  # In Ortervirales.
-    "Closteroviridae",  # Unassigned.
-    "Geminiviridae",  # Unassigned.
-    "Luteoviridae",  # Unassigned.
-    "Nanoviridae",  # Unassigned.
-    "Partitiviridae",  # Unassigned.
-    "Pospiviroidae",  # Unassigned (viroids).
-    "Secoviridae",  # In Picornavirales.
-    "Tombusviridae",  # Unassigned.
-    "Tospoviridae",  # In Bunyavirales.
-    "Virgaviridae",  # Unassigned.
+    'Aspiviridae',  # (Formerly Ophioviridae) in Serpentovirales.
+    'Avsunviroidae',  # Viroids.
+    'Betaflexiviridae',  # In Tymovirales.
+    'Bromoviridae',  # Unassigned.
+    'Caulimoviridae',  # In Ortervirales.
+    'Closteroviridae',  # Unassigned.
+    'Geminiviridae',  # Unassigned.
+    'Luteoviridae',  # Unassigned.
+    'Nanoviridae',  # Unassigned.
+    'Partitiviridae',  # Unassigned.
+    'Pospiviroidae',  # Unassigned (viroids).
+    'Secoviridae',  # In Picornavirales.
+    'Tombusviridae',  # Unassigned.
+    'Tospoviridae',  # In Bunyavirales.
+    'Virgaviridae',  # Unassigned.
 }
 
 
-PLANT_ONLY_ORDERS = {"Tymovirales"}
+PLANT_ONLY_ORDERS = {
+    'Tymovirales'
+}
 
 
 class _UnknownNameError(Exception):
     "An unknown name was used."
 
 
-class LineageFetcher:
+class LineageFetcher(object):
     """
     Provide access to the NCBI taxonomy database so we can retrieve the lineage
     of title sequences hit by BLAST.
     """
-
     def __init__(self, db=None, cursor=None):
         self._db = db or getDatabaseConnection()
         self._cursor = cursor or self._db.cursor()
         self._cache = {}
 
-    def lineage(self, title: str) -> list[tuple[int, str]]:
+    def lineage(self, title):
         """
         Get lineage information from the taxonomy database for a given title.
 
         @param title: A C{str} sequence title (e.g., from a BLAST hit). Of the
             form 'gi|63148399|gb|DQ011818.1| Description...'. It is the gi
             number (63148399 in this example) that is looked up in the taxonomy
             database.
@@ -112,61 +109,61 @@
             preceeding one. If no taxonomy is found, the returned list will be
             empty.
         """
         if title in self._cache:
             return self._cache[title]
 
         lineage = []
-        gi = int(title.split("|")[1])
-        query = "SELECT taxID FROM gi_taxid WHERE gi = %d" % gi
+        gi = int(title.split('|')[1])
+        query = 'SELECT taxID FROM gi_taxid WHERE gi = %d' % gi
 
         try:
             while True:
                 self._cursor.execute(query)
                 taxID = self._cursor.fetchone()[0]
                 if taxID == 1:
                     break
-                query = "SELECT name FROM names WHERE taxId = %s" % taxID
+                query = 'SELECT name FROM names WHERE taxId = %s' % taxID
                 self._cursor.execute(query)
                 scientificName = self._cursor.fetchone()[0]
                 lineage.append((taxID, scientificName))
                 # Move up to the parent.
-                query = "SELECT parent_taxID FROM nodes WHERE taxID = %s" % taxID
+                query = ('SELECT parent_taxID FROM nodes WHERE taxID = %s' %
+                         taxID)
         except TypeError:
             lineage = []
 
         self._cache[title] = lineage
         return lineage
 
-    def close(self) -> None:
+    def close(self):
         """
         Close the database connection and render self invalid. Any subsequent
         re-use of self will raise an error.
         """
         self._cursor.close()
         self._db.close()
         self._cursor = self._db = self._cache = None
 
 
-class Taxonomy:
+class Taxonomy(object):
     """
     Provide access to the NCBI taxonomy database so we can retrieve the
     taxonomy lineage corresponding to an accession number.
 
     @param dbFilenameOrConnection: Either a C{str} database filename or an
         open sqlite3 database. The database must contain taxonomy information
         with tables and columns named as in the building scripts used in
         https://github.com/acorg/ncbi-taxonomy-database
     """
-
-    CACHE_SIZE = 10e6
+    CACHE_SIZE = 10E6
 
     def __init__(self, dbFilenameOrConnection):
         if isinstance(dbFilenameOrConnection, string_types):
-            self._db = sqliteConnect(dbFilenameOrConnection)
+            self._db = sqlite3.connect(dbFilenameOrConnection)
             self._closeConnection = True
         else:
             self._db = dbFilenameOrConnection
             self._closeConnection = False
         self._lineageCache = LRUCache(maxsize=self.CACHE_SIZE)
         self._hostsCache = LRUCache(maxsize=self.CACHE_SIZE)
         self._plantVirusCache = LRUCache(maxsize=self.CACHE_SIZE)
@@ -200,42 +197,43 @@
         cursor = self._db.cursor()
         execute = cursor.execute
         fetchone = cursor.fetchone
 
         lineage = []
 
         while taxid != 1:
-            execute("SELECT name FROM names WHERE taxid = ?", (taxid,))
+            execute('SELECT name FROM names WHERE taxid = ?', (taxid,))
             result = fetchone()
             if result is None:
                 raise ValueError(
-                    "Could not find taxonomy id %r in names table" % (taxid,)
-                )
+                    'Could not find taxonomy id %r in names table' %
+                    (taxid,))
             name = result[0]
-            execute("SELECT parent_taxid, rank FROM nodes WHERE taxid = ?", (taxid,))
+            execute('SELECT parent_taxid, rank FROM nodes WHERE taxid = ?',
+                    (taxid,))
             result = fetchone()
             if result is None:
                 raise ValueError(
-                    "Could not find taxonomy id %r in nodes table" % (taxid,)
-                )
+                    'Could not find taxonomy id %r in nodes table' %
+                    (taxid,))
 
             parentTaxid, rank = result
             element = LineageElement(taxid, name, rank)
 
             if not (skipFunc and skipFunc(element)):
                 lineage.append(element)
 
             if stopFunc and stopFunc(element):
                 break
 
             taxid = parentTaxid
 
         return tuple(lineage)
 
-    @cachedmethod(attrgetter("_lineageCache"))
+    @cachedmethod(attrgetter('_lineageCache'))
     def lineage(self, id_, skipFunc=None, stopFunc=None):
         """
         Get lineage information from the taxonomy database for an
         accession number, name, or taxonomy id.
 
         @param id_: A C{str} accession number, C{str} name (e.g.,
             'Hymenoptera'), or an C{int} taxonomy id. If a C{str} accession
@@ -258,66 +256,67 @@
             (scientific) name, and the rank (species, genus, etc). The first
             element in the tuple corresponds to the passed C{id_} and each
             successive element is the parent of the preceeding one. The top
             level of the taxonomy hierarchy (with taxid = 1) is not included
             in the returned tuple.
         """
         if isinstance(id_, int):
-            return self.lineageFromTaxid(id_, skipFunc=skipFunc, stopFunc=stopFunc)
+            return self.lineageFromTaxid(
+                id_, skipFunc=skipFunc, stopFunc=stopFunc)
 
         cursor = self._db.cursor()
 
-        cursor.execute("SELECT taxid FROM accession_taxid WHERE accession = ?", (id_,))
+        cursor.execute(
+            'SELECT taxid FROM accession_taxid WHERE accession = ?', (id_,))
         row = cursor.fetchone()
         if row:
             return self.lineageFromTaxid(
-                int(row[0]), skipFunc=skipFunc, stopFunc=stopFunc
-            )
+                int(row[0]), skipFunc=skipFunc, stopFunc=stopFunc)
 
         try:
             taxid = self.taxIdFromName(id_)
         except _UnknownNameError:
             raise ValueError(
-                "Could not find %r in accession_taxid or names tables" % id_
-            )
+                'Could not find %r in accession_taxid or names tables' % id_)
         else:
-            return self.lineageFromTaxid(taxid, skipFunc=skipFunc, stopFunc=stopFunc)
+            return self.lineageFromTaxid(
+                taxid, skipFunc=skipFunc, stopFunc=stopFunc)
 
-    @cachedmethod(attrgetter("_hostsCache"))
+    @cachedmethod(attrgetter('_hostsCache'))
     def hostsFromTaxid(self, taxid):
         """
         Get host information from the taxonomy database for a taxonomy id.
 
         @param taxid: An C{int} taxonomy id.
         @raise AttributeError: If C{self.close} has been called.
         @return: A C{set} of C{str} host names. If no host information is found
             for C{taxid}, return C{None}.
         """
         cursor = self._db.cursor()
-        cursor.execute("SELECT hosts FROM hosts WHERE taxid = ?", (taxid,))
+        cursor.execute('SELECT hosts FROM hosts WHERE taxid = ?', (taxid,))
         row = cursor.fetchone()
         if row:
-            return set(row[0].split(","))
+            return set(row[0].split(','))
 
     def taxIdFromName(self, name):
         """
         Get a taxonomy id from a name.
 
         @param name: A C{str} taxonomy name. This must be a unique name, as
             found in the names.dmp file of the NCBI taxonomy names.dmp file.
         @raise _UnknownNameError: If a taxonomy id cannot be found for C{name}.
         @return: An C{int} taxonomy id.
         """
         cursor = self._db.cursor()
-        cursor.execute("SELECT taxid FROM names WHERE name = ?", (name,))
+        cursor.execute('SELECT taxid FROM names WHERE name = ?', (name,))
         row = cursor.fetchone()
         if row:
             return int(row[0])
 
-        raise _UnknownNameError("Name %r not found in names tables" % name)
+        raise _UnknownNameError('Name %r not found in names tables' % name)
 
     def hosts(self, id_):
         """
         Get host information from the taxonomy database for an accession number
         or taxonomy id.
 
         @param id_: A C{str} accession number or C{int} taxonomy id.
@@ -330,90 +329,83 @@
             information.
         """
         if isinstance(id_, int):
             return self.hostsFromTaxid(id_)
 
         cursor = self._db.cursor()
 
-        cursor.execute("SELECT taxid FROM accession_taxid WHERE accession = ?", (id_,))
+        cursor.execute(
+            'SELECT taxid FROM accession_taxid WHERE accession = ?',
+            (id_,))
         row = cursor.fetchone()
         if row:
             return self.hostsFromTaxid(int(row[0]))
 
-        cursor.execute("SELECT taxid FROM names WHERE name = ?", (id_,))
+        cursor.execute('SELECT taxid FROM names WHERE name = ?', (id_,))
         row = cursor.fetchone()
         if row:
             return self.hostsFromTaxid(int(row[0]))
 
-    @cachedmethod(attrgetter("_fungusVirusCache"))
-    def isFungusOnlyVirus(self, lineage, title=None) -> bool:
+    @cachedmethod(attrgetter('_fungusVirusCache'))
+    def isFungusOnlyVirus(self, lineage, title=None):
         """
         Determine whether a lineage corresponds to a fungus-only virus (i.e.,
         a virus that only infects fungi hosts).
 
         @param lineage: An iterable of C{tuple}s of taxonomy id, scientific
             name, and rank as returned by C{Taxonomy.lineage}.
         @param title: If not C{None}, a C{str} title of the virus.
         @return: C{True} if the lineage corresponds to a fungus-only virus,
             C{False} otherwise.
         """
         for taxid, name, rank in lineage:
-            if (
-                rank == "family"
-                and name in FUNGUS_ONLY_FAMILIES
-                or rank == "genus"
-                and name in FUNGUS_ONLY_GENERA
-            ):
+            if (rank == 'family' and name in FUNGUS_ONLY_FAMILIES or
+                    rank == 'genus' and name in FUNGUS_ONLY_GENERA):
                 return True
 
         if title and FUNGUS_ONLY_VIRUS_REGEX.search(title):
             return True
 
         # Do host taxonomy database lookups. Try to look up host
         # information at all taxonomy levels. This is (of course) slower,
         # but it (likely, as with plant viruses) results in more
         # fungus-only viruses being identified.
         for taxid, _, _ in lineage:
-            if self.hosts(taxid) == {"fungi"}:
+            if self.hosts(taxid) == {'fungi'}:
                 return True
 
         return False
 
-    @cachedmethod(attrgetter("_plantVirusCache"))
-    def isPlantOnlyVirus(self, lineage, title=None) -> bool:
+    @cachedmethod(attrgetter('_plantVirusCache'))
+    def isPlantOnlyVirus(self, lineage, title=None):
         """
         Determine whether a lineage corresponds to a plant-only virus (i.e.,
         a virus that only infects plant hosts).
 
         @param lineage: An iterable of C{tuple}s of taxonomy id, scientific
             name, and rank as returned by C{Taxonomy.lineage}.
         @param title: If not C{None}, a C{str} title of the virus.
         @return: C{True} if the lineage corresponds to a plant-only virus,
             C{False} otherwise.
         """
         for taxid, name, rank in lineage:
-            if (
-                rank == "order"
-                and name in PLANT_ONLY_ORDERS
-                or rank == "family"
-                and name in PLANT_ONLY_FAMILIES
-                or rank == "genus"
-                and name in PLANT_ONLY_GENERA
-            ):
+            if (rank == 'order' and name in PLANT_ONLY_ORDERS or
+                    rank == 'family' and name in PLANT_ONLY_FAMILIES or
+                    rank == 'genus' and name in PLANT_ONLY_GENERA):
                 return True
 
         if title and PLANT_ONLY_VIRUS_REGEX.search(title):
             return True
 
         # Do host taxonomy database lookups. Try to look up host information at
         # all taxonomy levels. This is (of course) slower, but it does result
         # in more plant-only viruses being identified, e.g., with rank
         # 'unclassified' and name 'Partitiviridae'.
         for taxid, _, _ in lineage:
-            if self.hosts(taxid) == {"plants"}:
+            if self.hosts(taxid) == {'plants'}:
                 return True
 
         return False
 
     @staticmethod
     def subsetLineageByRanks(lineage, func):
         """
@@ -425,102 +417,75 @@
             and returns C{True} or C{False} according to whether the lineage
             element should be retained.
         @return: A filter object that yields C{tuple}s of taxonomy id,
             scientific name, and rank, where the elements are those that
             C{func} returns C{True}. The elements in the returned value will
             be in the order in which they are present in C{lineage}.
         """
-        return filter(lambda thisLineage: func(thisLineage.rank), lineage)
+        return filter(lambda l: func(l.rank), lineage)
 
-    def close(self) -> None:
+    def close(self):
         """
         Close the database connection (if we opened it).
         """
         if self._closeConnection:
             self._db.close()
         # Set self._db to None so self.lineage will raise an AttributeError
         # exception if it is called again.
         self._db = None
 
-    def __enter__(self) -> Taxonomy:
+    def __enter__(self):
         return self
 
-    def __exit__(self, excType, excValue, traceback) -> None:
+    def __exit__(self, excType, excValue, traceback):
         self.close()
 
 
-def isRetrovirus(lineage: Iterable[LineageElement]) -> bool:
+def isRetrovirus(lineage):
     """
     Determine whether a lineage corresponds to a retrovirus.
 
     @param lineage: An iterable of C{LineageElement} instances.
     @return: C{True} if the lineage corresponds to a retrovirus, C{False}
         otherwise.
     """
     for element in lineage:
-        if element.rank == "family" and element.name == "Retroviridae":
+        if element.rank == 'family' and element.name == 'Retroviridae':
             return True
 
     return False
 
 
 def isRNAVirus(lineage):
     """
     Determine whether a lineage corresponds to an RNA virus.
 
     @param lineage: An iterable of C{LineageElement} instances.
     @return: C{True} if the lineage corresponds to an RNA virus, C{False}
         otherwise.
     """
     for element in lineage:
-        if (element.name, element.rank) in RNA_VIRUS_LINEAGE_ELEMENTS:
+        if (element.rank, element.name) in RNA_VIRUS_LINEAGE_ELEMENTS:
             return True
 
     return False
 
 
-def isDNAVirus(lineage: Iterable[LineageElement]) -> bool:
+def isDNAVirus(lineage):
     """
     Determine whether a lineage corresponds to an DNA virus.
 
     @param lineage: An iterable of C{LineageElement} instances.
     @return: C{True} if the lineage corresponds to a DNA virus, C{False}
         otherwise.
     """
     return not isRNAVirus(lineage)
 
 
-def isAllowedTaxonomicRank(allowedTaxonomicRanks, lineage):
-    """
-    Determine whether a lineage matches a set of desired ranks.
-
-    @param allowedTaxonomicRanks: If not C{None}, a set of (case insensitive)
-        acceptable (name, rank) C{str} tuples. E.g.,
-            set((
-                ("nidovirales", "order"),
-                ("retroviridae", "family"),
-            ))
-    @param lineage: An iterable of C{LineageElement} instances.
-    @return: C{True} if the lineage matches at least one of the name:rank
-        pairs. Else C{False}.
-    """
-    lcAllowedTaxonomicRanks = set()
-    for name, rank in allowedTaxonomicRanks:
-        lcAllowedTaxonomicRanks.add((name.lower(), rank.lower()))
-
-    for element in lineage:
-        if (element.name.lower(), element.rank.lower()) in lcAllowedTaxonomicRanks:
-            return True
-
-    return False
-
-
-def formatLineage(
-    lineage, namesOnly: bool = False, separator: str = ", ", prefix: str = ""
-) -> str:
+def formatLineage(lineage, namesOnly=False, separator=None, prefix=''):
     """
     Format a lineage for printing.
 
     @param lineage: An iterable of C{LineageElement} instances.
     @param namesOnly: If C{True} only print taxonomic names.
     @param separator: A C{str} separator to put between fields. If C{None},
         return a space-padded aligned columns.
@@ -528,159 +493,148 @@
     @return: A formatted C{str} for printing.
     """
     if namesOnly:
         # The separator is guaranteed to be set by our caller.
         return prefix + separator.join(element.name for element in lineage)
 
     if separator is not None:
-        return "\n".join(
-            "%s%s%s%s%s%s" % (prefix, rank, separator, name, separator, taxid)
-            for (taxid, name, rank) in lineage
-        )
+        return '\n'.join(
+            '%s%s%s%s%s%s' % (prefix, rank, separator, name, separator, taxid)
+            for (taxid, name, rank) in lineage)
 
     # This is a bit slow, walking through the lineage list 3 times.
     taxidWidth = max(len(str(element.taxid)) for element in lineage)
     nameWidth = max(len(element.name) for element in lineage)
     rankWidth = max(len(element.rank) for element in lineage)
 
-    return "\n".join(
-        "%s%-*s %-*s %*d"
-        % (prefix, rankWidth, rank, nameWidth, name, taxidWidth, taxid)
-        for (taxid, name, rank) in lineage
-    )
+    return '\n'.join(
+        '%s%-*s %-*s %*d' % (
+            prefix, rankWidth, rank, nameWidth, name, taxidWidth, taxid)
+        for (taxid, name, rank) in lineage)
 
 
-def lineageTaxonomyLinks(lineage: Iterable[LineageElement]) -> list[str]:
+def lineageTaxonomyLinks(lineage):
     """
     Get HTML links for a lineage.
 
     @param lineage: An iterable of C{LineageElement} instances.
     @return: A C{list} of HTML C{str} links.
     """
     names = [element.name for element in lineage]
-    names[0] = "taxon"
+    assert names[-1] == 'Viruses'
+    names[0] = 'taxon'
 
     taxids = [element.taxid for element in lineage]
 
     return [
-        '<a href="%s%s">%s</a>'
-        % ("https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=", taxid, name)
-        for taxid, name in list(zip(taxids, names))[:-1]
+        '<a href="%s%s">%s</a>' % (
+            'https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=',
+            taxid, name) for taxid, name in list(zip(taxids, names))[:-1]
     ]
 
 
-class _HierarchyNode:
-    def __init__(self, name: str):
+class _HierarchyNode(object):
+    def __init__(self, name):
         self.name = name
         self.count = 0
-        self.nodes: dict[str, _HierarchyNode] = {}
-        self.tips: list[tuple[str, str]] = []
+        self.nodes = {}
+        self.tips = []
 
-    def addChild(self, name) -> _HierarchyNode:
+    def addChild(self, name):
         self.count += 1
         try:
             node = self.nodes[name]
         except KeyError:
             node = self.nodes[name] = _HierarchyNode(name)
 
         return node
 
-    def addTip(self, name: str, genomeAccession: str) -> None:
+    def addTip(self, name, genomeAccession):
         self.count += 1
         self.tips.append((name, genomeAccession))
 
-    def toDict(self) -> dict:
+    def toDict(self):
         nodes = [node.toDict() for node in self.nodes.values()]
 
         if self.tips:
-            nodes.extend(
-                [
-                    {
-                        "text": name,
-                        "href": "#pathogen-" + accession,
-                    }
-                    for (name, accession) in sorted(self.tips)
-                ]
-            )
+            nodes.extend([{
+                'text': name,
+                'href': '#pathogen-' + accession,
+            } for (name, accession) in sorted(self.tips)])
 
         return {
             # 'count': self.count,
-            "nodes": nodes,
+            'nodes': nodes,
             # 'name': self.name,
             # 'tips': self.tips,
-            "text": "%s (%d)" % (self.name, self.count),
+            'text': '%s (%d)' % (self.name, self.count),
         }
 
 
-class Hierarchy:
+class Hierarchy(object):
     """
     Collect information about a lineages in a taxonomy hierarchy.
     """
-
-    def __init__(self, rootName: str = "Viruses"):
+    def __init__(self, rootName='Viruses'):
         self._root = _HierarchyNode(rootName)
 
-    def add(self, lineage: Iterable[LineageElement], genomeAccession: str) -> None:
+    def add(self, lineage, genomeAccession):
         """
         Add a new lineage.
 
         @param lineage: An iterable of C{LineageElement} instances.
         @param genomeAccession: A C{str} pathogen accession number.
         """
         names = [element.name for element in lineage]
 
+        assert names[-1] == 'Viruses'
+
         n = len(names) - 2
         node = self._root
 
         while n:
             node = node.addChild(names[n])
             n -= 1
 
         node.addTip(names[0], genomeAccession)
 
     def toJSON(self):
         return dumps([self._root.toDict()])
 
 
-def addTaxonomyDatabaseCommandLineOptions(parser: argparse.ArgumentParser) -> None:
+def addTaxonomyDatabaseCommandLineOptions(parser):
     """
     Add standard taxonomy database command-line options to an argparse parser.
 
     @param parser: An C{argparse.ArgumentParser} instance.
     """
     parser.add_argument(
-        "--" + TAXONOMY_DATABASE_COMMAND_LINE_OPTION,
-        metavar="DATABASE-FILE",
-        help=(
-            "The file holding an sqlite3 taxonomy database. See "
-            "https://github.com/acorg/ncbi-taxonomy-database for how to "
-            "build one. If not specified, the value in the %r environment "
-            "variable (if any) will be used." % TAXONOMY_DATABASE_ENV_VAR
-        ),
-    )
+        '--' + TAXONOMY_DATABASE_COMMAND_LINE_OPTION, metavar='DATABASE-FILE',
+        help=('The file holding an sqlite3 taxonomy database. See '
+              'https://github.com/acorg/ncbi-taxonomy-database for how to '
+              'build one. If not specified, the value in the %r environment '
+              'variable (if any) will be used.' % TAXONOMY_DATABASE_ENV_VAR), )
 
 
-def parseTaxonomyDatabaseCommandLineOptions(args, parser) -> Optional[Taxonomy]:
+def parseTaxonomyDatabaseCommandLineOptions(args, parser):
     """
     Examine parsed command-line options and return a Taxonomy instance. Exits
     if no taxonomy database is given or named in the TAXONOMY_DATABASE_ENV_VAR
     environment variable.
 
     @param args: An argparse namespace, as returned by the argparse
         C{parse_args} function.
     @param parser: An C{argparse.ArgumentParser} instance.
     @return: A C{Taxonomy} instance, or C{None} if no database filename is
         given or set via the environment variable named in
         TAXONOMY_DATABASE_ENV_VAR.
     """
-    filename = args.taxonomyDatabase or environ.get(TAXONOMY_DATABASE_ENV_VAR)
+    filename = args.taxonomyDatabase or environ.get(
+        TAXONOMY_DATABASE_ENV_VAR)
 
     if filename:
         return Taxonomy(filename)
     else:
         parser.error(
-            "A taxonomy database file must be given, either via --%s on "
-            "the command line or via the %r environment variable."
-            % (TAXONOMY_DATABASE_COMMAND_LINE_OPTION, TAXONOMY_DATABASE_ENV_VAR)
-        )
-
-        return None
+            'A taxonomy database file must be given, either via --%s on '
+            'the command line or via the %r environment variable.' %
+            (TAXONOMY_DATABASE_COMMAND_LINE_OPTION, TAXONOMY_DATABASE_ENV_VAR))
```

### Comparing `dark-matter-4.0.84/dark/titles.py` & `dark-matter-4.0.9/dark/titles.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,15 +19,15 @@
     titles = defaultdict(int)
     for readAlignments in readsAlignments:
         for alignment in readAlignments:
             titles[alignment.subjectTitle] += 1
     return titles
 
 
-class TitleAlignment:
+class TitleAlignment(object):
     """
     Hold information about a read's HSPs for a title alignment.
 
     @param read: The C{Read} that aligned.
     @param hsps: A C{list} of L{dark.hsp.HSP} (or subclass) instances.
     """
 
@@ -38,16 +38,16 @@
     def toDict(self):
         """
         Get information about a title alignment as a dictionary.
 
         @return: A C{dict} representation of the title aligment.
         """
         return {
-            "hsps": [hsp.toDict() for hsp in self.hsps],
-            "read": self.read.toDict(),
+            'hsps': [hsp.toDict() for hsp in self.hsps],
+            'read': self.read.toDict(),
         }
 
 
 class TitleAlignments(list):
     """
     Holds information about a list of alignments against a sequence.
 
@@ -189,51 +189,49 @@
             along with the bit score of the matching read.
         """
         result = defaultdict(list)
 
         for titleAlignment in self:
             for hsp in titleAlignment.hsps:
                 score = hsp.score.score
-                for subjectOffset, base, _ in titleAlignment.read.walkHSP(
-                    hsp, includeWhiskers=False
-                ):
+                for (subjectOffset, base, _) in titleAlignment.read.walkHSP(
+                        hsp, includeWhiskers=False):
                     result[subjectOffset].append((score, base))
 
         return result
 
-    def residueCounts(self, convertCaseTo="upper"):
+    def residueCounts(self, convertCaseTo='upper'):
         """
         Count residue frequencies at all sequence locations matched by reads.
 
         @param convertCaseTo: A C{str}, 'upper', 'lower', or 'none'.
             If 'none', case will not be converted (both the upper and lower
             case string of a residue will be present in the result if they are
             present in the read - usually due to low complexity masking).
         @return: A C{dict} whose keys are C{int} offsets into the title
             sequence and whose values are C{Counters} with the residue as keys
             and the count of that residue at that location as values.
         """
-        if convertCaseTo == "none":
-
+        if convertCaseTo == 'none':
             def convert(x):
                 return x
-
-        elif convertCaseTo == "lower":
+        elif convertCaseTo == 'lower':
             convert = str.lower
-        elif convertCaseTo == "upper":
+        elif convertCaseTo == 'upper':
             convert = str.upper
         else:
-            raise ValueError("convertCaseTo must be one of 'none', 'lower', or 'upper'")
+            raise ValueError(
+                "convertCaseTo must be one of 'none', 'lower', or 'upper'")
 
         counts = defaultdict(Counter)
 
         for titleAlignment in self:
             read = titleAlignment.read
             for hsp in titleAlignment.hsps:
-                for subjectOffset, residue, inMatch in read.walkHSP(hsp):
+                for (subjectOffset, residue, inMatch) in read.walkHSP(hsp):
                     counts[subjectOffset][convert(residue)] += 1
 
         return counts
 
     def summary(self):
         """
         Summarize the alignments for this subject.
@@ -245,33 +243,34 @@
             hspCount: The C{int} number of hsps that match the subject.
             medianScore: The C{float} median score of the matching reads.
             readCount: The C{int} number of reads that match the subject.
             subjectLength: The C{int} length of the subject.
             subjectTitle: The C{str} title of the subject.
         """
         return {
-            "bestScore": self.bestHsp().score.score,
-            "coverage": self.coverage(),
-            "hspCount": self.hspCount(),
-            "medianScore": self.medianScore(),
-            "readCount": self.readCount(),
-            "subjectLength": self.subjectLength,
-            "subjectTitle": self.subjectTitle,
+            'bestScore': self.bestHsp().score.score,
+            'coverage': self.coverage(),
+            'hspCount': self.hspCount(),
+            'medianScore': self.medianScore(),
+            'readCount': self.readCount(),
+            'subjectLength': self.subjectLength,
+            'subjectTitle': self.subjectTitle,
         }
 
     def toDict(self):
         """
         Get information about the title's alignments as a dictionary.
 
         @return: A C{dict} representation of the title's aligments.
         """
         return {
-            "titleAlignments": [titleAlignment.toDict() for titleAlignment in self],
-            "subjectTitle": self.subjectTitle,
-            "subjectLength": self.subjectLength,
+            'titleAlignments': [titleAlignment.toDict()
+                                for titleAlignment in self],
+            'subjectTitle': self.subjectTitle,
+            'subjectLength': self.subjectLength,
         }
 
 
 class TitlesAlignments(dict):
     """
     Holds (as a dictionary) a set of titles, each with its alignments.
 
@@ -291,48 +290,36 @@
         for readAlignments in readsAlignments:
             for alignment in readAlignments:
                 title = alignment.subjectTitle
                 try:
                     titleAlignments = self[title]
                 except KeyError:
                     titleAlignments = self[title] = TitleAlignments(
-                        title, alignment.subjectLength
-                    )
+                        title, alignment.subjectLength)
                 titleAlignments.addAlignment(
-                    TitleAlignment(readAlignments.read, alignment.hsps)
-                )
+                    TitleAlignment(readAlignments.read, alignment.hsps))
 
     def addTitle(self, title, titleAlignments):
         """
         Add a new title to self.
 
         @param title: A C{str} title.
         @param titleAlignments: An instance of L{TitleAlignments}.
         @raises KeyError: If the title is already present.
         """
         if title in self:
-            raise KeyError(
-                "Title %r already present in TitlesAlignments instance." % title
-            )
+            raise KeyError('Title %r already present in TitlesAlignments '
+                           'instance.' % title)
         else:
             self[title] = titleAlignments
 
-    def filter(
-        self,
-        minMatchingReads=None,
-        maxMatchingReads=None,
-        minMedianScore=None,
-        withScoreBetterThan=None,
-        minNewReads=None,
-        minCoverage=None,
-        maxTitles=None,
-        sortOn="maxScore",
-        titleRegex=None,
-        negativeTitleRegex=None,
-    ):
+    def filter(self, minMatchingReads=None, maxMatchingReads=None,
+               minMedianScore=None, withScoreBetterThan=None, minNewReads=None,
+               minCoverage=None, maxTitles=None, sortOn='maxScore',
+               titleRegex=None, negativeTitleRegex=None):
         """
         Filter the titles in self.
 
         @param minMatchingReads: titles that are matched by fewer reads
             are unacceptable.
         @param maxMatchingReads: titles that are matched by more reads
             are unacceptable.
@@ -365,78 +352,75 @@
         else:
             if self.readSetFilter is None:
                 self.readSetFilter = ReadSetFilter(minNewReads)
             readSetFilter = self.readSetFilter
 
         if maxTitles is not None and len(self) > maxTitles:
             if maxTitles < 0:
-                raise ValueError("maxTitles (%r) cannot be negative." % maxTitles)
+                raise ValueError('maxTitles (%r) cannot be negative.' %
+                                 maxTitles)
             else:
                 # There are too many titles. Make a sorted list of them so
                 # we loop through them (below) in the desired order and can
                 # break when/if we've reached the maximum. We can't just
                 # take the first maxTitles titles from the sorted list now,
                 # as some of those titles might later be discarded by the
                 # filter and then we'd return a result with fewer titles
                 # than we should.
                 titles = self.sortTitles(sortOn)
         else:
             titles = list(self)
 
-        if titleRegex or negativeTitleRegex:
+        if (titleRegex or negativeTitleRegex):
             titleFilter = TitleFilter(
-                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex
-            )
+                positiveRegex=titleRegex, negativeRegex=negativeTitleRegex)
         else:
             titleFilter = None
 
         titlesToKeep = set()
 
         for title in titles:
             # Test max titles up front, as it may be zero.
             if maxTitles is not None and len(titlesToKeep) == maxTitles:
                 break
 
             # Test positive and negative regexps.
-            if titleFilter and titleFilter.accept(title) == TitleFilter.REJECT:
+            if (titleFilter and
+                    titleFilter.accept(title) == TitleFilter.REJECT):
                 continue
 
             titleAlignments = self[title]
-            if (
-                minMatchingReads is not None
-                and titleAlignments.readCount() < minMatchingReads
-            ):
+            if (minMatchingReads is not None and
+                    titleAlignments.readCount() < minMatchingReads):
                 continue
 
-            if (
-                maxMatchingReads is not None
-                and titleAlignments.readCount() > maxMatchingReads
-            ):
+            if (maxMatchingReads is not None and
+                    titleAlignments.readCount() > maxMatchingReads):
                 continue
 
             # To compare the median score with another score, we must
             # convert both values to instances of the score class used in
             # this data set so they can be compared without us needing to
             # know if numerically greater scores are considered better or
             # not.
-            if minMedianScore is not None and self.scoreClass(
-                titleAlignments.medianScore()
-            ) < self.scoreClass(minMedianScore):
+            if (minMedianScore is not None and
+                    self.scoreClass(titleAlignments.medianScore()) <
+                    self.scoreClass(minMedianScore)):
                 continue
 
-            if (
-                withScoreBetterThan is not None
-                and not titleAlignments.hasScoreBetterThan(withScoreBetterThan)
-            ):
+            if (withScoreBetterThan is not None and not
+                    titleAlignments.hasScoreBetterThan(withScoreBetterThan)):
                 continue
 
-            if minCoverage is not None and titleAlignments.coverage() < minCoverage:
+            if (minCoverage is not None and
+                    titleAlignments.coverage() < minCoverage):
                 continue
 
-            if readSetFilter and not readSetFilter.accept(title, titleAlignments):
+            if (readSetFilter and not
+                    readSetFilter.accept(title, titleAlignments)):
                 continue
 
             titlesToKeep.add(title)
 
         # Filter self.
         for title in list(self):
             if title not in titlesToKeep:
@@ -446,57 +430,50 @@
 
     def hsps(self):
         """
         Get all HSPs for all the alignments for all titles.
 
         @return: A generator yielding L{dark.hsp.HSP} instances.
         """
-        return (
-            hsp
-            for titleAlignments in self.values()
-            for alignment in titleAlignments
-            for hsp in alignment.hsps
-        )
+        return (hsp for titleAlignments in self.values()
+                for alignment in titleAlignments for hsp in alignment.hsps)
 
     def sortTitles(self, by):
         """
         Sort titles by a given attribute and then by title.
 
         @param by: A C{str}, one of 'length', 'maxScore', 'medianScore',
             'readCount', or 'title'.
         @raise ValueError: If an unknown C{by} value is given.
         @return: A sorted C{list} of titles.
         """
         # First sort titles by the secondary key, which is always the title.
         titles = sorted(iter(self))
 
         # Then sort on the primary key (if any).
-        if by == "length":
+        if by == 'length':
+            return sorted(
+                titles, reverse=True,
+                key=lambda title: self[title].subjectLength)
+        if by == 'maxScore':
             return sorted(
-                titles, reverse=True, key=lambda title: self[title].subjectLength
-            )
-        if by == "maxScore":
-            return sorted(titles, reverse=True, key=lambda title: self[title].bestHsp())
-        if by == "medianScore":
+                titles, reverse=True, key=lambda title: self[title].bestHsp())
+        if by == 'medianScore':
             return sorted(
-                titles,
-                reverse=True,
-                key=lambda title: self.scoreClass(self[title].medianScore()),
-            )
-        if by == "readCount":
+                titles, reverse=True,
+                key=lambda title: self.scoreClass(self[title].medianScore()))
+        if by == 'readCount':
             return sorted(
-                titles, reverse=True, key=lambda title: self[title].readCount()
-            )
-        if by == "title":
+                titles, reverse=True,
+                key=lambda title: self[title].readCount())
+        if by == 'title':
             return titles
 
-        raise ValueError(
-            'Sort attribute must be one of "length", "maxScore", '
-            '"medianScore", "readCount", "title".'
-        )
+        raise ValueError('Sort attribute must be one of "length", "maxScore", '
+                         '"medianScore", "readCount", "title".')
 
     def summary(self, sortOn=None):
         """
         Summarize all the alignments for this title.
 
         @param sortOn: A C{str} attribute to sort titles on. One of 'length',
             'maxScore', 'medianScore', 'readCount', or 'title'.
@@ -531,36 +508,29 @@
         # to add them at the end, but be careful / think.
         #
         # A TAB-separated file can easily be read by awk using e.g.,
         # awk 'BEGIN {FS = "\t"} ...'
 
         result = []
         for titleSummary in self.summary(sortOn):
-            result.append(
-                "\t".join(
-                    [
-                        "%(coverage)f",
-                        "%(medianScore)f",
-                        "%(bestScore)f",
-                        "%(readCount)d",
-                        "%(hspCount)d",
-                        "%(subjectLength)d",
-                        "%(subjectTitle)s",
-                    ]
-                )
-                % titleSummary
-            )
-        return "\n".join(result)
+            result.append('\t'.join([
+                '%(coverage)f',
+                '%(medianScore)f',
+                '%(bestScore)f',
+                '%(readCount)d',
+                '%(hspCount)d',
+                '%(subjectLength)d',
+                '%(subjectTitle)s',
+            ]) % titleSummary)
+        return '\n'.join(result)
 
     def toDict(self):
         """
         Get information about the titles alignments as a dictionary.
 
         @return: A C{dict} representation of the titles aligments.
         """
         return {
-            "scoreClass": self.scoreClass.__name__,
-            "titles": dict(
-                (title, titleAlignments.toDict())
-                for title, titleAlignments in self.items()
-            ),
+            'scoreClass': self.scoreClass.__name__,
+            'titles': dict((title, titleAlignments.toDict())
+                           for title, titleAlignments in self.items()),
         }
```

### Comparing `dark-matter-4.0.84/dark/utils.py` & `dark-matter-4.0.9/dark/utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,33 +1,34 @@
+from __future__ import division
+
 import os
 import re
 import string
+import six
 import bz2
 import gzip
-from pathlib import Path
 from os.path import basename
 from contextlib import contextmanager
 from re import compile
-from statistics import median as _median
-from typing import List, Optional
+import numpy as np
 
 
-def numericallySortFilenames(names: List[str]) -> List[str]:
+def numericallySortFilenames(names):
     """
     Sort (ascending) a list of file names by their numerical prefixes.
     The number sorted on is the numeric prefix of the basename of
     the given filename. E.g., '../output/1.json.bz2' will sort before
     '../output/10.json.bz2'.
 
     @param: A C{list} of file names, each of whose basename starts with a
         string of digits.
     @return: The sorted C{list} of full file names.
     """
 
-    def numericPrefix(name: str) -> int:
+    def numericPrefix(name):
         """
         Find any numeric prefix of C{name} and return it as an C{int}.
 
         @param: A C{str} file name, whose name possibly starts with digits.
         @return: The C{int} number at the start of the name, else 0 if
             there are no leading digits in the name.
         """
@@ -38,113 +39,160 @@
             else:
                 break
         return 0 if count == 0 else int(name[0:count])
 
     return sorted(names, key=lambda name: numericPrefix(basename(name)))
 
 
+# Set up a median function that works on different Python versions and on pypy
+# (even if numpypy is still broken).
+#
+# First try numpy, and check that an ndarray has a partition method (to avoid a
+# shortcoming in pypy numpy, see
+# https://bitbucket.org/pypy/numpy/issues/12/median-calling-ndarraypartition
+# If numpy seems ok, use it. Else try for the Python 3.4 median function, else
+# write our own.
+
+_a = np.array([1])
+
+try:
+    _a.partition
+except AttributeError:
+    # Cannot use numpy. Try for the new (Python 3.4) built-in function.
+    try:
+        from statistics import median as _median
+    except ImportError:
+        def _median(numbers):
+            """
+            Find the median of a set of numbers.
+
+            @param numbers: A C{list} of numeric values.
+            @return: The median value in C{numbers}.
+            """
+            numbers = sorted(numbers)
+            n = len(numbers)
+            if n % 2:
+                return numbers[n // 2]
+            else:
+                n //= 2
+                return (numbers[n - 1] + numbers[n]) / 2
+else:
+    # We have a working numpy. Just make sure we raise on an empty list as
+    # numpy returns numpy.nan
+    _median = np.median
+
+del _a
+
+
 def median(numbers):
     """
     Find the median of a set of numbers.
 
     @param numbers: A C{list} of numeric values.
     @raise ValueError: If C{l} is empty.
-    @return: The median of C{numbers}.
+    @return: The median value in C{l}.
     """
+
+    # Handle the zero length case ahead of time because various median
+    # implementations do different things. numpy returns nan, whereas Python
+    # 3.4 and later raise StatisticsError
+
     if len(numbers) == 0:
         # Match the empty-argument exception message of Python's built-in max
         # and min functions.
-        raise ValueError("arg is an empty sequence")
+        raise ValueError('arg is an empty sequence')
     else:
         return _median(numbers)
 
 
 @contextmanager
-def asHandle(fileNameOrHandle, mode="rt", encoding="UTF-8"):
+def asHandle(fileNameOrHandle, mode='rt', encoding='UTF-8'):
     """
     Decorator for file opening that makes it easy to open compressed files
     and which can be passed an already-open file handle or a file name.
     Based on L{Bio.File.as_handle}.
 
     @param fileNameOrHandle: Either a C{str} or a file handle.
     @param mode: The C{str} mode to use for opening the file.
     @param encoding: The C{str} encoding to use when opening the file.
     @return: A generator that can be turned into a context manager via
         L{contextlib.contextmanager}.
     """
-    if isinstance(fileNameOrHandle, (Path, str)):
-        fileNameOrHandle = str(fileNameOrHandle)
-        if fileNameOrHandle.endswith(".gz"):
-            yield gzip.open(fileNameOrHandle, mode=mode, encoding=encoding)
-        elif fileNameOrHandle.endswith(".bz2"):
-            yield bz2.open(fileNameOrHandle, mode=mode, encoding=encoding)
+    if isinstance(fileNameOrHandle, six.string_types):
+        if fileNameOrHandle.endswith('.gz'):
+            if six.PY3:
+                yield gzip.open(fileNameOrHandle, mode=mode, encoding=encoding)
+            else:
+                yield gzip.GzipFile(fileNameOrHandle, mode=mode)
+        elif fileNameOrHandle.endswith('.bz2'):
+            if six.PY3:
+                yield bz2.open(fileNameOrHandle, mode=mode, encoding=encoding)
+            else:
+                yield bz2.BZ2File(fileNameOrHandle, mode=mode)
         else:
             # Putting mode=mode, encoding=encoding into the following
             # causes a hard-to-understand error from the mocking library.
             with open(fileNameOrHandle) as fp:
                 yield fp
     else:
         yield fileNameOrHandle
 
 
-_rangeRegex = compile(r"^\s*(\d+)(?:\s*-\s*(\d+))?\s*$")
+_rangeRegex = compile(r'^\s*(\d+)(?:\s*-\s*(\d+))?\s*$')
 
 
 # Note: the parseRangeExpression, which uses the following function as a
 #       helper (see below) is more general / powerful than this function on
 #       its own.
-def parseRangeString(s, convertToZeroBased=False, asList: bool = False):
+def parseRangeString(s, convertToZeroBased=False):
     """
     Parse a range string of the form 1-5,12,100-200.
 
     @param s: A C{str} specifiying a set of numbers, given in the form of
         comma separated numeric ranges or individual indices.
     @param convertToZeroBased: If C{True} all indices will have one
         subtracted from them.
     @raise ValueError: If the range in C{s} cannot be parsed.
     @return: A C{set} of all C{int}s in the specified set.
     """
 
-    result = []
-    seen = set()
-    for _range in s.split(","):
+    result = set()
+    for _range in s.split(','):
         match = _rangeRegex.match(_range)
         if match:
             start, end = match.groups()
             start = int(start)
-            end = start if end is None else int(end)
+            if end is None:
+                end = start
+            else:
+                end = int(end)
             if start > end:
                 start, end = end, start
-
-            toAdd = (
-                range(start - 1, end) if convertToZeroBased else range(start, end + 1)
-            )
-
-            for n in toAdd:
-                if n not in seen:
-                    seen.add(n)
-                    result.append(n)
+            if convertToZeroBased:
+                result.update(range(start - 1, end))
+            else:
+                result.update(range(start, end + 1))
         else:
             raise ValueError(
-                "Illegal range %r. Ranges must single numbers or "
-                "number-number." % _range
-            )
+                'Illegal range %r. Ranges must single numbers or '
+                'number-number.' % _range)
 
-    return result if asList else set(result)
+    return result
 
 
 # The following matches range expressions such as
 #
 #   3
 #   3-4
 #   3-4,5
 #   3-4,6,9-10,99
 #
 # including any embedded whitespace.
-_rangeExpressionRegex = re.compile(r"\d+(:?\s*-\s*\d+)?(:?\s*,\s*\d+(:?\s*-\s*\d+)?)*")
+_rangeExpressionRegex = re.compile(
+    r'\d+(:?\s*-\s*\d+)?(:?\s*,\s*\d+(:?\s*-\s*\d+)?)*')
 
 
 def parseRangeExpression(s, convertToZeroBased=False):
     """
     Parse a range string expression of the form "1-5,6 & (12 | 100-200)".
 
     @param s: A C{str} specifiying a range expression, given in the form of
@@ -155,119 +203,131 @@
     @raise ValueError: If the expression in C{s} cannot be evaluated.
     @return: A C{set} of all C{int}s in the specified expression.
     """
     if not s:
         return set()
 
     pos = 0
-    expr = ""
+    expr = ''
     for match in _rangeExpressionRegex.finditer(s):
         start, end = match.span()
         if start > pos:
             expr += s[pos:start]
-        expr += "{%s}" % ",".join(
-            map(str, parseRangeString(match.group(0), convertToZeroBased))
-        )
+        expr += '{%s}' % ','.join(
+            map(str, parseRangeString(match.group(0), convertToZeroBased)))
         pos = end
 
     if pos < len(s):
         expr += s[pos:]
 
     try:
         return eval(expr)
     except Exception:
         raise ValueError(expr)
 
 
+if six.PY3:
+    from io import StringIO
+else:
+    from six import StringIO as sixStringIO
+
+    class StringIO(sixStringIO):
+        """
+        A StringIO class that can be used as a context manager, seeing as the
+        six.StringIO class does not provide __enter__ and __exit__ methods
+        under Python 2.
+        """
+        def __enter__(self):
+            return self
+
+        def __exit__(self, exc_type, exc_val, exc_tb):
+            self.close()
+            return False
+
+
 def baseCountsToStr(counts):
     """
     Convert base counts to a string.
 
     @param counts: A C{Counter} instance.
     @return: A C{str} representation of nucleotide counts at an offset.
     """
-    return " ".join([("%s:%d" % (base, counts[base])) for base in sorted(counts)])
+    return ' '.join([
+        ('%s:%d' % (base, counts[base])) for base in sorted(counts)])
 
 
-def nucleotidesToStr(nucleotides, prefix=""):
+def nucleotidesToStr(nucleotides, prefix=''):
     """
     Convert offsets and base counts to a string.
 
     @param nucleotides: A C{defaultdict(Counter)} instance, keyed
         by C{int} offset, with nucleotides keying the Counters.
     @param prefix: A C{str} to put at the start of each line.
     @return: A C{str} representation of the offsets and nucleotide
         counts for each.
     """
     result = []
     for offset in sorted(nucleotides):
         result.append(
-            "%s%d: %s" % (prefix, offset, baseCountsToStr(nucleotides[offset]))
-        )
-    return "\n".join(result)
+            '%s%d: %s' % (prefix, offset,
+                          baseCountsToStr(nucleotides[offset])))
+    return '\n'.join(result)
 
 
-def countPrint(mesg: str, count: int, len1: int, len2: Optional[int] = None) -> str:
+def countPrint(mesg, count, len1, len2=None):
     """
     Format a message followed by an integer count and a percentage (or
     two, if the sequence lengths are unequal).
 
     @param mesg: a C{str} message.
     @param count: a numeric value.
     @param len1: the C{int} length of sequence 1.
     @param len2: the C{int} length of sequence 2. If C{None}, will
         default to C{len1}.
     @return: A C{str} for printing.
     """
-
-    def percentage(a: int, b: int) -> float:
+    def percentage(a, b):
         """
         What percent of a is b?
 
         @param a: a numeric value.
         @param b: a numeric value.
         @return: the C{float} percentage.
         """
         return 100.0 * a / b if b else 0.0
 
     if count == 0:
-        return "%s: %d" % (mesg, count)
+        return '%s: %d' % (mesg, count)
     else:
         len2 = len2 or len1
         if len1 == len2:
-            return "%s: %d/%d (%.2f%%)" % (mesg, count, len1, percentage(count, len1))
+            return '%s: %d/%d (%.2f%%)' % (
+                mesg, count, len1, percentage(count, len1))
         else:
-            return (
-                "%s: %d/%d (%.2f%%) of sequence 1, "
-                "%d/%d (%.2f%%) of sequence 2"
-                % (
-                    mesg,
-                    count,
-                    len1,
-                    percentage(count, len1),
-                    count,
-                    len2,
-                    percentage(count, len2),
-                )
-            )
+            return ('%s: %d/%d (%.2f%%) of sequence 1, '
+                    '%d/%d (%.2f%%) of sequence 2' % (
+                        mesg,
+                        count, len1, percentage(count, len1),
+                        count, len2, percentage(count, len2)))
 
 
-def pct(a: int, b: int) -> str:
+def pct(a, b):
     """
     Format a string showing two integers and what percentage the first
     is of the second.
 
     @param a: An C{int}, the numerator.
     @param b: An C{int}, the denominator.
     """
     assert 0 <= a <= b
     if b:
-        return "%d/%d (%.3f%%)" % (a, b, (a / b if b else 0.0) * 100.0)
+        return ('%d/%d (%.3f%%)' %
+                (a, b, (a / b if b else 0.0) * 100.0))
     else:
-        return "0/0 (0.000%)"
+        return '0/0 (0.000%)'
 
 
 @contextmanager
 def cd(newdir):
     """
     Trivial context manager for temporarily switching directory.
 
@@ -315,48 +375,10 @@
 
     @param fp: An open file pointer to read. The file must contain lines with
         a name, a TAB, then a replacement name.
     @return: A C{dict} mapping old names to new names.
     """
     result = {}
     for line in fp:
-        oldName, newName = map(str.strip, line.split("\t"))
+        oldName, newName = map(str.strip, line.split('\t'))
         result[oldName] = newName
     return result
-
-
-def matchOffset(leftPaddedReference, leftPaddedQuery):
-    """
-    At what reference offset does a query begin to match a reference?
-
-    @param leftPaddedReference: A left-padded reference C{str}.
-    @param leftPaddedQuery: A left-padded query C{str}.
-    @return: An C{int} offset into the (unpadded) reference.
-    """
-    offset = 0
-    for queryChar, referenceChar in zip(leftPaddedQuery, leftPaddedReference):
-        if queryChar not in " -":
-            break
-        offset += referenceChar not in " -"
-
-    return offset
-
-
-@contextmanager
-def openOr(filename, mode="r", defaultFp=None, specialCaseHyphen=True):
-    """
-    A context manager to either open a file or use a pre-opened default file.
-
-    @param filename: If not C{None}, this is the argument to pass to C{open}
-        along with C{mode}. If C{None}, C{fp} is used.
-    @param mode: The C{str} file opening mode, used if C{filename} is not
-        C{None}.
-    @param defaultFp: An open file-like object to yield if C{filename} is
-        C{None}.
-    @param specialCaseHyphen: If C{True}, treat '-' as a C{None} filename
-        and yield the C{defaultFp}.
-    """
-    if filename is None or filename == "-" and specialCaseHyphen:
-        yield defaultFp
-    else:
-        with open(filename, mode) as fp:
-            yield fp
```

### Comparing `dark-matter-4.0.84/dark_matter.egg-info/SOURCES.txt` & `dark-matter-4.0.9/dark_matter.egg-info/SOURCES.txt`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-LICENSE
 README.md
 setup.py
 bin/aa-info.py
 bin/aa-to-dna.py
 bin/aa-to-properties.py
 bin/adaptor-distances.py
 bin/alignment-panel-civ.py
@@ -18,65 +17,58 @@
 bin/convert-diamond-to-sam.py
 bin/convert-sam-to-fastq.sh
 bin/create-newick-relabeling-output.py
 bin/dark-matter-version.py
 bin/describe-protein-database.py
 bin/dna-to-aa.py
 bin/download-genbank.sh
-bin/download-refseq-viral-fasta.sh
-bin/download-refseq-viral-gbff.sh
 bin/e-value-to-bit-score.py
 bin/extract-ORFs.py
 bin/fasta-base-indices.py
-bin/fasta-count-chars.py
 bin/fasta-count.py
-bin/fasta-coverage.py
 bin/fasta-diff.sh
-bin/fasta-find.py
 bin/fasta-identity-table.py
 bin/fasta-ids.py
 bin/fasta-join.py
 bin/fasta-lengths.py
-bin/fasta-match-offsets.py
 bin/fasta-sequences.py
 bin/fasta-sort.py
 bin/fasta-split-by-id.py
 bin/fasta-split.py
 bin/fasta-subset.py
 bin/fasta-subtraction.py
 bin/fasta-to-phylip.py
-bin/fasta-translate.py
 bin/fasta-variable-sites.py
-bin/fastq-set-quality.py
 bin/filter-fasta-by-complexity.py
 bin/filter-fasta-by-taxonomy.py
 bin/filter-fasta.py
 bin/filter-hits-to-fasta.py
 bin/filter-reads-alignments.py
 bin/filter-sam.py
+bin/find-hits.py
 bin/format-fasta.py
-bin/genbank-grep.py
 bin/genome-protein-summary.py
 bin/get-features.py
 bin/get-hosts.py
 bin/get-reads.py
 bin/get-taxonomy.py
 bin/graph-evalues.py
-bin/ids.py
 bin/local-align.py
 bin/make-consensus.py
 bin/make-fasta-database.py
 bin/make-protein-database.py
 bin/ncbi-fetch-id.py
 bin/newick-to-ascii.py
 bin/noninteractive-alignment-panel.py
 bin/parse-genbank-flat-file.py
 bin/plot-references-by-inter-read-distance.py
 bin/position-summary.py
 bin/pre-commit.sh
+bin/print-blast-xml-for-derek.py
+bin/print-blast-xml.py
 bin/print-read-lengths.py
 bin/proteins-to-pathogens-civ.py
 bin/proteins-to-pathogens.py
 bin/randomize-fasta.py
 bin/read-blast-json.py
 bin/read-blast-xml.py
 bin/reference-read-scores-to-JSON.py
@@ -85,36 +77,33 @@
 bin/run-bwa.py
 bin/sam-coverage-depth.py
 bin/sam-coverage.py
 bin/sam-reference-read-counts.py
 bin/sam-references.py
 bin/sam-to-fasta-alignment.py
 bin/sff-to-fastq.py
-bin/simple-consensus.py
 bin/split-fasta-by-adaptors.py
 bin/subset-protein-database.py
 bin/summarize-fasta-bases.py
 bin/summarize-reads.py
 bin/translate.py
 bin/trim-primers.py
 bin/trim-reads.py
 bin/write-htcondor-job-spec.py
 dark/__init__.py
 dark/aa.py
-dark/aaVars.py
 dark/aligners.py
 dark/alignments.py
 dark/analyze_reads.py
 dark/baseimage.py
 dark/bowtie2.py
 dark/btop.py
 dark/cigar.py
 dark/codonDistance.py
 dark/colors.py
-dark/consensus-with-debugging.py
 dark/consensus.py
 dark/database.py
 dark/dimension.py
 dark/distance.py
 dark/dna.py
 dark/entrez.py
 dark/errors.py
@@ -125,30 +114,27 @@
 dark/filter.py
 dark/fpcache.py
 dark/genbank.py
 dark/genomes.py
 dark/graphics.py
 dark/hsp.py
 dark/html.py
-dark/idutils.py
 dark/intervals.py
 dark/ipynb.py
 dark/local_align.py
 dark/mutations.py
 dark/ncbidb.py
 dark/orfs.py
 dark/process.py
-dark/progress.py
 dark/proteins.py
 dark/reads.py
 dark/sam.py
 dark/score.py
 dark/sequence.py
 dark/simplify.py
-dark/sqlite3.py
 dark/summarize.py
 dark/taxonomy.py
 dark/titles.py
 dark/utils.py
 dark/blast/__init__.py
 dark/blast/alignments.py
 dark/blast/conversion.py
@@ -169,37 +155,34 @@
 dark/diamond/sam.py
 dark_matter.egg-info/PKG-INFO
 dark_matter.egg-info/SOURCES.txt
 dark_matter.egg-info/dependency_links.txt
 dark_matter.egg-info/requires.txt
 dark_matter.egg-info/top_level.txt
 test/test_aa.py
-test/test_aligners.py
 test/test_alignments.py
 test/test_analyze_reads.py
 test/test_bowtie2.py
 test/test_btop.py
 test/test_cigar.py
 test/test_codonDistance.py
 test/test_colors.py
-test/test_consensus.py
 test/test_dimension.py
 test/test_distance.py
 test/test_dna.py
 test/test_fasta.py
 test/test_fasta_ss.py
 test/test_fastq.py
 test/test_features.py
 test/test_filter.py
 test/test_genbank.py
 test/test_genomes.py
 test/test_graphics.py
 test/test_hsp.py
 test/test_html.py
-test/test_idutils.py
 test/test_intervals.py
 test/test_local_align.py
 test/test_mutations.py
 test/test_orfs.py
 test/test_process.py
 test/test_proteins.py
 test/test_reads.py
```

### Comparing `dark-matter-4.0.84/test/test_aa.py` & `dark-matter-4.0.9/test/test_aa.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,64 +1,33 @@
 import six
 from unittest import TestCase
 from itertools import product
-from collections import defaultdict
 
 from dark.aa import (
-    AminoAcid,
-    find,
-    propertiesForSequence,
-    clustersForSequence,
-    compareAaReads,
-    matchToString,
-)
-
-from dark.aaVars import (
-    PROPERTIES,
-    ALL_PROPERTIES,
-    PROPERTY_NAMES,
-    ACIDIC,
-    ALIPHATIC,
-    AROMATIC,
-    BASIC_POSITIVE,
-    HYDROPHILIC,
-    HYDROPHOBIC,
-    HYDROXYLIC,
-    NEGATIVE,
-    NONE,
-    POLAR,
-    SMALL,
-    SULPHUR,
-    TINY,
-    NAMES,
-    NAMES_TO_ABBREV1,
-    ABBREV3,
-    ABBREV3_TO_ABBREV1,
-    AA_LETTERS,
-    PROPERTY_CLUSTERS,
-    PROPERTY_DETAILS_RAW,
-    CODONS,
-    REVERSE_CODONS,
-    START_CODON,
-    STOP_CODONS,
-)
+    PROPERTIES, ALL_PROPERTIES, PROPERTY_NAMES, ACIDIC,
+    ALIPHATIC, AROMATIC, BASIC_POSITIVE, HYDROPHILIC, HYDROPHOBIC,
+    HYDROXYLIC, NEGATIVE, NONE, POLAR, SMALL, SULPHUR, TINY, NAMES,
+    NAMES_TO_ABBREV1, ABBREV3, ABBREV3_TO_ABBREV1, CODONS, AA_LETTERS,
+    find, AminoAcid, clustersForSequence, propertiesForSequence,
+    PROPERTY_CLUSTERS, PROPERTY_DETAILS_RAW, START_CODON, STOP_CODONS,
+    compareAaReads, matchToString)
 from dark.reads import AARead
 
 
 class TestAALetters(TestCase):
     """
     Test the AA_LETTERS string in dark.aa
     """
 
     def testExpectedAALetters(self):
         """
         The AA_LETTERS value must be as expected.
         """
         # From https://en.wikipedia.org/wiki/Amino_acid
-        expected = sorted("ARNDCEQGHILKMFPSTWYV")
+        expected = sorted('ARNDCEQGHILKMFPSTWYV')
         self.assertEqual(expected, AA_LETTERS)
 
 
 class TestProperties(TestCase):
     """
     Test the AA properties in dark.aa
     """
@@ -69,64 +38,51 @@
         """
         self.assertEqual(AA_LETTERS, sorted(PROPERTIES))
 
     def testAllProperties(self):
         """
         The ALL_PROPERTIES tuple must contain all known properties.
         """
-        expected = set(
-            [
-                ACIDIC,
-                ALIPHATIC,
-                AROMATIC,
-                BASIC_POSITIVE,
-                HYDROPHILIC,
-                HYDROPHOBIC,
-                HYDROXYLIC,
-                NEGATIVE,
-                NONE,
-                POLAR,
-                SMALL,
-                SULPHUR,
-                TINY,
-            ]
-        )
+        expected = set([
+            ACIDIC, ALIPHATIC, AROMATIC, BASIC_POSITIVE, HYDROPHILIC,
+            HYDROPHOBIC, HYDROXYLIC, NEGATIVE, NONE, POLAR, SMALL, SULPHUR,
+            TINY])
         self.assertEqual(set(ALL_PROPERTIES), expected)
 
     def testPropertyValuesDiffer(self):
         """
         All individual property values must be different.
         """
         self.assertEqual(len(ALL_PROPERTIES), len(set(ALL_PROPERTIES)))
 
     def testEachAAHasItsCorrectPropertiesAndNoOthers(self):
         """
         Each amino acid must have the properties expected of it, and no others.
         """
         expected = {
-            "A": set([HYDROPHOBIC, SMALL, TINY]),
-            "C": set([HYDROPHOBIC, SMALL, TINY, SULPHUR]),
-            "D": set([HYDROPHILIC, SMALL, POLAR, NEGATIVE]),
-            "E": set([HYDROPHILIC, NEGATIVE, ACIDIC]),
-            "F": set([HYDROPHOBIC, AROMATIC]),
-            "G": set([HYDROPHILIC, SMALL, TINY]),
-            "H": set([HYDROPHOBIC, AROMATIC, POLAR, BASIC_POSITIVE]),
-            "I": set([ALIPHATIC, HYDROPHOBIC]),
-            "K": set([HYDROPHOBIC, BASIC_POSITIVE, POLAR]),
-            "L": set([ALIPHATIC, HYDROPHOBIC]),
-            "M": set([HYDROPHOBIC, SULPHUR]),
-            "N": set([HYDROPHILIC, SMALL, POLAR, ACIDIC]),
-            "P": set([HYDROPHILIC, SMALL]),
-            "Q": set([HYDROPHILIC, POLAR, ACIDIC]),
-            "R": set([HYDROPHILIC, POLAR, BASIC_POSITIVE]),
-            "S": set([HYDROPHILIC, SMALL, POLAR, HYDROXYLIC]),
-            "T": set([HYDROPHOBIC, SMALL, HYDROXYLIC]),
-            "V": set([ALIPHATIC, HYDROPHOBIC, SMALL]),
-            "W": set([HYDROPHOBIC, AROMATIC, POLAR]),
-            "Y": set([HYDROPHOBIC, AROMATIC, POLAR]),
+            'A': set([HYDROPHOBIC, SMALL, TINY]),
+            'C': set([HYDROPHOBIC, SMALL, TINY, SULPHUR]),
+            'D': set([HYDROPHILIC, SMALL, POLAR, NEGATIVE]),
+            'E': set([HYDROPHILIC, NEGATIVE, ACIDIC]),
+            'F': set([HYDROPHOBIC, AROMATIC]),
+            'G': set([HYDROPHILIC, SMALL, TINY]),
+            'H': set([HYDROPHOBIC, AROMATIC, POLAR, BASIC_POSITIVE]),
+            'I': set([ALIPHATIC, HYDROPHOBIC]),
+            'K': set([HYDROPHOBIC, BASIC_POSITIVE, POLAR]),
+            'L': set([ALIPHATIC, HYDROPHOBIC]),
+            'M': set([HYDROPHOBIC, SULPHUR]),
+            'N': set([HYDROPHILIC, SMALL, POLAR, ACIDIC]),
+            'P': set([HYDROPHILIC, SMALL]),
+            'Q': set([HYDROPHILIC, POLAR, ACIDIC]),
+            'R': set([HYDROPHILIC, POLAR, BASIC_POSITIVE]),
+            'S': set([HYDROPHILIC, SMALL, POLAR, HYDROXYLIC]),
+            'T': set([HYDROPHOBIC, SMALL, HYDROXYLIC]),
+            'V': set([ALIPHATIC, HYDROPHOBIC, SMALL]),
+            'W': set([HYDROPHOBIC, AROMATIC, POLAR]),
+            'Y': set([HYDROPHOBIC, AROMATIC, POLAR]),
         }
 
         # Make sure our 'expected' dict (above) has properties for everything.
         self.assertEqual(AA_LETTERS, sorted(expected))
 
         for aa in AA_LETTERS:
             for prop in ALL_PROPERTIES:
@@ -141,15 +97,16 @@
         """
         self.assertEqual(sorted(ALL_PROPERTIES), sorted(PROPERTY_NAMES))
 
     def testProperyNamesValuesDiffer(self):
         """
         The PROPERTY_NAMES dict must have different values for each key.
         """
-        self.assertEqual(len(PROPERTY_NAMES), len(set(PROPERTY_NAMES.values())))
+        self.assertEqual(len(PROPERTY_NAMES),
+                         len(set(PROPERTY_NAMES.values())))
 
 
 class TestNames(TestCase):
     """
     Test the NAMES dict in dark.aa
     """
 
@@ -172,15 +129,16 @@
     Test the NAMES_TO_ABBREV1 dict in dark.aa
     """
 
     def testCorrectAAs(self):
         """
         The NAMES_TO_ABBREV1 dict must have the correct AA values.
         """
-        self.assertEqual(AA_LETTERS, sorted(NAMES_TO_ABBREV1.values()))
+        self.assertEqual(AA_LETTERS,
+                         sorted(NAMES_TO_ABBREV1.values()))
 
 
 class TestAbbrev3(TestCase):
     """
     Test the ABBREV3 dict in dark.aa
     """
 
@@ -203,15 +161,16 @@
     Test the ABBREV3_TO_ABBREV1 dict in dark.aa
     """
 
     def testCorrectAAs(self):
         """
         The ABBREV3_TO_ABBREV1 dict must have the correct AA values.
         """
-        self.assertEqual(AA_LETTERS, sorted(ABBREV3_TO_ABBREV1.values()))
+        self.assertEqual(AA_LETTERS,
+                         sorted(ABBREV3_TO_ABBREV1.values()))
 
 
 class TestCodons(TestCase):
     """
     Tests for the CODONS dict.
     """
 
@@ -237,25 +196,24 @@
 
     def testCodonContent(self):
         """
         Codons must only contain the letters A, T, G, C.
         """
         for codons in CODONS.values():
             for codon in codons:
-                self.assertTrue(all(letter in "ACGT" for letter in codon))
+                self.assertTrue(all(letter in 'ACGT' for letter in codon))
 
     def testCodonsAreNotAbbrev3s(self):
         """
         No codon can be the same as an amino acid 3-letter abbreviation (or
         else our find function may not be unambiguous in what it returns).
         """
         for codons in CODONS.values():
             self.assertFalse(
-                any(codon.title() in ABBREV3_TO_ABBREV1 for codon in codons)
-            )
+                any(codon.title() in ABBREV3_TO_ABBREV1 for codon in codons))
 
     def testDistinct(self):
         """
         All nucleotide triples must be distinct.
         """
         seen = set()
         for codons in CODONS.values():
@@ -263,80 +221,69 @@
                 seen.add(codon)
         self.assertEqual(61, len(seen))
 
     def testStartCodon(self):
         """
         The start codon must have the expected value.
         """
-        self.assertEqual("ATG", START_CODON)
+        self.assertEqual('ATG', START_CODON)
 
     def testStartCodonIsMethionine(self):
         """
         The start codon is the same as Methionine.
         """
-        self.assertEqual((START_CODON,), CODONS["M"])
+        self.assertEqual((START_CODON,), CODONS['M'])
 
     def testStopCodons(self):
         """
         The stop codons must have the expected value.
         """
-        self.assertEqual(("TAA", "TAG", "TGA"), STOP_CODONS)
+        self.assertEqual(('TAA', 'TAG', 'TGA'), STOP_CODONS)
 
     def testStopCodonsNotInCodonTable(self):
         """
         The stop codons must not be in the main table.
         """
         for stop in STOP_CODONS:
             for codons in CODONS.values():
                 self.assertNotIn(stop, codons)
 
     def testAllCodonsPresent(self):
         """
         All possible codons must be present, as either coding for an AA
         or as a stop codon.
         """
-        combinations = set("".join(x) for x in product("ACGT", "ACGT", "ACGT"))
+        combinations = set(
+            ''.join(x) for x in product('ACGT', 'ACGT', 'ACGT'))
         for codons in CODONS.values():
             for codon in codons:
                 combinations.remove(codon)
 
         # Just the stop codons should be left.
         self.assertEqual(set(STOP_CODONS), combinations)
 
-    def testReverseCodons(self):
-        """
-        The REVERSE_CODONS dictionary must be correct.
-        """
-        roundtrip = defaultdict(set)
-        for codon, aa in REVERSE_CODONS.items():
-            roundtrip[aa].add(codon)
-
-        for aa, codons in CODONS.items():
-            self.assertEqual(roundtrip[aa], set(codons), aa)
-
 
 class TestAminoAcid(TestCase):
     """
     Test the AminoAcid class in dark.aa
     """
 
     def testExpectedAttributes(self):
         """
         An amino acid instance must have the expected attributes.
         """
         properties = {}
         propertyDetails = {}
         codons = []
         propertyClusters = {}
-        aa = AminoAcid(
-            "Alanine", "Ala", "A", codons, properties, propertyDetails, propertyClusters
-        )
-        self.assertEqual("Alanine", aa.name)
-        self.assertEqual("Ala", aa.abbrev3)
-        self.assertEqual("A", aa.abbrev1)
+        aa = AminoAcid('Alanine', 'Ala', 'A', codons, properties,
+                       propertyDetails, propertyClusters)
+        self.assertEqual('Alanine', aa.name)
+        self.assertEqual('Ala', aa.abbrev3)
+        self.assertEqual('A', aa.abbrev1)
         self.assertIs(codons, aa.codons)
         self.assertIs(properties, aa.properties)
         self.assertIs(propertyDetails, aa.propertyDetails)
         self.assertIs(propertyClusters, aa.propertyClusters)
 
 
 class TestFind(TestCase):
@@ -345,1013 +292,887 @@
     """
 
     def testFindUnknown(self):
         """
         find must return an empty generator when called with an unrecognized
         value.
         """
-        self.assertEqual([], list(find("silly")))
+        self.assertEqual([], list(find('silly')))
 
     def testFindByAbbrev1(self):
         """
         It must be possible to find an amino acid by its 1-letter abbreviation.
         """
-        aa = list(find("A"))[0]
-        self.assertEqual("Alanine", aa.name)
-        self.assertEqual("Ala", aa.abbrev3)
-        self.assertEqual("A", aa.abbrev1)
-        self.assertEqual(("GCA", "GCC", "GCG", "GCT"), aa.codons)
+        aa = list(find('A'))[0]
+        self.assertEqual('Alanine', aa.name)
+        self.assertEqual('Ala', aa.abbrev3)
+        self.assertEqual('A', aa.abbrev1)
+        self.assertEqual(('GCA', 'GCC', 'GCG', 'GCT'), aa.codons)
         self.assertEqual(HYDROPHOBIC | SMALL | TINY, aa.properties)
         self.assertEqual(
             {
-                "aliphaticity": 0.305785123967,
-                "aromaticity": -0.550128534704,
-                "composition": -1.0,
-                "hydrogenation": 0.8973042362,
-                "hydropathy": 0.4,
-                "hydroxythiolation": -0.265160523187,
-                "iep": -0.191489361702,
-                "polar requirement": -0.463414634146,
-                "polarity": -0.20987654321,
-                "volume": -0.664670658683,
+                'aliphaticity': 0.305785123967,
+                'aromaticity': -0.550128534704,
+                'composition': -1.0,
+                'hydrogenation': 0.8973042362,
+                'hydropathy': 0.4,
+                'hydroxythiolation': -0.265160523187,
+                'iep': -0.191489361702,
+                'polar requirement': -0.463414634146,
+                'polarity': -0.20987654321,
+                'volume': -0.664670658683,
+            },
+            aa.propertyDetails)
+        self.assertEqual(
+            {
+                'aliphaticity': 1,
+                'aromaticity': 1,
+                'composition': 1,
+                'hydrogenation': 1,
+                'hydropathy': 3,
+                'hydroxythiolation': 2,
+                'iep': 2,
+                'polar requirement': 2,
+                'polarity': 2,
+                'volume': 2,
             },
-            aa.propertyDetails,
-        )
-        self.assertEqual(
-            {
-                "aliphaticity": 1,
-                "aromaticity": 1,
-                "composition": 1,
-                "hydrogenation": 1,
-                "hydropathy": 3,
-                "hydroxythiolation": 2,
-                "iep": 2,
-                "polar requirement": 2,
-                "polarity": 2,
-                "volume": 2,
-            },
-            aa.propertyClusters,
-        )
+            aa.propertyClusters)
 
     def testFindByAbbrev3(self):
         """
         It must be possible to find an amino acid by its 3-letter abbreviation.
         """
-        aa = list(find("Ala"))[0]
-        self.assertEqual("Alanine", aa.name)
-        self.assertEqual("Ala", aa.abbrev3)
-        self.assertEqual("A", aa.abbrev1)
-        self.assertEqual(("GCA", "GCC", "GCG", "GCT"), aa.codons)
+        aa = list(find('Ala'))[0]
+        self.assertEqual('Alanine', aa.name)
+        self.assertEqual('Ala', aa.abbrev3)
+        self.assertEqual('A', aa.abbrev1)
+        self.assertEqual(('GCA', 'GCC', 'GCG', 'GCT'), aa.codons)
         self.assertEqual(HYDROPHOBIC | SMALL | TINY, aa.properties)
         self.assertEqual(
             {
-                "aliphaticity": 0.305785123967,
-                "aromaticity": -0.550128534704,
-                "composition": -1.0,
-                "hydrogenation": 0.8973042362,
-                "hydropathy": 0.4,
-                "hydroxythiolation": -0.265160523187,
-                "iep": -0.191489361702,
-                "polar requirement": -0.463414634146,
-                "polarity": -0.20987654321,
-                "volume": -0.664670658683,
+                'aliphaticity': 0.305785123967,
+                'aromaticity': -0.550128534704,
+                'composition': -1.0,
+                'hydrogenation': 0.8973042362,
+                'hydropathy': 0.4,
+                'hydroxythiolation': -0.265160523187,
+                'iep': -0.191489361702,
+                'polar requirement': -0.463414634146,
+                'polarity': -0.20987654321,
+                'volume': -0.664670658683,
+            },
+            aa.propertyDetails)
+        self.assertEqual(
+            {
+                'aliphaticity': 1,
+                'aromaticity': 1,
+                'composition': 1,
+                'hydrogenation': 1,
+                'hydropathy': 3,
+                'hydroxythiolation': 2,
+                'iep': 2,
+                'polar requirement': 2,
+                'polarity': 2,
+                'volume': 2,
             },
-            aa.propertyDetails,
-        )
-        self.assertEqual(
-            {
-                "aliphaticity": 1,
-                "aromaticity": 1,
-                "composition": 1,
-                "hydrogenation": 1,
-                "hydropathy": 3,
-                "hydroxythiolation": 2,
-                "iep": 2,
-                "polar requirement": 2,
-                "polarity": 2,
-                "volume": 2,
-            },
-            aa.propertyClusters,
-        )
+            aa.propertyClusters)
 
     def testFindByCodon(self):
         """
         It must be possible to find an amino acid by a 3-letter codon.
         """
-        aa = list(find("GCC"))[0]
-        self.assertEqual("Alanine", aa.name)
-        self.assertEqual("Ala", aa.abbrev3)
-        self.assertEqual("A", aa.abbrev1)
-        self.assertEqual(("GCA", "GCC", "GCG", "GCT"), aa.codons)
+        aa = list(find('GCC'))[0]
+        self.assertEqual('Alanine', aa.name)
+        self.assertEqual('Ala', aa.abbrev3)
+        self.assertEqual('A', aa.abbrev1)
+        self.assertEqual(('GCA', 'GCC', 'GCG', 'GCT'), aa.codons)
         self.assertEqual(HYDROPHOBIC | SMALL | TINY, aa.properties)
         self.assertEqual(
             {
-                "aliphaticity": 0.305785123967,
-                "aromaticity": -0.550128534704,
-                "composition": -1.0,
-                "hydrogenation": 0.8973042362,
-                "hydropathy": 0.4,
-                "hydroxythiolation": -0.265160523187,
-                "iep": -0.191489361702,
-                "polar requirement": -0.463414634146,
-                "polarity": -0.20987654321,
-                "volume": -0.664670658683,
+                'aliphaticity': 0.305785123967,
+                'aromaticity': -0.550128534704,
+                'composition': -1.0,
+                'hydrogenation': 0.8973042362,
+                'hydropathy': 0.4,
+                'hydroxythiolation': -0.265160523187,
+                'iep': -0.191489361702,
+                'polar requirement': -0.463414634146,
+                'polarity': -0.20987654321,
+                'volume': -0.664670658683,
+            },
+            aa.propertyDetails)
+        self.assertEqual(
+            {
+                'aliphaticity': 1,
+                'aromaticity': 1,
+                'composition': 1,
+                'hydrogenation': 1,
+                'hydropathy': 3,
+                'hydroxythiolation': 2,
+                'iep': 2,
+                'polar requirement': 2,
+                'polarity': 2,
+                'volume': 2,
             },
-            aa.propertyDetails,
-        )
-        self.assertEqual(
-            {
-                "aliphaticity": 1,
-                "aromaticity": 1,
-                "composition": 1,
-                "hydrogenation": 1,
-                "hydropathy": 3,
-                "hydroxythiolation": 2,
-                "iep": 2,
-                "polar requirement": 2,
-                "polarity": 2,
-                "volume": 2,
-            },
-            aa.propertyClusters,
-        )
+            aa.propertyClusters)
 
     def testFindByName(self):
         """
         It must be possible to find an amino acid by its name.
         """
-        aa = list(find("Alanine"))[0]
-        self.assertEqual("Alanine", aa.name)
-        self.assertEqual("Ala", aa.abbrev3)
-        self.assertEqual("A", aa.abbrev1)
-        self.assertEqual(("GCA", "GCC", "GCG", "GCT"), aa.codons)
+        aa = list(find('Alanine'))[0]
+        self.assertEqual('Alanine', aa.name)
+        self.assertEqual('Ala', aa.abbrev3)
+        self.assertEqual('A', aa.abbrev1)
+        self.assertEqual(('GCA', 'GCC', 'GCG', 'GCT'), aa.codons)
         self.assertEqual(HYDROPHOBIC | SMALL | TINY, aa.properties)
         self.assertEqual(
             {
-                "aliphaticity": 0.305785123967,
-                "aromaticity": -0.550128534704,
-                "composition": -1.0,
-                "hydrogenation": 0.8973042362,
-                "hydropathy": 0.4,
-                "hydroxythiolation": -0.265160523187,
-                "iep": -0.191489361702,
-                "polar requirement": -0.463414634146,
-                "polarity": -0.20987654321,
-                "volume": -0.664670658683,
+                'aliphaticity': 0.305785123967,
+                'aromaticity': -0.550128534704,
+                'composition': -1.0,
+                'hydrogenation': 0.8973042362,
+                'hydropathy': 0.4,
+                'hydroxythiolation': -0.265160523187,
+                'iep': -0.191489361702,
+                'polar requirement': -0.463414634146,
+                'polarity': -0.20987654321,
+                'volume': -0.664670658683,
+            },
+            aa.propertyDetails)
+        self.assertEqual(
+            {
+                'aliphaticity': 1,
+                'aromaticity': 1,
+                'composition': 1,
+                'hydrogenation': 1,
+                'hydropathy': 3,
+                'hydroxythiolation': 2,
+                'iep': 2,
+                'polar requirement': 2,
+                'polarity': 2,
+                'volume': 2,
             },
-            aa.propertyDetails,
-        )
-        self.assertEqual(
-            {
-                "aliphaticity": 1,
-                "aromaticity": 1,
-                "composition": 1,
-                "hydrogenation": 1,
-                "hydropathy": 3,
-                "hydroxythiolation": 2,
-                "iep": 2,
-                "polar requirement": 2,
-                "polarity": 2,
-                "volume": 2,
-            },
-            aa.propertyClusters,
-        )
+            aa.propertyClusters)
 
     def testFindByNameCaseIgnored(self):
         """
         It must be possible to find an amino acid by its name when the name is
         given in mixed case.
         """
-        aa = list(find("alaNIne"))[0]
-        self.assertEqual("Alanine", aa.name)
-        self.assertEqual("Ala", aa.abbrev3)
-        self.assertEqual("A", aa.abbrev1)
-        self.assertEqual(("GCA", "GCC", "GCG", "GCT"), aa.codons)
+        aa = list(find('alaNIne'))[0]
+        self.assertEqual('Alanine', aa.name)
+        self.assertEqual('Ala', aa.abbrev3)
+        self.assertEqual('A', aa.abbrev1)
+        self.assertEqual(('GCA', 'GCC', 'GCG', 'GCT'), aa.codons)
         self.assertEqual(HYDROPHOBIC | SMALL | TINY, aa.properties)
         self.assertEqual(
             {
-                "aliphaticity": 0.305785123967,
-                "aromaticity": -0.550128534704,
-                "composition": -1.0,
-                "hydrogenation": 0.8973042362,
-                "hydropathy": 0.4,
-                "hydroxythiolation": -0.265160523187,
-                "iep": -0.191489361702,
-                "polar requirement": -0.463414634146,
-                "polarity": -0.20987654321,
-                "volume": -0.664670658683,
+                'aliphaticity': 0.305785123967,
+                'aromaticity': -0.550128534704,
+                'composition': -1.0,
+                'hydrogenation': 0.8973042362,
+                'hydropathy': 0.4,
+                'hydroxythiolation': -0.265160523187,
+                'iep': -0.191489361702,
+                'polar requirement': -0.463414634146,
+                'polarity': -0.20987654321,
+                'volume': -0.664670658683,
+            },
+            aa.propertyDetails)
+        self.assertEqual(
+            {
+                'aliphaticity': 1,
+                'aromaticity': 1,
+                'composition': 1,
+                'hydrogenation': 1,
+                'hydropathy': 3,
+                'hydroxythiolation': 2,
+                'iep': 2,
+                'polar requirement': 2,
+                'polarity': 2,
+                'volume': 2,
             },
-            aa.propertyDetails,
-        )
-        self.assertEqual(
-            {
-                "aliphaticity": 1,
-                "aromaticity": 1,
-                "composition": 1,
-                "hydrogenation": 1,
-                "hydropathy": 3,
-                "hydroxythiolation": 2,
-                "iep": 2,
-                "polar requirement": 2,
-                "polarity": 2,
-                "volume": 2,
-            },
-            aa.propertyClusters,
-        )
+            aa.propertyClusters)
 
     def testFindByNameCaseIgnoredNameWithSpace(self):
         """
         It must be possible to find an amino acid by its name when the name is
         given in mixed case, including if the name has a space in it.
         """
-        aa = list(find("asparTIC aCId"))[0]
-        self.assertEqual("Aspartic acid", aa.name)
-        self.assertEqual("Asp", aa.abbrev3)
-        self.assertEqual("D", aa.abbrev1)
-        self.assertEqual(("GAC", "GAT"), aa.codons)
+        aa = list(find('asparTIC aCId'))[0]
+        self.assertEqual('Aspartic acid', aa.name)
+        self.assertEqual('Asp', aa.abbrev3)
+        self.assertEqual('D', aa.abbrev1)
+        self.assertEqual(('GAC', 'GAT'), aa.codons)
         self.assertEqual(HYDROPHILIC | SMALL | POLAR | NEGATIVE, aa.properties)
         self.assertEqual(
             {
-                "aliphaticity": -0.818181818182,
-                "aromaticity": -1.0,
-                "composition": 0.00363636363636,
-                "hydrogenation": -0.90243902439,
-                "hydropathy": -0.777777777778,
-                "hydroxythiolation": -0.348394768133,
-                "iep": -1.0,
-                "polar requirement": 1.0,
-                "polarity": 1.0,
-                "volume": -0.389221556886,
+                'aliphaticity': -0.818181818182,
+                'aromaticity': -1.0,
+                'composition': 0.00363636363636,
+                'hydrogenation': -0.90243902439,
+                'hydropathy': -0.777777777778,
+                'hydroxythiolation': -0.348394768133,
+                'iep': -1.0,
+                'polar requirement': 1.0,
+                'polarity': 1.0,
+                'volume': -0.389221556886,
+            },
+            aa.propertyDetails)
+        self.assertEqual(
+            {
+                'aliphaticity': 1,
+                'aromaticity': 1,
+                'composition': 2,
+                'hydrogenation': 1,
+                'hydropathy': 1,
+                'hydroxythiolation': 2,
+                'iep': 1,
+                'polar requirement': 4,
+                'polarity': 4,
+                'volume': 3,
             },
-            aa.propertyDetails,
-        )
-        self.assertEqual(
-            {
-                "aliphaticity": 1,
-                "aromaticity": 1,
-                "composition": 2,
-                "hydrogenation": 1,
-                "hydropathy": 1,
-                "hydroxythiolation": 2,
-                "iep": 1,
-                "polar requirement": 4,
-                "polarity": 4,
-                "volume": 3,
-            },
-            aa.propertyClusters,
-        )
+            aa.propertyClusters)
 
     def testFindByPartialName(self):
         """
         It must be possible to find an amino acid by a partial name.
         """
-        aa = list(find("nine"))[0]
-        self.assertEqual("Alanine", aa.name)
+        aa = list(find('nine'))[0]
+        self.assertEqual('Alanine', aa.name)
 
     def testFindByPartialNameMixedCase(self):
         """
         It must be possible to find an amino acid by a mixed-case partial name.
         """
-        aa = list(find("NiNe"))[0]
-        self.assertEqual("Alanine", aa.name)
+        aa = list(find('NiNe'))[0]
+        self.assertEqual('Alanine', aa.name)
 
     def testFindMultipleMatches(self):
         """
         It must be possible to find more than one matching amino acid.
         """
-        aa1, aa2 = list(find("acid"))
-        self.assertEqual("Aspartic acid", aa1.name)
-        self.assertEqual("Glutamic acid", aa2.name)
+        aa1, aa2 = list(find('acid'))
+        self.assertEqual('Aspartic acid', aa1.name)
+        self.assertEqual('Glutamic acid', aa2.name)
 
 
 class TestPropertyClusters(TestCase):
     """
     Tests for the PROPERTY_CLUSTERS dict.
     """
-
     def testPropertyClusterKeys(self):
         """
         The PROPERTY_CLUSTERS dict must contain the right keys.
         """
         self.assertEqual(AA_LETTERS, sorted(PROPERTY_CLUSTERS))
 
     def testNumberOfValues(self):
         """
         Each key in PROPERTY_CLUSTERS must have a dict with 10 elements in it
         as the value.
         """
         for propertyNames in PROPERTY_CLUSTERS.values():
-            self.assertEqual(
-                [
-                    "aliphaticity",
-                    "aromaticity",
-                    "composition",
-                    "hydrogenation",
-                    "hydropathy",
-                    "hydroxythiolation",
-                    "iep",
-                    "polar requirement",
-                    "polarity",
-                    "volume",
-                ],
-                sorted(propertyNames),
-            )
+            self.assertEqual([
+                'aliphaticity', 'aromaticity', 'composition',
+                'hydrogenation', 'hydropathy', 'hydroxythiolation',
+                'iep', 'polar requirement', 'polarity', 'volume'],
+                sorted(propertyNames))
 
     def testAliphaticity(self):
         """
         Aliphaticity must always be in cluster 1.
         """
         for propertiesDict in PROPERTY_CLUSTERS.values():
-            self.assertEqual(1, propertiesDict["aliphaticity"])
+            self.assertEqual(1, propertiesDict['aliphaticity'])
 
     def testPermittedClustersOnly(self):
         """
         All cluster numbers must be in {1, 2, 3, 4, 5}.
         """
         for propertiesDict in PROPERTY_CLUSTERS.values():
             for clusterNr in propertiesDict.values():
                 self.assertIn(clusterNr, {1, 2, 3, 4, 5})
 
 
 class TestPropertyDetailsRaw(TestCase):
     """
     Tests for the PROPERTY_DETAILS_RAW dict.
     """
-
     def testPropertyDetailsRawKeys(self):
         """
         The PROPERTY_DETAILS_RAW dict must contain the right keys.
         """
         self.assertEqual(AA_LETTERS, sorted(PROPERTY_DETAILS_RAW))
 
     def testNumberOfValues(self):
         """
         Each key in PROPERTY_DETAILS_RAW must have a dict with 10 elements in
         it as the value.
         """
         for propertyNames in PROPERTY_DETAILS_RAW.values():
-            self.assertEqual(
-                [
-                    "aliphaticity",
-                    "aromaticity",
-                    "composition",
-                    "hydrogenation",
-                    "hydropathy",
-                    "hydroxythiolation",
-                    "iep",
-                    "polar requirement",
-                    "polarity",
-                    "volume",
-                ],
-                sorted(propertyNames),
-            )
+            self.assertEqual([
+                'aliphaticity', 'aromaticity', 'composition',
+                'hydrogenation', 'hydropathy', 'hydroxythiolation',
+                'iep', 'polar requirement', 'polarity', 'volume'],
+                sorted(propertyNames))
 
     def testAliphaticity(self):
         """
         Aliphaticity of Alanin must have the right value.
         """
-        self.assertEqual(0.239, PROPERTY_DETAILS_RAW["A"]["aliphaticity"])
+        self.assertEqual(0.239, PROPERTY_DETAILS_RAW['A']['aliphaticity'])
 
     def testValuesMustBeFloats(self):
         """
         Each key in PROPERTY_DETAILS_RAW must have a dict whose values are
         all floats.
         """
         for properties in PROPERTY_DETAILS_RAW.values():
-            self.assertTrue(all(isinstance(v, float) for v in properties.values()))
+            self.assertTrue(all(type(v) is float for v in properties.values()))
 
 
 class TestPropertiesForSequence(TestCase):
     """
     Tests for the propertiesForSequence function in aa.py
     """
-
     def testUnknownProperty(self):
         """
         A C{ValueError} must be raised if an unknown property name is passed.
         """
-        error = "Unknown property: xxx"
-        read = AARead("id", "RRR")
-        six.assertRaisesRegex(
-            self, ValueError, error, propertiesForSequence, read, ["xxx"]
-        )
+        error = 'Unknown property: xxx'
+        read = AARead('id', 'RRR')
+        six.assertRaisesRegex(self, ValueError, error,
+                              propertiesForSequence, read, ['xxx'])
 
     def testNoProperties(self):
         """
         If no properties are wanted, an empty dict must be returned.
         """
-        read = AARead("id", "RRR")
+        read = AARead('id', 'RRR')
         self.assertEqual({}, propertiesForSequence(read, []))
 
     def testOnePropertyEmptySequence(self):
         """
         If one property is wanted but the sequence is empty, a dict with the
         property must be returned, and have an empty list value.
         """
-        read = AARead("id", "")
+        read = AARead('id', '')
         self.assertEqual(
             {
-                "hydropathy": [],
+                'hydropathy': [],
             },
-            propertiesForSequence(read, ["hydropathy"]),
-        )
+            propertiesForSequence(read, ['hydropathy']))
 
     def testPropertyNameIsLowercased(self):
         """
         The property name must be lower-cased in the result.
         """
-        read = AARead("id", "")
-        self.assertTrue("hydropathy" in propertiesForSequence(read, ["HYDROPATHY"]))
+        read = AARead('id', '')
+        self.assertTrue('hydropathy' in
+                        propertiesForSequence(read, ['HYDROPATHY']))
 
     def testOneProperty(self):
         """
         If one property is wanted, a dict with the property must be returned,
         and have the expected property values.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "hydropathy": [0.4, 1.0],
+                'hydropathy': [0.4, 1.0],
             },
-            propertiesForSequence(read, ["hydropathy"]),
-        )
+            propertiesForSequence(read, ['hydropathy']))
 
     def testTwoProperties(self):
         """
         If two properties are wanted, a dict with the properties must be
         returned, and have the expected property values.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "composition": [-1.0, -1.0],
-                "hydropathy": [0.4, 1.0],
+                'composition': [-1.0, -1.0],
+                'hydropathy': [0.4, 1.0],
             },
-            propertiesForSequence(read, ["composition", "hydropathy"]),
-        )
+            propertiesForSequence(read, ['composition', 'hydropathy']))
 
     def testDuplicatedPropertyName(self):
         """
         If a property name is mentioned more than once, a dict with the
         wanted properties must be returned, and have the expected property
         values.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "composition": [-1.0, -1.0],
-                "hydropathy": [0.4, 1.0],
+                'composition': [-1.0, -1.0],
+                'hydropathy': [0.4, 1.0],
             },
-            propertiesForSequence(read, ["composition", "hydropathy", "hydropathy"]),
-        )
+            propertiesForSequence(read, ['composition',
+                                         'hydropathy', 'hydropathy']))
 
     def testMissingAminoAcid(self):
         """
         If an unknown amino acid appears in the sequence, its property value
         must be the default (-1.1).
         """
-        read = AARead("id", "XX")
+        read = AARead('id', 'XX')
         self.assertEqual(
             {
-                "composition": [-1.1, -1.1],
-                "hydropathy": [-1.1, -1.1],
+                'composition': [-1.1, -1.1],
+                'hydropathy': [-1.1, -1.1],
             },
-            propertiesForSequence(read, ["composition", "hydropathy"]),
-        )
+            propertiesForSequence(read, ['composition', 'hydropathy']))
 
     def testMissingAminoAcidWithNonDefaultMissingValue(self):
         """
         If an unknown amino acid appears in the sequence, its property value
         must be the missing AA value that was passed.
         """
-        read = AARead("id", "XX")
+        read = AARead('id', 'XX')
         self.assertEqual(
             {
-                "composition": [-1.5, -1.5],
-                "hydropathy": [-1.5, -1.5],
+                'composition': [-1.5, -1.5],
+                'hydropathy': [-1.5, -1.5],
             },
-            propertiesForSequence(
-                read, ["composition", "hydropathy"], missingAAValue=-1.5
-            ),
-        )
+            propertiesForSequence(read, ['composition', 'hydropathy'],
+                                  missingAAValue=-1.5))
 
 
 class TestClustersForSequence(TestCase):
     """
     Tests for the clustersForSequence function in aa.py
     """
-
     def testUnknownProperty(self):
         """
         A C{ValueError} must be raised if an unknown property name is passed.
         """
-        error = "Unknown property: xxx"
-        read = AARead("id", "RRR")
-        six.assertRaisesRegex(
-            self, ValueError, error, clustersForSequence, read, ["xxx"]
-        )
+        error = 'Unknown property: xxx'
+        read = AARead('id', 'RRR')
+        six.assertRaisesRegex(self, ValueError, error,
+                              clustersForSequence, read, ['xxx'])
 
     def testNoProperties(self):
         """
         If no properties are wanted, an empty dict must be returned.
         """
-        read = AARead("id", "RRR")
+        read = AARead('id', 'RRR')
         self.assertEqual({}, clustersForSequence(read, []))
 
     def testOnePropertyEmptySequence(self):
         """
         If one property is wanted but the sequence is empty, a dict with the
         property must be returned, and have an empty list value.
         """
-        read = AARead("id", "")
+        read = AARead('id', '')
         self.assertEqual(
             {
-                "hydropathy": [],
+                'hydropathy': [],
             },
-            clustersForSequence(read, ["hydropathy"]),
-        )
+            clustersForSequence(read, ['hydropathy']))
 
     def testPropertyNameIsLowercased(self):
         """
         The property name must be lower-cased in the result.
         """
-        read = AARead("id", "")
-        self.assertTrue("hydropathy" in clustersForSequence(read, ["HYDROPATHY"]))
+        read = AARead('id', '')
+        self.assertTrue('hydropathy' in
+                        clustersForSequence(read, ['HYDROPATHY']))
 
     def testOneProperty(self):
         """
         If one property is wanted, a dict with the property must be returned,
         and have the expected property cluster number.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "hydropathy": [3, 4],
+                'hydropathy': [3, 4],
             },
-            clustersForSequence(read, ["hydropathy"]),
-        )
+            clustersForSequence(read, ['hydropathy']))
 
     def testTwoProperties(self):
         """
         If two properties are wanted, a dict with the properties must be
         returned, and have the expected property cluster numbers.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "composition": [1, 1],
-                "hydropathy": [3, 4],
+                'composition': [1, 1],
+                'hydropathy': [3, 4],
             },
-            clustersForSequence(read, ["composition", "hydropathy"]),
-        )
+            clustersForSequence(read, ['composition', 'hydropathy']))
 
     def testDuplicatedPropertyName(self):
         """
         If a property name is mentioned more than once, a dict with the
         wanted properties must be returned, and have the expected property
         cluster numbers.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "composition": [1, 1],
-                "hydropathy": [3, 4],
+                'composition': [1, 1],
+                'hydropathy': [3, 4],
             },
-            clustersForSequence(read, ["composition", "hydropathy", "hydropathy"]),
-        )
+            clustersForSequence(read, ['composition',
+                                       'hydropathy', 'hydropathy']))
 
     def testMissingAminoAcid(self):
         """
         If an unknown amino acid appears in the sequence, its property cluster
         must be the default (0).
         """
-        read = AARead("id", "XX")
+        read = AARead('id', 'XX')
         self.assertEqual(
             {
-                "composition": [0, 0],
-                "hydropathy": [0, 0],
+                'composition': [0, 0],
+                'hydropathy': [0, 0],
             },
-            clustersForSequence(read, ["composition", "hydropathy"]),
-        )
+            clustersForSequence(read, ['composition', 'hydropathy']))
 
     def testMissingAminoAcidWithNonDefaultMissingValue(self):
         """
         If an unknown amino acid appears in the sequence, its property cluster
         must be the missing AA value that was passed.
         """
-        read = AARead("id", "XX")
+        read = AARead('id', 'XX')
         self.assertEqual(
             {
-                "composition": [10, 10],
-                "hydropathy": [10, 10],
+                'composition': [10, 10],
+                'hydropathy': [10, 10],
             },
-            clustersForSequence(read, ["composition", "hydropathy"], missingAAValue=10),
-        )
+            clustersForSequence(read, ['composition', 'hydropathy'],
+                                missingAAValue=10))
 
 
 class TestCompareAaReads(TestCase):
     """
     Test the compareAaReads function.
     """
-
     def testEmptySequences(self):
         """
         Two empty sequences must compare as expected.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 0,
-                    "gapMismatchCount": 0,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
+                'match': {
+                    'matchCount': 0,
+                    'gapMismatchCount': 0,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
                 },
             },
-            compareAaReads(AARead("id1", ""), AARead("id2", "")),
-        )
+            compareAaReads(AARead('id1', ''),
+                           AARead('id2', '')))
 
     def testExactMatch(self):
         """
         Two sequences that match exactly must compare as expected.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 5,
-                    "gapMismatchCount": 0,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
+                'match': {
+                    'matchCount': 5,
+                    'gapMismatchCount': 0,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
                 },
             },
-            compareAaReads(AARead("id1", "GALHN"), AARead("id2", "GALHN")),
-        )
+            compareAaReads(AARead('id1', 'GALHN'),
+                           AARead('id2', 'GALHN')))
 
     def testMismatch(self):
         """
         If the sequences have mismatched bases, their count
         must be given correctly in the nonGapMismatchCount.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 3,
-                    "gapMismatchCount": 0,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 2,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
+                'match': {
+                    'matchCount': 3,
+                    'gapMismatchCount': 0,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 2,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
                 },
             },
-            compareAaReads(AARead("id1", "GALYY"), AARead("id2", "GALHN")),
-        )
+            compareAaReads(AARead('id1', 'GALYY'),
+                           AARead('id2', 'GALHN')))
 
     def testNoOffsets(self):
         """
         If an empty set of wanted offsets is passed, the result must be empty.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 0,
-                    "gapMismatchCount": 0,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-            },
-            compareAaReads(
-                AARead("id1", "GAL-N"), AARead("id2", "G-LHN"), offsets=set()
-            ),
-        )
+                'match': {
+                    'matchCount': 0,
+                    'gapMismatchCount': 0,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+            },
+            compareAaReads(AARead('id1', 'GAL-N'),
+                           AARead('id2', 'G-LHN'), offsets=set()))
 
     def testOffsets(self):
         """
         If a set of wanted offsets is passed, the result must be restricted to
         just those offsets.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 1,
-                    "gapMismatchCount": 0,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 1,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-            },
-            compareAaReads(
-                AARead("id1", "GAL-L"), AARead("id2", "G-LHN"), offsets=set([0, 4])
-            ),
-        )
+                'match': {
+                    'matchCount': 1,
+                    'gapMismatchCount': 0,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 1,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+            },
+            compareAaReads(AARead('id1', 'GAL-L'),
+                           AARead('id2', 'G-LHN'), offsets=set([0, 4])))
 
     def testGapInFirst(self):
         """
         A gap in the first sequence must be dealt with correctly.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 4,
-                    "gapMismatchCount": 1,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [3],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
+                'match': {
+                    'matchCount': 4,
+                    'gapMismatchCount': 1,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [3],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
                 },
             },
-            compareAaReads(AARead("id1", "GAL-N"), AARead("id2", "GALHN")),
-        )
+            compareAaReads(AARead('id1', 'GAL-N'),
+                           AARead('id2', 'GALHN')))
 
     def testGapInSecond(self):
         """
         A gap in the second sequence must be dealt with correctly.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 3,
-                    "gapMismatchCount": 2,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [1, 2],
+                'match': {
+                    'matchCount': 3,
+                    'gapMismatchCount': 2,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [1, 2],
                 },
             },
-            compareAaReads(AARead("id1", "GALHN"), AARead("id2", "G--HN")),
-        )
+            compareAaReads(AARead('id1', 'GALHN'),
+                           AARead('id2', 'G--HN')))
 
     def testNonDefaultGapChars(self):
         """
         We must be able to specify the gap characters.
         """
-        for gap in "+$":
+        for gap in '+$':
             self.assertEqual(
                 {
-                    "match": {
-                        "matchCount": 3,
-                        "gapMismatchCount": 2,
-                        "gapGapMismatchCount": 0,
-                        "nonGapMismatchCount": 0,
+                    'match': {
+                        'matchCount': 3,
+                        'gapMismatchCount': 2,
+                        'gapGapMismatchCount': 0,
+                        'nonGapMismatchCount': 0,
                     },
-                    "read1": {
-                        "extraCount": 0,
-                        "gapOffsets": [2],
+                    'read1': {
+                        'extraCount': 0,
+                        'gapOffsets': [2],
                     },
-                    "read2": {
-                        "extraCount": 0,
-                        "gapOffsets": [0],
+                    'read2': {
+                        'extraCount': 0,
+                        'gapOffsets': [0],
                     },
                 },
-                compareAaReads(
-                    AARead("id1", "GA%sHN" % gap),
-                    AARead("id2", "%sALHN" % gap),
-                    gapChars="+$",
-                ),
-            )
+                compareAaReads(AARead('id1', 'GA%sHN' % gap),
+                               AARead('id2', '%sALHN' % gap), gapChars='+$'))
 
     def testGapGap(self):
         """
         Coinciding gaps in the sequences must be dealt with correctly
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 2,
-                    "gapMismatchCount": 2,
-                    "gapGapMismatchCount": 1,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [2, 3],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [1, 2],
+                'match': {
+                    'matchCount': 2,
+                    'gapMismatchCount': 2,
+                    'gapGapMismatchCount': 1,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [2, 3],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [1, 2],
                 },
             },
-            compareAaReads(AARead("id1", "GA--N"), AARead("id2", "G--HN")),
-        )
+            compareAaReads(AARead('id1', 'GA--N'),
+                           AARead('id2', 'G--HN')))
 
     def testExtraInFirst(self):
         """
         If the first sequence has extra bases, they must be indicated in the
         extraCount.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 5,
-                    "gapMismatchCount": 0,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 2,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
+                'match': {
+                    'matchCount': 5,
+                    'gapMismatchCount': 0,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 2,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
                 },
             },
-            compareAaReads(AARead("id1", "GALHNHN"), AARead("id2", "GALHN")),
-        )
+            compareAaReads(AARead('id1', 'GALHNHN'),
+                           AARead('id2', 'GALHN')))
 
     def testExtraInSecond(self):
         """
         If the second sequence has extra bases, they must be indicated in the
         extraCount.
         """
         self.assertEqual(
             {
-                "match": {
-                    "matchCount": 5,
-                    "gapMismatchCount": 0,
-                    "gapGapMismatchCount": 0,
-                    "nonGapMismatchCount": 0,
-                },
-                "read1": {
-                    "extraCount": 0,
-                    "gapOffsets": [],
-                },
-                "read2": {
-                    "extraCount": 2,
-                    "gapOffsets": [],
+                'match': {
+                    'matchCount': 5,
+                    'gapMismatchCount': 0,
+                    'gapGapMismatchCount': 0,
+                    'nonGapMismatchCount': 0,
+                },
+                'read1': {
+                    'extraCount': 0,
+                    'gapOffsets': [],
+                },
+                'read2': {
+                    'extraCount': 2,
+                    'gapOffsets': [],
                 },
             },
-            compareAaReads(AARead("id1", "GALHN"), AARead("id2", "GALHNHN")),
-        )
+            compareAaReads(AARead('id1', 'GALHN'),
+                           AARead('id2', 'GALHNHN')))
 
 
 class TestMatchToString(TestCase):
     """
     Test the matchToString function.
     """
-
     def testMismatchAndMatch(self):
         """
         Two sequences containing matches and mismatches must compare as
         expected.
         """
-        read1 = AARead("id1", "GALHNG")
-        read2 = AARead("id2", "GALHNA")
+        read1 = AARead('id1', 'GALHNG')
+        read2 = AARead('id2', 'GALHNA')
         match = compareAaReads(read1, read2)
 
         self.assertEqual(
-            """\
-Matches:
-  Overall: 5/6 (83.33%)
-  Not involving gaps (i.e., identities): 5/6 (83.33%)
-Mismatches:
-  Overall: 1/6 (16.67%)
+            '''\
+Matches: 5/6 (83.33%)
+Mismatches: 1/6 (16.67%)
   Not involving gaps (i.e., conflicts): 1/6 (16.67%)
   Involving a gap in one sequence: 0
   Involving a gap in both sequences: 0
-Id: id1
-  Length: 6
-  Gaps: 0
-Id: id2
-  Length: 6
-  Gaps: 0""",
-            matchToString(match, read1, read2),
+  Id: id1
+    Length: 6
+    Gaps: 0
+  Id: id2
+    Length: 6
+    Gaps: 0''',
+            matchToString(match, read1, read2)
         )
 
     def testGapAndMatch(self):
         """
-        Two sequences containing gaps and matches must compare as
+        Two sequences containing matches and gaps must compare as
         expected.
         """
-        read1 = AARead("id1", "GALHN-")
-        read2 = AARead("id2", "GALHNA")
+        read1 = AARead('id1', 'GALHN-')
+        read2 = AARead('id2', 'GALHNA')
         match = compareAaReads(read1, read2)
 
         self.assertEqual(
-            """\
-Matches:
-  Overall: 5/6 (83.33%)
-  Not involving gaps (i.e., identities): 5/5 (100.00%)
-Mismatches:
-  Overall: 1/6 (16.67%)
+            '''\
+Matches: 5/6 (83.33%)
+Mismatches: 1/6 (16.67%)
   Not involving gaps (i.e., conflicts): 0
   Involving a gap in one sequence: 1/6 (16.67%)
   Involving a gap in both sequences: 0
-Id: id1
-  Length: 6
-  Gaps: 1/6 (16.67%)
-  Gap locations (1-based): 6
-Id: id2
-  Length: 6
-  Gaps: 0""",
-            matchToString(match, read1, read2),
-        )
-
-    def testGapAndMatchAndMismatch(self):
-        """
-        Two sequences containing gaps and matches and mismatches must compare
-        as expected.
-        """
-        read1 = AARead("id1", "--GBLHN-")
-        read2 = AARead("id2", "--GALHNA")
-        match = compareAaReads(read1, read2)
-
-        self.assertEqual(
-            """\
-Matches:
-  Overall: 4/8 (50.00%)
-  Not involving gaps (i.e., identities): 4/5 (80.00%)
-Mismatches:
-  Overall: 4/8 (50.00%)
-  Not involving gaps (i.e., conflicts): 1/8 (12.50%)
-  Involving a gap in one sequence: 1/8 (12.50%)
-  Involving a gap in both sequences: 2/8 (25.00%)
-Id: id1
-  Length: 8
-  Gaps: 3/8 (37.50%)
-  Gap locations (1-based): 1, 2, 8
-Id: id2
-  Length: 8
-  Gaps: 2/8 (25.00%)
-  Gap locations (1-based): 1, 2""",
-            matchToString(match, read1, read2),
-        )
-
-    def testUnequalLengthGapAndMatchAndMismatch(self):
-        """
-        Two sequences of unequal length containing gaps and matches and
-        mismatches must compare as expected.
-        """
-        read1 = AARead("id1", "--GBLHN-CC")
-        read2 = AARead("id2", "--GALHNA")
-        match = compareAaReads(read1, read2)
-
-        self.assertEqual(
-            """\
-Matches:
-  Overall: 4/10 (40.00%) of sequence 1, 4/8 (50.00%) of sequence 2
-  Not involving gaps (i.e., identities): 4/5 (80.00%)
-Mismatches:
-  Overall: 4/10 (40.00%) of sequence 1, 4/8 (50.00%) of sequence 2
-  Not involving gaps (i.e., conflicts): 1/10 (10.00%) of sequence 1, \
-1/8 (12.50%) of sequence 2
-  Involving a gap in one sequence: 1/10 (10.00%) of sequence 1, \
-1/8 (12.50%) of sequence 2
-  Involving a gap in both sequences: 2/10 (20.00%) of sequence 1, \
-2/8 (25.00%) of sequence 2
-Id: id1
-  Length: 10
-  Gaps: 3/10 (30.00%)
-  Gap locations (1-based): 1, 2, 8
-  Extra amino acids at end: 2/10 (20.00%)
-Id: id2
-  Length: 8
-  Gaps: 2/8 (25.00%)
-  Gap locations (1-based): 1, 2""",
-            matchToString(match, read1, read2),
+  Id: id1
+    Length: 6
+    Gaps: 1/6 (16.67%)
+    Gap locations (1-based): 6
+  Id: id2
+    Length: 6
+    Gaps: 0''',
+            matchToString(match, read1, read2)
         )
```

### Comparing `dark-matter-4.0.84/test/test_alignments.py` & `dark-matter-4.0.9/test/test_alignments.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,188 +1,183 @@
 import six
 from unittest import TestCase
 
 from dark.reads import Read, Reads
 from dark.score import HigherIsBetterScore
 from dark.hsp import HSP, LSP
 from dark.alignments import (
-    Alignment,
-    bestAlignment,
-    ReadAlignments,
-    ReadsAlignmentsParams,
-    ReadsAlignments,
-)
+    Alignment, bestAlignment, ReadAlignments, ReadsAlignmentsParams,
+    ReadsAlignments)
 
 
 class TestAlignment(TestCase):
     """
     Tests for the dark.alignment.Alignment class
     """
 
     def testExpectedAttrs(self):
         """
         An alignment must have the expected attributes.
         """
-        alignment = Alignment(45, "title")
-        self.assertEqual("title", alignment.subjectTitle)
+        alignment = Alignment(45, 'title')
+        self.assertEqual('title', alignment.subjectTitle)
         self.assertEqual(45, alignment.subjectLength)
 
     def testNoHspsWhenCreated(self):
         """
         An alignment must have no HSPs when it is created.
         """
-        alignment = Alignment(45, "title")
+        alignment = Alignment(45, 'title')
         self.assertEqual(0, len(alignment.hsps))
 
     def testAddHsp(self):
         """
         It must be possible to add an HSP to an alignment.
         """
-        alignment = Alignment(45, "title")
+        alignment = Alignment(45, 'title')
         alignment.addHsp(HSP(3))
         self.assertEqual(HSP(3), alignment.hsps[0])
 
 
 class TestReadAlignments(TestCase):
     """
     Tests for the dark.alignment.ReadAlignments class
     """
 
     def testRead(self):
         """
         An read alignments must store its read.
         """
-        read = Read("id", "ACGT")
+        read = Read('id', 'ACGT')
         readAlignments = ReadAlignments(read)
         self.assertEqual(read, readAlignments.read)
 
     def testNoAlignments(self):
         """
         An read alignments must be able to have no alignments.
         """
-        read = Read("id", "ACGT")
+        read = Read('id', 'ACGT')
         readAlignments = ReadAlignments(read)
         self.assertEqual(0, len(readAlignments))
 
     def testAlignments(self):
         """
         An read alignments must store its alignments.
         """
-        read = Read("id", "ACGT")
-        alignment1 = Alignment(45, "title1")
-        alignment2 = Alignment(55, "title2")
+        read = Read('id', 'ACGT')
+        alignment1 = Alignment(45, 'title1')
+        alignment2 = Alignment(55, 'title2')
         readAlignments = ReadAlignments(read, [alignment1, alignment2])
         self.assertEqual([alignment1, alignment2], readAlignments)
 
 
 class TestBestAlignmentHSP(TestCase):
     """
     Test the L{dark.hits.bestAlignment} function when HSPs are used.
     """
 
     def testOneAlignment(self):
         """
         When one alignment is present that alignment must be returned by
         bestAlignment.
         """
-        alignment = Alignment(44, "Seq 1")
+        alignment = Alignment(44, 'Seq 1')
         alignment.addHsp(HSP(10))
         alignment.addHsp(HSP(9))
 
         alignments = [alignment]
-        hit = ReadAlignments(Read("id1", "aaa"), alignments)
+        hit = ReadAlignments(Read('id1', 'aaa'), alignments)
         best = bestAlignment(hit)
-        self.assertEqual("Seq 1", best.subjectTitle)
+        self.assertEqual('Seq 1', best.subjectTitle)
         self.assertEqual(44, best.subjectLength)
 
     def testThreeAlignments(self):
         """
         When three alignments are present, the one with the highest first HSP
         must be returned by bestAlignment.
         """
-        alignment1 = Alignment(33, "Seq 1")
+        alignment1 = Alignment(33, 'Seq 1')
         alignment1.addHsp(HSP(10))
         alignment1.addHsp(HSP(9))
 
-        alignment2 = Alignment(44, "Seq 2")
+        alignment2 = Alignment(44, 'Seq 2')
         alignment2.addHsp(HSP(30))
         alignment2.addHsp(HSP(29))
 
-        alignment3 = Alignment(55, "Seq 3")
+        alignment3 = Alignment(55, 'Seq 3')
         alignment3.addHsp(HSP(20))
         alignment3.addHsp(HSP(19))
 
         alignments = [alignment1, alignment2, alignment3]
-        hit = ReadAlignments(Read("id1", "aaa"), alignments)
+        hit = ReadAlignments(Read('id1', 'aaa'), alignments)
         best = bestAlignment(hit)
-        self.assertEqual("Seq 2", best.subjectTitle)
+        self.assertEqual('Seq 2', best.subjectTitle)
         self.assertEqual(44, best.subjectLength)
 
 
 class TestBestAlignmentLSP(TestCase):
     """
     Test the L{dark.hits.bestAlignment} function when LSPs are used.
     """
 
     def testOneAlignment(self):
         """
         When one alignment is present that alignment must be returned by
         bestAlignment.
         """
-        alignment = Alignment(44, "Seq 1")
+        alignment = Alignment(44, 'Seq 1')
         alignment.addHsp(LSP(10))
         alignment.addHsp(LSP(9))
 
         alignments = [alignment]
-        readAlignments = ReadAlignments(Read("id0", "aaa"), alignments)
+        readAlignments = ReadAlignments(Read('id0', 'aaa'), alignments)
         best = bestAlignment(readAlignments)
-        self.assertEqual("Seq 1", best.subjectTitle)
+        self.assertEqual('Seq 1', best.subjectTitle)
         self.assertEqual(44, best.subjectLength)
 
     def testThreeAlignments(self):
         """
         When three alignments are present, the one with the lowest first HSP
         must be returned by bestAlignment.
         """
-        alignment1 = Alignment(33, "Seq 1")
+        alignment1 = Alignment(33, 'Seq 1')
         alignment1.addHsp(LSP(10))
         alignment1.addHsp(LSP(9))
 
-        alignment2 = Alignment(44, "Seq 2")
+        alignment2 = Alignment(44, 'Seq 2')
         alignment2.addHsp(LSP(3))
         alignment2.addHsp(LSP(2))
 
-        alignment3 = Alignment(55, "Seq 3")
+        alignment3 = Alignment(55, 'Seq 3')
         alignment3.addHsp(LSP(20))
         alignment3.addHsp(LSP(19))
 
         alignments = [alignment1, alignment2, alignment3]
-        readAlignments = ReadAlignments(Read("id0", "aaa"), alignments)
+        readAlignments = ReadAlignments(Read('id0', 'aaa'), alignments)
         best = bestAlignment(readAlignments)
-        self.assertEqual("Seq 2", best.subjectTitle)
+        self.assertEqual('Seq 2', best.subjectTitle)
         self.assertEqual(44, best.subjectLength)
 
 
 class TestReadsAlignmentsParams(TestCase):
     """
     Test the L{dark.alignments.ReadsAlignmentsParams} class.
     """
 
     def testExpectedAttrs(self):
         """
         A ReadsAlignmentsParams instance must have the expected attributes.
         """
         applicationParams = {}
-        params = ReadsAlignmentsParams(
-            "application name", applicationParams, False, "Bit score"
-        )
-        self.assertEqual("application name", params.application)
+        params = ReadsAlignmentsParams('application name', applicationParams,
+                                       False, 'Bit score')
+        self.assertEqual('application name', params.application)
         self.assertIs(applicationParams, params.applicationParams)
         self.assertFalse(params.subjectIsNucleotides)
-        self.assertEqual("Bit score", params.scoreTitle)
+        self.assertEqual('Bit score', params.scoreTitle)
 
 
 class TestReadsAlignments(TestCase):
     """
     Test the L{dark.alignments.ReadsAlignments} class.
     """
 
@@ -192,37 +187,34 @@
     # diamond/test_alignments.py and blast/test_alignments.py.
 
     def testExpectedAttrs(self):
         """
         A ReadsAlignments instance must have the expected attributes.
         """
         reads = Reads()
-        params = {"application": "app name"}
+        params = {
+            'application': 'app name'
+        }
         readsAlignments = ReadsAlignments(reads, params)
         self.assertIs(readsAlignments.reads, reads)
-        self.assertEqual("app name", readsAlignments.params["application"])
+        self.assertEqual('app name', readsAlignments.params['application'])
         self.assertIs(params, readsAlignments.params)
         self.assertIs(HigherIsBetterScore, readsAlignments.scoreClass)
 
     def testNotIterable(self):
         """
         Iterating an empty ReadsAlignments must result in the empty list.
         """
         reads = Reads()
-        readsAlignments = ReadsAlignments(reads, "applicationName", None)
+        readsAlignments = ReadsAlignments(reads, 'applicationName', None)
         self.assertEqual([], list(readsAlignments))
 
     def testGetSubjectSequence(self):
         """
         A ReadsAlignments instance will not implement getSubjectSequence.
         Subclasses are expected to implement it.
         """
         reads = Reads()
-        readsAlignments = ReadsAlignments(reads, "applicationName", None)
-        error = "getSubjectSequence must be implemented by a subclass"
-        six.assertRaisesRegex(
-            self,
-            NotImplementedError,
-            error,
-            readsAlignments.getSubjectSequence,
-            "title",
-        )
+        readsAlignments = ReadsAlignments(reads, 'applicationName', None)
+        error = 'getSubjectSequence must be implemented by a subclass'
+        six.assertRaisesRegex(self, NotImplementedError, error,
+                              readsAlignments.getSubjectSequence, 'title')
```

### Comparing `dark-matter-4.0.84/test/test_bowtie2.py` & `dark-matter-4.0.9/test/test_bowtie2.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,492 +1,464 @@
 from unittest import TestCase
-from unittest.mock import patch
 from io import StringIO
 
+try:
+    from unittest.mock import patch
+except ImportError:
+    from mock import patch
+
 from dark.bowtie2 import Bowtie2
 from dark.process import Executor
 
 
 class TestBowtie2(TestCase):
     """
     Test the Bowtie2 class.
     """
-
     def testIndexAccession(self):
         """
         Making a Bowtie index from an accession number must result in the
         expected commands being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("MN908947.3")
+        bt.buildIndex('MN908947.3')
         self.assertEqual(
-            "$ bowtie2-build --quiet '/tmp/xxx/MN908947.3.fasta' '/tmp/xxx/index'",
-            e.log[-1],
-        )
+            "$ bowtie2-build --quiet '/tmp/xxx/MN908947.3.fasta' "
+            "'/tmp/xxx/index'",
+            e.log[-1])
         log = fp.getvalue()
         self.assertTrue(
-            log.startswith("Downloading FASTA for accession MN908947.3 from NCBI.\n")
-        )
+            log.startswith('Downloading FASTA for accession MN908947.3 '
+                           'from NCBI.\n'))
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testIndexFromFile(self, existsMock):
         """
         Making a Bowtie index from a file name must result in the
         expected commands being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
+        bt.buildIndex('file.fasta')
         self.assertEqual(
-            "$ bowtie2-build --quiet 'file.fasta' '/tmp/xxx/index'", e.log[-1]
-        )
+            "$ bowtie2-build --quiet 'file.fasta' '/tmp/xxx/index'",
+            e.log[-1])
         log = fp.getvalue()
-        self.assertTrue(log.find("Building Bowtie2 index from file.fasta.\n") > -1)
+        self.assertTrue(
+            log.find("Building Bowtie2 index from file.fasta.\n") > -1)
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testIndexFromBowtie2File(self, existsMock):
         """
         Making a Bowtie index from a file that is an existing Bowtie2 index
         file must result in the expected commands being run and output being
         produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.1.bt2")
-        self.assertEqual(-1, e.log[-1].find("bowtie2-build"))
+        bt.buildIndex('file.1.bt2')
+        self.assertEqual(-1, e.log[-1].find('bowtie2-build'))
         log = fp.getvalue()
         self.assertEqual("Using pre-existing Bowtie2 index 'file'.\n", log)
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testIndexFromBowtie2FilePrefix(self, existsMock):
         """
         Making a Bowtie index from a file that is a prefix of an existing
         Bowtie2 index file name must result in the expected commands being run
         and output being produced.
         """
-
-        class SideEffect:
+        class SideEffect(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename):
                 if self.count == 0:
-                    self.test.assertEqual("idx-file", filename)
+                    self.test.assertEqual('idx-file', filename)
                     self.count += 1
                     return False
                 elif self.count == 1:
-                    self.test.assertEqual("idx-file.1.bt2", filename)
+                    self.test.assertEqual('idx-file.1.bt2', filename)
                     self.count += 1
                     return True
                 else:
-                    self.test.fail("Unexpected third call to exists.")
+                    self.test.fail('Unexpected third call to exists.')
 
         existsMock.side_effect = SideEffect(self).sideEffect
 
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("idx-file")
-        self.assertEqual(-1, e.log[-1].find("bowtie2-build"))
+        bt.buildIndex('idx-file')
+        self.assertEqual(-1, e.log[-1].find('bowtie2-build'))
         log = fp.getvalue()
         self.assertEqual("Using pre-existing Bowtie2 index 'idx-file'.\n", log)
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testAlignOneFASTQ(self, existsMock):
         """
         Making a Bowtie index from a file name and running an alignment with
         one FASTQ file must result in the expected commands being run and
         output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq", threads=4)
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq', threads=4)
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nAligning with Bowtie2.\n"))
+        self.assertTrue(log.endswith('\nAligning with Bowtie2.\n'))
         self.assertEqual(
             "$ bowtie2 --no-unal --threads 4 --rg-id 'orig' --rg 'SM:orig' "
             "-x '/tmp/xxx/index' "
-            "-U 'file1.fastq' > '/tmp/xxx/result.sam'",
-            e.log[-1],
-        )
+            "-U 'file1.fastq' > '/tmp/xxx/result.sam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testAlignOneFASTQWithReadGroup(self, existsMock):
         """
         Making a Bowtie index from a file name and running an alignment with
         one FASTQ file and specifying a read group must result in the expected
         commands being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq", threads=4, readGroup="xxx")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq', threads=4, readGroup='xxx')
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nAligning with Bowtie2.\n"))
+        self.assertTrue(log.endswith('\nAligning with Bowtie2.\n'))
         self.assertEqual(
             "$ bowtie2 --no-unal --threads 4 --rg-id 'xxx' --rg 'SM:orig' "
             "-x '/tmp/xxx/index' "
-            "-U 'file1.fastq' > '/tmp/xxx/result.sam'",
-            e.log[-1],
-        )
+            "-U 'file1.fastq' > '/tmp/xxx/result.sam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testAlignOneFASTQWithSampleName(self, existsMock):
         """
         Making a Bowtie index from a file name and running an alignment with
         one FASTQ file and specifying a sample name must result in the expected
         commands being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq", threads=4, sampleName="xxx")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq', threads=4, sampleName='xxx')
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nAligning with Bowtie2.\n"))
+        self.assertTrue(log.endswith('\nAligning with Bowtie2.\n'))
         self.assertEqual(
             "$ bowtie2 --no-unal --threads 4 --rg-id 'orig' --rg 'SM:xxx' "
             "-x '/tmp/xxx/index' "
-            "-U 'file1.fastq' > '/tmp/xxx/result.sam'",
-            e.log[-1],
-        )
+            "-U 'file1.fastq' > '/tmp/xxx/result.sam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testAlignOneFASTQWithFlags(self, existsMock):
         """
         Making a Bowtie index from a file name and running an alignment with
         one FASTQ file and some (fictional) args must result in the expected
         commands being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq", threads=4, bowtie2Args="--up --dn")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq', threads=4, bowtie2Args='--up --dn')
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nAligning with Bowtie2.\n"))
+        self.assertTrue(log.endswith('\nAligning with Bowtie2.\n'))
         self.assertEqual(
             "$ bowtie2 --up --dn --threads 4 --rg-id 'orig' --rg 'SM:orig' -x "
             "'/tmp/xxx/index' -U 'file1.fastq' > '/tmp/xxx/result.sam'",
-            e.log[-1],
-        )
+            e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testAlignTwoFASTQs(self, existsMock):
         """
         Making a Bowtie index from a file name and running an alignment with
         two FASTQ files must result in the expected commands being run and
         output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq", fastq2="file2.fastq", threads=4)
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq', fastq2='file2.fastq', threads=4)
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nAligning with Bowtie2.\n"))
+        self.assertTrue(log.endswith('\nAligning with Bowtie2.\n'))
         self.assertEqual(
             "$ bowtie2 --no-unal --threads 4 --rg-id 'orig' --rg 'SM:orig' -x "
             "'/tmp/xxx/index' "
             "-1 'file1.fastq' -2 'file2.fastq' > '/tmp/xxx/result.sam'",
-            e.log[-1],
-        )
+            e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testAlignTwoFASTQsWithReadGroup(self, existsMock):
         """
         Making a Bowtie index from a file name and running an alignment with
         two FASTQ files and a read group must result in the expected commands
         being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq", fastq2="file2.fastq", threads=4, readGroup="xxx")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq', fastq2='file2.fastq', threads=4,
+                 readGroup='xxx')
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nAligning with Bowtie2.\n"))
+        self.assertTrue(log.endswith('\nAligning with Bowtie2.\n'))
         self.assertEqual(
             "$ bowtie2 --no-unal --threads 4 --rg-id 'xxx' --rg 'SM:orig' -x "
             "'/tmp/xxx/index' "
             "-1 'file1.fastq' -2 'file2.fastq' > '/tmp/xxx/result.sam'",
-            e.log[-1],
-        )
+            e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testAlignTwoFASTQsWithSampleName(self, existsMock):
         """
         Making a Bowtie index from a file name and running an alignment with
         two FASTQ files and a sample name must result in the expected commands
         being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(
-            fastq1="file1.fastq", fastq2="file2.fastq", threads=4, sampleName="xxx"
-        )
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq', fastq2='file2.fastq', threads=4,
+                 sampleName='xxx')
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nAligning with Bowtie2.\n"))
+        self.assertTrue(log.endswith('\nAligning with Bowtie2.\n'))
         self.assertEqual(
             "$ bowtie2 --no-unal --threads 4 --rg-id 'orig' --rg 'SM:xxx' -x "
             "'/tmp/xxx/index' "
             "-1 'file1.fastq' -2 'file2.fastq' > '/tmp/xxx/result.sam'",
-            e.log[-1],
-        )
+            e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testMakeBAM(self, existsMock):
         """
         Making a BAM file must result in the expected commands being run and
         output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.makeBAM()
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nConverting SAM to BAM.\n"))
+        self.assertTrue(log.endswith('\nConverting SAM to BAM.\n'))
         self.assertEqual(
-            "$ samtools view -b  '/tmp/xxx/result.sam' > '/tmp/xxx/result.bam'",
-            e.log[-1],
-        )
+            "$ samtools view -b  '/tmp/xxx/result.sam' > "
+            "'/tmp/xxx/result.bam'",
+            e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testMakeIndexedBAM(self, existsMock):
         """
         Making a BAM file and indexing it must result in the expected commands
         being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.makeBAM()
         bt.indexBAM()
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nIndexing BAM.\n"))
+        self.assertTrue(log.endswith('\nIndexing BAM.\n'))
         self.assertEqual("$ samtools index '/tmp/xxx/result.bam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testRemoveDuplicates(self, existsMock):
         """
         Removing duplicates must result in the expected commands
         being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.removeDuplicates()
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nRemoving marked duplicates.\n"))
-        # Note the two spaces in the following. This is due to the way the "-b"
-        # argument is inserted when BAM is being made (which is not the case
-        # here).
-        self.assertEqual(
-            "$ samtools view  -F 1024 '/tmp/xxx/result.sam' "
-            "> '/tmp/xxx/non-duplicates.sam'",
-            e.log[-2],
-        )
-        self.assertEqual(
-            "$ mv '/tmp/xxx/non-duplicates.sam' '/tmp/xxx/result.sam'", e.log[-1]
-        )
+        self.assertTrue(log.endswith('\nRemoving marked duplicates.\n'))
+        self.assertEqual("$ samtools view -b -F 1024 '/tmp/xxx/result.sam' "
+                         "> '/tmp/xxx/non-duplicates.sam'", e.log[-2])
+        self.assertEqual("$ mv '/tmp/xxx/non-duplicates.sam' "
+                         "'/tmp/xxx/result.sam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testSortByCoord(self, existsMock):
         """
         Sorting by coord (the default) must result in the expected commands
         being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.sort()
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nSorting SAM (by coord).\n"))
-        self.assertEqual(
-            "$ samtools sort '/tmp/xxx/result.sam' > '/tmp/xxx/result-sorted.sam'",
-            e.log[-2],
-        )
-        self.assertEqual(
-            "$ mv '/tmp/xxx/result-sorted.sam' '/tmp/xxx/result.sam'", e.log[-1]
-        )
+        self.assertTrue(log.endswith('\nSorting SAM (by coord).\n'))
+        self.assertEqual("$ samtools sort '/tmp/xxx/result.sam' > "
+                         "'/tmp/xxx/result-sorted.sam'", e.log[-2])
+        self.assertEqual("$ mv '/tmp/xxx/result-sorted.sam' "
+                         "'/tmp/xxx/result.sam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testSortByName(self, existsMock):
         """
         Sorting by name must result in the expected commands
         being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.sort(byName=True)
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nSorting SAM (by name).\n"))
-        self.assertEqual(
-            "$ samtools sort -n '/tmp/xxx/result.sam' > "
-            "'/tmp/xxx/result-sorted.sam'",
-            e.log[-2],
-        )
-        self.assertEqual(
-            "$ mv '/tmp/xxx/result-sorted.sam' '/tmp/xxx/result.sam'", e.log[-1]
-        )
+        self.assertTrue(log.endswith('\nSorting SAM (by name).\n'))
+        self.assertEqual("$ samtools sort -n '/tmp/xxx/result.sam' > "
+                         "'/tmp/xxx/result-sorted.sam'", e.log[-2])
+        self.assertEqual("$ mv '/tmp/xxx/result-sorted.sam' "
+                         "'/tmp/xxx/result.sam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testOutputFileSAM(self, existsMock):
         """
         The output file must be a SAM file if BAM hasn't been produced.
         """
-
-        class SideEffect:
+        class SideEffect(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename):
                 if self.count == 0:
-                    self.test.assertEqual("index", filename)
+                    self.test.assertEqual('index', filename)
                     self.count += 1
                     return False
                 elif self.count == 1:
-                    self.test.assertEqual("index.1.bt2", filename)
+                    self.test.assertEqual('index.1.bt2', filename)
                     self.count += 1
                     return True
                 elif self.count == 2:
-                    self.test.assertEqual("/tmp/xxx/result.bam", filename)
+                    self.test.assertEqual('/tmp/xxx/result.bam', filename)
                     self.count += 1
                     return False
                 elif self.count == 3:
-                    self.test.assertEqual("/tmp/xxx/result.sam", filename)
+                    self.test.assertEqual('/tmp/xxx/result.sam', filename)
                     self.count += 1
                     return True
                 else:
                     self.test.fail(
-                        "Unexpected 5th call to exists. Filename: %r." % filename
-                    )
+                        'Unexpected 5th call to exists. Filename: %r.' %
+                        filename)
 
         existsMock.side_effect = SideEffect(self).sideEffect
 
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("index")
-        bt.align(fastq1="file1.fastq")
-        self.assertEqual("/tmp/xxx/result.sam", bt.outputFile())
+        bt.buildIndex('index')
+        bt.align(fastq1='file1.fastq')
+        self.assertEqual('/tmp/xxx/result.sam', bt.outputFile())
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testOutputFileBAM(self, existsMock):
         """
         The output file must be BAM if it has been produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.makeBAM()
-        self.assertEqual("/tmp/xxx/result.bam", bt.outputFile())
+        self.assertEqual('/tmp/xxx/result.bam', bt.outputFile())
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testMarkDuplicatesPicard(self, existsMock):
         """
         Using Picard to mark duplicates must result in the expected commands
         being run and output being produced.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.makeBAM()
         bt.indexBAM()
-        bt.markDuplicatesPicard("picard.jar")
+        bt.markDuplicatesPicard('picard.jar')
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nMarking duplicates with Picard.\n"))
+        self.assertTrue(log.endswith('\nMarking duplicates with Picard.\n'))
         self.assertEqual(
-            "$ java -Xmn2g -Xms2g -Xmx2g -jar picard.jar MarkDuplicates "
+            '$ java -Xmn2g -Xms2g -Xmx2g -jar picard.jar MarkDuplicates '
             "I='/tmp/xxx/result.bam' O='/tmp/xxx/picard-duplicates.bam' "
             "M=/dev/null >'/tmp/xxx/picard.errs' 2>&1",
-            e.log[-2],
-        )
-        self.assertEqual(
-            "$ mv '/tmp/xxx/picard-duplicates.bam' '/tmp/xxx/result.bam'", e.log[-1]
-        )
+            e.log[-2])
+        self.assertEqual("$ mv '/tmp/xxx/picard-duplicates.bam' "
+                         "'/tmp/xxx/result.bam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testMarkDuplicatesGATKBowtie2Threads(self, existsMock):
         """
         Using GATK to mark duplicates must result in the expected commands
         being run and output being produced. The number of threads is taken
         from the Bowtie2 instance.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp, threads=4)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.makeBAM()
         bt.indexBAM()
         bt.markDuplicatesGATK()
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nMarking duplicates with GATK.\n"))
+        self.assertTrue(log.endswith('\nMarking duplicates with GATK.\n'))
         self.assertEqual(
             "$ gatk MarkDuplicatesSpark -I '/tmp/xxx/result.bam' -O "
             "'/tmp/xxx/gatk-duplicates.bam' --conf spark.executor.cores=4",
-            e.log[-2],
-        )
-        self.assertEqual(
-            "$ mv '/tmp/xxx/gatk-duplicates.bam' '/tmp/xxx/result.bam'", e.log[-1]
-        )
+            e.log[-2])
+        self.assertEqual("$ mv '/tmp/xxx/gatk-duplicates.bam' "
+                         "'/tmp/xxx/result.bam'", e.log[-1])
 
-    @patch("os.path.exists")
+    @patch('os.path.exists')
     def testMarkDuplicatesGATKThreadsInArg(self, existsMock):
         """
         Using GATK to mark duplicates must result in the expected commands
         being run and output being produced. The number of threads is given
         in the call to markDuplicatesGATK and must override the number given
         to the Bowtie2 instance.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
         bt = Bowtie2(executor=e, dryRun=True, verboseFp=fp, threads=4)
-        bt.buildIndex("file.fasta")
-        bt.align(fastq1="file1.fastq")
+        bt.buildIndex('file.fasta')
+        bt.align(fastq1='file1.fastq')
         bt.makeBAM()
         bt.indexBAM()
         bt.markDuplicatesGATK(threads=32)
         log = fp.getvalue()
-        self.assertTrue(log.endswith("\nMarking duplicates with GATK.\n"))
+        self.assertTrue(log.endswith('\nMarking duplicates with GATK.\n'))
         self.assertEqual(
             "$ gatk MarkDuplicatesSpark -I '/tmp/xxx/result.bam' -O "
             "'/tmp/xxx/gatk-duplicates.bam' --conf spark.executor.cores=32",
-            e.log[-2],
-        )
-        self.assertEqual(
-            "$ mv '/tmp/xxx/gatk-duplicates.bam' '/tmp/xxx/result.bam'", e.log[-1]
-        )
+            e.log[-2])
+        self.assertEqual("$ mv '/tmp/xxx/gatk-duplicates.bam' "
+                         "'/tmp/xxx/result.bam'", e.log[-1])
 
     def testClose(self):
         """
         Calling close() must result in the temporary directory being removed.
         """
         e = Executor(dryRun=True)
         fp = StringIO()
```

### Comparing `dark-matter-4.0.84/test/test_btop.py` & `dark-matter-4.0.9/test/test_btop.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,309 +6,290 @@
 
 def btop2cigarStr(btopString, concise=False, aa=False):
     """
     Call btopString and turn its generator result into a string.
 
     See btopString for the explanation of the args.
     """
-    return "".join(btop2cigar(btopString, concise, aa))
+    return ''.join(btop2cigar(btopString, concise, aa))
 
 
 class TestParseBtop(TestCase):
     """
     Tests for the parseBtop function.
     """
-
     def testOneLetter(self):
         """
         An argument with just one letter must result in a ValueError.
         """
-        error = (
-            "^BTOP string 'F' has a trailing query letter 'F' with no "
-            "corresponding subject letter$"
-        )
-        assertRaisesRegex(self, ValueError, error, list, parseBtop("F"))
+        error = ("^BTOP string 'F' has a trailing query letter 'F' with no "
+                 "corresponding subject letter$")
+        assertRaisesRegex(self, ValueError, error, list, parseBtop('F'))
 
     def testConsecutiveGaps(self):
         """
         An argument that has two consecutive gaps characters must result in a
         ValueError.
         """
         error = "^BTOP string '36--' has two consecutive gaps at offset 2$"
-        assertRaisesRegex(self, ValueError, error, list, parseBtop("36--"))
+        assertRaisesRegex(self, ValueError, error, list, parseBtop('36--'))
 
     def testConsecutiveIdentical(self):
         """
         An argument that has two consecutive identical (non-gap) characters
         must result in a ValueError.
         """
-        error = (
-            "^BTOP string '36AA' has two consecutive identical 'A' "
-            "letters at offset 2$"
-        )
-        assertRaisesRegex(self, ValueError, error, list, parseBtop("36AA"))
+        error = ("^BTOP string '36AA' has two consecutive identical 'A' "
+                 "letters at offset 2$")
+        assertRaisesRegex(self, ValueError, error, list, parseBtop('36AA'))
 
     def testEmpty(self):
         """
         An empty argument must result in an empty list.
         """
-        self.assertEqual([], list(parseBtop("")))
+        self.assertEqual([], list(parseBtop('')))
 
     def testOneNumberWithTrailingOneLetter(self):
         """
         An argument that is a number with a single letter must result in a
         ValueError.
         """
-        error = (
-            "^BTOP string '36F' has a trailing query letter 'F' with no "
-            "corresponding subject letter$"
-        )
-        assertRaisesRegex(self, ValueError, error, list, parseBtop("36F"))
+        error = ("^BTOP string '36F' has a trailing query letter 'F' with no "
+                 "corresponding subject letter$")
+        assertRaisesRegex(self, ValueError, error, list, parseBtop('36F'))
 
     def testThreeLetters(self):
         """
         An argument that has three letters must result in a ValueError.
         """
-        error = (
-            "^BTOP string 'ABC' has a trailing query letter 'C' with no "
-            "corresponding subject letter$"
-        )
-        assertRaisesRegex(self, ValueError, error, list, parseBtop("ABC"))
+        error = ("^BTOP string 'ABC' has a trailing query letter 'C' with no "
+                 "corresponding subject letter$")
+        assertRaisesRegex(self, ValueError, error, list, parseBtop('ABC'))
 
     def testOneLetterThenANumber(self):
         """
         An argument that is a single letter followed by a number must result
         in a ValueError.
         """
-        error = (
-            "^BTOP string 'F36' has a query letter 'F' at offset 0 with "
-            "no corresponding subject letter$"
-        )
-        assertRaisesRegex(self, ValueError, error, list, parseBtop("F36"))
+        error = ("^BTOP string 'F36' has a query letter 'F' at offset 0 with "
+                 "no corresponding subject letter$")
+        assertRaisesRegex(self, ValueError, error, list, parseBtop('F36'))
 
     def testTwoNumbersWithOneLetterBetween(self):
         """
         An argument that is a number, a single letter, and another number must
         result in a ValueError.
         """
-        error = (
-            "^BTOP string '36F77' has a query letter 'F' at offset 2 "
-            "with no corresponding subject letter$"
-        )
-        assertRaisesRegex(self, ValueError, error, list, parseBtop("36F77"))
+        error = ("^BTOP string '36F77' has a query letter 'F' at offset 2 "
+                 "with no corresponding subject letter$")
+        assertRaisesRegex(self, ValueError, error, list, parseBtop('36F77'))
 
     def testOneNumber(self):
         """
         An argument that is just one number must give the expected result.
         """
-        self.assertEqual([54], list(parseBtop("54")))
+        self.assertEqual([54], list(parseBtop('54')))
 
     def testOneNumberThatIsZero(self):
         """
         An argument that is just the number zero must give the expected result.
         """
-        self.assertEqual([0], list(parseBtop("0")))
+        self.assertEqual([0], list(parseBtop('0')))
 
     def testOneNumberWithLeadingZeroes(self):
         """
         An argument that is just one number with leading zeroes must give the
         expected result.
         """
-        self.assertEqual([54], list(parseBtop("0054")))
+        self.assertEqual([54], list(parseBtop('0054')))
 
     def testOneQuerySubjectPair(self):
         """
         An argument that is a single query/subject letter pair must give the
         expected result.
         """
-        self.assertEqual([("A", "G")], list(parseBtop("AG")))
+        self.assertEqual([('A', 'G')], list(parseBtop('AG')))
 
     def testTwoQuerySubjectPairs(self):
         """
         An argument that has two query/subject letter pairs must give the
         expected result.
         """
-        self.assertEqual([("A", "G"), ("C", "T")], list(parseBtop("AGCT")))
+        self.assertEqual([('A', 'G'), ('C', 'T')], list(parseBtop('AGCT')))
 
     def testOneQuerySubjectPairAndANumber(self):
         """
         An argument that is a single query/subject letter pair followed by a
         number must give the expected result.
         """
-        self.assertEqual([("A", "G"), 33], list(parseBtop("AG33")))
+        self.assertEqual([('A', 'G'), 33], list(parseBtop('AG33')))
 
 
 class TestCountGaps(TestCase):
     """
     Tests for the countGaps function.
     """
-
     def testEmpty(self):
         """
         An argument with an empty string must produce the expected result.
         """
-        self.assertEqual((0, 0), countGaps(""))
+        self.assertEqual((0, 0), countGaps(''))
 
     def testNumberOnly(self):
         """
         An argument with just a number must produce the expected result.
         """
-        self.assertEqual((0, 0), countGaps("88"))
+        self.assertEqual((0, 0), countGaps('88'))
 
     def testLettersButNoGaps(self):
         """
         An argument with just letters must produce the expected result.
         """
-        self.assertEqual((0, 0), countGaps("FGAC"))
+        self.assertEqual((0, 0), countGaps('FGAC'))
 
     def testOneQueryGap(self):
         """
         An argument with just a query gap must produce the expected result.
         """
-        self.assertEqual((1, 0), countGaps("-G"))
+        self.assertEqual((1, 0), countGaps('-G'))
 
     def testOneSubjectGap(self):
         """
         An argument with just a subject gap must produce the expected result.
         """
-        self.assertEqual((0, 1), countGaps("G-"))
+        self.assertEqual((0, 1), countGaps('G-'))
 
     def testOneQueryAndOneSubjectGap(self):
         """
         An argument with a query and a subject gap must produce the expected
         result.
         """
-        self.assertEqual((1, 1), countGaps("G--G"))
+        self.assertEqual((1, 1), countGaps('G--G'))
 
     def testMultipleQueryAndSubjectGaps(self):
         """
         An argument with multiple query and a subject gaps must produce the
         expected result.
         """
-        self.assertEqual((3, 2), countGaps("-GG-34-T-T39F-"))
+        self.assertEqual((3, 2), countGaps('-GG-34-T-T39F-'))
 
 
 class TestBtop2CigarPrecise(TestCase):
     """
     Tests for the btop2cigar function when concise is False.
     """
-
     def testEmpty(self):
         """
         An empty BTOP string must result in an empty CIGAR string.
         """
-        self.assertEqual("", btop2cigarStr("", concise=False))
+        self.assertEqual('', btop2cigarStr('', concise=False))
 
     def testMixedMatch(self):
         """
         If a BTOP string specifies that all characters match (in the imprecise
         CIGAR sense where M could be identical characters or not), the CIGAR
         string must be all Ms.
         """
-        self.assertEqual("7M", btop2cigarStr("2GC3AT", concise=False))
+        self.assertEqual('7M', btop2cigarStr('2GC3AT', concise=False))
 
     def testRefenceInsertion(self):
         """
         If a BTOP string specifies that the query has character but the
         subject (reference) does not, the CIGAR string must indicate an
         insertion to the reference.
         """
-        self.assertEqual("1I", btop2cigarStr("A-", concise=False))
+        self.assertEqual('1I', btop2cigarStr('A-', concise=False))
 
     def testQueryInsertion(self):
         """
         If a BTOP string specifies that the subject (reference) has character
         but the query does not, the CIGAR string must indicate an deletion in
         the reference.
         """
-        self.assertEqual("1D", btop2cigarStr("-A", concise=False))
+        self.assertEqual('1D', btop2cigarStr('-A', concise=False))
 
     def testAll(self):
         """
         If a BTOP string specifies all possible variations, the CIGAR
         string must be correct.
         """
-        self.assertEqual("7M2I4M2D5M", btop2cigarStr("2GC3ATC-G-4-T-A5", concise=False))
+        self.assertEqual('7M2I4M2D5M',
+                         btop2cigarStr('2GC3ATC-G-4-T-A5', concise=False))
 
     def testAllList(self):
         """
         If a BTOP string specifies all possible variations, the CIGAR
         string components must be correct.
         """
-        self.assertEqual(
-            ["7M", "2I", "4M", "2D", "5M"],
-            list(btop2cigar("2GC3ATC-G-4-T-A5", concise=False)),
-        )
+        self.assertEqual(['7M', '2I', '4M', '2D', '5M'],
+                         list(btop2cigar('2GC3ATC-G-4-T-A5', concise=False)))
 
     def testAllAA(self):
         """
         If a BTOP string specifies all possible variations, and we indicate
         that the BTOP string refers to amino acids, the CIGAR string must be
         correct (i.e., all counts must be tripled).
         """
         self.assertEqual(
-            "21M6I12M6D15M", btop2cigarStr("2GC3ATC-G-4-T-A5", concise=False, aa=True)
-        )
+            '21M6I12M6D15M',
+            btop2cigarStr('2GC3ATC-G-4-T-A5', concise=False, aa=True))
 
     def testAllAAList(self):
         """
         If a BTOP string specifies all possible variations, and we indicate
         that the BTOP string refers to amino acids, the CIGAR string components
         must be correct (i.e., all counts must be tripled).
         """
         self.assertEqual(
-            ["21M", "6I", "12M", "6D", "15M"],
-            list(btop2cigar("2GC3ATC-G-4-T-A5", concise=False, aa=True)),
-        )
+            ['21M', '6I', '12M', '6D', '15M'],
+            list(btop2cigar('2GC3ATC-G-4-T-A5', concise=False, aa=True)))
 
 
 class TestBtop2CigarConcise(TestCase):
     """
     Tests for the btop2cigar function when concise is True.
     """
 
     def testEmpty(self):
         """
         An empty BTOP string must result in an empty CIGAR string.
         """
-        self.assertEqual("", btop2cigarStr("", concise=True))
+        self.assertEqual('', btop2cigarStr('', concise=True))
 
     def testMixedMatch(self):
         """
         If a BTOP string specifies that some characters match and some do
         not, the CIGAR string must be specific about the matches / mismatches.
         """
-        self.assertEqual("2=1X3=1X", btop2cigarStr("2GC3AT", concise=True))
+        self.assertEqual('2=1X3=1X', btop2cigarStr('2GC3AT', concise=True))
 
     def testRefenceInsertion(self):
         """
         If a BTOP string specifies that the query has character but the
         subject (reference) does not, the CIGAR string must indicate an
         insertion to the reference.
         """
-        self.assertEqual("1I", btop2cigarStr("A-", concise=True))
+        self.assertEqual('1I', btop2cigarStr('A-', concise=True))
 
     def testQueryInsertion(self):
         """
         If a BTOP string specifies that the subject (reference) has character
         but the query does not, the CIGAR string must indicate an deletion in
         the reference.
         """
-        self.assertEqual("1D", btop2cigarStr("-A", concise=True))
+        self.assertEqual('1D', btop2cigarStr('-A', concise=True))
 
     def testAll(self):
         """
         If a BTOP string specifies all possible variations, the CIGAR
         string must be correct.
         """
-        self.assertEqual(
-            "2=1X3=1X2I4=2D5=", btop2cigarStr("2GC3ATC-G-4-T-A5", concise=True)
-        )
+        self.assertEqual('2=1X3=1X2I4=2D5=',
+                         btop2cigarStr('2GC3ATC-G-4-T-A5', concise=True))
 
     def testWithAATrue(self):
         """
         If concise and aa are both set to True, a ValueError must be raised.
         """
-        error = "^aa and concise cannot both be True$"
-        assertRaisesRegex(
-            self, ValueError, error, btop2cigarStr, "", concise=True, aa=True
-        )
+        error = '^aa and concise cannot both be True$'
+        assertRaisesRegex(self, ValueError, error, btop2cigarStr, '',
+                          concise=True, aa=True)
```

### Comparing `dark-matter-4.0.84/test/test_codonDistance.py` & `dark-matter-4.0.9/test/test_codonDistance.py`

 * *Files 24% similar despite different names*

```diff
@@ -3,45 +3,34 @@
 from dark.codonDistance import codonInformation, findDistance
 
 
 class TestCodonInformation(TestCase):
     """
     Tests for the codonInformation function.
     """
-
     def testReturnRightCodon(self):
         """
-        The function must return the right codon distances.
+        Must return the right codon.
         """
-        result = codonInformation(["GAT", "GAC"], ["GCC", "GCA"])
-        self.assertEqual([("GAC", "GCC")], result[1])
-        self.assertEqual([("GAT", "GCC"), ("GAT", "GCA"), ("GAC", "GCA")], result[2])
-
-    def testReturnRightCodonWithTransitionCount(self):
-        """
-        The function must return the right codon distances and the correct
-        number of transitions.
-        """
-        result = codonInformation(["GAT", "GAC"], ["GCC", "AGT"], countTransitions=True)
-        self.assertEqual([("GAC", "GCC", 0)], result[1])
-        self.assertEqual([("GAT", "GCC", 1), ("GAT", "AGT", 2)], result[2])
-        self.assertEqual([("GAC", "AGT", 3)], result[3])
+        result = codonInformation(['GAT', 'GAC'], ['GCC', 'GCA'])
+        self.assertEqual([['GAC', 'GCC']], result[1])
+        self.assertEqual([['GAT', 'GCC'], ['GAT', 'GCA'], ['GAC', 'GCA']],
+                         result[2])
 
 
 class TestFindDistance(TestCase):
     """
     Tests for the findDistance function.
     """
-
     def testFindDistanceThree(self):
         """
         findDistance must return the right distance if codons are different.
         """
-        distance = findDistance("ACA", "TGT")
+        distance = findDistance('ACA', 'TGT')
         self.assertEqual(3, distance)
 
     def testFindDistanceZero(self):
         """
         findDistance must return the right distance if codons are identical.
         """
-        distance = findDistance("ACA", "ACA")
+        distance = findDistance('ACA', 'ACA')
         self.assertEqual(0, distance)
```

### Comparing `dark-matter-4.0.84/test/test_colors.py` & `dark-matter-4.0.9/test/test_colors.py`

 * *Files 26% similar despite different names*

```diff
@@ -4,160 +4,155 @@
 from dark.colors import ColorsForCounts
 
 
 class TestColorsForCounts(TestCase):
     """
     Test the ColorsForCounts class.
     """
-
     def testCountNotInt(self):
         """
         A C{ValueError} must be raised if a non-integer count is given.
         """
-        error = (
-            r"^color arguments must be given as space-separated pairs of "
-            r"\"count color\" where the count is an integer threshold\. "
-            r"Your value \('non-int'\) was not an integer\.$"
-        )
-        six.assertRaisesRegex(
-            self, ValueError, error, ColorsForCounts, ("non-int red",)
-        )
+        error = (r"^color arguments must be given as space-separated pairs of "
+                 r"\"count color\" where the count is an integer threshold\. "
+                 r"Your value \('non-int'\) was not an integer\.$")
+        six.assertRaisesRegex(self, ValueError, error, ColorsForCounts,
+                              ('non-int red',))
 
     def testCountNegative(self):
         """
         A C{ValueError} must be raised if a count is less than zero.
         """
-        error = (
-            r"^color arguments must be given as space-separated pairs "
-            r"of \"count color\" where the count is non-negative. Your "
-            r"value \(-4\) is less than 0\.$"
-        )
-        six.assertRaisesRegex(self, ValueError, error, ColorsForCounts, ("-4 red",))
+        error = (r"^color arguments must be given as space-separated pairs "
+                 r"of \"count color\" where the count is non-negative. Your "
+                 r"value \(-4\) is less than 0\.$")
+        six.assertRaisesRegex(self, ValueError, error, ColorsForCounts,
+                              ('-4 red',))
 
     def testNoSpace(self):
         """
         A C{ValueError} must be raised if a count/color value has no space.
         """
-        error = (
-            r"^color arguments must be given as space-separated pairs "
-            r"of \"value color\"\. Your value \('4red'\) does not "
-            r"contain a space\.$"
-        )
-        six.assertRaisesRegex(self, ValueError, error, ColorsForCounts, ("4red",))
+        error = (r"^color arguments must be given as space-separated pairs "
+                 r"of \"value color\"\. Your value \('4red'\) does not "
+                 r"contain a space\.$")
+        six.assertRaisesRegex(self, ValueError, error, ColorsForCounts,
+                              ('4red',))
 
     def testRepeatedCount(self):
         """
         A C{ValueError} must be raised if a count is repeated.
         """
         error = r"^repeated color argument count \(4\)\.$"
-        six.assertRaisesRegex(
-            self, ValueError, error, ColorsForCounts, ("4 red", "4 black")
-        )
+        six.assertRaisesRegex(self, ValueError, error, ColorsForCounts,
+                              ('4 red', '4 black'))
 
     def testThresholdForCountNegative(self):
         """
         The thresholdForCount method must raise AssertionError if the count
         is negative.
         """
-        colors = ColorsForCounts(("4 red",))
-        error = r"^Count \(-4\) cannot be negative\.$"
-        six.assertRaisesRegex(self, AssertionError, error, colors.thresholdForCount, -4)
+        colors = ColorsForCounts(('4 red',))
+        error = (r"^Count \(-4\) cannot be negative\.$")
+        six.assertRaisesRegex(self, AssertionError, error,
+                              colors.thresholdForCount, -4)
 
     def testThresholdForTooLowCount(self):
         """
         The thresholdForCount method must work correctly when the lowest
         threshold is not reached.
         """
-        colors = ColorsForCounts(("4 red",))
+        colors = ColorsForCounts(('4 red',))
         self.assertEqual(0, colors.thresholdForCount(2))
 
     def testThresholdForCountOneThreshold(self):
         """
         The thresholdForCount method must work correctly when there is one
         threshold.
         """
-        colors = ColorsForCounts(("4 red",))
+        colors = ColorsForCounts(('4 red',))
         self.assertEqual(4, colors.thresholdForCount(4))
         self.assertEqual(4, colors.thresholdForCount(10))
 
     def testThresholdForCountTwoThresholds(self):
         """
         The thresholdForCount method must work correctly when there are two
         thresholds.
         """
-        colors = ColorsForCounts(("4 red", "10 green"))
+        colors = ColorsForCounts(('4 red', '10 green'))
         self.assertEqual(4, colors.thresholdForCount(6))
         self.assertEqual(10, colors.thresholdForCount(12))
 
     def testThresholdForCountThreeThresholds(self):
         """
         The thresholdForCount method must work correctly when there are three
         thresholds.
         """
-        colors = ColorsForCounts(("4 red", "10 green", "100 blue"))
+        colors = ColorsForCounts(('4 red', '10 green', '100 blue'))
         self.assertEqual(4, colors.thresholdForCount(6))
         self.assertEqual(10, colors.thresholdForCount(86))
         self.assertEqual(100, colors.thresholdForCount(1000))
 
     def testColorForTooLowCount(self):
         """
         The colorForCount method must work correctly when the lowest
         threshold is not reached.
         """
-        colors = ColorsForCounts(("4 red",))
-        self.assertEqual("black", colors.colorForCount(2))
+        colors = ColorsForCounts(('4 red',))
+        self.assertEqual('black', colors.colorForCount(2))
 
     def testColorForTooLowCountDefault(self):
         """
         The colorForCount method must work correctly when the lowest
         threshold is not reached and a default color is given.
         """
-        colors = ColorsForCounts(("4 red",), defaultColor="fuschia")
-        self.assertEqual("fuschia", colors.colorForCount(2))
+        colors = ColorsForCounts(('4 red',), defaultColor='fuschia')
+        self.assertEqual('fuschia', colors.colorForCount(2))
 
     def testColorForCountOneThreshold(self):
         """
         The colorForCount method must work correctly when there is one
         threshold.
         """
-        colors = ColorsForCounts(("4 red",))
-        self.assertEqual("black", colors.colorForCount(1))
-        self.assertEqual("red", colors.colorForCount(4))
-        self.assertEqual("red", colors.colorForCount(10))
+        colors = ColorsForCounts(('4 red',))
+        self.assertEqual('black', colors.colorForCount(1))
+        self.assertEqual('red', colors.colorForCount(4))
+        self.assertEqual('red', colors.colorForCount(10))
 
     def testColorForCountTwoThresholds(self):
         """
         The colorForCount method must work correctly when there are two
         thresholds.
         """
-        colors = ColorsForCounts(("4 red", "10 green"))
-        self.assertEqual("black", colors.colorForCount(1))
-        self.assertEqual("red", colors.colorForCount(6))
-        self.assertEqual("green", colors.colorForCount(12))
+        colors = ColorsForCounts(('4 red', '10 green'))
+        self.assertEqual('black', colors.colorForCount(1))
+        self.assertEqual('red', colors.colorForCount(6))
+        self.assertEqual('green', colors.colorForCount(12))
 
     def testColorForCountThreeThresholds(self):
         """
         The colorForCount method must work correctly when there are three
         thresholds.
         """
-        colors = ColorsForCounts(("4 red", "10 green", "100 blue"))
-        self.assertEqual("black", colors.colorForCount(1))
-        self.assertEqual("red", colors.colorForCount(6))
-        self.assertEqual("green", colors.colorForCount(86))
-        self.assertEqual("blue", colors.colorForCount(1000))
+        colors = ColorsForCounts(('4 red', '10 green', '100 blue'))
+        self.assertEqual('black', colors.colorForCount(1))
+        self.assertEqual('red', colors.colorForCount(6))
+        self.assertEqual('green', colors.colorForCount(86))
+        self.assertEqual('blue', colors.colorForCount(1000))
 
     def testThresholdToCssName(self):
         """
         The thresholdToCssName method must work as expected.
         """
-        colors = ColorsForCounts(("4 red",))
-        self.assertEqual("threshold-4", colors.thresholdToCssName(4))
+        colors = ColorsForCounts(('4 red',))
+        self.assertEqual('threshold-4', colors.thresholdToCssName(4))
 
     def testColorsForThreeThresholds(self):
         """
         The colors attribute must be as expected when there are three
         thresholds.
         """
-        colors = ColorsForCounts(("4 red", "10 green", "100 blue"), defaultColor="pink")
+        colors = ColorsForCounts(('4 red', '10 green', '100 blue'),
+                                 defaultColor='pink')
         self.assertEqual(
-            ((100, "blue"), (10, "green"), (4, "red"), (0, "pink")), colors.colors
-        )
+            ((100, 'blue'), (10, 'green'), (4, 'red'), (0, 'pink')),
+            colors.colors)
```

### Comparing `dark-matter-4.0.84/test/test_distance.py` & `dark-matter-4.0.9/test/test_distance.py`

 * *Files 20% similar despite different names*

```diff
@@ -8,20 +8,23 @@
     Tests for the dark.simplify.levenshtein function.
     """
 
     def testIdentical(self):
         """
         Two identical strings must have distance zero.
         """
-        self.assertEqual(0, levenshtein("BLAH", "BLAH"))
+        self.assertEqual(0, levenshtein('BLAH',
+                                        'BLAH'))
 
     def testMutation(self):
         """
         Test a single character results in a distance of 1.
         """
-        self.assertEqual(1, levenshtein("ACGTACACACG", "ACGTACACACT"))
+        self.assertEqual(1, levenshtein('ACGTACACACG',
+                                        'ACGTACACACT'))
 
     def testInsert(self):
         """
         Test a string insertion that results in a distance of 2.
         """
-        self.assertEqual(2, levenshtein("AGTACACACTG", "ACGTACACACT"))
+        self.assertEqual(2, levenshtein('AGTACACACTG',
+                                        'ACGTACACACT'))
```

### Comparing `dark-matter-4.0.84/test/test_fasta.py` & `dark-matter-4.0.9/test/test_fasta.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 import os
 from six.moves import builtins
 from six import assertRaisesRegex
 from io import BytesIO
-from unittest import TestCase, skip
-from unittest.mock import patch, mock_open
-from io import StringIO
+from unittest import TestCase
+
 from Bio import SeqIO, bgzf
 
+try:
+    from unittest.mock import patch, mock_open
+except ImportError:
+    from mock import patch
+
 from dark.reads import Read, AARead, DNARead, RNARead, Reads
-from dark.fasta import (
-    dedupFasta,
-    dePrefixAndSuffixFasta,
-    fastaSubtract,
-    FastaReads,
-    combineReads,
-    SqliteIndex,
-)
+from dark.fasta import (dedupFasta, dePrefixAndSuffixFasta, fastaSubtract,
+                        FastaReads, combineReads, SqliteIndex)
+from dark.utils import StringIO
 
 
 class FastaDeDup(TestCase):
     """
     Tests for de-duping FASTA sequence lists.
     """
 
@@ -30,441 +29,418 @@
         self.assertEqual(list(dedupFasta([])), [])
 
     def testLengthOne(self):
         """
         A FASTA list with just one item gets de-duped to the same one item.
         """
         reads = Reads()
-        reads.add(Read("id", "GGG"))
-        self.assertEqual(list(dedupFasta(reads)), [Read("id", "GGG")])
+        reads.add(Read('id', 'GGG'))
+        self.assertEqual(list(dedupFasta(reads)), [Read('id', 'GGG')])
 
     def testRemovalOfIdenticalSequences(self):
         """
         A list with 2 copies of the same seq is de-duped to have 1 copy.
         """
         reads = Reads()
-        reads.add(Read("id", "GGG"))
-        reads.add(Read("id", "GGG"))
-        self.assertEqual(list(dedupFasta(reads)), [Read("id", "GGG")])
+        reads.add(Read('id', 'GGG'))
+        reads.add(Read('id', 'GGG'))
+        self.assertEqual(list(dedupFasta(reads)), [Read('id', 'GGG')])
 
     def testRemovalOfIdenticalSequencesWithDifferingIds(self):
         """
         A list with 2 copies of the same seq is de-duped to have 1 copy,
         including when the read ids differ.
         """
         reads = Reads()
-        reads.add(Read("id1", "GGG"))
-        reads.add(Read("id2", "GGG"))
-        self.assertEqual(list(dedupFasta(reads)), [Read("id1", "GGG")])
+        reads.add(Read('id1', 'GGG'))
+        reads.add(Read('id2', 'GGG'))
+        self.assertEqual(list(dedupFasta(reads)), [Read('id1', 'GGG')])
 
 
 class Unused(TestCase):
+
     def testEmpty(self):
         """
         An empty FASTA list gets de-duped to an empty list.
         """
         self.assertEqual(list(dePrefixAndSuffixFasta([])), [])
 
     def testLengthOne(self):
         """
         A FASTA list with just one item gets de-duped to the same one item.
         """
-        seq = ">hey\nagtcagtcagtc"
-        s1 = SeqIO.read(StringIO(seq), "fasta")
+        seq = '>hey\nagtcagtcagtc'
+        s1 = SeqIO.read(StringIO(seq), 'fasta')
         self.assertEqual(list(dePrefixAndSuffixFasta([s1])), [s1])
 
     def testRemovalOfIdenticalSequences(self):
         """
         A list with 2 copies of the same seq is de-duped to have 1 copy.
         """
-        seq = ">hey\nagtcagtcagtc"
-        s1 = SeqIO.read(StringIO(seq), "fasta")
-        s2 = SeqIO.read(StringIO(seq), "fasta")
+        seq = '>hey\nagtcagtcagtc'
+        s1 = SeqIO.read(StringIO(seq), 'fasta')
+        s2 = SeqIO.read(StringIO(seq), 'fasta')
         self.assertEqual(list(dePrefixAndSuffixFasta([s1, s2])), [s1])
 
     def testRemovalOfPrefix(self):
         """
         A sequence that is a prefix of another is removed.
         """
-        s1 = SeqIO.read(StringIO(">s1\nagtcagtcagtc"), "fasta")
-        s2 = SeqIO.read(StringIO(">s2\nagtcag"), "fasta")
+        s1 = SeqIO.read(StringIO('>s1\nagtcagtcagtc'), 'fasta')
+        s2 = SeqIO.read(StringIO('>s2\nagtcag'), 'fasta')
         self.assertEqual(list(dePrefixAndSuffixFasta([s1, s2])), [s1])
 
     def testRemovalOfSuffix(self):
         """
         A sequence that is a suffix of another is removed.
         """
-        s1 = SeqIO.read(StringIO(">s1\nagtcagtcagtc"), "fasta")
-        s2 = SeqIO.read(StringIO(">s2\ncagtc"), "fasta")
+        s1 = SeqIO.read(StringIO('>s1\nagtcagtcagtc'), 'fasta')
+        s2 = SeqIO.read(StringIO('>s2\ncagtc'), 'fasta')
         self.assertEqual(list(dePrefixAndSuffixFasta([s1, s2])), [s1])
 
     def testRemovalOfPrefixSuffixAndDuplicate(self):
         """
         Prefixes, suffixes, and duplicates should collectively all be removed.
         """
-        s1 = SeqIO.read(StringIO(">s1\nagtcagtcagtc"), "fasta")
-        s2 = SeqIO.read(StringIO(">s2\nagtcagtcagtc"), "fasta")
-        s3 = SeqIO.read(StringIO(">s3\nagtcagt"), "fasta")
-        s4 = SeqIO.read(StringIO(">s4\ntcagtc"), "fasta")
+        s1 = SeqIO.read(StringIO('>s1\nagtcagtcagtc'), 'fasta')
+        s2 = SeqIO.read(StringIO('>s2\nagtcagtcagtc'), 'fasta')
+        s3 = SeqIO.read(StringIO('>s3\nagtcagt'), 'fasta')
+        s4 = SeqIO.read(StringIO('>s4\ntcagtc'), 'fasta')
         self.assertEqual(list(dePrefixAndSuffixFasta([s1, s2, s3, s4])), [s1])
 
     def testOrderIndependent(self):
         """
         A sequence that is a prefix of another is removed when it appears
         first.
         """
-        s1 = SeqIO.read(StringIO(">s1\nagtcag"), "fasta")
-        s2 = SeqIO.read(StringIO(">s2\nagtcagtcagtc"), "fasta")
+        s1 = SeqIO.read(StringIO('>s1\nagtcag'), 'fasta')
+        s2 = SeqIO.read(StringIO('>s2\nagtcagtcagtc'), 'fasta')
         self.assertEqual(list(dePrefixAndSuffixFasta([s1, s2])), [s2])
 
 
 class TestFastaSubtract(TestCase):
     """
     Test the fastaSubtract() function.
     """
-
     def testZeroFiles(self):
         self.assertRaises(IndexError, fastaSubtract, [])
 
     def testOneFile(self):
         """
         When just one file is passed we should get a result that has as many
         reads as was in the single input file.
         """
-        fasta1 = "\n".join(
-            [
-                ">one",
-                "agtcagtcagtc",
-                ">two",
-                "acctg",
-                ">three",
-                "atgggtc",
-                ">four",
-                "atggctattgaactgtatct",
-            ]
-        )
+        fasta1 = '\n'.join([
+            '>one',
+            'agtcagtcagtc',
+            '>two',
+            'acctg',
+            '>three',
+            'atgggtc',
+            '>four',
+            'atggctattgaactgtatct',
+        ])
 
         result = list(fastaSubtract([StringIO(fasta1)]))
         self.assertEqual(len(result), 4)
 
     def testSubtractEverything(self):
         """
         When two input files have the same reads, subtraction must result in an
         empty (no reads) output.
         """
-        fasta1 = "\n".join(
-            [
-                ">one",
-                "agtcagtcagtc",
-                ">two",
-                "acctg",
-                ">three",
-                "atgggtc",
-                ">four",
-                "atggctattgaactgtatct",
-            ]
-        )
+        fasta1 = '\n'.join([
+            '>one',
+            'agtcagtcagtc',
+            '>two',
+            'acctg',
+            '>three',
+            'atgggtc',
+            '>four',
+            'atggctattgaactgtatct',
+        ])
 
         result = list(fastaSubtract([StringIO(fasta1), StringIO(fasta1)]))
         self.assertEqual([], result)
 
     def testSubtractFromNothing(self):
         """
         When the first file is empty, the result shoud be too.
         """
-        fasta1 = ""
-        fasta2 = "\n".join(
-            [
-                ">five",
-                "agtcagtcagtc",
-                ">six",
-                "acctg",
-            ]
-        )
+        fasta1 = ''
+        fasta2 = '\n'.join([
+            '>five',
+            'agtcagtcagtc',
+            '>six',
+            'acctg',
+        ])
 
         result = list(fastaSubtract([StringIO(fasta1), StringIO(fasta2)]))
         self.assertEqual([], result)
 
     def testSubtractNothing(self):
         """
         When two input files have no overlap, subtraction must result in the
         same reads as are in the first input.
         """
-        fasta1 = "\n".join(
-            [
-                ">one",
-                "agtcagtcagtc",
-                ">two",
-                "acctg",
-                ">three",
-                "atgggtc",
-                ">four",
-                "atggctattgaactgtatct",
-            ]
-        )
-        fasta2 = "\n".join(
-            [
-                ">five",
-                "agtcagtcagtc",
-                ">six",
-                "acctg",
-            ]
-        )
+        fasta1 = '\n'.join([
+            '>one',
+            'agtcagtcagtc',
+            '>two',
+            'acctg',
+            '>three',
+            'atgggtc',
+            '>four',
+            'atggctattgaactgtatct',
+        ])
+        fasta2 = '\n'.join([
+            '>five',
+            'agtcagtcagtc',
+            '>six',
+            'acctg',
+        ])
 
         result = list(fastaSubtract([StringIO(fasta1), StringIO(fasta2)]))
-        self.assertEqual(
-            ["four", "one", "three", "two"], sorted([seq.id for seq in result])
-        )
+        self.assertEqual(['four', 'one', 'three', 'two'],
+                         sorted([seq.id for seq in result]))
 
     def testThreeFiles(self):
         """
         Subtraction of three files must work correctly.
         """
-        fasta1 = "\n".join(
-            [
-                ">one",
-                "agtcagtcagtc",
-                ">two",
-                "acctg",
-                ">three",
-                "atgggtc",
-                ">four",
-                "atggctattgaactgtatct",
-            ]
-        )
-        fasta2 = "\n".join(
-            [
-                ">one",
-                "agtcagtcagtc",
-            ]
-        )
-        fasta3 = "\n".join(
-            [
-                ">two",
-                "acctg",
-                ">three",
-                "atgggtc",
-            ]
-        )
-
-        result = list(
-            fastaSubtract([StringIO(fasta1), StringIO(fasta2), StringIO(fasta3)])
-        )
+        fasta1 = '\n'.join([
+            '>one',
+            'agtcagtcagtc',
+            '>two',
+            'acctg',
+            '>three',
+            'atgggtc',
+            '>four',
+            'atggctattgaactgtatct',
+        ])
+        fasta2 = '\n'.join([
+            '>one',
+            'agtcagtcagtc',
+        ])
+        fasta3 = '\n'.join([
+            '>two',
+            'acctg',
+            '>three',
+            'atgggtc',
+        ])
+
+        result = list(fastaSubtract([StringIO(fasta1),
+                                     StringIO(fasta2),
+                                     StringIO(fasta3)]))
         self.assertEqual(len(result), 1)
-        self.assertEqual(str(result[0].seq), "atggctattgaactgtatct")
-        self.assertEqual(str(result[0].id), "four")
+        self.assertEqual(str(result[0].seq), 'atggctattgaactgtatct')
+        self.assertEqual(str(result[0].id), 'four')
 
     def testSequencesAreChecked(self):
         """
         If a two reads with the same id do not have the same sequence,
         an assertion error must be raised.
         """
-        fasta1 = "\n".join(
-            [
-                ">one",
-                "ag",
-            ]
-        )
-        fasta2 = "\n".join(
-            [
-                ">one",
-                "at",
-            ]
-        )
-
-        self.assertRaises(
-            AssertionError, fastaSubtract, [StringIO(fasta1), StringIO(fasta2)]
-        )
+        fasta1 = '\n'.join([
+            '>one',
+            'ag',
+        ])
+        fasta2 = '\n'.join([
+            '>one',
+            'at',
+        ])
+
+        self.assertRaises(AssertionError, fastaSubtract,
+                          [StringIO(fasta1), StringIO(fasta2)])
 
 
 class TestFastaReads(TestCase):
     """
     Tests for the L{dark.fasta.FastaReads} class.
     """
 
     def testEmpty(self):
         """
         An empty FASTA file results in an empty iterator.
         """
-        with patch.object(builtins, "open", mock_open()):
-            reads = FastaReads("filename.fasta")
+        with patch.object(builtins, 'open', mock_open()):
+            reads = FastaReads('filename.fasta')
             self.assertEqual([], list(reads))
 
     def testOneRead(self):
         """
         A FASTA file with one read must be read properly.
         """
-        data = "\n".join([">id1", "ACGT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta"))
-            self.assertEqual([Read("id1", "ACGT")], reads)
+        data = '\n'.join(['>id1', 'ACGT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta'))
+            self.assertEqual([Read('id1', 'ACGT')], reads)
 
     def testNoQuality(self):
         """
         A FASTA file read must not have any quality information.
         """
-        data = "\n".join([">id1", "ACGT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta"))
+        data = '\n'.join(['>id1', 'ACGT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta'))
             self.assertEqual(None, reads[0].quality)
 
     def testTwoReads(self):
         """
         A FASTA file with two reads must be read properly and its
         sequences must be returned in the correct order.
         """
-        data = "\n".join([">id1", "ACGT", ">id2", "TGCA"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta"))
+        data = '\n'.join(['>id1', 'ACGT', '>id2', 'TGCA'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta'))
             self.assertEqual(2, len(reads))
-            self.assertEqual([Read("id1", "ACGT"), Read("id2", "TGCA")], reads)
+            self.assertEqual([Read('id1', 'ACGT'), Read('id2', 'TGCA')], reads)
 
     def testTypeDefaultsToDNA(self):
         """
         A FASTA file whose type is not specified must result in reads that
         are instances of DNARead.
         """
-        data = "\n".join([">id1", "ACGT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta"))
+        data = '\n'.join(['>id1', 'ACGT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta'))
             self.assertTrue(isinstance(reads[0], DNARead))
 
     def testTypeAA(self):
         """
         A FASTA file whose read class is AARead must result in reads that
         are instances of AARead.
         """
-        data = "\n".join([">id1", "ACGST"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta", AARead))
+        data = '\n'.join(['>id1', 'ACGST'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta', AARead))
             self.assertTrue(isinstance(reads[0], AARead))
 
     def testTypeDNA(self):
         """
         A FASTA file whose read class is DNARead must result in reads that
         are instances of DNARead.
         """
-        data = "\n".join([">id1", "ACGT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta", DNARead))
+        data = '\n'.join(['>id1', 'ACGT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta', DNARead))
             self.assertTrue(isinstance(reads[0], DNARead))
 
     def testTypeRNA(self):
         """
         A FASTA file whose read class is RNARead must result in reads that
         are instances of RNARead.
         """
-        data = "\n".join([">id1", "ACGT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta", RNARead))
+        data = '\n'.join(['>id1', 'ACGT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta', RNARead))
             self.assertTrue(isinstance(reads[0], RNARead))
 
     def testConvertLowerToUpperCaseIfSpecifiedAARead(self):
         """
         A read needs to be converted from lower to upper case if specified.
         """
-        data = "\n".join([">id1", "actgs"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta", readClass=AARead, upperCase=True))
-            self.assertEqual([AARead("id1", "ACTGS")], reads)
+        data = '\n'.join(['>id1', 'actgs'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta', readClass=AARead,
+                         upperCase=True))
+            self.assertEqual([AARead('id1', 'ACTGS')], reads)
 
     def testConvertLowerToUpperCaseIfSpecifiedDNARead(self):
         """
         A read needs to be converted from lower to upper case if specified.
         """
-        data = "\n".join([">id1", "actg"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta", upperCase=True))
-            self.assertEqual([AARead("id1", "ACTG")], reads)
+        data = '\n'.join(['>id1', 'actg'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta', upperCase=True))
+            self.assertEqual([AARead('id1', 'ACTG')], reads)
 
     def testDontConvertLowerToUpperCaseIfNotSpecified(self):
         """
         A read must not be converted from lower to upper case if not specified.
         """
-        data = "\n".join([">id1", "actgs"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastaReads("filename.fasta", readClass=AARead))
-            self.assertEqual([AARead("id1", "actgs")], reads)
+        data = '\n'.join(['>id1', 'actgs'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastaReads('filename.fasta', readClass=AARead))
+            self.assertEqual([AARead('id1', 'actgs')], reads)
 
     def testFilterRandomSubsetOfZeroFromZeroReads(self):
         """
         It must be possible to select a random subset of zero reads from a set
         of zero reads, where the read count is provided to C{filter} via the
         C{trueLength} argument.
         """
-        data = ""
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = FastaReads("filename.fasta")
+        data = ''
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = FastaReads('filename.fasta')
             result = list(reads.filter(randomSubset=0, trueLength=0))
             self.assertEqual([], result)
 
     def testFilterRandomSubsetOfTwoFromTwoReads(self):
         """
         It must be possible to select a random subset of two reads from a set
         of two reads, where the read count is provided to C{filter} via the
         C{trueLength} argument.
         """
-        data = "\n".join([">id1", "ACGT", ">id2", "TGCA"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = FastaReads("filename.fasta")
+        data = '\n'.join(['>id1', 'ACGT', '>id2', 'TGCA'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = FastaReads('filename.fasta')
             result = list(reads.filter(randomSubset=2, trueLength=2))
-            self.assertEqual([Read("id1", "ACGT"), Read("id2", "TGCA")], result)
+            self.assertEqual([Read('id1', 'ACGT'), Read('id2', 'TGCA')],
+                             result)
 
     def testFilterRandomSubsetOfOneFromTenReads(self):
         """
         It must be possible to select a random subset of one read from a set
         of ten reads, where the read count is provided to C{filter} via the
         C{trueLength} argument.
         """
-        data = "\n".join([">id", "ACGT"] * 10)
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = FastaReads("filename.fasta")
+        data = '\n'.join(['>id', 'ACGT'] * 10)
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = FastaReads('filename.fasta')
             result = list(reads.filter(randomSubset=1, trueLength=10))
             self.assertEqual(1, len(result))
 
     def testTwoFiles(self):
         """
         It must be possible to read from two FASTA files.
         """
-
-        class SideEffect:
+        class SideEffect(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("file1.fasta", filename)
+                    self.test.assertEqual('file1.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n")
+                    return StringIO('>id1\nACTG\n')
                 elif self.count == 1:
-                    self.test.assertEqual("file2.fasta", filename)
+                    self.test.assertEqual('file2.fasta', filename)
                     self.count += 1
-                    return StringIO(">id2\nCAGT\n")
+                    return StringIO('>id2\nCAGT\n')
                 else:
-                    self.test.fail("We are only supposed to be called twice!")
+                    self.test.fail('We are only supposed to be called twice!')
 
         sideEffect = SideEffect(self)
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect.sideEffect
-            reads = FastaReads(["file1.fasta", "file2.fasta"])
+            reads = FastaReads(['file1.fasta', 'file2.fasta'])
             self.assertEqual(
                 [
-                    DNARead("id1", "ACTG"),
-                    DNARead("id2", "CAGT"),
+                    DNARead('id1', 'ACTG'),
+                    DNARead('id2', 'CAGT'),
                 ],
-                list(reads),
-            )
+                list(reads))
 
 
 class TestCombineReads(TestCase):
     """
     Tests for the L{dark.fasta.combineReads} function.
     """
-
     def testNoneNone(self):
         """
         A C{None} FASTA file name and None sequences results in an empty
         FastaReads instance.
         """
         reads = combineReads(None, None)
         self.assertEqual([], list(reads))
@@ -478,645 +454,607 @@
         self.assertEqual([], reads)
 
     def testFileOnly(self):
         """
         If a FASTA file is given but sequences is C{None}, the resulting
         FastaReads must contain the expected read.
         """
-        data = "\n".join([">id1", "ACGT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(combineReads("filename.fasta", None))
-            self.assertEqual([Read("id1", "ACGT")], reads)
+        data = '\n'.join(['>id1', 'ACGT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(combineReads('filename.fasta', None))
+            self.assertEqual([Read('id1', 'ACGT')], reads)
 
     def testNoUpperCaseFileOnly(self):
         """
         If upperCase is not passed and a FASTA file is given, the resulting
         FastaReads must contain the expected read, in the original case.
         """
-        data = "\n".join([">id1", "AcgT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(combineReads("filename.fasta", None))
-            self.assertEqual([Read("id1", "AcgT")], reads)
+        data = '\n'.join(['>id1', 'AcgT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(combineReads('filename.fasta', None))
+            self.assertEqual([Read('id1', 'AcgT')], reads)
 
     def testUpperCaseFileOnly(self):
         """
         When passing upperCase=True and a FASTA file, the resulting
         FastaReads must have the read sequence in uppper case.
         """
-        data = "\n".join([">id1", "acgt"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(combineReads("filename.fasta", None, upperCase=True))
-            self.assertEqual([Read("id1", "ACGT")], reads)
+        data = '\n'.join(['>id1', 'acgt'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(combineReads('filename.fasta', None, upperCase=True))
+            self.assertEqual([Read('id1', 'ACGT')], reads)
 
     def testSequencesOnly(self):
         """
         A C{None} FASTA file name and a non-empty sequences list results in a
         FastaReads instance with the expected read.
         """
-        reads = list(combineReads(None, ["id ACGTSSS"], readClass=AARead))
-        self.assertEqual([AARead("id", "ACGTSSS")], reads)
+        reads = list(combineReads(None, ['id ACGTSSS'], readClass=AARead))
+        self.assertEqual([AARead('id', 'ACGTSSS')], reads)
 
     def testNoUpperCaseSequencesOnly(self):
         """
         If upperCase is not passed to combineReads the resulting read
         sequences must have their original case.
         """
-        reads = list(combineReads(None, ["id aCGt"]))
-        self.assertEqual([Read("id", "aCGt")], reads)
+        reads = list(combineReads(None, ['id aCGt']))
+        self.assertEqual([Read('id', 'aCGt')], reads)
 
     def testUpperCaseSequencesOnly(self):
         """
         Passing upperCase=True to combineReads must result in read sequences
         being upper cased.
         """
-        reads = list(combineReads(None, ["id acgt"], upperCase=True))
-        self.assertEqual([Read("id", "ACGT")], reads)
+        reads = list(combineReads(None, ['id acgt'], upperCase=True))
+        self.assertEqual([Read('id', 'ACGT')], reads)
 
     def testDefaultReadIdPrefix(self):
         """
         A C{None} FASTA file name and a non-empty sequences list with a
         sequence that has no id results in a FastaReads instance with the
         expected read.
         """
-        reads = list(combineReads(None, ["ACGT"]))
-        self.assertEqual([Read("command-line-read-1", "ACGT")], reads)
+        reads = list(combineReads(None, ['ACGT']))
+        self.assertEqual([Read('command-line-read-1', 'ACGT')], reads)
 
     def testCustomReadIdPrefix(self):
         """
         A C{None} FASTA file name and a non-empty sequences list with a
         sequence that has no id, but with a custom read id prefix, results in a
         FastaReads instance with the expected read.
         """
-        reads = list(
-            combineReads(None, ["ACGTSSS"], idPrefix="prefix-", readClass=AARead)
-        )
-        self.assertEqual([AARead("prefix-1", "ACGTSSS")], reads)
+        reads = list(combineReads(None, ['ACGTSSS'], idPrefix='prefix-',
+                     readClass=AARead))
+        self.assertEqual([AARead('prefix-1', 'ACGTSSS')], reads)
 
     def testSpecificReadClass(self):
         """
         A specific read class must result in a FastaReads instance with reads
         of that class, both for reads from a FASTA file and from individually
         specified sequences.
         """
-        data = "\n".join([">id1", "ACGT"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(combineReads("filename.fasta", ["ACGT"], readClass=RNARead))
+        data = '\n'.join(['>id1', 'ACGT'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(combineReads('filename.fasta', ['ACGT'],
+                                      readClass=RNARead))
             self.assertTrue(isinstance(reads[0], RNARead))
             self.assertTrue(isinstance(reads[1], RNARead))
 
 
 class TestSqliteIndex(TestCase):
     """
     Tests for the SqliteIndex class.
     """
-
     def testAddFilename(self):
-        """
+        """"
         Test the internal _addFilename method.
         """
-        index = SqliteIndex(":memory:")
-        self.assertEqual(1, index._addFilename("filename1.fasta"))
-        self.assertEqual(2, index._addFilename("filename2.fasta"))
+        index = SqliteIndex(':memory:')
+        self.assertEqual(1, index._addFilename('filename1.fasta'))
+        self.assertEqual(2, index._addFilename('filename2.fasta'))
         index.close()
 
     def testAddDuplicateFilename(self):
-        """
+        """"
         When _addFilename is called twice with the same name, a ValueError
         must be raised.
         """
-        index = SqliteIndex(":memory:")
-        self.assertEqual(1, index._addFilename("f.fas"))
+        index = SqliteIndex(':memory:')
+        self.assertEqual(1, index._addFilename('f.fas'))
         error = "^Duplicate file name: 'f.fas'$"
-        assertRaisesRegex(self, ValueError, error, index._addFilename, "f.fas")
+        assertRaisesRegex(self, ValueError, error, index._addFilename, 'f.fas')
 
     def testGetNonexistentFilename(self):
-        """
+        """"
         If the internal _getFilename method is called with a file number that
         has not been added, it must return None.
         """
-        index = SqliteIndex(":memory:")
+        index = SqliteIndex(':memory:')
         self.assertEqual(None, index._getFilename(1))
         index.close()
 
     def testGetFilename(self):
-        """
+        """"
         The internal _getFilename method must return the expected result.
         """
-        index = SqliteIndex(":memory:")
-        self.assertEqual(1, index._addFilename("filename.fasta"))
-        self.assertEqual("filename.fasta", index._getFilename(1))
+        index = SqliteIndex(':memory:')
+        self.assertEqual(1, index._addFilename('filename.fasta'))
+        self.assertEqual('filename.fasta', index._getFilename(1))
         index.close()
 
     def testGetNonexistentFileNumber(self):
-        """
+        """"
         If the internal _getFileNumber method is called with a file whose name
         has not been added, it must return None.
         """
-        index = SqliteIndex(":memory:")
-        self.assertEqual(None, index._getFileNumber("filename.fasta"))
+        index = SqliteIndex(':memory:')
+        self.assertEqual(None, index._getFileNumber('filename.fasta'))
         index.close()
 
     def testGetFileNumber(self):
-        """
+        """"
         The internal _getFileNumber method must return the expected result.
         """
-        index = SqliteIndex(":memory:")
-        self.assertEqual(1, index._addFilename("filename.fasta"))
-        self.assertEqual(1, index._getFileNumber("filename.fasta"))
+        index = SqliteIndex(':memory:')
+        self.assertEqual(1, index._addFilename('filename.fasta'))
+        self.assertEqual(1, index._getFileNumber('filename.fasta'))
         index.close()
 
     def testBZ2File(self):
-        """
+        """"
         Trying to add a .bz2 file must result in a ValueError.
         """
-        index = SqliteIndex(":memory:")
-        error = (
-            "^Compressed FASTA is only supported in BGZF format\\. Use "
-            "bgzip to compresss your FASTA\\.$"
-        )
-        assertRaisesRegex(self, ValueError, error, index.addFile, "file.bz2")
+        index = SqliteIndex(':memory:')
+        error = ('^Compressed FASTA is only supported in BGZF format\\. Use '
+                 'bgzip to compresss your FASTA\\.$')
+        assertRaisesRegex(self, ValueError, error, index.addFile, 'file.bz2')
 
     def testAddOneFile(self):
-        """
+        """"
         Test the creation of an index with sequences added from one file.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id2\nAACCTTGG\n")
+                    return StringIO('>id1\nACTG\n>id2\nAACCTTGG\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            self.assertEqual(2, index.addFile("filename.fasta"))
+            index = SqliteIndex(':memory:')
+            self.assertEqual(2, index.addFile('filename.fasta'))
             index.close()
 
     def testAddFileWithDuplicateSequence(self):
-        """
+        """"
         If a sequence id is duplicated in a FASTA file, a ValueError must be
         raised.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id1\nAACCTTGG\n")
+                    return StringIO('>id1\nACTG\n>id1\nAACCTTGG\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            error = (
-                "^FASTA sequence id 'id1' found twice in file 'filename.fasta'\\.$"
-            )
-            assertRaisesRegex(self, ValueError, error, index.addFile, "filename.fasta")
+            index = SqliteIndex(':memory:')
+            error = ("^FASTA sequence id 'id1' found twice in file "
+                     "'filename.fasta'\\.$")
+            assertRaisesRegex(self, ValueError, error, index.addFile,
+                              'filename.fasta')
             index.close()
 
     def testAddFilesWithDuplicateSequence(self):
-        """
+        """"
         If a sequence id occurs in more than one FASTA file, a ValueError must
         be raised.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("filename1.fasta", filename)
+                    self.test.assertEqual('filename1.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id2\nAACCTTGG\n")
+                    return StringIO('>id1\nACTG\n>id2\nAACCTTGG\n')
                 elif self.count == 1:
-                    self.test.assertEqual("filename2.fasta", filename)
+                    self.test.assertEqual('filename2.fasta', filename)
                     self.count += 1
-                    return StringIO(">id2\nAAACCC\n")
+                    return StringIO('>id2\nAAACCC\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename1.fasta")
-            error = (
-                "^FASTA sequence id 'id2', found in file "
-                "'filename2\\.fasta', was previously added from file "
-                "'filename1\\.fasta'\\.$"
-            )
-            assertRaisesRegex(self, ValueError, error, index.addFile, "filename2.fasta")
+            index = SqliteIndex(':memory:')
+            index.addFile('filename1.fasta')
+            error = ("^FASTA sequence id 'id2', found in file "
+                     "'filename2\\.fasta', was previously added from file "
+                     "'filename1\\.fasta'\\.$")
+            assertRaisesRegex(self, ValueError, error, index.addFile,
+                              'filename2.fasta')
             index.close()
 
     def testAddDuplicateFile(self):
-        """
+        """"
         If a filename is passed to addFile more than once, a ValueError must
         be raised.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id2\nAACCTTGG\n")
+                    return StringIO('>id1\nACTG\n>id2\nAACCTTGG\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            self.assertEqual(2, index.addFile("filename.fasta"))
+            index = SqliteIndex(':memory:')
+            self.assertEqual(2, index.addFile('filename.fasta'))
             error = "^Duplicate file name: 'filename\\.fasta'$"
-            assertRaisesRegex(
-                self, ValueError, error, index._addFilename, "filename.fasta"
-            )
+            assertRaisesRegex(self, ValueError, error, index._addFilename,
+                              'filename.fasta')
             index.close()
 
     def testFind(self):
-        """
+        """"
         The _find method must return the expected filename and offset.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id2\nAACCTTGG\n")
+                    return StringIO('>id1\nACTG\n>id2\nAACCTTGG\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename.fasta")
-            self.assertEqual(("filename.fasta", 5), index._find("id1"))
-            self.assertEqual(("filename.fasta", 15), index._find("id2"))
+            index = SqliteIndex(':memory:')
+            index.addFile('filename.fasta')
+            self.assertEqual(('filename.fasta', 5), index._find('id1'))
+            self.assertEqual(('filename.fasta', 15), index._find('id2'))
             index.close()
 
     def testFindWithTwoFiles(self):
-        """
+        """"
         The _find method must return the expected filename and offset when
         sequences are added from two files.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("filename1.fasta", filename)
+                    self.test.assertEqual('filename1.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id2\nAACCTTGG\n")
+                    return StringIO('>id1\nACTG\n>id2\nAACCTTGG\n')
                 elif self.count == 1:
-                    self.test.assertEqual("filename2.fasta", filename)
+                    self.test.assertEqual('filename2.fasta', filename)
                     self.count += 1
-                    return StringIO(">sequence3\nAAACCC\n")
+                    return StringIO('>sequence3\nAAACCC\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename1.fasta")
-            index.addFile("filename2.fasta")
-            self.assertEqual(("filename1.fasta", 5), index._find("id1"))
-            self.assertEqual(("filename1.fasta", 15), index._find("id2"))
-            self.assertEqual(("filename2.fasta", 11), index._find("sequence3"))
+            index = SqliteIndex(':memory:')
+            index.addFile('filename1.fasta')
+            index.addFile('filename2.fasta')
+            self.assertEqual(('filename1.fasta', 5), index._find('id1'))
+            self.assertEqual(('filename1.fasta', 15), index._find('id2'))
+            self.assertEqual(('filename2.fasta', 11), index._find('sequence3'))
             index.close()
 
     def testDictLookupSequenceCrossesNewlines(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected read when the sequence spans multiple lines of the input file,
         including lines ending in \n and \r\n.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0 or self.count == 1:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\r\nCCCC\nGGG\n>id2\nAACCTG\n")
+                    return StringIO('>id1\nACTG\r\nCCCC\nGGG\n>id2\nAACCTG\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename.fasta")
-            self.assertEqual(DNARead("id1", "ACTGCCCCGGG"), index["id1"])
+            index = SqliteIndex(':memory:')
+            index.addFile('filename.fasta')
+            self.assertEqual(DNARead('id1', 'ACTGCCCCGGG'), index['id1'])
             index.close()
 
     def testDictLookupWithFastaDirectory(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected read, obtained from the expected file name, when a FASTA base
         directory is specified.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("/tmp/f.fasta", filename)
+                    self.test.assertEqual('/tmp/f.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\r\nCCCC\nGGG\n>id2\nAACCTG\n")
+                    return StringIO('>id1\nACTG\r\nCCCC\nGGG\n>id2\nAACCTG\n')
                 if self.count == 1:
                     self.test.assertEqual(
-                        os.path.join("/usr/local/fasta", "f.fasta"), filename
-                    )
+                        os.path.join('/usr/local/fasta', 'f.fasta'), filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\r\nCCCC\nGGG\n>id2\nAACCTG\n")
+                    return StringIO('>id1\nACTG\r\nCCCC\nGGG\n>id2\nAACCTG\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:", fastaDirectory="/usr/local/fasta")
-            index.addFile("/tmp/f.fasta")
-            self.assertEqual(DNARead("id1", "ACTGCCCCGGG"), index["id1"])
+            index = SqliteIndex(':memory:', fastaDirectory='/usr/local/fasta')
+            index.addFile('/tmp/f.fasta')
+            self.assertEqual(DNARead('id1', 'ACTGCCCCGGG'), index['id1'])
             index.close()
 
     def testDictLookupSequenceLastInFile(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected read when the sequence spans multiple lines and is the last
         one in the input file.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0 or self.count == 1:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\r\nCCCC\n>id2\nAACCTG\nAAA\n")
+                    return StringIO('>id1\nACTG\r\nCCCC\n>id2\nAACCTG\nAAA\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename.fasta")
-            self.assertEqual(DNARead("id2", "AACCTGAAA"), index["id2"])
+            index = SqliteIndex(':memory:')
+            index.addFile('filename.fasta')
+            self.assertEqual(DNARead('id2', 'AACCTGAAA'), index['id2'])
             index.close()
 
     def testDictLookupSequenceMiddleOfThree(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected read when the sequence spans multiple lines and is the middle
         one of three sequences in the input file.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0 or self.count == 1:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\nCCCC\n>id2\nAACCTG\nAAA\n>id3\nAAA\n")
+                    return StringIO(
+                        '>id1\nACTG\nCCCC\n>id2\nAACCTG\nAAA\n>id3\nAAA\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename.fasta")
-            self.assertEqual(DNARead("id2", "AACCTGAAA"), index["id2"])
+            index = SqliteIndex(':memory:')
+            index.addFile('filename.fasta')
+            self.assertEqual(DNARead('id2', 'AACCTGAAA'), index['id2'])
             index.close()
 
     def testDictLookupWithTwoFiles(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected reads when sequences are added from two files.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0 or self.count == 2 or self.count == 3:
-                    self.test.assertEqual("filename1.fasta", filename)
+                    self.test.assertEqual('filename1.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id2\nAACCTTGG\n")
+                    return StringIO('>id1\nACTG\n>id2\nAACCTTGG\n')
                 elif self.count == 1 or self.count == 4:
-                    self.test.assertEqual("filename2.fasta", filename)
+                    self.test.assertEqual('filename2.fasta', filename)
                     self.count += 1
-                    return StringIO(">seq3\nAAACCC\n")
+                    return StringIO('>seq3\nAAACCC\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename1.fasta")
-            index.addFile("filename2.fasta")
-            self.assertEqual(DNARead("id1", "ACTG"), index["id1"])
-            self.assertEqual(DNARead("id2", "AACCTTGG"), index["id2"])
-            self.assertEqual(DNARead("seq3", "AAACCC"), index["seq3"])
+            index = SqliteIndex(':memory:')
+            index.addFile('filename1.fasta')
+            index.addFile('filename2.fasta')
+            self.assertEqual(DNARead('id1', 'ACTG'), index['id1'])
+            self.assertEqual(DNARead('id2', 'AACCTTGG'), index['id2'])
+            self.assertEqual(DNARead('seq3', 'AAACCC'), index['seq3'])
             index.close()
 
     def testDictLookupSpecificReadClass(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected read type.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count == 0 or self.count == 1:
-                    self.test.assertEqual("filename.fasta", filename)
+                    self.test.assertEqual('filename.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nMM\n>id2\n")
+                    return StringIO('>id1\nMM\n>id2\n')
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:", readClass=AARead)
-            index.addFile("filename.fasta")
-            result = index["id1"]
+            index = SqliteIndex(':memory:', readClass=AARead)
+            index.addFile('filename.fasta')
+            result = index['id1']
             self.assertTrue(isinstance(result, AARead))
-            self.assertEqual(AARead("id1", "MM"), result)
+            self.assertEqual(AARead('id1', 'MM'), result)
             index.close()
 
-    @skip("Skipped until fix in matplotlib is released")
     def testDictLookupGzipDataWithBGZsuffix(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected read when the index file is in BGZF format and has a .bgz
         suffix.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count <= 1:
-                    self.test.assertEqual("filename.fasta.bgz", filename)
+                    self.test.assertEqual('filename.fasta.bgz', filename)
                     self.count += 1
                     writerIO = BytesIO()
                     writer = bgzf.BgzfWriter(fileobj=writerIO)
-                    writer.write(b">id0\nAC\n")
+                    writer.write(b'>id0\nAC\n')
                     writer.flush()
                     fileobj = BytesIO(writerIO.getvalue())
-                    fileobj.mode = "rb"
+                    fileobj.mode = 'rb'
                     return bgzf.BgzfReader(fileobj=fileobj)
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(bgzf, "open") as mockMethod:
+        with patch.object(bgzf, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename.fasta.bgz")
-            self.assertEqual(DNARead("id0", "AC"), index["id0"])
+            index = SqliteIndex(':memory:')
+            index.addFile('filename.fasta.bgz')
+            self.assertEqual(DNARead('id0', 'AC'), index['id0'])
             index.close()
 
-    @skip("Skipped until fix in matplotlib is released")
     def testDictLookupGzipData(self):
-        """
+        """"
         The __getitem__ method (i.e., dictionary-like lookup) must return the
         expected reads when sequences span multiple lines of the input file,
         and include lines ending in \n and \r\n and have been compressed with
         bgzip, including when sequences are more than 64K bytes into the input
         file.
         """
-
-        class Open:
+        class Open(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, *args, **kwargs):
                 if self.count <= 4:
-                    self.test.assertEqual("filename.fasta.gz", filename)
+                    self.test.assertEqual('filename.fasta.gz', filename)
                     self.count += 1
                     writerIO = BytesIO()
                     writer = bgzf.BgzfWriter(fileobj=writerIO)
                     writer.write(
-                        b">id0\nAC\n"
-                        + b">id1\n"
-                        + (b"A" * 70000)
-                        + b"\n"
-                        + b">id2\r\nACTG\r\nCCCC\r\nGGG\r\n"
-                        + b">id3\nAACCTG\n"
-                    )
+                        b'>id0\nAC\n' +
+                        b'>id1\n' + (b'A' * 70000) + b'\n' +
+                        b'>id2\r\nACTG\r\nCCCC\r\nGGG\r\n' +
+                        b'>id3\nAACCTG\n')
                     writer.flush()
                     fileobj = BytesIO(writerIO.getvalue())
-                    fileobj.mode = "rb"
+                    fileobj.mode = 'rb'
                     return bgzf.BgzfReader(fileobj=fileobj)
                 else:
                     self.test.fail(
-                        "Open called too many times. Filename: %r, Args: %r, "
-                        "Keyword args: %r." % (filename, args, kwargs)
-                    )
+                        'Open called too many times. Filename: %r, Args: %r, '
+                        'Keyword args: %r.' % (filename, args, kwargs))
 
         sideEffect = Open(self).sideEffect
-        with patch.object(bgzf, "open") as mockMethod:
+        with patch.object(bgzf, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect
-            index = SqliteIndex(":memory:")
-            index.addFile("filename.fasta.gz")
-            self.assertEqual(DNARead("id0", "AC"), index["id0"])
-            self.assertEqual(DNARead("id1", "A" * 70000), index["id1"])
-            self.assertEqual(DNARead("id2", "ACTGCCCCGGG"), index["id2"])
-            self.assertEqual(DNARead("id3", "AACCTG"), index["id3"])
+            index = SqliteIndex(':memory:')
+            index.addFile('filename.fasta.gz')
+            self.assertEqual(DNARead('id0', 'AC'), index['id0'])
+            self.assertEqual(DNARead('id1', 'A' * 70000), index['id1'])
+            self.assertEqual(DNARead('id2', 'ACTGCCCCGGG'), index['id2'])
+            self.assertEqual(DNARead('id3', 'AACCTG'), index['id3'])
             index.close()
```

### Comparing `dark-matter-4.0.84/test/test_fasta_ss.py` & `dark-matter-4.0.9/test/test_fasta_ss.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,165 +1,162 @@
 import six
 from six.moves import builtins
 from unittest import TestCase
-from unittest.mock import patch, mock_open
-from io import StringIO
+
+try:
+    from unittest.mock import patch, mock_open
+except ImportError:
+    from mock import patch
 
 from dark.reads import SSAARead
 from dark.fasta_ss import SSFastaReads
+from dark.utils import StringIO
 
 
 class TestSSFastaReads(TestCase):
     """
     Tests for the L{dark.fasta.SSFastaReads} class.
     """
 
     def testEmpty(self):
         """
         An empty PDB FASTA file results in an empty iterator.
         """
-        data = ""
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = ''
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = SSFastaReads(data)
             self.assertEqual([], list(reads))
 
     def testOddNumberOfRecords(self):
         """
         Trying to parse a PDB FASTA file with an odd number of records must
         raise a ValueError.
         """
-        data = "\n".join([">seq1", "REDD", ">str1", "HH--", ">seq2", "REAA"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            error = "^Structure file 'x.fasta' has an odd number of records\\.$"
-            six.assertRaisesRegex(
-                self, ValueError, error, list, SSFastaReads("x.fasta")
-            )
+        data = '\n'.join(['>seq1', 'REDD', '>str1', 'HH--',
+                          '>seq2', 'REAA'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            error = ("^Structure file 'x.fasta' has an odd number of "
+                     "records\\.$")
+            six.assertRaisesRegex(self, ValueError, error, list,
+                                  SSFastaReads('x.fasta'))
 
     def testUnequalSequenceAndStructureLengths(self):
         """
         Trying to parse a PDB FASTA file that has a sequence whose structure
         is of a different length must raise a ValueError.
         """
-        data = "\n".join(
-            [">seq1", "REDD", ">str1", "HH--", ">seq2", "REAA", ">str2", "HH"]
-        )
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'REDD', '>str1', 'HH--',
+                          '>seq2', 'REAA', '>str2', 'HH'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             error = (
                 "Sequence 'seq2' length \\(4\\) is not equal to structure "
-                "'str2' length \\(2\\) in input file 'x\\.fasta'\\.$"
-            )
-            six.assertRaisesRegex(
-                self, ValueError, error, list, SSFastaReads("x.fasta")
-            )
+                "'str2' length \\(2\\) in input file 'x\\.fasta'\\.$")
+            six.assertRaisesRegex(self, ValueError, error, list,
+                                  SSFastaReads('x.fasta'))
 
     def testOneRead(self):
         """
         A PDB FASTA file with one read must be read properly.
         """
-        data = "\n".join([">seq1", "REDD", ">str1", "HH--"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'REDD', '>str1', 'HH--'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = list(SSFastaReads(data))
-            self.assertEqual([SSAARead("seq1", "REDD", "HH--")], reads)
+            self.assertEqual([SSAARead('seq1', 'REDD', 'HH--')], reads)
 
     def testNoQuality(self):
         """
         A PDB FASTA file read must not have any quality information.
         """
-        data = "\n".join([">seq1", "REDD", ">str1", "HH--"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'REDD', '>str1', 'HH--'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = list(SSFastaReads(data))
             self.assertIs(None, reads[0].quality)
 
     def testTwoReads(self):
         """
         A PDB FASTA file with two reads must be read properly and its
         sequences must be returned in the correct order.
         """
-        data = "\n".join(
-            [">seq1", "REDD", ">str1", "HH--", ">seq2", "REAA", ">str2", "HHEE"]
-        )
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'REDD', '>str1', 'HH--',
+                          '>seq2', 'REAA', '>str2', 'HHEE'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = list(SSFastaReads(data))
             self.assertEqual(2, len(reads))
-            self.assertEqual(
-                [SSAARead("seq1", "REDD", "HH--"), SSAARead("seq2", "REAA", "HHEE")],
-                reads,
-            )
+            self.assertEqual([SSAARead('seq1', 'REDD', 'HH--'),
+                              SSAARead('seq2', 'REAA', 'HHEE')],
+                             reads)
 
     def testTypeDefaultsToSSAARead(self):
         """
         A PDB FASTA file whose type is not specified must result in reads that
         are instances of SSAARead.
         """
-        data = "\n".join([">seq1", "REDD", ">str1", "HH--"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'REDD', '>str1', 'HH--'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = list(SSFastaReads(data))
             self.assertTrue(isinstance(reads[0], SSAARead))
 
     def testReadClass(self):
         """
         A PDB FASTA file whose read class is something other than SSAARead must
         result in reads that are instances of that class.
         """
-
         class ReadClass:
             def __init__(self, id, sequence, structure):
                 pass
 
-        data = "\n".join([">seq1", "RRRR", ">str1", "HHHH"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'RRRR', '>str1', 'HHHH'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = list(SSFastaReads(data, readClass=ReadClass))
             self.assertTrue(isinstance(reads[0], ReadClass))
 
     def testConvertLowerToUpperCaseIfSpecified(self):
         """
         A read sequence and structure must be converted from lower to upper
         case if requested.
         """
-        data = "\n".join([">seq1", "rrrff", ">str1", "hheeh"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'rrrff', '>str1', 'hheeh'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = list(SSFastaReads(data, upperCase=True))
-            self.assertEqual([SSAARead("seq1", "RRRFF", "HHEEH")], reads)
+            self.assertEqual([SSAARead('seq1', 'RRRFF', 'HHEEH')], reads)
 
     def testDontConvertLowerToUpperCaseIfNotSpecified(self):
         """
         A read sequence and its structure must not be converted from lower to
         upper case if the conversion is not requested.
         """
-        data = "\n".join([">seq1", "rrFF", ">str1", "HHee"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '\n'.join(['>seq1', 'rrFF', '>str1', 'HHee'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = list(SSFastaReads(data))
-            self.assertEqual([SSAARead("seq1", "rrFF", "HHee")], reads)
+            self.assertEqual([SSAARead('seq1', 'rrFF', 'HHee')], reads)
 
     def testTwoFiles(self):
         """
         It must be possible to read from two FASTA files.
         """
-
-        class SideEffect:
+        class SideEffect(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("file1.fasta", filename)
+                    self.test.assertEqual('file1.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id1\nhhhh\n")
+                    return StringIO('>id1\nACTG\n>id1\nhhhh\n')
                 elif self.count == 1:
-                    self.test.assertEqual("file2.fasta", filename)
+                    self.test.assertEqual('file2.fasta', filename)
                     self.count += 1
-                    return StringIO(">id2\nCAGT\n>id2\neeee\n")
+                    return StringIO('>id2\nCAGT\n>id2\neeee\n')
                 else:
-                    self.test.fail("We are only supposed to be called twice!")
+                    self.test.fail('We are only supposed to be called twice!')
 
         sideEffect = SideEffect(self)
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect.sideEffect
-            reads = SSFastaReads(["file1.fasta", "file2.fasta"])
+            reads = SSFastaReads(['file1.fasta', 'file2.fasta'])
             self.assertEqual(
                 [
-                    SSAARead("id1", "ACTG", "hhhh"),
-                    SSAARead("id2", "CAGT", "eeee"),
+                    SSAARead('id1', 'ACTG', 'hhhh'),
+                    SSAARead('id2', 'CAGT', 'eeee'),
                 ],
-                list(reads),
-            )
+                list(reads))
```

### Comparing `dark-matter-4.0.84/test/test_fastq.py` & `dark-matter-4.0.9/test/test_fastq.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,119 +1,121 @@
 from six.moves import builtins
-from io import StringIO
 
 from dark.reads import AARead, DNARead, RNARead
 from dark.fastq import FastqReads
+from dark.utils import StringIO
 
 from unittest import TestCase, skip
-from unittest.mock import patch, mock_open
+
+try:
+    from unittest.mock import patch, mock_open
+except ImportError:
+    from mock import patch
 
 
 class TestFastqReads(TestCase):
     """
     Tests for the L{dark.fastq.FastqReads} class.
     """
 
     def testEmpty(self):
         """
         An empty FASTQ file results in an empty iterator.
         """
-        with patch.object(builtins, "open", mock_open()):
-            reads = FastqReads("filename.fastq")
+        with patch.object(builtins, 'open', mock_open()):
+            reads = FastqReads('filename.fastq')
             self.assertEqual([], list(reads))
 
     def testOneRead(self):
         """
         A FASTQ file with one read must be read properly.
         """
-        data = "\n".join(["@id1", "ACGT", "+", "!!!!"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastqReads("filename.fastq"))
-            self.assertEqual([DNARead("id1", "ACGT", "!!!!")], reads)
+        data = '\n'.join(['@id1', 'ACGT', '+', '!!!!'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastqReads('filename.fastq'))
+            self.assertEqual([DNARead('id1', 'ACGT', '!!!!')], reads)
 
     def testTwoReads(self):
         """
         A FASTQ file with two reads must be read properly and its
         sequences must be returned in the correct order.
         """
-        data = "\n".join(["@id1", "ACGT", "+", "!!!!", "@id2", "TGCA", "+", "????"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastqReads("filename.fastq"))
+        data = '\n'.join(['@id1', 'ACGT', '+', '!!!!',
+                          '@id2', 'TGCA', '+', '????'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastqReads('filename.fastq'))
             self.assertEqual(2, len(reads))
-            self.assertEqual(
-                [DNARead("id1", "ACGT", "!!!!"), DNARead("id2", "TGCA", "????")], reads
-            )
+            self.assertEqual([DNARead('id1', 'ACGT', '!!!!'),
+                              DNARead('id2', 'TGCA', '????')], reads)
 
     def testTypeDefaultsToDNA(self):
         """
         A FASTQ file whose type is not specified must result in reads that
         are instances of DNARead.
         """
-        data = "\n".join(["@id1", "ACGT", "+", "!!!!"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastqReads("filename.fastq"))
+        data = '\n'.join(['@id1', 'ACGT', '+', '!!!!'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastqReads('filename.fastq'))
             self.assertTrue(isinstance(reads[0], DNARead))
 
     def testTypeAA(self):
         """
         A FASTQ file whose read class is AARead must result in reads that
         are instances of AARead.
         """
-        data = "\n".join(["@id1", "ACGT", "+", "!!!!"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastqReads("filename.fastq", AARead))
+        data = '\n'.join(['@id1', 'ACGT', '+', '!!!!'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastqReads('filename.fastq', AARead))
             self.assertTrue(isinstance(reads[0], AARead))
 
     def testTypeDNA(self):
         """
         A FASTQ file whose read class is DNARead must result in reads that
         are instances of DNARead.
         """
-        data = "\n".join(["@id1", "ACGT", "+", "!!!!"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastqReads("filename.fastq", DNARead))
+        data = '\n'.join(['@id1', 'ACGT', '+', '!!!!'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastqReads('filename.fastq', DNARead))
             self.assertTrue(isinstance(reads[0], DNARead))
 
     def testTypeRNA(self):
         """
         A FASTQ file whose read class is RNARead must result in reads that
         are instances of RNARead.
         """
-        data = "\n".join(["@id1", "ACGT", "+", "!!!!"])
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            reads = list(FastqReads("filename.fastq", RNARead))
+        data = '\n'.join(['@id1', 'ACGT', '+', '!!!!'])
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            reads = list(FastqReads('filename.fastq', RNARead))
             self.assertTrue(isinstance(reads[0], RNARead))
 
-    @skip("Some tests are broken and skipped under latest BioPython")
+    @skip('Some tests are broken and skipped under latest BioPython')
     def testTwoFiles(self):
         """
         It must be possible to read from two FASTQ files.
         """
-
-        class SideEffect:
+        class SideEffect(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename):
                 if self.count == 0:
-                    self.test.assertEqual("file1.fastq", filename)
+                    self.test.assertEqual('file1.fastq', filename)
                     self.count += 1
-                    return StringIO("@id1\nACTG\n+\n!!!!\n")
+                    return StringIO('@id1\nACTG\n+\n!!!!\n')
                 elif self.count == 1:
-                    self.test.assertEqual("file2.fastq", filename)
+                    self.test.assertEqual('file2.fastq', filename)
                     self.count += 1
-                    return StringIO("@id2\nCAGT\n+\n!!!!\n")
+                    return StringIO('@id2\nCAGT\n+\n!!!!\n')
                 else:
-                    self.test.fail("We are only supposed to be called twice!")
+                    self.test.fail('We are only supposed to be called twice!')
 
         sideEffect = SideEffect(self)
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect.sideEffect
-            reads = FastqReads(["file1.fastq", "file2.fastq"])
+            reads = FastqReads(['file1.fastq', 'file2.fastq'])
             self.assertEqual(
                 [
-                    DNARead("id1", "ACTG", "!!!!"),
-                    DNARead("id2", "CAGT", "!!!!"),
+                    DNARead('id1', 'ACTG', '!!!!'),
+                    DNARead('id2', 'CAGT', '!!!!'),
                 ],
-                list(reads),
-            )
+                list(reads))
```

### Comparing `dark-matter-4.0.84/test/test_features.py` & `dark-matter-4.0.9/test/test_features.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,28 +1,42 @@
 import numpy as np
-from unittest import TestCase
-from unittest.mock import call, MagicMock, ANY
+from unittest import TestCase, skipUnless
 
-import matplotlib
+try:
+    import matplotlib
+except ImportError:
+    import platform
+    if platform.python_implementation() == 'PyPy':
+        havePlt = False
+        # PyPy doesn't have a version of matplotlib. Make a fake class that
+        # raises if used.
+
+        class plt(object):
+            def __getattr__(self, _):
+                raise NotImplementedError(
+                    'matplotlib is not supported under pypy')
+    else:
+        raise
+else:
+    matplotlib.use('Agg')
+    from matplotlib import pyplot as plt
+    havePlt = True
+
+try:
+    from unittest.mock import call, MagicMock, ANY
+except ImportError:
+    from mock import call, MagicMock, ANY
 
 from Bio.SeqFeature import FeatureLocation, SeqFeature
 from Bio.SeqRecord import SeqRecord
 
 from random import uniform
 
-from dark.features import (
-    Feature,
-    FeatureList,
-    _FeatureAdder,
-    ProteinFeatureAdder,
-    NucleotideFeatureAdder,
-)
-
-matplotlib.use("Agg")
-from matplotlib import pyplot as plt
+from dark.features import (Feature, FeatureList, _FeatureAdder,
+                           ProteinFeatureAdder, NucleotideFeatureAdder)
 
 
 def _randomLabel():
     return str(uniform(1, 1e9))
 
 
 class Test_Feature(TestCase):
@@ -70,207 +84,204 @@
     def testSetColor(self):
         """
         The setColor method must set the 'color' attribute on the feature.
         """
         location = FeatureLocation(100, 200)
         seqFeature = SeqFeature(location=location)
         feature = Feature(seqFeature)
-        feature.setColor("red")
-        self.assertEqual("red", feature.color)
+        feature.setColor('red')
+        self.assertEqual('red', feature.color)
 
     def testLegendLabel(self):
         """
         The legendLabel method must return a description.
         """
         location = FeatureLocation(100, 200)
         qualifiers = {
-            "note": ["Capsid protein"],
+            'note': ['Capsid protein'],
         }
-        seqFeature = SeqFeature(location=location, type="site", qualifiers=qualifiers)
+        seqFeature = SeqFeature(location=location, type='site',
+                                qualifiers=qualifiers)
         feature = Feature(seqFeature)
-        self.assertEqual("100-200 site. note: Capsid protein", feature.legendLabel())
+        self.assertEqual('100-200 site. note: Capsid protein',
+                         feature.legendLabel())
 
     def testLegendLabelQualifiersSorted(self):
         """
         The legendLabel method must return a description with sorted
         qualifiers.
         """
         location = FeatureLocation(100, 200)
         qualifiers = {
-            "note": ["Capsid protein"],
-            "product": ["CP1"],
+            'note': ['Capsid protein'],
+            'product': ['CP1'],
         }
-        seqFeature = SeqFeature(location=location, type="site", qualifiers=qualifiers)
+        seqFeature = SeqFeature(location=location, type='site',
+                                qualifiers=qualifiers)
         feature = Feature(seqFeature)
-        self.assertEqual(
-            "100-200 site. note: Capsid protein, product: CP1", feature.legendLabel()
-        )
+        self.assertEqual('100-200 site. note: Capsid protein, product: CP1',
+                         feature.legendLabel())
 
     def testLegendLabelNoQualifiers(self):
         """
         The legendLabel method must return a correct description for a feature
         that has no qualifiers.
         """
         location = FeatureLocation(100, 200)
-        seqFeature = SeqFeature(location=location, type="site")
+        seqFeature = SeqFeature(location=location, type='site')
         feature = Feature(seqFeature)
-        self.assertEqual("100-200 site.", feature.legendLabel())
+        self.assertEqual('100-200 site.', feature.legendLabel())
 
     def testLegendLabelTruncatesValues(self):
         """
         The legendLabel method must return a description with qualifier
         values truncated to length 30 (including the trailing ...).
         """
         location = FeatureLocation(100, 200)
         qualifiers = {
-            "note": ["x" * 40],
+            'note': ['x' * 40],
         }
-        seqFeature = SeqFeature(location=location, type="site", qualifiers=qualifiers)
+        seqFeature = SeqFeature(location=location, type='site',
+                                qualifiers=qualifiers)
         feature = Feature(seqFeature)
-        xs = "x" * 27 + "..."
-        self.assertEqual("100-200 site. note: %s" % xs, feature.legendLabel())
+        xs = 'x' * 27 + '...'
+        self.assertEqual('100-200 site. note: %s' % xs,
+                         feature.legendLabel())
 
 
+# We can't test anything that uses a FeatureList under pypy because
+# dark.features makes use of matplotlib.
+@skipUnless(havePlt, 'matplotlib not supported under pypy')
 class Test_FeatureList(TestCase):
     """
     Tests of the C{FeatureList} class.
     """
 
     def testOffline(self):
         """
         If the sequence fetcher returns C{None} we must be marked as being
         offline.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return None
 
-        featureList = FeatureList("title", "database", set(), sequenceFetcher=fetcher)
+        featureList = FeatureList('title', 'database', set(),
+                                  sequenceFetcher=fetcher)
         self.assertEqual(True, featureList.offline)
 
     def testOfflineLength(self):
         """
         If the sequence fetcher indicates we're offline, the feature list
         must have length zero.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return None
 
-        featureList = FeatureList("title", "database", set(), sequenceFetcher=fetcher)
+        featureList = FeatureList('title', 'database', set(),
+                                  sequenceFetcher=fetcher)
         self.assertEqual(0, len(featureList))
 
     def testFetcherValueError(self):
         """
         If the sequence fetcher throws a C{ValueError}, the feature list
         must have length zero and should not be marked as being offline.
         """
-
         def fetcher(title, db):
             raise ValueError()
 
-        featureList = FeatureList("title", "database", set(), sequenceFetcher=fetcher)
+        featureList = FeatureList('title', 'database', set(),
+                                  sequenceFetcher=fetcher)
         self.assertEqual(0, len(featureList))
         self.assertEqual(False, featureList.offline)
 
     def testNotOffline(self):
         """
         If the sequence fetcher does not return C{None} we must be marked as
         being online.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return SeqRecord(None)
 
-        featureList = FeatureList("title", "database", set(), sequenceFetcher=fetcher)
+        featureList = FeatureList('title', 'database', set(),
+                                  sequenceFetcher=fetcher)
         self.assertEqual(False, featureList.offline)
 
     def testNoFeaturesLength(self):
         """
         If the sequence fetcher returns a record with no features, the
         L{FeatureList} instance must have length zero.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return SeqRecord(None)
 
-        featureList = FeatureList("title", "database", set(), sequenceFetcher=fetcher)
+        featureList = FeatureList('title', 'database', set(),
+                                  sequenceFetcher=fetcher)
         self.assertEqual(0, len(featureList))
 
     def testNoQualifiersLength(self):
         """
         If the sequence fetcher returns a record with two features but
         neither of them has any qualifiers, the L{FeatureList} instance
         must still include both features.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(type="site", location=location)
+            feature = SeqFeature(type='site', location=location)
             return SeqRecord(None, features=[feature, feature])
 
-        featureList = FeatureList(
-            "title", "database", set(["site"]), sequenceFetcher=fetcher
-        )
+        featureList = FeatureList('title', 'database', set(['site']),
+                                  sequenceFetcher=fetcher)
         self.assertEqual(2, len(featureList))
 
     def testNotSubfeature(self):
         """
         If the sequence fetcher returns a record with a feature that is
         not a subfeature, it must not be marked as a subfeature.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(
-                type="site", qualifiers={"a": ["b"]}, location=location
-            )
+            feature = SeqFeature(type='site', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature])
 
-        featureList = FeatureList(
-            "title", "database", set(["site"]), sequenceFetcher=fetcher
-        )
+        featureList = FeatureList('title', 'database', set(['site']),
+                                  sequenceFetcher=fetcher)
         self.assertFalse(featureList[0].subfeature)
 
     def testWantedTypeLength(self):
         """
         If the sequence fetcher returns a record with two features but
         only one of them has a wanted type ('site'), the L{FeatureList}
         instance must have length one.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature1 = SeqFeature(type="region", location=location)
-            feature2 = SeqFeature(
-                type="site", qualifiers={"a": ["b"]}, location=location
-            )
+            feature1 = SeqFeature(type='region', location=location)
+            feature2 = SeqFeature(type='site', qualifiers={'a': ['b']},
+                                  location=location)
             return SeqRecord(None, features=[feature1, feature2])
 
-        featureList = FeatureList(
-            "title", "database", set(["site"]), sequenceFetcher=fetcher
-        )
+        featureList = FeatureList('title', 'database', set(['site']),
+                                  sequenceFetcher=fetcher)
         self.assertEqual(1, len(featureList))
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testColors(self):
         """
         If the sequence fetcher returns a record with 3 features, each
         must be assigned a correct color.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(
-                type="site", qualifiers={"a": ["b"]}, location=location
-            )
+            feature = SeqFeature(type='site', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature] * 3)
 
-        featureList = FeatureList(
-            "title", "database", set(["site"]), sequenceFetcher=fetcher
-        )
+        featureList = FeatureList('title', 'database', set(['site']),
+                                  sequenceFetcher=fetcher)
         colormap = plt.cm.coolwarm
         colors = [colormap(i) for i in np.linspace(0.0, 0.99, 3)]
 
         for i in range(3):
             self.assertEqual(colors[i], featureList[i].color)
 
 
@@ -283,358 +294,322 @@
         """
         A new instance of L{_FeatureAdder} must be marked on creation as not
         having too many features to plot.
         """
         featureAdder = _FeatureAdder()
         self.assertFalse(featureAdder.tooManyFeaturesToPlot)
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testTitle(self):
         """
         A L{_FeatureAdder} must set the title of its figure.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return None
 
         featureAdder = _FeatureAdder()
-        fig, ax = plt.subplots()
-        ax.set_title = MagicMock()
-        featureAdder.add(ax, "title", 0, 100, sequenceFetcher=fetcher)
-        ax.set_title.assert_called_with("Target sequence features", fontsize=16)
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.set_title = MagicMock()
+        featureAdder.add(fig, 'title', 0, 100, sequenceFetcher=fetcher)
+        fig.set_title.assert_called_with('Target sequence features',
+                                         fontsize=16)
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testYTicks(self):
         """
         A L{_FeatureAdder} must set the title of its figure.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return None
 
         featureAdder = _FeatureAdder()
-        fig, ax = plt.subplots()
-        ax.set_yticks = MagicMock()
-        featureAdder.add(ax, "title", 0, 100, sequenceFetcher=fetcher)
-        ax.set_yticks.assert_called_with([])
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.set_yticks = MagicMock()
+        featureAdder.add(fig, 'title', 0, 100, sequenceFetcher=fetcher)
+        fig.set_yticks.assert_called_with([])
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testOffline(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns C{None},
         the C{add} method of the L{_FeatureAdder} must return C{None}. The
         C{text} and C{axis} methods on the fig must both be called correctly.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return None
 
         featureAdder = _FeatureAdder()
-        fig, ax = plt.subplots()
-        ax.text = MagicMock()
-        ax.axis = MagicMock()
-        featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
-        ax.text.assert_called_with(
-            100, 0, "You (or Genbank) appear to be offline.", fontsize=20
-        )
-        ax.axis.assert_called_with([0, 300, -1, 1])
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.text = MagicMock()
+        fig.axis = MagicMock()
+        featureAdder.add(fig, 'title', 0, 300, sequenceFetcher=fetcher)
+        fig.text.assert_called_with(100, 0,
+                                    'You (or Genbank) appear to be offline.',
+                                    fontsize=20)
+        fig.axis.assert_called_with([0, 300, -1, 1])
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testNoFeatures(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns no features
         the C{text} and C{axis} methods on the fig must both be called
         correctly and the C{add} method must return C{[]}.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             return SeqRecord(None)
 
         featureAdder = _FeatureAdder()
-        featureAdder.WANTED_TYPES = ("site",)
-        fig, ax = plt.subplots()
-        ax.text = MagicMock()
-        ax.axis = MagicMock()
-        result = featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
-        ax.text.assert_called_with(
-            0.5,
-            0.5,
-            "No features found",
-            horizontalalignment="center",
-            verticalalignment="center",
-            transform=ANY,
-            fontsize=20,
-        )
-        ax.axis.assert_called_with([0, 300, -1, 1])
+        featureAdder.WANTED_TYPES = ('site',)
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.text = MagicMock()
+        fig.axis = MagicMock()
+        result = featureAdder.add(fig, 'title', 0, 300,
+                                  sequenceFetcher=fetcher)
+        fig.text.assert_called_with(0.5, 0.5,
+                                    'No features found',
+                                    horizontalalignment='center',
+                                    verticalalignment='center',
+                                    transform=ANY, fontsize=20)
+        fig.axis.assert_called_with([0, 300, -1, 1])
         self.assertEqual([], result)
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testOneFeatureRaisesNotImplementedError(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns a feature,
         the C{add} method must raise C{NotImplementedError} because the
         C{_displayFeatures} method is not implemented.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(
-                type="site", qualifiers={"a": ["b"]}, location=location
-            )
+            feature = SeqFeature(type='site', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature])
 
         featureAdder = _FeatureAdder()
-        featureAdder.WANTED_TYPES = ("site",)
-        fig, ax = plt.subplots()
-        self.assertRaises(
-            NotImplementedError,
-            featureAdder.add,
-            ax,
-            "title",
-            0,
-            300,
-            sequenceFetcher=fetcher,
-        )
+        featureAdder.WANTED_TYPES = ('site',)
+        fig = plt.subplot(111, label=_randomLabel())
+        self.assertRaises(NotImplementedError, featureAdder.add, fig, 'title',
+                          0, 300, sequenceFetcher=fetcher)
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testTooManyFeatures(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns too many
         features, the C{text} and C{axis} methods on the figure must be called
         correctly and the C{add} call must return the sequences.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(
-                type="site", qualifiers={"a": ["b"]}, location=location
-            )
+            feature = SeqFeature(type='site', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature] * 100)
 
         featureAdder = _FeatureAdder()
-        featureAdder.WANTED_TYPES = ("site",)
-        fig, ax = plt.subplots()
-        ax.text = MagicMock()
-        ax.axis = MagicMock()
-        result = featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
-        ax.text.assert_called_with(
-            0.5,
-            0.5,
-            "Too many features to plot",
-            horizontalalignment="center",
-            verticalalignment="center",
-            transform=ANY,
-            fontsize=20,
-        )
-        ax.axis.assert_called_with([0, 300, -1, 1])
+        featureAdder.WANTED_TYPES = ('site',)
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.text = MagicMock()
+        fig.axis = MagicMock()
+        result = featureAdder.add(fig, 'title', 0, 300,
+                                  sequenceFetcher=fetcher)
+        fig.text.assert_called_with(0.5, 0.5,
+                                    'Too many features to plot',
+                                    horizontalalignment='center',
+                                    verticalalignment='center',
+                                    transform=ANY, fontsize=20)
+        fig.axis.assert_called_with([0, 300, -1, 1])
         self.assertTrue(isinstance(result, FeatureList))
         self.assertEqual(100, len(result))
 
 
 class TestProteinFeatureAdder(TestCase):
     """
     Tests of the C{ProteinFeatureAdder} class.
     """
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testUnwantedFeature(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns a feature
         whose type is not wanted, the figure's plot method must not be called
         and the C{add} method must return an empty feature list.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(
-                type="unwanted", qualifiers={"a": ["b"]}, location=location
-            )
+            feature = SeqFeature(type='unwanted', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature])
 
         featureAdder = ProteinFeatureAdder()
-        fig, ax = plt.subplots()
-        ax.plot = MagicMock()
-        result = featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
-        self.assertEqual([], ax.plot.call_args_list)
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.plot = MagicMock()
+        result = featureAdder.add(fig, 'title', 0, 300,
+                                  sequenceFetcher=fetcher)
+        self.assertEqual([], fig.plot.call_args_list)
         self.assertEqual([], result)
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testOneFeature(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns a feature,
         the C{text} and C{axis} methods on the figure must be called correctly
         and the C{add} call must return the sequences.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(
-                type="Site", qualifiers={"a": ["b"]}, location=location
-            )
+            feature = SeqFeature(type='Site', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature])
 
         featureAdder = ProteinFeatureAdder()
-        fig, ax = plt.subplots()
-        ax.plot = MagicMock()
-        ax.axis = MagicMock()
-        ax.legend = MagicMock()
-        result = featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
-        ax.plot.assert_called_with(
-            [100, 200],
-            [-0.0, -0.0],
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.plot = MagicMock()
+        fig.axis = MagicMock()
+        fig.legend = MagicMock()
+        result = featureAdder.add(fig, 'title', 0, 300,
+                                  sequenceFetcher=fetcher)
+        fig.plot.assert_called_with(
+            [100, 200], [-0.0, -0.0],
             color=(0.2298057, 0.298717966, 0.75368315299999999, 1.0),
-            linewidth=2,
-        )
-        ax.axis.assert_called_with([0, 300, -0.4, 0.2])
-        ax.legend.assert_called_with(
-            ["100-200 Site. a: b"],
-            loc="lower center",
-            shadow=True,
-            bbox_to_anchor=(0.5, 1.4),
-            ncol=2,
-            fancybox=True,
-        )
+            linewidth=2)
+        fig.axis.assert_called_with([0, 300, -0.4, 0.2])
+        fig.legend.assert_called_with(
+            ['100-200 Site. a: b'], loc='lower center', shadow=True,
+            bbox_to_anchor=(0.5, 1.4), ncol=2, fancybox=True)
         self.assertTrue(isinstance(result, FeatureList))
         self.assertEqual(1, len(result))
 
 
 class TestNucleotideFeatureAdder(TestCase):
     """
     Tests of the C{NucleotideFeatureAdder} class.
     """
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testUnwantedFeature(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns a feature
         whose type is not wanted, the figure's plot method must not be called
         and the C{add} method must return an empty feature list.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(
-                type="unwanted", qualifiers={"a": ["b"]}, location=location
-            )
+            feature = SeqFeature(type='unwanted', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature])
 
         featureAdder = NucleotideFeatureAdder()
-        fig, ax = plt.subplots()
-        ax.plot = MagicMock()
-        result = featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
-        self.assertEqual([], ax.plot.call_args_list)
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.plot = MagicMock()
+        result = featureAdder.add(fig, 'title', 0, 300,
+                                  sequenceFetcher=fetcher)
+        self.assertEqual([], fig.plot.call_args_list)
         self.assertEqual([], result)
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testOneFeature(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns a feature,
         the C{text} and C{axis} methods on the figure must be called correctly
         and the C{add} call must return the sequences.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(type="CDS", qualifiers={"a": ["b"]}, location=location)
+            feature = SeqFeature(type='CDS', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature])
 
         featureAdder = NucleotideFeatureAdder()
-        fig, ax = plt.subplots()
-        ax.plot = MagicMock()
-        ax.axis = MagicMock()
-        ax.legend = MagicMock()
-        result = featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
-        ax.plot.assert_called_with(
-            [100, 200],
-            [1, 1],
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.plot = MagicMock()
+        fig.axis = MagicMock()
+        fig.legend = MagicMock()
+        result = featureAdder.add(fig, 'title', 0, 300,
+                                  sequenceFetcher=fetcher)
+        fig.plot.assert_called_with(
+            [100, 200], [1, 1],
             color=(0.2298057, 0.298717966, 0.75368315299999999, 1.0),
-            linewidth=2,
-        )
-        ax.axis.assert_called_with([0, 300, -0.5, 2.5])
-        ax.legend.assert_called_with(
-            ["100-200 CDS. a: b"],
-            loc="lower center",
-            shadow=True,
-            ncol=2,
-            fancybox=True,
-            bbox_to_anchor=(0.5, 2.5),
-        )
+            linewidth=2)
+        fig.axis.assert_called_with([0, 300, -0.5, 2.5])
+        fig.legend.assert_called_with(
+            ['100-200 CDS. a: b'], loc='lower center',
+            shadow=True, ncol=2, fancybox=True,
+            bbox_to_anchor=(0.5, 2.5))
         self.assertTrue(isinstance(result, FeatureList))
         self.assertEqual(1, len(result))
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testOneFeatureAdjusted(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns a feature,
         the C{text} and C{axis} methods on the figure must be called correctly
         and the C{add} call must return the sequences.
 
         Note that offsets in the legend of nucleotide plots are adjusted. They
         shouldn't be as the adjusted offsets make no sense to the reader.
         """
-
-        def fetcher(title, db="database"):
+        def fetcher(title, db='database'):
             location = FeatureLocation(100, 200)
-            feature = SeqFeature(type="CDS", qualifiers={"a": ["b"]}, location=location)
+            feature = SeqFeature(type='CDS', qualifiers={'a': ['b']},
+                                 location=location)
             return SeqRecord(None, features=[feature])
 
         featureAdder = NucleotideFeatureAdder()
-        fig, ax = plt.subplots()
-        ax.plot = MagicMock()
-        ax.axis = MagicMock()
-        ax.legend = MagicMock()
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.plot = MagicMock()
+        fig.axis = MagicMock()
+        fig.legend = MagicMock()
 
         def adjuster(x):
             return 3 * x
 
-        result = featureAdder.add(
-            ax, "title", 0, 300, adjuster, sequenceFetcher=fetcher
-        )
-        ax.plot.assert_called_with(
-            [300, 600],
-            [0, 0],
+        result = featureAdder.add(fig, 'title', 0, 300, adjuster,
+                                  sequenceFetcher=fetcher)
+        fig.plot.assert_called_with(
+            [300, 600], [0, 0],
             color=(0.2298057, 0.298717966, 0.75368315299999999, 1.0),
-            linewidth=2,
-        )
-        ax.axis.assert_called_with([0, 300, -0.5, 2.5])
-        ax.legend.assert_called_with(
-            ["100-200 CDS. a: b"],
-            loc="lower center",
-            shadow=True,
-            ncol=2,
-            fancybox=True,
-            bbox_to_anchor=(0.5, 2.5),
-        )
+            linewidth=2)
+        fig.axis.assert_called_with([0, 300, -0.5, 2.5])
+        fig.legend.assert_called_with(
+            ['100-200 CDS. a: b'], loc='lower center',
+            shadow=True, ncol=2, fancybox=True,
+            bbox_to_anchor=(0.5, 2.5))
         self.assertTrue(isinstance(result, FeatureList))
         self.assertEqual(1, len(result))
 
+    @skipUnless(havePlt, 'matplotlib not supported under pypy')
     def testPolyproteinsAreMovedUp(self):
         """
         If the sequence fetcher used by a L{_FeatureAdder} returns a feature,
         that's a polyprotein, the feature must be plotted a little (0.2) above
         its normal location.
         """
-
-        def fetcher(title, db="database"):
-            feature1 = SeqFeature(
-                type="CDS",
-                qualifiers={"product": ["a polyprotein"]},
-                location=FeatureLocation(100, 200),
-            )
-            feature2 = SeqFeature(
-                type="CDS", qualifiers={"a": ["b"]}, location=FeatureLocation(130, 150)
-            )
+        def fetcher(title, db='database'):
+            feature1 = SeqFeature(type='CDS',
+                                  qualifiers={'product': ['a polyprotein']},
+                                  location=FeatureLocation(100, 200))
+            feature2 = SeqFeature(type='CDS',
+                                  qualifiers={'a': ['b']},
+                                  location=FeatureLocation(130, 150))
             return SeqRecord(None, features=[feature1, feature2])
 
         featureAdder = NucleotideFeatureAdder()
-        fig, ax = plt.subplots()
-        ax.plot = MagicMock()
-        ax.axis = MagicMock()
-        ax.legend = MagicMock()
-        result = featureAdder.add(ax, "title", 0, 300, sequenceFetcher=fetcher)
+        fig = plt.subplot(111, label=_randomLabel())
+        fig.plot = MagicMock()
+        fig.axis = MagicMock()
+        fig.legend = MagicMock()
+        result = featureAdder.add(fig, 'title', 0, 300,
+                                  sequenceFetcher=fetcher)
         self.assertEqual(
-            ax.plot.call_args_list,
+            fig.plot.call_args_list,
             [
                 call([100, 200], [1.2, 1.2], color=ANY, linewidth=2),
                 call([130, 150], [1.0, 1.0], color=ANY, linewidth=2),
-            ],
-        )
-        ax.axis.assert_called_with([0, 300, -0.5, 2.5])
-        ax.legend.assert_called_with(
-            ["100-200 CDS. product: a polyprotein", "130-150 CDS. a: b"],
-            loc="lower center",
-            shadow=True,
-            ncol=2,
-            fancybox=True,
-            bbox_to_anchor=(0.5, 2.5),
-        )
+            ])
+        fig.axis.assert_called_with([0, 300, -0.5, 2.5])
+        fig.legend.assert_called_with(
+            ['100-200 CDS. product: a polyprotein',
+             '130-150 CDS. a: b'],
+            loc='lower center', shadow=True, ncol=2, fancybox=True,
+            bbox_to_anchor=(0.5, 2.5))
         self.assertTrue(isinstance(result, FeatureList))
         self.assertEqual(2, len(result))
```

### Comparing `dark-matter-4.0.84/test/test_filter.py` & `dark-matter-4.0.9/test/test_intervals.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,472 +1,653 @@
-from six.moves import builtins
 from unittest import TestCase
-from unittest.mock import patch, mock_open
+from collections import Counter
 
-from dark.filter import ReadSetFilter, SequenceFilter, TitleFilter
-from dark.reads import Read
-from dark.titles import TitleAlignment, TitleAlignments
+from dark.intervals import OffsetAdjuster, ReadIntervals
+from dark.hsp import HSP
 
 
-class TitleFilterTest(TestCase):
+class TestReadIntervals(TestCase):
     """
-    Tests for the L{dark.filter.TitleFilter} class.
+    Test the ReadIntervals class
     """
 
-    def testNoRestriction(self):
-        """
-        Testing for acceptance against a title filter that has no
-        restrictions should return C{TitleFilter.DEFAULT_ACCEPT}.
-        """
-        tf = TitleFilter()
-        self.assertEqual(TitleFilter.DEFAULT_ACCEPT, tf.accept("hey"))
+    EMPTY = ReadIntervals.EMPTY
+    FULL = ReadIntervals.FULL
 
-    def testPositiveRegex(self):
+    def testEmpty(self):
         """
-        Testing for acceptance against a title filter with a positive regex
-        must work.
+        When no intervals are added, walk should just return one empty
+        interval that spans the entire rangoe from 0 to the sequence
+        length.
         """
-        tf = TitleFilter(positiveRegex=r"x+\s")
-        self.assertEqual(TitleFilter.DEFAULT_ACCEPT, tf.accept("hey xxx you"))
-        self.assertEqual(TitleFilter.REJECT, tf.accept("hey xxyou"))
+        ri = ReadIntervals(100)
+        self.assertEqual(
+            [
+                (self.EMPTY, (0, 100))
+            ],
+            list(ri.walk()))
 
-    def testNegativeRegex(self):
+    def testOneIntervalExactCovering(self):
         """
-        Testing for acceptance against a title filter with a negative regex
-        must work.
+        If there is a single interval that spans the whole hit exactly, just
+        that one interval should be returned by walk, and it should be full.
         """
-        tf = TitleFilter(negativeRegex=r"x+\s")
-        self.assertEqual(TitleFilter.REJECT, tf.accept("hey xxx you"))
-        self.assertEqual(TitleFilter.DEFAULT_ACCEPT, tf.accept("hey xxyou"))
-
-    def testPositiveRegexHasPrecedenceOverRepeatedTruncatedTitle(self):
+        ri = ReadIntervals(100)
+        ri.add(0, 100)
+        self.assertEqual(
+            [
+                (self.FULL, (0, 100))
+            ],
+            list(ri.walk()))
+
+    def testOneIntervalCoveringAllExtendingLeft(self):
+        """
+        If there is a single interval that spans the whole hit, including
+        going negative to the left, that one interval should be returned by
+        walk, and it should be full.
         """
-        Testing for acceptance against a title filter with a positive regex
-        must have precedence over checking for truncated titles when the same
-        non-matching title (that will be truncated) is passed twice.
+        ri = ReadIntervals(100)
+        ri.add(-10, 100)
+        self.assertEqual(
+            [
+                (self.FULL, (-10, 100))
+            ],
+            list(ri.walk()))
+
+    def testOneIntervalCoveringAllExtendingRight(self):
+        """
+        If there is a single interval that spans the whole hit, including
+        going beyond the hit to the right, that one interval should be returned
+        by walk, and it should be full.
         """
-        tf = TitleFilter(positiveRegex=r"xxxxx", truncateAfter="virus")
-        self.assertEqual(TitleFilter.REJECT, tf.accept("spotty virus 1"))
-        self.assertEqual(TitleFilter.REJECT, tf.accept("spotty virus 1"))
-
-    def testNegativeRegexHasPrecedenceOverRepeatedTruncatedTitle(self):
+        ri = ReadIntervals(100)
+        ri.add(0, 110)
+        self.assertEqual(
+            [
+                (self.FULL, (0, 110))
+            ],
+            list(ri.walk()))
+
+    def testOneIntervalCoveringAllExtendingBoth(self):
+        """
+        If there is a single interval that spans the whole hit, including
+        starting before zero and also going beyond the hit to the right, that
+        one interval should be returned by walk, and it should be full.
         """
-        Testing for acceptance against a title filter with a negative regex
-        must have precedence over checking for truncated titles when the same
-        matching title (that will be truncated) is passed twice.
+        ri = ReadIntervals(100)
+        ri.add(-10, 110)
+        self.assertEqual(
+            [
+                (self.FULL, (-10, 110))
+            ],
+            list(ri.walk()))
+
+    def testOneIntervalStartingAtZero(self):
+        """
+        If there is a single interval that starts at zero but doesn't
+        cover the whole hit, we should get 2 intervals back from walk,
+        a full one and then an empty.
         """
-        tf = TitleFilter(negativeRegex=r"spotty", truncateAfter="virus")
-        self.assertEqual(TitleFilter.REJECT, tf.accept("spotty virus 1"))
-        self.assertEqual(TitleFilter.REJECT, tf.accept("spotty virus 1"))
-
-    def testFullWordTruncation(self):
+        ri = ReadIntervals(100)
+        ri.add(0, 50)
+        self.assertEqual(
+            [
+                (self.FULL, (0, 50)),
+                (self.EMPTY, (50, 100)),
+            ],
+            list(ri.walk()))
+
+    def testOneIntervalStartingBeforeZero(self):
+        """
+        If there is a single interval that starts before zero but doesn't
+        cover the whole hit, we should get 2 intervals back from walk,
+        a full one and then an empty.
         """
-        Testing for acceptance against a title filter with title truncation
-        in effect must work if the title contains the C{truncateAfter} string
-        as a distint word.
+        ri = ReadIntervals(100)
+        ri.add(-50, 50)
+        self.assertEqual(
+            [
+                (self.FULL, (-50, 50)),
+                (self.EMPTY, (50, 100)),
+            ],
+            list(ri.walk()))
+
+    def testOneIntervalEndingAtHitEnd(self):
+        """
+        If there is a single interval that ends at the end of the hit
+        but doesn't start at zero, we should get 2 intervals back from walk,
+        an empty then a full.
         """
-        tf = TitleFilter(truncateAfter=r"virus")
-        # Note that the truncation code will chop off the first part of the
-        # title (the title ID).
+        ri = ReadIntervals(100)
+        ri.add(50, 100)
         self.assertEqual(
-            TitleFilter.DEFAULT_ACCEPT,
-            tf.accept("gi|400684|gb|AY421767.1| herpes virus 1"),
-        )
+            [
+                (self.EMPTY, (0, 50)),
+                (self.FULL, (50, 100)),
+            ],
+            list(ri.walk()))
+
+    def testOneIntervalEndingAfterHitEnd(self):
+        """
+        If there is a single interval that ends after the end of the hit
+        but doesn't start at zero, we should get 2 intervals back from walk,
+        an empty then a full.
+        """
+        ri = ReadIntervals(100)
+        ri.add(50, 150)
         self.assertEqual(
-            TitleFilter.REJECT, tf.accept("gi|400684|gb|AY421767.1| herpes virus 2")
-        )
+            [
+                (self.EMPTY, (0, 50)),
+                (self.FULL, (50, 150)),
+            ],
+            list(ri.walk()))
 
-    def testPartialWordTruncation(self):
+    def testOneIntervalInMiddle(self):
         """
-        Testing for acceptance against a title filter with title truncation
-        in effect must work if the title contains the C{truncateAfter} string
-        as a partial word.
+        If there is a single interval in the middle of the hit, we
+        should get 3 intervals back from walk: empty, full, empty.
+
         """
-        tf = TitleFilter(truncateAfter=r"virus")
-        # Note that the truncation code will chop off the first part of the
-        # title (the title ID).
+        ri = ReadIntervals(100)
+        ri.add(50, 60)
         self.assertEqual(
-            TitleFilter.DEFAULT_ACCEPT,
-            tf.accept("gi|400684|gb|AY421767.1| rotavirus 1"),
-        )
+            [
+                (self.EMPTY, (0, 50)),
+                (self.FULL, (50, 60)),
+                (self.EMPTY, (60, 100)),
+            ],
+            list(ri.walk()))
+
+    def testTwoOverlappingIntervalsInMiddle(self):
+        """
+        If there are two overlapping intervals in the middle of the hit, we
+        should get 3 intervals back from walk: empty, full, empty.
+        """
+        ri = ReadIntervals(100)
+        ri.add(50, 60)
+        ri.add(55, 70)
         self.assertEqual(
-            TitleFilter.REJECT, tf.accept("gi|400684|gb|AY421767.1| rotavirus 2")
-        )
-
-    def testWordTruncationRepeat(self):
-        """
-        Testing for acceptance against a title filter with title truncation
-        in effect must allow the exact same title twice, even if the title
-        is being truncated.
-        """
-        tf = TitleFilter(truncateAfter=r"virus")
-        # Note that the truncation code will chop off the first part of the
-        # title (the title ID).
+            [
+                (self.EMPTY, (0, 50)),
+                (self.FULL, (50, 70)),
+                (self.EMPTY, (70, 100)),
+            ],
+            list(ri.walk()))
+
+    def testThreeOverlappingIntervalsInMiddle(self):
+        """
+        If there are three overlapping intervals in the middle of the hit, we
+        should get 3 intervals back from walk: empty, full, empty.
+        """
+        ri = ReadIntervals(100)
+        ri.add(50, 60)
+        ri.add(65, 75)
+        ri.add(55, 70)
         self.assertEqual(
-            TitleFilter.DEFAULT_ACCEPT,
-            tf.accept("gi|400684|gb|AY421767.1| herpes virus 1"),
-        )
+            [
+                (self.EMPTY, (0, 50)),
+                (self.FULL, (50, 75)),
+                (self.EMPTY, (75, 100)),
+            ],
+            list(ri.walk()))
+
+    def testPairOfTwoOverlappingIntervals(self):
+        """
+        If there are two sets of two overlapping intervals in the middle of
+        the hit, we should get 5 intervals back from walk.
+        """
+        ri = ReadIntervals(100)
+        # First overlapping pair, 50-70.
+        ri.add(50, 60)
+        ri.add(55, 70)
+        # First overlapping pair, 80-95.
+        ri.add(80, 90)
+        ri.add(85, 95)
         self.assertEqual(
-            TitleFilter.DEFAULT_ACCEPT,
-            tf.accept("gi|400684|gb|AY421767.1| herpes virus 1"),
-        )
+            [
+                (self.EMPTY, (0, 50)),
+                (self.FULL, (50, 70)),
+                (self.EMPTY, (70, 80)),
+                (self.FULL, (80, 95)),
+                (self.EMPTY, (95, 100)),
+            ],
+            list(ri.walk()))
+
+    def testOverlappingIntervalsThatCoverEverything(self):
+        """
+        If there are sets of overlapping intervals that cover the whole hit,
+        we should get 1 full interval back from walk.
+        """
+        ri = ReadIntervals(100)
+        ri.add(-10, 20)
+        ri.add(15, 40)
+        ri.add(40, 70)
+        ri.add(66, 89)
+        ri.add(77, 93)
+        ri.add(70, 110)
+        self.assertEqual(
+            [
+                (self.FULL, (-10, 110))
+            ],
+            list(ri.walk()))
 
-    def testWhitelist(self):
-        """
-        Testing for acceptance against a title filter with a whitelist
-        must work even when a title is ruled out for other violations.
-        """
-        tf = TitleFilter(whitelist=["always ok"], negativeRegex="ok")
-        self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("always ok"))
-        self.assertEqual(TitleFilter.REJECT, tf.accept("always ok not"))
+    # The following tests have the same setup as above, but they test the
+    # coverageCounts() method.
 
-    def testBlacklist(self):
+    def testEmptyCoverageCountsOnZeroLengthSequence(self):
         """
-        Testing for acceptance against a title filter with a blacklist
-        must work.
+        When no intervals are added, coverageCounts should return an empty
+        Counter.
         """
-        tf = TitleFilter(blacklist=["never ok"], positiveRegex="ok")
-        self.assertEqual(TitleFilter.REJECT, tf.accept("never ok"))
+        ri = ReadIntervals(0)
+        self.assertEqual({}, ri.coverageCounts())
 
-    def testBlacklistFile(self):
+    def testEmptyCoverageCounts(self):
         """
-        Testing for acceptance against a title filter with a blacklist file.
+        When no intervals are added, coverageCounts should return an empty
+        Counter.
         """
-        data = "\n".join(["id1", "id2"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            tf = TitleFilter(blacklistFile="black.txt")
-            self.assertEqual(TitleFilter.REJECT, tf.accept("id1"))
-            self.assertEqual(TitleFilter.REJECT, tf.accept("id2"))
-            self.assertEqual(TitleFilter.DEFAULT_ACCEPT, tf.accept("id3"))
+        ri = ReadIntervals(100)
+        self.assertEqual({}, ri.coverageCounts())
 
-    def testBlacklistFileAndBlacklist(self):
+    def testOneIntervalExactCoveringCoverageCounts(self):
         """
-        Testing for acceptance against a title filter with a blacklist file and
-        some specific other blacklist titles.
+        If there is a single interval that spans the whole hit exactly,
+        coverageCounts should return the correct result.
         """
-        data = "\n".join(["id1", "id2"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            tf = TitleFilter(blacklistFile="black.txt", blacklist=set(["id3"]))
-            self.assertEqual(TitleFilter.REJECT, tf.accept("id1"))
-            self.assertEqual(TitleFilter.REJECT, tf.accept("id2"))
-            self.assertEqual(TitleFilter.REJECT, tf.accept("id3"))
-            self.assertEqual(TitleFilter.DEFAULT_ACCEPT, tf.accept("id4"))
+        ri = ReadIntervals(10)
+        ri.add(0, 10)
+        c = Counter([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
+        self.assertEqual(c, ri.coverageCounts())
 
-    def testWhitelistTakesPrecedenceOverBlacklist(self):
+    def testOneIntervalCoveringAllExtendingLeftCoverageCounts(self):
         """
-        Testing for acceptance against a title filter with a whitelist
-        and a blacklist that contain the same title must work (the whitelist
-        takes precedence).
+        If there is a single interval that spans the whole hit, including
+        going negative to the left, coverageCounts should return the correct
+        result.
         """
-        tf = TitleFilter(whitelist=["always ok"], blacklist=["always ok"])
-        self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("always ok"))
+        ri = ReadIntervals(10)
+        ri.add(-2, 10)
+        c = Counter([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
+        self.assertEqual(c, ri.coverageCounts())
 
-    def testWhitelistOnly(self):
+    def testOneIntervalCoveringAllExtendingRightCoverageCounts(self):
         """
-        Testing for acceptance against a title filter with a whitelist
-        and a negative regex that matches everything.
+        If there is a single interval that spans the whole hit, including
+        going beyond the hit to the right, coverageCounts should return the
+        correct result.
         """
-        tf = TitleFilter(whitelist=["always ok"], negativeRegex=".")
-        self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("always ok"))
-        self.assertEqual(TitleFilter.REJECT, tf.accept("always not ok"))
-        self.assertEqual(TitleFilter.REJECT, tf.accept("rubbish"))
+        ri = ReadIntervals(10)
+        ri.add(0, 12)
+        c = Counter([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
+        self.assertEqual(c, ri.coverageCounts())
 
-    def testWhitelistFileOnly(self):
+    def testOneIntervalStartingAtZeroCoverageCounts(self):
         """
-        Testing for acceptance against a title filter with a whitelist file
-        and a negative regex that matches everything.
+        If there is a single interval that starts at zero but doesn't
+        cover the whole hit, coverageCounts should return the correct result.
         """
-        data = "\n".join(["id1", "id2"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            tf = TitleFilter(whitelistFile="white.txt", negativeRegex=".")
-            self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("id1"))
-            self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("id2"))
-            self.assertEqual(TitleFilter.REJECT, tf.accept("id3"))
+        ri = ReadIntervals(10)
+        ri.add(0, 5)
+        c = Counter([0, 1, 2, 3, 4])
+        self.assertEqual(c, ri.coverageCounts())
 
-    def testWhitelistFileAndWhitelistOnly(self):
+    def testOneIntervalEndingAtHitEndCoverageCounts(self):
         """
-        Testing for acceptance against a title filter with a whitelist file
-        and some specific whitelist titles, with a negative regex that matches
-        everything.
+        If there is a single interval that ends at the end of the hit
+        but doesn't start at zero, coverageCounts should return the correct
+        result.
         """
-        data = "\n".join(["id1", "id2"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            tf = TitleFilter(
-                whitelistFile="white.txt", whitelist=set(["id3"]), negativeRegex="."
-            )
-            self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("id1"))
-            self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("id2"))
-            self.assertEqual(TitleFilter.WHITELIST_ACCEPT, tf.accept("id3"))
-            self.assertEqual(TitleFilter.REJECT, tf.accept("id4"))
-
+        ri = ReadIntervals(10)
+        ri.add(5, 10)
+        c = Counter([5, 6, 7, 8, 9])
+        self.assertEqual(c, ri.coverageCounts())
 
-class SequenceFilterTest(TestCase):
-    """
-    Tests for the L{dark.filter.SequenceFilter} class.
-    """
-
-    def testNoRestriction(self):
+    def testOneIntervalInMiddleCoverageCounts(self):
         """
-        Testing for acceptance against a sequence filter that has no
-        restrictions should return C{SequenceFilter.DEFAULT_ACCEPT}.
+        If there is a single interval in the middle of the hit, coverageCounts
+        should return the correct result.
         """
-        sf = SequenceFilter()
-        self.assertEqual(SequenceFilter.DEFAULT_ACCEPT, sf.accept("ACGT"))
+        ri = ReadIntervals(10)
+        ri.add(5, 6)
+        c = Counter([5])
+        self.assertEqual(c, ri.coverageCounts())
 
-    def testPositiveRegex(self):
+    def testTwoOverlappingIntervalsInMiddleCoverageCounts(self):
         """
-        Testing for acceptance against a sequence filter with a positive regex
-        must work.
+        If there are two overlapping intervals in the middle of the hit,
+        coverageCounts should return the correct result.
         """
-        sf = SequenceFilter(positiveRegex=r"G+C")
-        self.assertEqual(SequenceFilter.DEFAULT_ACCEPT, sf.accept("AAGGGC"))
-        self.assertEqual(SequenceFilter.REJECT, sf.accept("AAGGGTT"))
+        ri = ReadIntervals(10)
+        ri.add(5, 7)
+        ri.add(6, 8)
+        c = Counter([5, 6, 6, 7])
+        self.assertEqual(c, ri.coverageCounts())
 
-    def testNegativeRegex(self):
-        """
-        Testing for acceptance against a sequence filter with a negative regex
-        must work.
-        """
-        sf = SequenceFilter(negativeRegex=r"G+C")
-        self.assertEqual(SequenceFilter.REJECT, sf.accept("AAGGGC"))
-        self.assertEqual(SequenceFilter.DEFAULT_ACCEPT, sf.accept("AAGGGTT"))
+    # The following tests have the same setup as above, but they test the
+    # coverage() method.
 
-    def testWhitelist(self):
+    def testEmptyCoverageOnZeroLengthSequence(self):
         """
-        Testing for acceptance against a sequence filter with a whitelist
-        must work even when a sequence is ruled out for other violations.
+        When no intervals are added, coverage should return 0.0
         """
-        sf = SequenceFilter(whitelist=["GGG"], negativeRegex=".")
-        self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("GGG"))
-        self.assertEqual(SequenceFilter.REJECT, sf.accept("TCAAGGT"))
+        ri = ReadIntervals(0)
+        self.assertEqual(0.0, ri.coverage())
 
-    def testBlacklist(self):
+    def testEmptyCoverage(self):
         """
-        Testing for acceptance against a sequence filter with a blacklist
-        must work.
+        When no intervals are added, coverage should return 0.0
         """
-        sf = SequenceFilter(blacklist=["GGG"], positiveRegex=".")
-        self.assertEqual(SequenceFilter.REJECT, sf.accept("GGG"))
+        ri = ReadIntervals(100)
+        self.assertEqual(0.0, ri.coverage())
 
-    def testBlacklistFile(self):
+    def testOneIntervalExactCoveringCoverage(self):
         """
-        Testing for acceptance against a sequence filter with a blacklist file.
+        If there is a single interval that spans the whole hit exactly,
+        coverage should return 1.0.
         """
-        data = "\n".join(["GGG", "TTT"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            sf = SequenceFilter(blacklistFile="black.txt")
-            self.assertEqual(SequenceFilter.REJECT, sf.accept("GGG"))
-            self.assertEqual(SequenceFilter.REJECT, sf.accept("TTT"))
-            self.assertEqual(SequenceFilter.DEFAULT_ACCEPT, sf.accept("CCC"))
+        ri = ReadIntervals(100)
+        ri.add(0, 100)
+        self.assertEqual(1.0, ri.coverage())
 
-    def testBlacklistFileAndBlacklist(self):
+    def testOneIntervalCoveringAllExtendingLeftCoverage(self):
         """
-        Testing for acceptance against a sequence filter with a blacklist file and
-        some specific other blacklist sequences.
+        If there is a single interval that spans the whole hit, including
+        going negative to the left, coverage should return 1.0.
         """
-        data = "\n".join(["GGG", "TTT"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            sf = SequenceFilter(blacklistFile="black.txt", blacklist=set(["CCC"]))
-            self.assertEqual(SequenceFilter.REJECT, sf.accept("GGG"))
-            self.assertEqual(SequenceFilter.REJECT, sf.accept("TTT"))
-            self.assertEqual(SequenceFilter.REJECT, sf.accept("CCC"))
-            self.assertEqual(SequenceFilter.DEFAULT_ACCEPT, sf.accept("AAA"))
+        ri = ReadIntervals(100)
+        ri.add(-10, 100)
+        self.assertEqual(1.0, ri.coverage())
 
-    def testWhitelistTakesPrecedenceOverBlacklist(self):
+    def testOneIntervalCoveringAllExtendingRightCoverage(self):
         """
-        Testing for acceptance against a sequence filter with a whitelist
-        and a blacklist that contain the same sequence must work (the whitelist
-        takes precedence).
+        If there is a single interval that spans the whole hit, including
+        going beyond the hit to the right, coverage should return 1.0.
         """
-        sf = SequenceFilter(whitelist=["AAA"], blacklist=["AAA"])
-        self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("AAA"))
+        ri = ReadIntervals(100)
+        ri.add(0, 110)
+        self.assertEqual(1.0, ri.coverage())
 
-    def testWhitelistOnly(self):
+    def testOneIntervalCoveringAllExtendingBothCoverage(self):
         """
-        Testing for acceptance against a sequence filter with a whitelist
-        and a negative regex that matches everything.
+        If there is a single interval that spans the whole hit, including
+        starting before zero and also going beyond the hit to the right,
+        coverage should return 1.0
         """
-        sf = SequenceFilter(whitelist=["AAA"], negativeRegex=".")
-        self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("AAA"))
-        self.assertEqual(SequenceFilter.REJECT, sf.accept("TTT"))
+        ri = ReadIntervals(100)
+        ri.add(-10, 110)
+        self.assertEqual(1.0, ri.coverage())
 
-    def testWhitelistFileOnly(self):
+    def testOneIntervalStartingAtZeroCoverage(self):
         """
-        Testing for acceptance against a sequence filter with a whitelist file
-        and a negative regex that matches everything.
+        If there is a single interval that starts at zero but doesn't
+        cover the whole hit, coverage should return the correct value.
         """
-        data = "\n".join(["AAA", "CCC"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            sf = SequenceFilter(whitelistFile="white.txt", negativeRegex=".")
-            self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("AAA"))
-            self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("CCC"))
-            self.assertEqual(SequenceFilter.REJECT, sf.accept("GGG"))
+        ri = ReadIntervals(100)
+        ri.add(0, 50)
+        self.assertEqual(0.5, ri.coverage())
 
-    def testWhitelistFileAndWhitelistOnly(self):
+    def testOneIntervalStartingBeforeZeroCoverage(self):
         """
-        Testing for acceptance against a sequence filter with a whitelist file
-        and some specific whitelist sequences, with a negative regex that matches
-        everything.
+        If there is a single interval that starts before zero but doesn't
+        cover the whole hit, coverage should return the correct value.
         """
-        data = "\n".join(["AAA", "CCC"]) + "\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            sf = SequenceFilter(
-                whitelistFile="white.txt", whitelist=set(["GGG"]), negativeRegex="."
-            )
-            self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("AAA"))
-            self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("CCC"))
-            self.assertEqual(SequenceFilter.WHITELIST_ACCEPT, sf.accept("GGG"))
-            self.assertEqual(SequenceFilter.REJECT, sf.accept("TTT"))
-
-
-class ReadSetTest(TestCase):
-    """
-    Tests for the L{dark.filter.ReadSetFilter} class.
-    """
+        ri = ReadIntervals(100)
+        ri.add(-50, 50)
+        self.assertEqual(0.5, ri.coverage())
 
-    def makeTitleAlignments(self, *readIds):
+    def testOneIntervalEndingAtHitEndCoverage(self):
         """
-        Create a TitleAlignments instance containing reads with the
-        ids given by C{ids}.
-
-        param readIds: A C{list} of integer ids for reads.
-        @return: A C{TitleAlignments} instance with reads with the given ids.
+        If there is a single interval that ends at the end of the hit
+        but doesn't start at zero, coverage should return the correct value.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        for readId in readIds:
-            titleAlignment = TitleAlignment(Read("id" + str(readId), "A"), [])
-            titleAlignments.addAlignment(titleAlignment)
-        return titleAlignments
+        ri = ReadIntervals(100)
+        ri.add(50, 100)
+        self.assertEqual(0.5, ri.coverage())
 
-    def testFirstUse(self):
+    def testOneIntervalEndingAfterHitEndCoverage(self):
         """
-        Testing for acceptance against a read set filter that has not been
-        used should return C{True}.
+        If there is a single interval that ends after the end of the hit
+        but doesn't start at zero, coverage should return the correct value.
         """
-        titleAlignments = self.makeTitleAlignments()
-        rsf = ReadSetFilter(0.9)
-        self.assertTrue(rsf.accept("title1", titleAlignments))
+        ri = ReadIntervals(100)
+        ri.add(50, 150)
+        self.assertEqual(0.5, ri.coverage())
 
-    def testDuplicateSingleRead(self):
-        """
-        Testing for acceptance against a read set filter that has already
-        seen the exact set should return C{False} if the C{minNew} threshold
-        is non-zero.
+    def testOneIntervalInMiddleCoverage(self):
         """
-        rsf = ReadSetFilter(0.9)
-        rsf.accept("title1", self.makeTitleAlignments(0))
-        self.assertFalse(rsf.accept("title2", self.makeTitleAlignments(0)))
+        If there is a single interval in the middle of the hit, coverage
+        should return the correct value.
 
-    def testDuplicateSingleReadZeroThreshold(self):
         """
-        Testing for acceptance against a read set filter that has already
-        seen the exact set should return C{True} if the C{minNew} threshold
-        is zero.
-        """
-        rsf = ReadSetFilter(0.0)
-        rsf.accept("title1", self.makeTitleAlignments(0))
-        self.assertTrue(rsf.accept("title2", self.makeTitleAlignments(0)))
+        ri = ReadIntervals(100)
+        ri.add(50, 60)
+        self.assertEqual(0.1, ri.coverage())
 
-    def testDifferentSet(self):
+    def testTwoOverlappingIntervalsInMiddleCoverage(self):
         """
-        Testing for acceptance against a read set filter that has seen a set
-        should return C{True} if the new set is totally different.
+        If there are two overlapping intervals in the middle of the hit,
+        coverage should return the correct value.
         """
-        rsf = ReadSetFilter(1.0)
-        rsf.accept("title1", self.makeTitleAlignments(0))
-        self.assertTrue(rsf.accept("title2", self.makeTitleAlignments(1)))
+        ri = ReadIntervals(100)
+        ri.add(50, 60)
+        ri.add(55, 70)
+        self.assertEqual(0.2, ri.coverage())
 
-    def testSufficientlyDifferent(self):
+    def testThreeOverlappingIntervalsInMiddleCoverage(self):
         """
-        Testing for acceptance against a read set filter that has seen several
-        sets should return C{True} if the new set is sufficiently different.
+        If there are three overlapping intervals in the middle of the hit,
+        coverage should return the correct value.
         """
-        rsf = ReadSetFilter(0.5)
-        rsf.accept("title1", self.makeTitleAlignments(0, 1, 2, 3, 4))
-        rsf.accept("title2", self.makeTitleAlignments(5, 6, 7, 8, 9))
-        self.assertTrue(
-            rsf.accept("title3", self.makeTitleAlignments(0, 1, 2, 5, 6, 7))
-        )
+        ri = ReadIntervals(100)
+        ri.add(50, 60)
+        ri.add(65, 75)
+        ri.add(55, 70)
+        self.assertEqual(0.25, ri.coverage())
 
-    def testInsufficientlyDifferent(self):
+    def testPairOfTwoOverlappingIntervalsCoverage(self):
         """
-        Testing for acceptance against a read set filter that has seen several
-        sets should return C{False} if the new set is insufficiently different.
+        If there are two sets of two overlapping intervals in the middle of
+        the hit, coverage should return the correct value.
         """
-        rsf = ReadSetFilter(0.5)
-        rsf.accept("title1", self.makeTitleAlignments(0, 1, 2, 3, 4))
-        rsf.accept("title2", self.makeTitleAlignments(5, 6, 7, 8, 9))
-        self.assertFalse(rsf.accept("title3", self.makeTitleAlignments(0, 1, 2, 11)))
+        ri = ReadIntervals(100)
+        # First overlapping pair, 50-70.
+        ri.add(50, 60)
+        ri.add(55, 70)
+        # First overlapping pair, 80-95.
+        ri.add(80, 90)
+        ri.add(85, 95)
+        self.assertEqual(0.35, ri.coverage())
 
-    def testThresholdRoundsUp(self):
+    def testOverlappingIntervalsThatCoverEverythingCoverage(self):
         """
-        Testing for acceptance should round up the needed number of new reads.
+        If there are sets of overlapping intervals that cover the whole hit,
+        coverage should return the correct value.
         """
-        rsf = ReadSetFilter(0.5)
-        rsf.accept("title1", self.makeTitleAlignments(0, 1, 2, 3, 4))
-        # If we pass a read set of size three, two of the reads will need to be
-        # different.
-        self.assertFalse(rsf.accept("title2", self.makeTitleAlignments(0, 1, 6)))
+        ri = ReadIntervals(100)
+        ri.add(-10, 20)
+        ri.add(15, 40)
+        ri.add(40, 70)
+        ri.add(66, 89)
+        ri.add(77, 93)
+        ri.add(70, 110)
+        self.assertEqual(1.0, ri.coverage())
 
-    def testRepeatTitle(self):
-        """
-        Testing for acceptance on a title that has been seen before (in an
-        accepted read set) must raise C{AssertionError}.
-        """
-        rsf = ReadSetFilter(0.5)
-        rsf.accept("title1", self.makeTitleAlignments(0, 1, 2, 3, 4))
-        self.assertRaises(
-            AssertionError, rsf.accept, "title1", self.makeTitleAlignments()
-        )
 
-    def testInvalidates(self):
+class TestOffsetAdjuster(TestCase):
+    """
+    Tests for the OffsetAdjuster class.
+    """
+
+    def testEmpty(self):
         """
-        It must be possible to retrieve the list of titles that were
-        invalidated by an earlier title's read set.
+        When no intervals are given, the reduction should be for the full hit
+        width.
         """
-        rsf = ReadSetFilter(0.5)
-        rsf.accept("title1", self.makeTitleAlignments(0))
-        rsf.accept("title2", self.makeTitleAlignments(0))
-        rsf.accept("title3", self.makeTitleAlignments(1))
-        rsf.accept("title4", self.makeTitleAlignments(0))
-        self.assertEqual(["title2", "title4"], rsf.invalidates("title1"))
+        adjuster = OffsetAdjuster()
+        self.assertEqual([], adjuster.adjustments())
+        self.assertEqual(0, adjuster.adjustOffset(0))
 
-    def testInvalidatesEmpty(self):
+    def testNoReads(self):
         """
-        The list of titles invalidated by an earlier title that didn't
-        invalidate anything must be empty.
+        When no reads are added to an interval, the reduction should be for
+        the full hit width.
         """
-        rsf = ReadSetFilter(0.5)
-        self.assertEqual([], rsf.invalidates("title1"))
-
-
-class FakeCursor:
-    def __init__(self, results):
-        self._results = results
-        self._index = -1
-
-    def execute(self, p):
-        pass
-
-    def fetchone(self):
-        self._index += 1
-        return self._results[self._index]
-
-    def close(self):
-        pass
-
-
-class FakeDbConnection:
-    """
-    FakeDbConnection and FakeCursor fake results
-    for database calls.
-    """
-
-    def __init__(self, results):
-        self._results = results
-        self.open = True
-
-    def cursor(self):
-        return FakeCursor(self._results)
-
-    def close(self):
-        self.open = False
+        ri = ReadIntervals(64)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+                (64, 58)
+            ],
+            adjuster.adjustments())
+        self.assertEqual(6, adjuster.adjustOffset(64))
+
+    def testOneReadThatExactlyCoversHit(self):
+        """
+        When one read is given that exactly covers the hit, there should
+        be no length reductions.
+        """
+        ri = ReadIntervals(106)
+        ri.add(0, 106)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+            ],
+            adjuster.adjustments())
+        self.assertEqual(106, adjuster.adjustOffset(106))
+
+    def testOneReadThatExceedsHitOnBothEnds(self):
+        """
+        When one read is given that exceeds the hit at both ends, there should
+        be no length reductions.
+        """
+        ri = ReadIntervals(106)
+        ri.add(-100, 200)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+            ],
+            adjuster.adjustments())
+        self.assertEqual(106, adjuster.adjustOffset(106))
+
+    def testOneReadAtStart(self):
+        """
+        When one read is added to the start of an interval, there should be one
+        reduction for the empty section after the read.
+        """
+        ri = ReadIntervals(228)
+        ri.add(0, 100)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+                (228, 121),
+            ],
+            adjuster.adjustments())
+        self.assertEqual(107, adjuster.adjustOffset(228))
+
+    def testOneReadBeforeStart(self):
+        """
+        When one read is added to the start of an interval before zero, there
+        should be one reduction for the empty section after the read.
+        """
+        ri = ReadIntervals(228)
+        ri.add(-10, 100)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+                (228, 121),
+            ],
+            adjuster.adjustments())
+        self.assertEqual(107, adjuster.adjustOffset(228))
+
+    def testOneReadAtEnd(self):
+        """
+        When one read is added to the end of an interval, there should be one
+        reduction for the empty section before the read.
+        """
+        ri = ReadIntervals(228)
+        ri.add(128, 228)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+                (128, 121),
+            ],
+            adjuster.adjustments())
+        self.assertEqual(107, adjuster.adjustOffset(228))
+
+    def testOneReadAfterEnd(self):
+        """
+        When one read is added to the end of an interval, going beyond the end
+        of the hit, there should be one reduction for the empty section before
+        the read.
+        """
+        ri = ReadIntervals(228)
+        ri.add(128, 250)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+                (128, 121),
+            ],
+            adjuster.adjustments())
+        self.assertEqual(107, adjuster.adjustOffset(228))
+
+    def testOneReadInMiddle(self):
+        """
+        When one read is added to the middle of an interval, there should be
+        two reductions.
+        """
+        ri = ReadIntervals(106)
+        ri.add(32, 42)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+                (32, 27),
+                (106, 58),
+            ],
+            adjuster.adjustments())
+        self.assertEqual(106 - 27 - 58, adjuster.adjustOffset(106))
+
+    def testTwoReadsInMiddle(self):
+        """
+        When two reads are added to the middle of an interval, there should be
+        three reductions (after first empty area, after 2nd empty area, after
+        final empty area.
+        """
+        ri = ReadIntervals(132)
+        ri.add(32, 42)
+        ri.add(58, 68)
+        adjuster = OffsetAdjuster(ri)
+        self.assertEqual(
+            [
+                (32, 27),
+                (58, 12),
+                (132, 58),
+            ],
+            adjuster.adjustments())
+        self.assertEqual(132 - 27 - 12 - 58, adjuster.adjustOffset(132))
+
+        # Test an HSP at the beginning is unchanged.
+        hsp = HSP(10, readEndInSubject=10, readStartInSubject=0,
+                  subjectEnd=10, subjectStart=0)
+        adjuster.adjustHSP(hsp)
+        self.assertEqual(10, hsp.readEndInSubject)
+        self.assertEqual(0, hsp.readStartInSubject)
+        self.assertEqual(10, hsp.subjectEnd)
+        self.assertEqual(0, hsp.subjectStart)
+
+        # Test an HSP in the first read region.
+        hsp = HSP(10, readEndInSubject=42, readStartInSubject=32,
+                  subjectEnd=40, subjectStart=35)
+        adjuster.adjustHSP(hsp)
+        self.assertEqual(15, hsp.readEndInSubject)
+        self.assertEqual(5, hsp.readStartInSubject)
+        self.assertEqual(13, hsp.subjectEnd)
+        self.assertEqual(8, hsp.subjectStart)
+
+        # Test an HSP in the second read region.
+        hsp = HSP(10, readEndInSubject=68, readStartInSubject=58,
+                  subjectEnd=66, subjectStart=60)
+        adjuster.adjustHSP(hsp)
+        self.assertEqual(29, hsp.readEndInSubject)
+        self.assertEqual(19, hsp.readStartInSubject)
+        self.assertEqual(27, hsp.subjectEnd)
+        self.assertEqual(21, hsp.subjectStart)
```

### Comparing `dark-matter-4.0.84/test/test_genbank.py` & `dark-matter-4.0.9/test/test_genbank.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,449 +5,437 @@
 from dark.genbank import GenomeRanges
 
 
 class TestErrors(TestCase):
     """
     Test incorrect ways of instantitating the GenomeRanges class.
     """
-
     def testEmptyString(self):
         """
         The GenomeRanges class must raise a ValueError when passed an range
         empty string.
         """
-        error = (
-            r'^Could not parse GenBank range string ""\. '
-            r'Range "" does not end with \]\(\+\) or \]\(-\)\.$'
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "")
+        error = (r'^Could not parse GenBank range string ""\. '
+                 r'Range "" does not end with \]\(\+\) or \]\(-\)\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges, '')
 
     def testUnparseableString(self):
         """
         The GenomeRanges class must raise a ValueError when passed an
         unparseable string.
         """
-        error = (
-            r'^Could not parse GenBank range string "x"\. '
-            r'Range "x" does not end with \]\(\+\) or \]\(-\)\.$'
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "x")
+        error = (r'^Could not parse GenBank range string "x"\. '
+                 r'Range "x" does not end with \]\(\+\) or \]\(-\)\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges, 'x')
 
     def testNoComplementIndicator(self):
         """
         The GenomeRanges class must raise a ValueError when passed an a range
         that does not end with ](+] or ](-).
         """
-        error = (
-            r'^Could not parse GenBank range string "\[33:40\]"\. '
-            r'Range "\[33:40\]" does not end with \]\(\+\) or \]\(-\)\.$'
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "[33:40]")
+        error = (r'^Could not parse GenBank range string "\[33:40\]"\. '
+                 r'Range "\[33:40\]" does not end with \]\(\+\) or \]\(-\)\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges, '[33:40]')
 
     def testNoLeadingSquareBracket(self):
         """
         The GenomeRanges class must raise a ValueError when passed an a range
         that does not start with [.
         """
-        error = (
-            r'^Could not parse GenBank range string "33:40\]\(-\)"\. '
-            r'Range "33:40\]\(-\)" does not start with "\["\.$'
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "33:40](-)")
+        error = (r'^Could not parse GenBank range string "33:40\]\(-\)"\. '
+                 r'Range "33:40\]\(-\)" does not start with "\["\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges, '33:40](-)')
 
     def testJoinWithNoRange(self):
         """
         The GenomeRanges class must raise a ValueError when passed a join
         directive containing no ranges.
         """
-        error = (
-            r'^Could not parse GenBank range string "join{}"\. '
-            r"join{} can only be used with multiple ranges\.$"
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "join{}")
+        error = (r'^Could not parse GenBank range string "join{}"\. '
+                 r'join{} can only be used with multiple ranges\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges, 'join{}')
 
     def testDecreasingOrder(self):
         """
         The GenomeRanges class must raise a ValueError when passed a string in
         which the start, stop values decrease.
         """
-        error = (
-            r'^Could not parse GenBank range string "\[7:4\]\(\+\)"\. '
-            r"Offset values \(7, 4\) cannot decrease\.$"
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "[7:4](+)")
+        error = (r'^Could not parse GenBank range string "\[7:4\]\(\+\)"\. '
+                 r'Offset values \(7, 4\) cannot decrease\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges, '[7:4](+)')
 
     def testContiguousRanges(self):
         """
         The GenomeRanges class must raise a ValueError if passed two ranges
         that are contiguous and which have the same (-) direction.
         """
-        message = "Contiguous GenBank ranges detected: [3:5] followed by [5:7]."
+        message = (
+            'Contiguous GenBank ranges detected: [3:5] followed by [5:7].')
         with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
-            GenomeRanges("join{[3:5](-), [5:7](-)}")
+            warnings.simplefilter('always')
+            GenomeRanges('join{[3:5](-), [5:7](-)}')
             self.assertEqual(1, len(w))
             self.assertEqual(message, str(w[0].message))
 
     def testContiguousRangesComplementStrand(self):
         """
         The GenomeRanges class must raise a ValueError if passed two ranges
         that are contiguous and which have the same (+) direction.
         """
-        message = "Contiguous GenBank ranges detected: [3:5] followed by [5:7]."
+        message = (
+            'Contiguous GenBank ranges detected: [3:5] followed by [5:7].')
         with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
-            GenomeRanges("join{[3:5](+), [5:7](+)}")
+            warnings.simplefilter('always')
+            GenomeRanges('join{[3:5](+), [5:7](+)}')
             self.assertEqual(1, len(w))
             self.assertEqual(message, str(w[0].message))
 
     def testTwoNakedRanges(self):
         """
         Two ranges with no join qualifier must result in a ValueError.
         """
-        error = (
-            r"^Could not parse GenBank range string "
-            r'"\[3:5\(\+\), 7:9\(-\)\]"\. '
-            r"Multiple ranges must be wrapped in join{}\.$"
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "[3:5(+), 7:9(-)]")
+        error = (r'^Could not parse GenBank range string '
+                 r'"\[3:5\(\+\), 7:9\(-\)\]"\. '
+                 r'Multiple ranges must be wrapped in join{}\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges,
+                          '[3:5(+), 7:9(-)]')
 
     def testOneJoinedRange(self):
         """
         A single range with a join() must result in a ValueError.
         """
-        error = (
-            r"^Could not parse GenBank range string "
-            r'"join{\[3:5\]\(-\)}"\. '
-            r"join{} can only be used with multiple ranges\.$"
-        )
-        assertRaisesRegex(self, ValueError, error, GenomeRanges, "join{[3:5](-)}")
+        error = (r'^Could not parse GenBank range string '
+                 r'"join{\[3:5\]\(-\)}"\. '
+                 r'join{} can only be used with multiple ranges\.$')
+        assertRaisesRegex(self, ValueError, error, GenomeRanges,
+                          'join{[3:5](-)}')
 
 
 class TestRanges(TestCase):
     """
     Test the ranges attribute of the GenomeRanges class.
     """
-
     def testOneNakedRangePositive(self):
         """
         A single range on the positive strand must result in the the expected
         ranges value stored.
         """
-        gr = GenomeRanges("[3:5](+)")
+        gr = GenomeRanges('[3:5](+)')
         self.assertEqual(((3, 5, True),), gr.ranges)
 
     def testOneNakedRangeNegative(self):
         """
         A single range on the negative strand must result in the the expected
         ranges value stored.
         """
-        gr = GenomeRanges("[3:5](-)")
+        gr = GenomeRanges('[3:5](-)')
         self.assertEqual(((3, 5, False),), gr.ranges)
 
     def testTwoJoinedRanges(self):
         """
         Two joined ranges must return the expected result.
         """
-        gr = GenomeRanges("join{[3:5](+), [7:9](-)}")
+        gr = GenomeRanges('join{[3:5](+), [7:9](-)}')
         self.assertEqual(((3, 5, True), (7, 9, False)), gr.ranges)
 
     def testThreeJoinedRanges(self):
         """
         Three joined ranges must return the expected result.
         """
-        gr = GenomeRanges("join{[3:5](+), [7:9](-), [17:19](-)}")
-        self.assertEqual(((3, 5, True), (7, 9, False), (17, 19, False)), gr.ranges)
+        gr = GenomeRanges('join{[3:5](+), [7:9](-), [17:19](-)}')
+        self.assertEqual(((3, 5, True), (7, 9, False), (17, 19, False)),
+                         gr.ranges)
 
     def testTwoJoinedContiguousRangesMismatchedStrands(self):
         """
         Two joined ranges that are contiguous but not on the same strand must
         return the expected unmerged (two-range) result.
         """
-        gr = GenomeRanges("join{[3:5](-), [5:9](+)}")
+        gr = GenomeRanges('join{[3:5](-), [5:9](+)}')
         self.assertEqual(((3, 5, False), (5, 9, True)), gr.ranges)
 
     def testTwoJoinedContiguousRangesComplementStrand(self):
         """
         Two joined ranges that are contiguous on the same (complement) strand
         must return the expected (single-range) result.
         """
-        message = "Contiguous GenBank ranges detected: [3:5] followed by [5:9]."
+        message = (
+            'Contiguous GenBank ranges detected: [3:5] followed by [5:9].')
         with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
-            gr = GenomeRanges("join{[3:5](-), [5:9](-)}")
+            warnings.simplefilter('always')
+            gr = GenomeRanges('join{[3:5](-), [5:9](-)}')
             self.assertEqual(((3, 9, False),), gr.ranges)
             self.assertEqual(1, len(w))
             self.assertEqual(message, str(w[0].message))
 
     def testTwoJoinedContiguousRanges(self):
         """
         Two joined ranges that are contiguous on the same strand must return
         the expected (single-range) result.
         """
-        message = "Contiguous GenBank ranges detected: [3:5] followed by [5:9]."
+        message = (
+            'Contiguous GenBank ranges detected: [3:5] followed by [5:9].')
         with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
-            gr = GenomeRanges("join{[3:5](+), [5:9](+)}")
+            warnings.simplefilter('always')
+            gr = GenomeRanges('join{[3:5](+), [5:9](+)}')
             self.assertEqual(((3, 9, True),), gr.ranges)
             self.assertEqual(1, len(w))
             self.assertEqual(message, str(w[0].message))
 
     def testThreeJoinedContiguousRanges(self):
         """
         Three joined ranges that are contiguous must return the expected
         (single-range) result.
         """
-        message1 = "Contiguous GenBank ranges detected: [3:5] followed by [5:7]."
+        message1 = (
+            'Contiguous GenBank ranges detected: [3:5] followed by [5:7].')
         # Note that the second warning message has a range that doesn't
         # correspond to any of the ranges in the GenomeRanges
         # initialization string. That's because by the time the second
         # warning is issued the first two ranges ([3:5] and [5:7]) have
         # been merged into one ([3:7]).
-        message2 = "Contiguous GenBank ranges detected: [3:7] followed by [7:9]."
+        message2 = (
+            'Contiguous GenBank ranges detected: [3:7] followed by [7:9].')
         with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
-            gr = GenomeRanges("join{[3:5](-), [5:7](-), [7:9](-)}")
+            warnings.simplefilter('always')
+            gr = GenomeRanges('join{[3:5](-), [5:7](-), [7:9](-)}')
             self.assertEqual(((3, 9, False),), gr.ranges)
             self.assertEqual(2, len(w))
             self.assertEqual(message1, str(w[0].message))
             self.assertEqual(message2, str(w[1].message))
 
     def testTwoJoinedContiguousRangesInTheMiddleOfFourRanges(self):
         """
         Two joined ranges that are contiguous must return the expected
         result when there are non-contiguous ranges surrounding them.
         """
-        message = "Contiguous GenBank ranges detected: [3:5] followed by [5:9]."
+        message = (
+            'Contiguous GenBank ranges detected: [3:5] followed by [5:9].')
         with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
-            gr = GenomeRanges("join{[0:2](-), [3:5](-), [5:9](-), [12:15](-)}")
-            self.assertEqual(((0, 2, False), (3, 9, False), (12, 15, False)), gr.ranges)
+            warnings.simplefilter('always')
+            gr = GenomeRanges('join{[0:2](-), [3:5](-), [5:9](-), [12:15](-)}')
+            self.assertEqual(((0, 2, False), (3, 9, False), (12, 15, False)),
+                             gr.ranges)
             self.assertEqual(1, len(w))
             self.assertEqual(message, str(w[0].message))
 
 
 class TestCircular(TestCase):
     """
     Test the GenomeRanges class ranges method.
     """
-
     def testOneRange(self):
         """
         The circular method must return False when given only a single range
         tuple that is fully contained within the genome.
         """
-        self.assertFalse(GenomeRanges("[20:40](+)").circular(100))
+        self.assertFalse(GenomeRanges('[20:40](+)').circular(100))
 
     def testOneRangeEndingAtGenomeEnd(self):
         """
         The circular method must return False when given only a single range
         tuple that ends at the end of the genome.
         """
-        self.assertFalse(GenomeRanges("[20:40](+)").circular(40))
+        self.assertFalse(GenomeRanges('[20:40](+)').circular(40))
 
     def testOneRangeSpanningTheWholeGenome(self):
         """
         The circular method must return False when given only a single range
         tuple that ends at the end of the genome.
         """
-        self.assertFalse(GenomeRanges("[0:40](+)").circular(40))
+        self.assertFalse(GenomeRanges('[0:40](+)').circular(40))
 
     def testTwoRangesThatAreCircular(self):
         """
         The circular method must return True when given two ranges that span
         the end of the genome.
         """
-        self.assertTrue(GenomeRanges("join{[20:40](+), [0:10](+)}").circular(40))
+        self.assertTrue(
+            GenomeRanges('join{[20:40](+), [0:10](+)}').circular(40))
 
     def testThreeRangesThatAreCircular(self):
         """
         The circular method must return True when given three ranges that span
         the end of the genome.
         """
         self.assertTrue(
-            GenomeRanges("join{[20:30](+), [31:40](+), [0:10](+)}").circular(40)
-        )
+            GenomeRanges(
+                'join{[20:30](+), [31:40](+), [0:10](+)}').circular(40))
 
     def testThreeRangesThatAreCircular2(self):
         """
         The circular method must return True when given three ranges that span
         the end of the genome when one of the ranges is the last in the passed
         BioPython GenBank string and the second range (starting at zero) is the
         first.
         """
         self.assertTrue(
-            GenomeRanges("join{[0:10](+), [40:60](+), [80:90](+)}").circular(90)
-        )
+            GenomeRanges(
+                'join{[0:10](+), [40:60](+), [80:90](+)}').circular(90))
 
 
 class TestStartInGenome(TestCase):
     """
     Test the GenomeRanges class startInGenome method.
     """
-
     def testStartOutsideGenomeRange(self):
         """
         If the start location in the DIAMOND match is greater than the length
         of the genome, a ValueError must be raised.
         """
         # The starting offset in the genome is 27 because DIAMOND returns
         # 1-based offsets into the protein subject. So in Python terms the
         # start offset is amino acid 9, or nucleotide 27.
-        ranges = GenomeRanges("[10:20](+)")
-        error = (
-            r"^Starting nucleotide offset 27 not found in protein "
-            r"nucleotide ranges \(10, 20\)\.$"
-        )
-        assertRaisesRegex(self, ValueError, error, ranges.startInGenome, {"sstart": 10})
+        ranges = GenomeRanges('[10:20](+)')
+        error = (r'^Starting nucleotide offset 27 not found in protein '
+                 r'nucleotide ranges \(10, 20\)\.$')
+        assertRaisesRegex(self, ValueError, error, ranges.startInGenome,
+                          {'sstart': 10})
 
     def testStartOutsideGenomeRangeTwoRanges(self):
         """
         If the start location in the DIAMOND match is greater than the length
         of the genome when two ranges are given, a ValueError must be raised.
         """
         # The starting offset in the genome is 27 because DIAMOND returns
         # 1-based offsets into the protein subject. So in Python terms the
         # start offset is amino acid 9, or nucleotide 27.
-        ranges = GenomeRanges("join{[5:10](+), [12:18](+)}")
-        error = (
-            r"^Starting nucleotide offset 27 not found in protein "
-            r"nucleotide ranges \(5, 10\), \(12, 18\)\.$"
-        )
-        assertRaisesRegex(self, ValueError, error, ranges.startInGenome, {"sstart": 10})
+        ranges = GenomeRanges('join{[5:10](+), [12:18](+)}')
+        error = (r'^Starting nucleotide offset 27 not found in protein '
+                 r'nucleotide ranges \(5, 10\), \(12, 18\)\.$')
+        assertRaisesRegex(self, ValueError, error, ranges.startInGenome,
+                          {'sstart': 10})
 
     def testMatchAtStartOfFirstRange(self):
         """
         If the start location in the DIAMOND match is at the very beginning of
         the first range, the correct offset must be returned.
         """
         # The offset is 5 because the match starts 0 nucleotides into the
         # protein (0 = (1 - 1 ) * 3) and the protein starts at position 5 in
         # the genome. So the match begins at nucleotide 0 + 5 = 5.
-        ranges = GenomeRanges("[5:35](+)")
-        self.assertEqual(5, ranges.startInGenome({"sstart": 1}))
+        ranges = GenomeRanges('[5:35](+)')
+        self.assertEqual(5, ranges.startInGenome({'sstart': 1}))
 
     def testMatchAtEndOfFirstRange(self):
         """
         If the start location in the DIAMOND match is at the very end of
         the first range, the correct offset must be returned.
         """
         # The offset is 20 because the match starts 15 nucleotides into the
         # protein (15 = (6 - 1 ) * 3) and the protein starts at position 5 in
         # the genome. So the match begins at nucleotide 15 + 5 = 20.
-        ranges = GenomeRanges("[5:21](+)")
-        self.assertEqual(20, ranges.startInGenome({"sstart": 6}))
+        ranges = GenomeRanges('[5:21](+)')
+        self.assertEqual(20, ranges.startInGenome({'sstart': 6}))
 
     def testInFirstRange(self):
         """
         If the start location in the DIAMOND match is in the first range,
         the correct offset must be returned.
         """
         # The offset is 32 because the match starts 27 nucleotides into the
         # protein (27 = (10 - 1 ) * 3) and the protein starts at position 5 in
         # the genome. So the match begins at nucleotide 27 + 5 = 32.
-        ranges = GenomeRanges("[5:35](+)")
-        self.assertEqual(32, ranges.startInGenome({"sstart": 10}))
+        ranges = GenomeRanges('[5:35](+)')
+        self.assertEqual(32, ranges.startInGenome({'sstart': 10}))
 
     def testMatchAtStartOfSecondRange(self):
         """
         If the start location in the DIAMOND match is at the very beginning
         of the second range, the correct offset must be returned.
         """
         # The offset is 50 because the match starts 30 nucleotides into the
         # protein (45 = (16 - 1 ) * 3) and the protein has a range of 30
         # nucleotides (35 - 5 = 30) and then a range of 35 nucleotides (85 -
         # 50 = 35). So the match begins 15 (45 - 30 = 15) nucleotides into
         # the second range (which starts at 50), and 15 + 50 = 65.
-        ranges = GenomeRanges("join{[5:35](+), [50:85](+)}")
-        self.assertEqual(50, ranges.startInGenome({"sstart": 11}))
+        ranges = GenomeRanges('join{[5:35](+), [50:85](+)}')
+        self.assertEqual(50, ranges.startInGenome({'sstart': 11}))
 
     def testInSecondRange(self):
         """
         If the start location in the DIAMOND match is in the second range,
         the correct offset must be returned.
         """
         # The offset is 65 because the match starts 45 nucleotides into the
         # protein (45 = (16 - 1 ) * 3) and the protein has a range of 30
         # nucleotides (35 - 5 = 30) and then a range of 35 nucleotides (85 -
         # 50 = 35). So the match begins 15 (45 - 30 = 15) nucleotides into
         # the second range (which starts at 50), and 15 + 50 = 65.
-        ranges = GenomeRanges("join{[5:35](+), [50:85](+)}")
-        self.assertEqual(65, ranges.startInGenome({"sstart": 16}))
+        ranges = GenomeRanges('join{[5:35](+), [50:85](+)}')
+        self.assertEqual(65, ranges.startInGenome({'sstart': 16}))
 
     def testInThirdRange(self):
         """
         If the start location in the DIAMOND match is in the third range,
         the correct offset must be returned.
         """
         # The offset is 2900 because the match starts 1200 nucleotides into
         # the protein (1200 = (401 - 1 ) * 3) and the protein has a range of
         # 100 nucleotides (100 - 0 = 100), then a range of 200 nucleotides
         # (600 - 400 = 200), then a range of 1000 nucleotides. So the match
         # begins 900 (1200 - 300 = 900) nucleotides into the third range
         # (which starts at 2000), and 2000 + 900 = 2900.
-        ranges = GenomeRanges("join{[0:100](+), [400:600](+), [2000:3000](+)}")
-        self.assertEqual(2900, ranges.startInGenome({"sstart": 401}))
+        ranges = GenomeRanges('join{[0:100](+), [400:600](+), [2000:3000](+)}')
+        self.assertEqual(2900, ranges.startInGenome({'sstart': 401}))
 
 
 class TestOrientations(TestCase):
     """
     Test the GenomeRanges class orientations method.
     """
-
     def testAllComplement(self):
         """
         If all ranges are on the complement strand, the orientations method
         must return just True.
         """
-        ranges = GenomeRanges("join{[0:100](-), [400:600](-)}")
+        ranges = GenomeRanges('join{[0:100](-), [400:600](-)}')
         self.assertEqual({False}, ranges.orientations())
 
     def testNoComplement(self):
         """
         If no ranges are on the complement strand, the orientations method
         must return just False.
         """
-        ranges = GenomeRanges("join{[0:100](+), [400:600](+)}")
+        ranges = GenomeRanges('join{[0:100](+), [400:600](+)}')
         self.assertEqual({True}, ranges.orientations())
 
     def testMixed(self):
         """
         If the ranges are on the both the regular and the complement strand,
         the orientations method must return the set {True, False}.
         """
-        ranges = GenomeRanges("join{[0:100](+), [400:600](-)}")
+        ranges = GenomeRanges('join{[0:100](+), [400:600](-)}')
         self.assertEqual({True, False}, ranges.orientations())
 
 
 class TestDistinctRangeCount(TestCase):
     """
     Test the GenomeRanges class distinctRangeCount method.
     """
-
     def testOneRange(self):
         """
         If there is only one range, 1 must be returned.
         """
-        ranges = GenomeRanges("[0:100](+)")
+        ranges = GenomeRanges('[0:100](+)')
         self.assertEqual(1, ranges.distinctRangeCount(100))
 
     def testTwoRange(self):
         """
         If there are 2 ranges, 2 must be returned.
         """
-        ranges = GenomeRanges("join{[0:100](+), [400:600](+)}")
+        ranges = GenomeRanges('join{[0:100](+), [400:600](+)}')
         self.assertEqual(2, ranges.distinctRangeCount(100))
 
     def testThreeRange(self):
         """
         If there are 3 ranges, 3 must be returned.
         """
-        ranges = GenomeRanges("join{[0:100](+), [400:600](+), [2000:3000](+)}")
+        ranges = GenomeRanges('join{[0:100](+), [400:600](+), [2000:3000](+)}')
         self.assertEqual(3, ranges.distinctRangeCount(100))
 
     def testThreeRangesCircular(self):
         """
         If there are 3 ranges but the genome is circular, 2 must be returned.
         """
-        ranges = GenomeRanges("join{[0:100](+), [400:600](+), [2000:3000](+)}")
+        ranges = GenomeRanges('join{[0:100](+), [400:600](+), [2000:3000](+)}')
         self.assertEqual(2, ranges.distinctRangeCount(3000))
```

### Comparing `dark-matter-4.0.84/test/test_genomes.py` & `dark-matter-4.0.9/test/test_genomes.py`

 * *Files 10% similar despite different names*

```diff
@@ -3,207 +3,204 @@
 
 import dark
 from dark.genomes import GenomeProteinInfo
 from dark.civ.proteins import SqliteIndex
 
 TOP = dirname(dirname(dark.__file__))
 
-DB = SqliteIndex(join(TOP, "test", "data", "hbv", "hbv-proteins.db"))
+DB = SqliteIndex(join(TOP, 'test', 'data', 'hbv', 'hbv-proteins.db'))
 
-BAM1 = join(TOP, "test", "data", "hbv", "query1.bam")
-BAM2 = join(TOP, "test", "data", "hbv", "query2.bam")
-BAM3 = join(TOP, "test", "data", "hbv", "query3.bam")
+BAM1 = join(TOP, 'test', 'data', 'hbv', 'query1.bam')
+BAM2 = join(TOP, 'test', 'data', 'hbv', 'query2.bam')
+BAM3 = join(TOP, 'test', 'data', 'hbv', 'query3.bam')
 
 
 class TestGenomeProteinInfo(TestCase):
     """
     Test the GenomeProteinInfo class.
     """
 
     def testLoadReference(self):
         """
         Test that everything is as expected after loading the genome file.
         """
-        gpi = GenomeProteinInfo("KJ586809.1", DB, True)
-        self.assertEqual(gpi.genome["proteinCount"], len(gpi.proteins))
-        nonProteinOffsets = set(range(gpi.genome["length"])) - set(gpi.offsets)
+        gpi = GenomeProteinInfo('KJ586809.1', DB, True)
+        self.assertEqual(gpi.genome['proteinCount'], len(gpi.proteins))
+        nonProteinOffsets = (
+            set(range(gpi.genome['length'])) - set(gpi.offsets))
         self.assertEqual(set(), nonProteinOffsets)
-        self.assertEqual("KJ586809.1", gpi.genome["accession"])
-        self.assertEqual(
-            "Hepatitis B virus strain P18, complete genome", gpi.genome["name"]
-        )
+        self.assertEqual('KJ586809.1', gpi.genome['accession'])
+        self.assertEqual('Hepatitis B virus strain P18, complete genome',
+                         gpi.genome['name'])
 
     def testLoadBAM1(self):
         """
         Test that everything is as expected after loading the BAM1 file.
         """
-        gpi = GenomeProteinInfo("KJ586809.1", DB, True)
+        gpi = GenomeProteinInfo('KJ586809.1', DB, True)
         gpi.addSAM(BAM1)
 
         # Genome covered offsets.
         self.assertEqual(200, len(gpi.coveredOffsetCount))
         self.assertEqual(list(range(200)), list(gpi.coveredOffsetCount))
         self.assertEqual([1] * 200, list(gpi.coveredOffsetCount.values()))
 
         # SAM files.
         self.assertEqual([BAM1], gpi.samFiles)
-        self.assertEqual({"query1"}, gpi.readIdsMatchingGenome)
+        self.assertEqual({'query1'}, gpi.readIdsMatchingGenome)
 
         # Protein accession numbers.
-        expected = set(["AJF208%02d.1" % i for i in range(4, 11)])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 11)])
         self.assertEqual(expected, set(gpi.proteins))
 
         # Offset 200 is in 4 proteins but is not matched by the query.
-        self.assertEqual(set(), gpi.offsets[200]["readIds"])
-        expected = set(["AJF208%02d.1" % i for i in range(4, 8)])
-        self.assertEqual(expected, gpi.offsets[200]["proteinAccessions"])
+        self.assertEqual(set(), gpi.offsets[200]['readIds'])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 8)])
+        self.assertEqual(expected, gpi.offsets[200]['proteinAccessions'])
 
         # Offset 0 is in 3 proteins and is matched by the query.
-        self.assertEqual({"query1"}, gpi.offsets[0]["readIds"])
-        expected = set(["AJF208%02d.1" % i for i in range(4, 7)])
-        self.assertEqual(expected, gpi.offsets[0]["proteinAccessions"])
+        self.assertEqual({'query1'}, gpi.offsets[0]['readIds'])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 7)])
+        self.assertEqual(expected, gpi.offsets[0]['proteinAccessions'])
 
         # Read ids for all proteins.
-        self.assertEqual({"query1"}, gpi.readIdsForAllProteins())
+        self.assertEqual({'query1'}, gpi.readIdsForAllProteins())
 
         # AJF20804.1 coverage (its ranges are 2306-3221 and 0-1623)
-        info = gpi.proteinCoverageInfo("AJF20804.1")
-        self.assertEqual(200, info["coveredOffsets"])
-        self.assertEqual(200, info["totalBases"])
-        self.assertEqual((3221 - 2306) + (1623 - 0), info["ntLength"])
-        self.assertEqual({"query1"}, info["readIds"])
+        info = gpi.proteinCoverageInfo('AJF20804.1')
+        self.assertEqual(200, info['coveredOffsets'])
+        self.assertEqual(200, info['totalBases'])
+        self.assertEqual((3221 - 2306) + (1623 - 0), info['ntLength'])
+        self.assertEqual({'query1'}, info['readIds'])
 
     def testLoadBAM12(self):
         """
         Test that everything is as expected after loading the BAM1 and BAM2
         files.
         """
-        gpi = GenomeProteinInfo("KJ586809.1", DB, True)
+        gpi = GenomeProteinInfo('KJ586809.1', DB, True)
         gpi.addSAM(BAM1)
         gpi.addSAM(BAM2)
 
         # Genome covered offsets.
         self.assertEqual(300, len(gpi.coveredOffsetCount))
-        self.assertEqual(
-            list(range(200)) + list(range(1400, 1500)), list(gpi.coveredOffsetCount)
-        )
+        self.assertEqual(list(range(200)) + list(range(1400, 1500)),
+                         list(gpi.coveredOffsetCount))
         self.assertEqual([1] * 300, list(gpi.coveredOffsetCount.values()))
 
         # SAM files.
         self.assertEqual([BAM1, BAM2], gpi.samFiles)
-        self.assertEqual({"query1", "query2"}, gpi.readIdsMatchingGenome)
+        self.assertEqual({'query1', 'query2'}, gpi.readIdsMatchingGenome)
 
         # Protein accession numbers.
-        expected = set(["AJF208%02d.1" % i for i in range(4, 11)])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 11)])
         self.assertEqual(expected, set(gpi.proteins))
 
         # Offset 200 is in 4 proteins but is not matched by any query.
-        self.assertEqual(set(), gpi.offsets[200]["readIds"])
-        expected = set(["AJF208%02d.1" % i for i in range(4, 8)])
-        self.assertEqual(expected, gpi.offsets[200]["proteinAccessions"])
+        self.assertEqual(set(), gpi.offsets[200]['readIds'])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 8)])
+        self.assertEqual(expected, gpi.offsets[200]['proteinAccessions'])
 
         # Offset 0 is in 3 proteins and is matched by query1.
-        self.assertEqual({"query1"}, gpi.offsets[0]["readIds"])
-        expected = set(["AJF208%02d.1" % i for i in range(4, 7)])
-        self.assertEqual(expected, gpi.offsets[0]["proteinAccessions"])
+        self.assertEqual({'query1'}, gpi.offsets[0]['readIds'])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 7)])
+        self.assertEqual(expected, gpi.offsets[0]['proteinAccessions'])
 
         # Offset 1400 is in 2 proteins and is matched by query2.
-        self.assertEqual({"query2"}, gpi.offsets[1400]["readIds"])
-        self.assertEqual(
-            {"AJF20804.1", "AJF20808.1"}, gpi.offsets[1400]["proteinAccessions"]
-        )
+        self.assertEqual({'query2'}, gpi.offsets[1400]['readIds'])
+        self.assertEqual({'AJF20804.1', 'AJF20808.1'},
+                         gpi.offsets[1400]['proteinAccessions'])
 
         # Read ids for all proteins.
-        self.assertEqual({"query1", "query2"}, gpi.readIdsForAllProteins())
+        self.assertEqual({'query1', 'query2'}, gpi.readIdsForAllProteins())
 
         # AJF20804.1 coverage (its ranges are 2306-3221 and 0-1623)
-        info = gpi.proteinCoverageInfo("AJF20804.1")
-        self.assertEqual(300, info["coveredOffsets"])
-        self.assertEqual(300, info["totalBases"])
-        self.assertEqual((3221 - 2306) + (1623 - 0), info["ntLength"])
-        self.assertEqual({"query1", "query2"}, info["readIds"])
+        info = gpi.proteinCoverageInfo('AJF20804.1')
+        self.assertEqual(300, info['coveredOffsets'])
+        self.assertEqual(300, info['totalBases'])
+        self.assertEqual((3221 - 2306) + (1623 - 0), info['ntLength'])
+        self.assertEqual({'query1', 'query2'}, info['readIds'])
 
     def testLoadBAM123(self):
         """
         Test that everything is as expected after loading the BAM1, BAM2,
         and BAM3 files.
         """
-        gpi = GenomeProteinInfo("KJ586809.1", DB, True)
+        gpi = GenomeProteinInfo('KJ586809.1', DB, True)
         gpi.addSAM(BAM1)
         gpi.addSAM(BAM2)
         gpi.addSAM(BAM3)
 
         # Genome covered offsets.
         # There are 50 offsets that are covered twice.
         self.assertEqual(750 - 50, len(gpi.coveredOffsetCount))
-        self.assertEqual(
-            set(range(200)) | set(range(1000, 1500)), set(gpi.coveredOffsetCount)
-        )
-        self.assertEqual(
-            set([1] * 700 + [2] * 50), set(gpi.coveredOffsetCount.values())
-        )
+        self.assertEqual(set(range(200)) | set(range(1000, 1500)),
+                         set(gpi.coveredOffsetCount))
+        self.assertEqual(set([1] * 700 + [2] * 50),
+                         set(gpi.coveredOffsetCount.values()))
 
         # SAM files.
         self.assertEqual([BAM1, BAM2, BAM3], gpi.samFiles)
-        self.assertEqual({"query1", "query2", "query3"}, gpi.readIdsMatchingGenome)
+        self.assertEqual({'query1', 'query2', 'query3'},
+                         gpi.readIdsMatchingGenome)
 
         # Protein accession numbers.
-        expected = set(["AJF208%02d.1" % i for i in range(4, 11)])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 11)])
         self.assertEqual(expected, set(gpi.proteins))
 
         # Offset 200 is in 4 proteins but is not matched by any query.
-        self.assertEqual(set(), gpi.offsets[200]["readIds"])
-        expected = set(["AJF208%02d.1" % i for i in range(4, 8)])
-        self.assertEqual(expected, gpi.offsets[200]["proteinAccessions"])
+        self.assertEqual(set(), gpi.offsets[200]['readIds'])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 8)])
+        self.assertEqual(expected, gpi.offsets[200]['proteinAccessions'])
 
         # Offset 0 is in 3 proteins and is matched by query1.
-        self.assertEqual({"query1"}, gpi.offsets[0]["readIds"])
-        expected = set(["AJF208%02d.1" % i for i in range(4, 7)])
-        self.assertEqual(expected, gpi.offsets[0]["proteinAccessions"])
+        self.assertEqual({'query1'}, gpi.offsets[0]['readIds'])
+        expected = set(['AJF208%02d.1' % i for i in range(4, 7)])
+        self.assertEqual(expected, gpi.offsets[0]['proteinAccessions'])
 
         # Offset 1400 is in 2 proteins and is matched by query2 and query3.
-        self.assertEqual({"query2", "query3"}, gpi.offsets[1400]["readIds"])
-        self.assertEqual(
-            {"AJF20804.1", "AJF20808.1"}, gpi.offsets[1400]["proteinAccessions"]
-        )
+        self.assertEqual({'query2', 'query3'}, gpi.offsets[1400]['readIds'])
+        self.assertEqual({'AJF20804.1', 'AJF20808.1'},
+                         gpi.offsets[1400]['proteinAccessions'])
 
         # Read ids for all proteins.
-        self.assertEqual({"query1", "query2", "query3"}, gpi.readIdsForAllProteins())
+        self.assertEqual({'query1', 'query2', 'query3'},
+                         gpi.readIdsForAllProteins())
 
         # AJF20804.1 coverage (its ranges are 2306-3221 and 0-1623)
-        info = gpi.proteinCoverageInfo("AJF20804.1")
-        self.assertEqual(700, info["coveredOffsets"])
-        self.assertEqual(750, info["totalBases"])
-        self.assertEqual((3221 - 2306) + (1623 - 0), info["ntLength"])
-        self.assertEqual({"query1", "query2", "query3"}, info["readIds"])
+        info = gpi.proteinCoverageInfo('AJF20804.1')
+        self.assertEqual(700, info['coveredOffsets'])
+        self.assertEqual(750, info['totalBases'])
+        self.assertEqual((3221 - 2306) + (1623 - 0), info['ntLength'])
+        self.assertEqual({'query1', 'query2', 'query3'}, info['readIds'])
 
     def testTooFewReadOffsetsBAM1(self):
         """
         Test that a read is not returned as overlapping a protein unless it
         meets the minimum number of required overlapping offsets.
         """
-        gpi = GenomeProteinInfo("KJ586809.1", DB, True)
+        gpi = GenomeProteinInfo('KJ586809.1', DB, True)
         gpi.addSAM(BAM1)
 
         # Look at protein AJF20804.1 coverage (its ranges are 2306-3221 and
         # 0-1623). There should be no matching reads because the query
         # (query1) is only 200 nt long and so cannot match with at least
         # 500 nucleotides. The number of covered offsets and total bases
         # should both also be zero for the same reason.
-        info = gpi.proteinCoverageInfo("AJF20804.1", 500)
-        self.assertEqual(set(), info["readIds"])
-        self.assertEqual(0, info["totalBases"])
-        self.assertEqual(0, info["coveredOffsets"])
+        info = gpi.proteinCoverageInfo('AJF20804.1', 500)
+        self.assertEqual(set(), info['readIds'])
+        self.assertEqual(0, info['totalBases'])
+        self.assertEqual(0, info['coveredOffsets'])
 
     def testSufficientReadOffsetsBAM1(self):
         """
         Test that a read is returned as overlapping a protein when it meets
         the minimum number of required overlapping offsets.
         """
-        gpi = GenomeProteinInfo("KJ586809.1", DB, True)
+        gpi = GenomeProteinInfo('KJ586809.1', DB, True)
         gpi.addSAM(BAM1)
 
         # Look at protein AJF20804.1 coverage (its ranges are 2306-3221 and
         # 0-1623). The query (query1) must be returned as it has 200
         # matching nucleotides.
-        info = gpi.proteinCoverageInfo("AJF20804.1", 199)
-        self.assertEqual({"query1"}, info["readIds"])
+        info = gpi.proteinCoverageInfo('AJF20804.1', 199)
+        self.assertEqual({'query1'}, info['readIds'])
```

### Comparing `dark-matter-4.0.84/test/test_graphics.py` & `dark-matter-4.0.9/test/test_graphics.py`

 * *Files 19% similar despite different names*

```diff
@@ -4,42 +4,40 @@
 from dark.reads import AARead
 
 
 class TestPlotAAProperties(TestCase):
     """
     Tests for the plotAAProperties function in graphics.py
     """
-
     # Note that plotAAProperties relies on dark.aa.propertiesForSequence
     # which is tested thoroughly in test_aa.py
 
     def testNoProperties(self):
         """
         plotAAProperties must run correctly when called with no properties.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual({}, plotAAProperties(read, [], showFigure=False))
 
     def testOneProperty(self):
         """
         plotAAProperties must run correctly when called with one property.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "composition": [-1.0, -1.0],
+                'composition': [-1.0, -1.0],
             },
-            plotAAProperties(read, ["composition"], showFigure=False),
-        )
+            plotAAProperties(read, ['composition'], showFigure=False))
 
     def testTwoProperties(self):
         """
         plotAAProperties must run correctly when called with two properties.
         """
-        read = AARead("id", "AI")
+        read = AARead('id', 'AI')
         self.assertEqual(
             {
-                "composition": [-1.0, -1.0],
-                "hydropathy": [0.4, 1.0],
+                'composition': [-1.0, -1.0],
+                'hydropathy': [0.4, 1.0],
             },
-            plotAAProperties(read, ["composition", "hydropathy"], showFigure=False),
-        )
+            plotAAProperties(read, ['composition', 'hydropathy'],
+                             showFigure=False))
```

### Comparing `dark-matter-4.0.84/test/test_hsp.py` & `dark-matter-4.0.9/test/test_hsp.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,35 +8,27 @@
     Tests of the L{dark.hsp.HSP} class.
     """
 
     def testExpectedAttributes(self):
         """
         An HSP must have the expected attributes.
         """
-        hsp = HSP(
-            7,
-            readStart=1,
-            readEnd=2,
-            readStartInSubject=3,
-            readEndInSubject=4,
-            subjectStart=5,
-            subjectEnd=6,
-            readMatchedSequence="aaa",
-            subjectMatchedSequence="ccc",
-            readFrame=8,
-            subjectFrame=9,
-        )
+        hsp = HSP(7, readStart=1, readEnd=2,
+                  readStartInSubject=3, readEndInSubject=4,
+                  subjectStart=5, subjectEnd=6,
+                  readMatchedSequence='aaa', subjectMatchedSequence='ccc',
+                  readFrame=8, subjectFrame=9)
         self.assertEqual(1, hsp.readStart)
         self.assertEqual(2, hsp.readEnd)
         self.assertEqual(3, hsp.readStartInSubject)
         self.assertEqual(4, hsp.readEndInSubject)
         self.assertEqual(5, hsp.subjectStart)
         self.assertEqual(6, hsp.subjectEnd)
-        self.assertEqual("aaa", hsp.readMatchedSequence)
-        self.assertEqual("ccc", hsp.subjectMatchedSequence)
+        self.assertEqual('aaa', hsp.readMatchedSequence)
+        self.assertEqual('ccc', hsp.subjectMatchedSequence)
         self.assertEqual(7, hsp.score.score)
         self.assertEqual(8, hsp.readFrame)
         self.assertEqual(9, hsp.subjectFrame)
 
     def testEqual(self):
         """
         Two HSPs must compare properly with ==
@@ -63,84 +55,64 @@
         """
         self.assertFalse(HSP(5).betterThan(7))
 
     def testToDict(self):
         """
         The toDict method must return the expected dictionary.
         """
-        hsp = HSP(
-            0,
-            readStart=1,
-            readEnd=2,
-            readStartInSubject=3,
-            readEndInSubject=4,
-            subjectStart=5,
-            subjectEnd=6,
-            readMatchedSequence="aaa",
-            subjectMatchedSequence="ccc",
-            readFrame=7,
-            subjectFrame=8,
-            identicalCount=9,
-            percentIdentical=99.3,
-            positiveCount=10,
-            percentPositive=3.0,
-        )
+        hsp = HSP(0, readStart=1, readEnd=2,
+                  readStartInSubject=3, readEndInSubject=4,
+                  subjectStart=5, subjectEnd=6,
+                  readMatchedSequence='aaa', subjectMatchedSequence='ccc',
+                  readFrame=7, subjectFrame=8, identicalCount=9,
+                  percentIdentical=99.3, positiveCount=10, percentPositive=3.0)
 
         self.assertEqual(
             {
-                "score": 0,
-                "readStart": 1,
-                "readEnd": 2,
-                "readStartInSubject": 3,
-                "readEndInSubject": 4,
-                "subjectStart": 5,
-                "subjectEnd": 6,
-                "readFrame": 7,
-                "subjectFrame": 8,
-                "identicalCount": 9,
-                "percentIdentical": 99.3,
-                "positiveCount": 10,
-                "percentPositive": 3.0,
-                "readMatchedSequence": "aaa",
-                "subjectMatchedSequence": "ccc",
+                'score': 0,
+                'readStart': 1,
+                'readEnd': 2,
+                'readStartInSubject': 3,
+                'readEndInSubject': 4,
+                'subjectStart': 5,
+                'subjectEnd': 6,
+                'readFrame': 7,
+                'subjectFrame': 8,
+                'identicalCount': 9,
+                'percentIdentical': 99.3,
+                'positiveCount': 10,
+                'percentPositive': 3.0,
+                'readMatchedSequence': 'aaa',
+                'subjectMatchedSequence': 'ccc',
             },
-            hsp.toDict(),
-        )
+            hsp.toDict())
 
 
 class TestLSP(TestCase):
     """
     Tests of the L{dark.hsp.blast.LSP} class.
     """
 
     def testExpectedAttributes(self):
         """
         An LSP must have the expected attributes.
         """
-        lsp = LSP(
-            7,
-            readStart=1,
-            readEnd=2,
-            readStartInSubject=3,
-            readEndInSubject=4,
-            subjectStart=5,
-            subjectEnd=6,
-            readMatchedSequence="aaa",
-            subjectMatchedSequence="ccc",
-            readFrame=8,
-            subjectFrame=9,
-        )
+        lsp = LSP(7, readStart=1, readEnd=2,
+                  readStartInSubject=3, readEndInSubject=4,
+                  subjectStart=5, subjectEnd=6,
+                  readMatchedSequence='aaa', subjectMatchedSequence='ccc',
+                  readFrame=8, subjectFrame=9)
         self.assertEqual(1, lsp.readStart)
         self.assertEqual(2, lsp.readEnd)
         self.assertEqual(3, lsp.readStartInSubject)
         self.assertEqual(4, lsp.readEndInSubject)
         self.assertEqual(5, lsp.subjectStart)
         self.assertEqual(6, lsp.subjectEnd)
-        self.assertEqual("aaa", lsp.readMatchedSequence)
-        self.assertEqual("ccc", lsp.subjectMatchedSequence)
+        self.assertEqual('aaa', lsp.readMatchedSequence)
+        self.assertEqual('ccc', lsp.subjectMatchedSequence)
         self.assertEqual(7, lsp.score.score)
         self.assertEqual(8, lsp.readFrame)
         self.assertEqual(9, lsp.subjectFrame)
 
     def testEqual(self):
         """
         Two LSPs must compare properly with ==
@@ -167,45 +139,34 @@
         """
         self.assertFalse(LSP(7).betterThan(5))
 
     def testToDict(self):
         """
         The toDict method must return the expected dictionary.
         """
-        lsp = LSP(
-            0,
-            readStart=1,
-            readEnd=2,
-            readStartInSubject=3,
-            readEndInSubject=4,
-            subjectStart=5,
-            subjectEnd=6,
-            readMatchedSequence="aaa",
-            subjectMatchedSequence="ccc",
-            readFrame=7,
-            subjectFrame=8,
-            identicalCount=9,
-            percentIdentical=99.3,
-            positiveCount=10,
-            percentPositive=9.9,
-        )
+        lsp = LSP(0, readStart=1, readEnd=2,
+                  readStartInSubject=3, readEndInSubject=4,
+                  subjectStart=5, subjectEnd=6,
+                  readMatchedSequence='aaa', subjectMatchedSequence='ccc',
+                  readFrame=7, subjectFrame=8, identicalCount=9,
+                  percentIdentical=99.3, positiveCount=10,
+                  percentPositive=9.9)
 
         self.assertEqual(
             {
-                "score": 0,
-                "readStart": 1,
-                "readEnd": 2,
-                "readStartInSubject": 3,
-                "readEndInSubject": 4,
-                "subjectStart": 5,
-                "subjectEnd": 6,
-                "readFrame": 7,
-                "subjectFrame": 8,
-                "identicalCount": 9,
-                "percentIdentical": 99.3,
-                "positiveCount": 10,
-                "percentPositive": 9.9,
-                "readMatchedSequence": "aaa",
-                "subjectMatchedSequence": "ccc",
+                'score': 0,
+                'readStart': 1,
+                'readEnd': 2,
+                'readStartInSubject': 3,
+                'readEndInSubject': 4,
+                'subjectStart': 5,
+                'subjectEnd': 6,
+                'readFrame': 7,
+                'subjectFrame': 8,
+                'identicalCount': 9,
+                'percentIdentical': 99.3,
+                'positiveCount': 10,
+                'percentPositive': 9.9,
+                'readMatchedSequence': 'aaa',
+                'subjectMatchedSequence': 'ccc',
             },
-            lsp.toDict(),
-        )
+            lsp.toDict())
```

### Comparing `dark-matter-4.0.84/test/test_local_align.py` & `dark-matter-4.0.9/test/test_local_align.py`

 * *Files 18% similar despite different names*

```diff
@@ -7,340 +7,294 @@
 
 class TestLocalAlign(TestCase):
     """
     Test the LocalAlignment class.
     With match +1, mismatch -1, gap open -1, gap extend -1 and
         gap extend decay 0.0.
     """
-
     def testPositiveMismatch(self):
         """
         If the mismatch value passed is positive, an exception
         must be raised.
         """
-        seq1 = Read("seq1", "a")
-        seq2 = Read("seq2", "a")
-        six.assertRaisesRegex(
-            self,
-            ValueError,
-            "Mismatch must be negative",
-            LocalAlignment,
-            seq1,
-            seq2,
-            mismatch=3,
-        )
+        seq1 = Read('seq1', 'a')
+        seq2 = Read('seq2', 'a')
+        six.assertRaisesRegex(self, ValueError, 'Mismatch must be negative',
+                              LocalAlignment, seq1, seq2, mismatch=3)
 
     def testZeroMismatch(self):
         """
         If the mismatch value passed is zero, an exception
         must be raised.
         """
-        seq1 = Read("seq1", "a")
-        seq2 = Read("seq2", "a")
-        six.assertRaisesRegex(
-            self,
-            ValueError,
-            "Mismatch must be negative",
-            LocalAlignment,
-            seq1,
-            seq2,
-            mismatch=0,
-        )
+        seq1 = Read('seq1', 'a')
+        seq2 = Read('seq2', 'a')
+        six.assertRaisesRegex(self, ValueError, 'Mismatch must be negative',
+                              LocalAlignment, seq1, seq2, mismatch=0)
 
     def testPositiveGap(self):
         """
         If the gap value passed is positive, an exception
         must be raised.
         """
-        seq1 = Read("seq1", "a")
-        seq2 = Read("seq2", "a")
-        six.assertRaisesRegex(
-            self, ValueError, "Gap must be negative", LocalAlignment, seq1, seq2, gap=3
-        )
+        seq1 = Read('seq1', 'a')
+        seq2 = Read('seq2', 'a')
+        six.assertRaisesRegex(self, ValueError, 'Gap must be negative',
+                              LocalAlignment, seq1, seq2, gap=3)
 
     def testZeroGap(self):
         """
         If the gap value passed is zero, an exception
         must be raised.
         """
-        seq1 = Read("seq1", "a")
-        seq2 = Read("seq2", "a")
-        six.assertRaisesRegex(
-            self, ValueError, "Gap must be negative", LocalAlignment, seq1, seq2, gap=0
-        )
+        seq1 = Read('seq1', 'a')
+        seq2 = Read('seq2', 'a')
+        six.assertRaisesRegex(self, ValueError, 'Gap must be negative',
+                              LocalAlignment, seq1, seq2, gap=0)
 
     def testPositiveGapExtend(self):
         """
         If the gap extend value passed is positive, an exception
         must be raised.
         """
-        seq1 = Read("seq1", "a")
-        seq2 = Read("seq2", "a")
-        six.assertRaisesRegex(
-            self,
-            ValueError,
-            "Gap extension penalty cannot be positive",
-            LocalAlignment,
-            seq1,
-            seq2,
-            gapExtend=3,
-        )
+        seq1 = Read('seq1', 'a')
+        seq2 = Read('seq2', 'a')
+        six.assertRaisesRegex(self, ValueError,
+                              'Gap extension penalty cannot be positive',
+                              LocalAlignment, seq1, seq2, gapExtend=3)
 
     def testFirstSequenceEmpty(self):
         """
         If the first sequence passed is empty, an exception must be raised.
         """
-        seq1 = Read("seq1", "")
-        seq2 = Read("seq2", "agtcagtcagtc")
-        six.assertRaisesRegex(
-            self, ValueError, "Empty sequence: seq1", LocalAlignment, seq1, seq2
-        )
+        seq1 = Read('seq1', '')
+        seq2 = Read('seq2', 'agtcagtcagtc')
+        six.assertRaisesRegex(self, ValueError, 'Empty sequence: seq1',
+                              LocalAlignment, seq1, seq2)
 
     def testSecondSequenceEmpty(self):
         """
         If the second sequence passed is empty, an exception must be raised.
         """
-        seq1 = Read("seq1", "agtcagtcagtc")
-        seq2 = Read("seq2", "")
-        six.assertRaisesRegex(
-            self, ValueError, "Empty sequence: seq2", LocalAlignment, seq1, seq2
-        )
+        seq1 = Read('seq1', 'agtcagtcagtc')
+        seq2 = Read('seq2', '')
+        six.assertRaisesRegex(self, ValueError, 'Empty sequence: seq2',
+                              LocalAlignment, seq1, seq2)
 
     def testBothSequencesEmpty(self):
         """
         If two empty sequences are passed, an exception must be raised.
         """
-        seq1 = Read("seq1", "")
-        seq2 = Read("seq2", "")
-        six.assertRaisesRegex(
-            self, ValueError, "Empty sequence: seq1", LocalAlignment, seq1, seq2
-        )
+        seq1 = Read('seq1', '')
+        seq2 = Read('seq2', '')
+        six.assertRaisesRegex(self, ValueError, 'Empty sequence: seq1',
+                              LocalAlignment, seq1, seq2)
 
     def testGapAtStartOfSeq1(self):
-        seq1 = Read("seq1", "gaatcg")
-        seq2 = Read("seq2", "cgaatcg")
+        seq1 = Read('seq1', 'gaatcg')
+        seq2 = Read('seq2', 'cgaatcg')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 6=\n"
-            "seq1 Match start: 1 Match end: 6\n"
-            "seq2 Match start: 2 Match end: 7\n"
-            "seq1 1 GAATCG 6\n"
-            "       ||||||\n"
-            "seq2 2 GAATCG 7"
-        )
+        alignment = ('\nCigar string of aligned region: 6=\n'
+                     'seq1 Match start: 1 Match end: 6\n'
+                     'seq2 Match start: 2 Match end: 7\n'
+                     'seq1 1 GAATCG 6\n'
+                     '       ||||||\n'
+                     'seq2 2 GAATCG 7')
         self.assertEqual(result, alignment)
 
     def testGapAtStartOfSeq2(self):
-        seq1 = Read("seq1", "cgaatcg")
-        seq2 = Read("seq2", "gaatcg")
+        seq1 = Read('seq1', 'cgaatcg')
+        seq2 = Read('seq2', 'gaatcg')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 6=\n"
-            "seq1 Match start: 2 Match end: 7\n"
-            "seq2 Match start: 1 Match end: 6\n"
-            "seq1 2 GAATCG 7\n"
-            "       ||||||\n"
-            "seq2 1 GAATCG 6"
-        )
+        alignment = ('\nCigar string of aligned region: 6=\n'
+                     'seq1 Match start: 2 Match end: 7\n'
+                     'seq2 Match start: 1 Match end: 6\n'
+                     'seq1 2 GAATCG 7\n'
+                     '       ||||||\n'
+                     'seq2 1 GAATCG 6')
         self.assertEqual(result, alignment)
 
     def testGapAtEndOfSeq1(self):
-        seq1 = Read("seq1", "cgaatc")
-        seq2 = Read("seq2", "cgaatcg")
+        seq1 = Read('seq1', 'cgaatc')
+        seq2 = Read('seq2', 'cgaatcg')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 6=\n"
-            "seq1 Match start: 1 Match end: 6\n"
-            "seq2 Match start: 1 Match end: 6\n"
-            "seq1 1 CGAATC 6\n"
-            "       ||||||\n"
-            "seq2 1 CGAATC 6"
-        )
+        alignment = ('\nCigar string of aligned region: 6=\n'
+                     'seq1 Match start: 1 Match end: 6\n'
+                     'seq2 Match start: 1 Match end: 6\n'
+                     'seq1 1 CGAATC 6\n'
+                     '       ||||||\n'
+                     'seq2 1 CGAATC 6')
         self.assertEqual(result, alignment)
 
     def testGapAtEndOfSeq2(self):
-        seq1 = Read("seq1", "cgaatcg")
-        seq2 = Read("seq2", "cgaatc")
+        seq1 = Read('seq1', 'cgaatcg')
+        seq2 = Read('seq2', 'cgaatc')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 6=\n"
-            "seq1 Match start: 1 Match end: 6\n"
-            "seq2 Match start: 1 Match end: 6\n"
-            "seq1 1 CGAATC 6\n"
-            "       ||||||\n"
-            "seq2 1 CGAATC 6"
-        )
+        alignment = ('\nCigar string of aligned region: 6=\n'
+                     'seq1 Match start: 1 Match end: 6\n'
+                     'seq2 Match start: 1 Match end: 6\n'
+                     'seq1 1 CGAATC 6\n'
+                     '       ||||||\n'
+                     'seq2 1 CGAATC 6')
         self.assertEqual(result, alignment)
 
     def testGapAtBothEndsOfSeq1(self):
-        seq1 = Read("seq1", "gaatc")
-        seq2 = Read("seq2", "cgaatcg")
+        seq1 = Read('seq1', 'gaatc')
+        seq2 = Read('seq2', 'cgaatcg')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 5=\n"
-            "seq1 Match start: 1 Match end: 5\n"
-            "seq2 Match start: 2 Match end: 6\n"
-            "seq1 1 GAATC 5\n"
-            "       |||||\n"
-            "seq2 2 GAATC 6"
-        )
+        alignment = ('\nCigar string of aligned region: 5=\n'
+                     'seq1 Match start: 1 Match end: 5\n'
+                     'seq2 Match start: 2 Match end: 6\n'
+                     'seq1 1 GAATC 5\n'
+                     '       |||||\n'
+                     'seq2 2 GAATC 6')
         self.assertEqual(result, alignment)
 
     def testGapAtBothEndsOfSeq2(self):
-        seq1 = Read("seq1", "cgaatcg")
-        seq2 = Read("seq2", "gaatc")
+        seq1 = Read('seq1', 'cgaatcg')
+        seq2 = Read('seq2', 'gaatc')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 5=\n"
-            "seq1 Match start: 2 Match end: 6\n"
-            "seq2 Match start: 1 Match end: 5\n"
-            "seq1 2 GAATC 6\n"
-            "       |||||\n"
-            "seq2 1 GAATC 5"
-        )
+        alignment = ('\nCigar string of aligned region: 5=\n'
+                     'seq1 Match start: 2 Match end: 6\n'
+                     'seq2 Match start: 1 Match end: 5\n'
+                     'seq1 2 GAATC 6\n'
+                     '       |||||\n'
+                     'seq2 1 GAATC 5')
         self.assertEqual(result, alignment)
 
     def testAlignmentWithGapInMiddle(self):
-        seq1 = Read("seq1", "agtcagtcagtc")
-        seq2 = Read("seq2", "cgaatcg")
+        seq1 = Read('seq1', 'agtcagtcagtc')
+        seq2 = Read('seq2', 'cgaatcg')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 2=1D1=\n"
-            "seq1 Match start: 7 Match end: 10\n"
-            "seq2 Match start: 5 Match end: 7\n"
-            "seq1 7 TCAG 10\n"
-            "       || |\n"
-            "seq2 5 TC-G 7"
-        )
+        alignment = ('\nCigar string of aligned region: 2=1D1=\n'
+                     'seq1 Match start: 7 Match end: 10\n'
+                     'seq2 Match start: 5 Match end: 7\n'
+                     'seq1 7 TCAG 10\n'
+                     '       || |\n'
+                     'seq2 5 TC-G 7')
         self.assertEqual(result, alignment)
 
     def testTwoEqualSequences(self):
         """
         When two identical sequences are given, the result should
         show that the sequences completely match.
         """
-        seq1 = Read("seq1", "cgaatcg")
-        seq2 = Read("seq2", "cgaatcg")
+        seq1 = Read('seq1', 'cgaatcg')
+        seq2 = Read('seq2', 'cgaatcg')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 7=\n"
-            "seq1 Match start: 1 Match end: 7\n"
-            "seq2 Match start: 1 Match end: 7\n"
-            "seq1 1 CGAATCG 7\n"
-            "       |||||||\n"
-            "seq2 1 CGAATCG 7"
-        )
+        alignment = ('\nCigar string of aligned region: 7=\n'
+                     'seq1 Match start: 1 Match end: 7\n'
+                     'seq2 Match start: 1 Match end: 7\n'
+                     'seq1 1 CGAATCG 7\n'
+                     '       |||||||\n'
+                     'seq2 1 CGAATCG 7')
         self.assertEqual(result, alignment)
 
     def testTwoCompletelyDifferentSequences(self):
         """
         When two completely different sequences are given, the result
         should be the two sequences with an empty alignment.
         """
-        seq1 = Read("seq1", "aaaaaa")
-        seq2 = Read("seq2", "gggggg")
+        seq1 = Read('seq1', 'aaaaaa')
+        seq2 = Read('seq2', 'gggggg')
         align = LocalAlignment(seq1, seq2)
         result = align.createAlignment(resultFormat=str)
-        alignment = "\nNo alignment between seq1 and seq2\n"
+        alignment = ('\nNo alignment between seq1 and seq2\n')
         self.assertEqual(result, alignment)
 
     def testWikiAnswer(self):
         """
         Test the example given in Wikipedia:
         http://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm
         """
-        seq1 = Read("seq1", "ACACACTA")
-        seq2 = Read("seq2", "AGCACACA")
+        seq1 = Read('seq1', 'ACACACTA')
+        seq2 = Read('seq2', 'AGCACACA')
         align = LocalAlignment(seq1, seq2, match=2)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 1=1I5=1D1=\n"
-            "seq1 Match start: 1 Match end: 8\n"
-            "seq2 Match start: 1 Match end: 8\n"
-            "seq1 1 A-CACACTA 8\n"
-            "       | ||||| |\n"
-            "seq2 1 AGCACAC-A 8"
-        )
+        alignment = ('\nCigar string of aligned region: 1=1I5=1D1=\n'
+                     'seq1 Match start: 1 Match end: 8\n'
+                     'seq2 Match start: 1 Match end: 8\n'
+                     'seq1 1 A-CACACTA 8\n'
+                     '       | ||||| |\n'
+                     'seq2 1 AGCACAC-A 8')
         self.assertEqual(result, alignment)
 
     def testWikiAnswerWithMatchOne(self):
         """
         Test the example given in Wikipedia
         http://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm
         Wikipedia uses a match score of two, here we use a score of one.
         """
-        seq1 = Read("seq1", "ACACACTA")
-        seq2 = Read("seq2", "AGCACACA")
+        seq1 = Read('seq1', 'ACACACTA')
+        seq2 = Read('seq2', 'AGCACACA')
         align = LocalAlignment(seq1, seq2, match=1)
         result = align.createAlignment(resultFormat=str)
-        alignment = (
-            "\nCigar string of aligned region: 5=1D1=\n"
-            "seq1 Match start: 2 Match end: 8\n"
-            "seq2 Match start: 3 Match end: 8\n"
-            "seq1 2 CACACTA 8\n"
-            "       ||||| |\n"
-            "seq2 3 CACAC-A 8"
-        )
+        alignment = ('\nCigar string of aligned region: 5=1D1=\n'
+                     'seq1 Match start: 2 Match end: 8\n'
+                     'seq2 Match start: 3 Match end: 8\n'
+                     'seq1 2 CACACTA 8\n'
+                     '       ||||| |\n'
+                     'seq2 3 CACAC-A 8')
         self.assertEqual(result, alignment)
 
     def testWikiAnswerAsDict(self):
         """
         Test the example given in Wikipedia:
         http://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm
         with the return result being a dict.
         """
-        seq1 = Read("seq1", "ACACACTA")
-        seq2 = Read("seq2", "AGCACACA")
+        seq1 = Read('seq1', 'ACACACTA')
+        seq2 = Read('seq2', 'AGCACACA')
         align = LocalAlignment(seq1, seq2, match=2)
         result = align.createAlignment()
         self.assertEqual(
             {
-                "cigar": "1=1I5=1D1=",
-                "sequence1Start": 1,
-                "sequence1End": 8,
-                "sequence2Start": 1,
-                "sequence2End": 8,
-                "text": [
-                    "seq1 1 A-CACACTA 8",
-                    "       | ||||| |",
-                    "seq2 1 AGCACAC-A 8",
-                ],
+                'cigar': '1=1I5=1D1=',
+                'sequence1Start': 1,
+                'sequence1End': 8,
+                'sequence2Start': 1,
+                'sequence2End': 8,
+                'text': [
+                    'seq1 1 A-CACACTA 8',
+                    '       | ||||| |',
+                    'seq2 1 AGCACAC-A 8',
+                ]
             },
-            result,
+            result
         )
 
     def testWikiAnswerWithMatchOneAsDict(self):
         """
         Test the example given in Wikipedia
         http://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm
         Wikipedia uses a match score of two, here we use a score of one.
         Get the result as a dict.
         """
-        seq1 = Read("seq1", "ACACACTA")
-        seq2 = Read("seq2", "AGCACACA")
+        seq1 = Read('seq1', 'ACACACTA')
+        seq2 = Read('seq2', 'AGCACACA')
         align = LocalAlignment(seq1, seq2, match=1)
         result = align.createAlignment()
         self.assertEqual(
             {
-                "cigar": "5=1D1=",
-                "sequence1Start": 2,
-                "sequence1End": 8,
-                "sequence2Start": 3,
-                "sequence2End": 8,
-                "text": [
-                    "seq1 2 CACACTA 8",
-                    "       ||||| |",
-                    "seq2 3 CACAC-A 8",
-                ],
+                'cigar': '5=1D1=',
+                'sequence1Start': 2,
+                'sequence1End': 8,
+                'sequence2Start': 3,
+                'sequence2End': 8,
+                'text': [
+                    'seq1 2 CACACTA 8',
+                    '       ||||| |',
+                    'seq2 3 CACAC-A 8',
+                ]
             },
-            result,
+            result
         )
```

### Comparing `dark-matter-4.0.84/test/test_mutations.py` & `dark-matter-4.0.9/test/test_mutations.py`

 * *Files 18% similar despite different names*

```diff
@@ -4,143 +4,126 @@
 from dark.mutations import getAPOBECFrequencies, mutateString
 
 
 class TestGetAPOBECFrequencies(TestCase):
     """
     Tests the getAPOBECFrequencies function
     """
-
     def testCorrectResult(self):
         """
         The function should return the right bases.
         s:  AGTCTAAAGTCATGACTGGTCCCCTTG
         q:      ..AA..T....G....G...
         """
         result = []
-        subjectTitle = "333031"
-        subjectSequence = "AGTCTAAAGTCATGACTGGTCCCCTTG"
-        subject = "%s \t \t \t %s" % (subjectTitle, subjectSequence)
+        subjectTitle = '333031'
+        subjectSequence = 'AGTCTAAAGTCATGACTGGTCCCCTTG'
+        subject = '%s \t \t \t %s' % (subjectTitle, subjectSequence)
         result.append(subject)
 
-        queryTitle = "H9L0NJQ01DXGOQ"
-        querySequence = "    ..AA..T....G....G...   "
-        query = "%s \t %s" % (queryTitle, querySequence)
+        queryTitle = 'H9L0NJQ01DXGOQ'
+        querySequence = '    ..AA..T....G....G...   '
+        query = '%s \t %s' % (queryTitle, querySequence)
         result.append(query)
 
-        bases = getAPOBECFrequencies(result, "C", "G", "cPattern")
+        bases = getAPOBECFrequencies(result, 'C', 'G', 'cPattern')
 
-        self.assertEqual(
-            {
-                "ACA": 0,
-                "ACC": 0,
-                "ACG": 0,
-                "ACT": 1,
-                "CCA": 0,
-                "CCC": 0,
-                "CCG": 0,
-                "CCT": 0,
-                "GCA": 0,
-                "GCC": 0,
-                "GCG": 0,
-                "GCT": 0,
-                "TCA": 0,
-                "TCC": 1,
-                "TCG": 0,
-                "TCT": 0,
-            },
-            bases,
-        )
+        self.assertEqual({'ACA': 0, 'ACC': 0, 'ACG': 0, 'ACT': 1, 'CCA': 0,
+                          'CCC': 0, 'CCG': 0, 'CCT': 0, 'GCA': 0, 'GCC': 0,
+                          'GCG': 0, 'GCT': 0, 'TCA': 0, 'TCC': 1, 'TCG': 0,
+                          'TCT': 0}, bases)
 
 
 class TestMutateString(TestCase):
     """
     Tests the mutateString function.
     """
 
     def testZeroLength(self):
         """
         The function should raise when given an empty string
         """
-        error = "Empty original string passed."
+        error = 'Empty original string passed.'
         with six.assertRaisesRegex(self, ValueError, error):
-            mutateString("", 1)
+            mutateString('', 1)
 
     def testTooManyMutationsRequested(self):
         """
         The function should raise when asked to perform more mutations than
         there are in the original string.
         """
-        error = "Cannot make 2 mutations in a string of length 1"
+        error = 'Cannot make 2 mutations in a string of length 1'
         with six.assertRaisesRegex(self, ValueError, error):
-            mutateString("x", 2)
+            mutateString('x', 2)
 
     def testDuplicateReplacementLetter(self):
         """
         The function should raise when given a replacement string that contains
         a duplicate letter.
         """
-        error = "Replacement string contains duplicates"
+        error = 'Replacement string contains duplicates'
         with six.assertRaisesRegex(self, ValueError, error):
-            mutateString("x", 1, "aa")
+            mutateString('x', 1, 'aa')
 
     def testReplacementLengthOneAppearsInOriginal(self):
         """
         The function should raise when given a replacement string that contains
         just one letter if that letter also appears in the original.
         """
-        error = "Impossible replacement"
+        error = 'Impossible replacement'
         with six.assertRaisesRegex(self, ValueError, error):
-            mutateString("x", 1, "x")
+            mutateString('x', 1, 'x')
 
     def testZeroReplacements(self):
         """
         The function should return the original string when zero mutations
         are requested.
         """
-        self.assertEqual("acgt", mutateString("acgt", 0, "x"))
+        self.assertEqual('acgt', mutateString('acgt', 0, 'x'))
 
     def testOneDeterministicReplacement(self):
         """
         The function should return the correct result when one mutation is
         requested and only one mutation is possible.
         """
-        self.assertEqual("c", mutateString("a", 1, "ac"))
+        self.assertEqual('c', mutateString('a', 1, 'ac'))
 
     def testFiveDeterminsticReplacements(self):
         """
         The function should return the correct result when five mutations are
         requested and only one outcome is possible.
         """
-        self.assertEqual("ccccc", mutateString("aaaaa", 5, "ac"))
+        self.assertEqual('ccccc', mutateString('aaaaa', 5, 'ac'))
 
     def testOneReplacement(self):
         """
         The function should return all possible correct results (and only those
         results) when one mutation is requested and two outcomes are possible.
 
         NOTE: this test is a bit bad because it's non-deterministic.
         """
-        possible = set(["ab", "ba"])
+        possible = set(['ab', 'ba'])
         seen = set()
 
         for _ in range(100):
-            result = mutateString("aa", 1, "ab")
+            result = mutateString('aa', 1, 'ab')
             self.assertTrue(result in possible)
             seen.add(result)
         self.assertEqual(seen, possible)
 
     def testTwoReplacements(self):
         """
         The function should return all possible correct results (and only those
         results) when two mutations are requested and four outcomes are
         possible.
 
         NOTE: this test is a bit bad because it's non-deterministic.
         """
-        possible = set(["ab", "ba", "ac", "ca"])
+        possible = set(['ab', 'ba', 'ac', 'ca'])
         seen = set()
 
         for _ in range(100):
-            result = mutateString("aa", 1, "abc")
-            self.assertTrue(result in possible, "%s is not in %r" % (result, possible))
+            result = mutateString('aa', 1, 'abc')
+            self.assertTrue(result in possible,
+                            '%s is not in %r' % (result, possible))
             seen.add(result)
         self.assertEqual(seen, possible)
```

### Comparing `dark-matter-4.0.84/test/test_orfs.py` & `dark-matter-4.0.9/test/test_orfs.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,44 +1,44 @@
 from unittest import TestCase
 from Bio.Seq import Seq
 
 from dark.orfs import findCodons
 
 
 class TestFindCodons(TestCase):
-    """Tests of the findCodons helper."""
+    """Tests of the findCodons helper. """
 
     def testNoMatches(self):
         """
         When there are no codons in the sequence, returns an empty list.
         """
-        seq = Seq("AAAAAA")
-        self.assertEqual([], list(findCodons(seq, set(["ATG", "AGG"]))))
+        seq = Seq('AAAAAA')
+        self.assertEqual([], list(findCodons(seq, set(['ATG', 'AGG']))))
 
     def testMatchAtStart(self):
         """
         Finds a codon at the start of the sequence.
         """
-        seq = Seq("ATGAAA")
-        self.assertEqual([0], list(findCodons(seq, set(["ATG", "AGG"]))))
+        seq = Seq('ATGAAA')
+        self.assertEqual([0], list(findCodons(seq, set(['ATG', 'AGG']))))
 
     def testMatchAtEnd(self):
         """
         Finds a codon at the end of the sequence.
         """
-        seq = Seq("ATGAAA")
-        self.assertEqual([3], list(findCodons(seq, set(["AAA"]))))
+        seq = Seq('ATGAAA')
+        self.assertEqual([3], list(findCodons(seq, set(['AAA']))))
 
     def testMatchMultiple(self):
         """
         Finds multiple codons in the sequence.
         """
-        seq = Seq("ATGAAAGGGCCC")
-        self.assertEqual([0, 9], list(findCodons(seq, set(["ATG", "CCC"]))))
+        seq = Seq('ATGAAAGGGCCC')
+        self.assertEqual([0, 9], list(findCodons(seq, set(['ATG', 'CCC']))))
 
     def testDoesNotFindOutOfFrameMatches(self):
         """
         Does not find matching codons that are in a non-zero frame in the
         sequence.
         """
-        seq = Seq("TATGAAAGGGCCC")
-        self.assertEqual([], list(findCodons(seq, set(["ATG", "CCC"]))))
+        seq = Seq('TATGAAAGGGCCC')
+        self.assertEqual([], list(findCodons(seq, set(['ATG', 'CCC']))))
```

### Comparing `dark-matter-4.0.84/test/test_process.py` & `dark-matter-4.0.9/test/test_process.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,29 +7,25 @@
 from dark.process import Executor
 
 
 class TestProcess(TestCase):
     """
     Test the Process class.
     """
-
     def testUnknownCommand(self):
         """
         An unknown command must raise CalledProcessError.
         """
         e = Executor()
         # Presumably there will not be an executable with this name!
-        command = "/".join(["dev", "non-existent", "@" * 20])
+        command = '/'.join(['dev', 'non-existent', '@' * 20])
         error = r"^Command '%s' returned non-zero exit status 127%s$" % (
-            command,
-            "" if sys.version_info < (3, 6) else r"\.",
-        )
-        assertRaisesRegex(
-            self, CalledProcessError, error, e.execute, command, useStderr=False
-        )
+            command, '' if sys.version_info < (3, 6) else r'\.')
+        assertRaisesRegex(self, CalledProcessError, error, e.execute, command,
+                          useStderr=False)
 
     def testDryRunTrue(self):
         """
         The dryRun attribute must be set when dryRun=True.
         """
         e = Executor(dryRun=True)
         self.assertTrue(e.dryRun)
@@ -39,50 +35,50 @@
         The dryRun attribute must be set when dryRun=False.
         """
         e = Executor(dryRun=False)
         self.assertFalse(e.dryRun)
 
     def testDryRunDefault(self):
         e = Executor(dryRun=True)
-        result = e.execute("date")
+        result = e.execute('date')
         self.assertIsNone(result)
-        self.assertEqual("$ date", e.log[-1])
+        self.assertEqual('$ date', e.log[-1])
 
     def testDryRunDefaultOverride(self):
         """
         It must be possible to override the default dryRun setting by passing
         a value to C{execute}.
         """
         e = Executor(dryRun=False)
-        result = e.execute("date", dryRun=True)
+        result = e.execute('date', dryRun=True)
         self.assertIsNone(result)
-        self.assertEqual("$ date", e.log[-1])
+        self.assertEqual('$ date', e.log[-1])
 
-    @skipUnless(six.PY3, "subprocess output skipped under PY2")
+    @skipUnless(six.PY3, 'subprocess output skipped under PY2')
     def testEchoStr(self):
         """
         We should be able to call echo using a string command.
         """
         e = Executor()
-        result = e.execute("echo hello")
-        self.assertEqual("hello", result.stdout.strip())
-        self.assertTrue("$ echo hello" in e.log)
+        result = e.execute('echo hello')
+        self.assertEqual('hello', result.stdout.strip())
+        self.assertTrue('$ echo hello' in e.log)
 
-    @skipUnless(six.PY3, "subprocess output skipped under PY2")
+    @skipUnless(six.PY3, 'subprocess output skipped under PY2')
     def testEchoList(self):
         """
         We should be able to call echo using a list command.
         """
         e = Executor()
-        result = e.execute(["echo", "hello"])
-        self.assertEqual("hello", result.stdout.strip())
-        self.assertTrue("$ echo hello" in e.log)
+        result = e.execute(['echo', 'hello'])
+        self.assertEqual('hello', result.stdout.strip())
+        self.assertTrue('$ echo hello' in e.log)
 
-    @skipUnless(six.PY3, "subprocess output skipped under PY2")
+    @skipUnless(six.PY3, 'subprocess output skipped under PY2')
     def testPipe(self):
         """
         We should be able to pipe echo into wc -c.
         """
         e = Executor()
-        result = e.execute("echo hello | wc -c")
-        self.assertEqual("6", result.stdout.strip())
-        self.assertTrue("$ echo hello | wc -c" in e.log)
+        result = e.execute('echo hello | wc -c')
+        self.assertEqual('6', result.stdout.strip())
+        self.assertTrue('$ echo hello | wc -c' in e.log)
```

### Comparing `dark-matter-4.0.84/test/test_reads.py` & `dark-matter-4.0.9/test/test_reads.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,2253 +1,2139 @@
 import six
 from six.moves import builtins
 from unittest import TestCase
-from unittest.mock import patch, call, mock_open
 from random import seed
 from os import stat
-from io import StringIO
 
-from dark.aaVars import (
-    BASIC_POSITIVE,
-    HYDROPHOBIC,
-    HYDROPHILIC,
-    NEGATIVE,
-    NONE,
-    POLAR,
-    SMALL,
-    TINY,
-)
+try:
+    from unittest.mock import patch, call, mock_open
+except ImportError:
+    from mock import patch, call
+
+from dark.aa import (
+    BASIC_POSITIVE, HYDROPHOBIC, HYDROPHILIC, NEGATIVE, NONE, POLAR, SMALL,
+    TINY)
 from dark.errors import ReadLengthsNotIdenticalError
 from dark.fasta import FastaReads
 from dark.hsp import HSP
 from dark.reads import (
-    Read,
-    TranslatedRead,
-    Reads,
-    ReadsInRAM,
-    DNARead,
-    RNARead,
-    DNAKozakRead,
-    AARead,
-    AAReadORF,
-    AAReadWithX,
-    SSAARead,
-    SSAAReadWithX,
-    getNoCoverageCounts,
-    readClassNameToClass,
-)
+    Read, TranslatedRead, Reads, ReadsInRAM, DNARead, RNARead, DNAKozakRead,
+    AARead, AAReadORF, AAReadWithX, SSAARead, SSAAReadWithX,
+    readClassNameToClass)
+from dark.utils import StringIO
 
 
 class TestRead(TestCase):
     """
     Test the Read class.
     """
-
     def testGetitemReturnsNewRead(self):
         """
         __getitem__ must return a new Read instance.
         """
-        self.assertIs(Read, Read("id", "ACGT")[0:3].__class__)
+        self.assertIs(Read, Read('id', 'ACGT')[0:3].__class__)
 
     def testGetitemId(self):
         """
         __getitem__ must return a new Read instance with the same read id.
         """
-        self.assertEqual("id-1234", Read("id-1234", "ACGT")[0:3].id)
+        self.assertEqual('id-1234', Read('id-1234', 'ACGT')[0:3].id)
 
     def testGetitemSequence(self):
         """
         __getitem__ must return a Read instance with the expected sequence.
         """
-        self.assertEqual("CG", Read("id", "ACGT")[1:3].sequence)
+        self.assertEqual('CG', Read('id', 'ACGT')[1:3].sequence)
 
     def testGetitemQuality(self):
         """
         __getitem__ must return a Read instance with the expected quality
         string.
         """
-        self.assertEqual("12", Read("id", "ACGT", "1234")[0:2].quality)
+        self.assertEqual('12', Read('id', 'ACGT', '1234')[0:2].quality)
 
     def testGetitemLength(self):
         """
         __getitem__ must return a Read instance of the expected length.
         """
-        self.assertEqual(3, len(Read("id-1234", "ACGT")[0:3]))
+        self.assertEqual(3, len(Read('id-1234', 'ACGT')[0:3]))
 
     def testGetitemSingleIndex(self):
         """
         A single-index __getitem__ must return a length-one Read.
         """
-        self.assertEqual(1, len(Read("id", "ACGT")[0]))
+        self.assertEqual(1, len(Read('id', 'ACGT')[0]))
 
     def testGetitemFullCopy(self):
         """
         A full copy __getitem__ must return the expected result.
         """
-        self.assertEqual(Read("id", "ACGT"), Read("id", "ACGT")[:])
+        self.assertEqual(Read('id', 'ACGT'),
+                         Read('id', 'ACGT')[:])
 
     def testGetitemWithStep(self):
         """
         A stepped __getitem__ must return the expected result.
         """
-        self.assertEqual(Read("id", "AG", "13"), Read("id", "ACGT", "1234")[::2])
+        self.assertEqual(Read('id', 'AG', '13'),
+                         Read('id', 'ACGT', '1234')[::2])
 
     def testGetitemReversed(self):
         """
         A reverse copy __getitem__ must return the expected result.
         """
-        self.assertEqual(Read("id", "TGCA", "4321"), Read("id", "ACGT", "1234")[::-1])
+        self.assertEqual(Read('id', 'TGCA', '4321'),
+                         Read('id', 'ACGT', '1234')[::-1])
 
     def testUnequalLengths(self):
         """
         Attempting to construct a read whose sequence and quality strings are
         of different lengths must raise a ValueError.
         """
-        error = r"Invalid read: sequence length \(4\) != quality " r"length \(3\)"
+        error = (r'Invalid read: sequence length \(4\) != quality '
+                 r'length \(3\)')
         with six.assertRaisesRegex(self, ValueError, error):
-            Read("id", "ACGT", "!!!")
+            Read('id', 'ACGT', '!!!')
 
     def testNoQuality(self):
         """
         If no quality information is given, the read's 'quality' attribute must
         be None.
         """
-        read = Read("id", "ACGT")
+        read = Read('id', 'ACGT')
         self.assertIs(None, read.quality)
 
     def testCasePreservation(self):
         """
         The sequence passed to Read must not have its case converted.
         """
-        read = Read("id", "aCGt")
-        self.assertEqual("aCGt", read.sequence)
+        read = Read('id', 'aCGt')
+        self.assertEqual('aCGt', read.sequence)
 
     def testExpectedAttributes(self):
         """
         After constructing a read, the expected attributes must be present.
         """
-        read = Read("id", "ACGT", "!!!!")
-        self.assertEqual("id", read.id)
-        self.assertEqual("ACGT", read.sequence)
-        self.assertEqual("!!!!", read.quality)
+        read = Read('id', 'ACGT', '!!!!')
+        self.assertEqual('id', read.id)
+        self.assertEqual('ACGT', read.sequence)
+        self.assertEqual('!!!!', read.quality)
 
     def testLength(self):
         """
         len() must return the length of a read's sequence.
         """
-        read = Read("id", "ACGT", "!!!!")
+        read = Read('id', 'ACGT', '!!!!')
         self.assertEqual(4, len(read))
 
     def testToUnknownFormat(self):
         """
         toString must raise a ValueError if asked to convert to an unknown
         format.
         """
-        read = Read("id", "ACGT", "!!!!")
+        read = Read('id', 'ACGT', '!!!!')
         error = r"Format must be either 'fasta', 'fastq' or 'fasta-ss'\."
-        six.assertRaisesRegex(self, ValueError, error, read.toString, "unknown")
+        six.assertRaisesRegex(self, ValueError, error, read.toString,
+                              'unknown')
 
     def testToFASTA(self):
         """
         toString must return correct FASTA.
         """
-        read = Read("id", "ACGT")
-        self.assertEqual(">id\nACGT\n", read.toString("fasta"))
+        read = Read('id', 'ACGT')
+        self.assertEqual('>id\nACGT\n', read.toString('fasta'))
 
     def testToFASTAWithQuality(self):
         """
         toString must return correct FASTA, including when a read has quality
         information (which is not present in FASTA).
         """
-        read = Read("id", "ACGT", "!!!!")
-        self.assertEqual(">id\nACGT\n", read.toString("fasta"))
+        read = Read('id', 'ACGT', '!!!!')
+        self.assertEqual('>id\nACGT\n', read.toString('fasta'))
 
     def testToFASTQWithNoQuality(self):
         """
         toString must raise a ValueError if asked to convert to FASTQ but the
         read has no quality.
         """
-        read = Read("id", "ACGT")
+        read = Read('id', 'ACGT')
         error = "Read 'id' has no quality information"
-        six.assertRaisesRegex(self, ValueError, error, read.toString, "fastq")
+        six.assertRaisesRegex(self, ValueError, error, read.toString, 'fastq')
 
     def testToFASTQ(self):
         """
         toString must return correct FASTA.
         """
-        read = Read("id", "ACGT", "!@#$")
-        self.assertEqual("@id\nACGT\n+id\n!@#$\n", read.toString("fastq"))
+        read = Read('id', 'ACGT', '!@#$')
+        self.assertEqual('@id\nACGT\n+id\n!@#$\n', read.toString('fastq'))
 
     def testToDict(self):
         """
         toDict must return the correct dictionary.
         """
-        read = Read("id3", "ACGT", "!!2&")
+        read = Read('id3', 'ACGT', '!!2&')
         self.assertEqual(
             {
-                "id": "id3",
-                "sequence": "ACGT",
-                "quality": "!!2&",
+                'id': 'id3',
+                'sequence': 'ACGT',
+                'quality': '!!2&',
             },
-            read.toDict(),
-        )
+            read.toDict())
 
     def testToDictNoQuality(self):
         """
         toDict must return the correct dictionary when the read has no quality
         string.
         """
-        read = Read("id3", "ACGT")
+        read = Read('id3', 'ACGT')
         self.assertEqual(
             {
-                "id": "id3",
-                "sequence": "ACGT",
-                "quality": None,
+                'id': 'id3',
+                'sequence': 'ACGT',
+                'quality': None,
             },
-            read.toDict(),
-        )
+            read.toDict())
 
     def testFromDict(self):
         """
         fromDict must return the expected instance.
         """
         self.assertEqual(
-            Read("id3", "ACGT", "!!2&"),
-            Read.fromDict(
-                {
-                    "id": "id3",
-                    "sequence": "ACGT",
-                    "quality": "!!2&",
-                }
-            ),
-        )
+            Read('id3', 'ACGT', '!!2&'),
+            Read.fromDict({
+                'id': 'id3',
+                'sequence': 'ACGT',
+                'quality': '!!2&',
+            }))
 
     def testFromDictNoQuality(self):
         """
         fromDict must return the expected instance when the dictionary has no
         quality key.
         """
         self.assertEqual(
-            Read("id3", "ACGT"),
-            Read.fromDict(
-                {
-                    "id": "id3",
-                    "sequence": "ACGT",
-                }
-            ),
-        )
+            Read('id3', 'ACGT'),
+            Read.fromDict({
+                'id': 'id3',
+                'sequence': 'ACGT',
+            }))
 
     def testEqualityWithDifferingIds(self):
         """
         If two Read instances have different ids, they must not be
         considered equal.
         """
-        self.assertNotEqual(Read("id1", "AC"), Read("id2", "AC"))
+        self.assertNotEqual(Read('id1', 'AC'), Read('id2', 'AC'))
 
     def testEqualityWithDifferingSequences(self):
         """
         If two Read instances have different sequences, they must not be
         considered equal.
         """
-        self.assertNotEqual(Read("id1", "AA"), Read("id1", "CC"))
+        self.assertNotEqual(Read('id1', 'AA'), Read('id1', 'CC'))
 
     def testEqualityWithDifferingQuality(self):
         """
         If two Read instances have different quality, they must not be
         considered equal.
         """
-        self.assertNotEqual(Read("id1", "AC", "qq"), Read("id1", "AC", "rr"))
+        self.assertNotEqual(Read('id1', 'AC', 'qq'), Read('id1', 'AC', 'rr'))
 
     def testEqualityWithOneOmittedQuality(self):
         """
         If two Read instances have different quality (one is omitted), they
         must not be considered equal.
         """
-        self.assertNotEqual(Read("id1", "AC"), Read("id1", "AC", "rr"))
+        self.assertNotEqual(Read('id1', 'AC'), Read('id1', 'AC', 'rr'))
 
     def testEqualityWithNoQuality(self):
         """
         If two Read instances have the same id and sequence and neither has a
         quality, they must be considered equal.
         """
-        self.assertEqual(Read("id1", "AC"), Read("id1", "AC"))
+        self.assertEqual(Read('id1', 'AC'), Read('id1', 'AC'))
 
     def testEquality(self):
         """
         If two Read instances have the same id, sequence, and quality, they
         must be considered equal.
         """
-        self.assertEqual(Read("id1", "AC", "qq"), Read("id1", "AC", "qq"))
+        self.assertEqual(Read('id1', 'AC', 'qq'), Read('id1', 'AC', 'qq'))
 
     def testHashDiffersIfIdDiffers(self):
         """
         The __hash__ value for two reads must differ if their ids differ.
         """
-        self.assertNotEqual(hash(Read("id1", "AA")), hash(Read("id2", "AA")))
+        self.assertNotEqual(hash(Read('id1', 'AA')),
+                            hash(Read('id2', 'AA')))
 
     def testHashDiffersIfSequenceDiffers(self):
         """
         The __hash__ value for two reads must differ if their sequences
         differ.
         """
-        self.assertNotEqual(hash(Read("id", "AAT")), hash(Read("id", "AAG")))
+        self.assertNotEqual(hash(Read('id', 'AAT')),
+                            hash(Read('id', 'AAG')))
 
     def testHashDiffersIfQualityDiffers(self):
         """
         The __hash__ value for two reads must differ if their quality strings
         differ.
         """
-        self.assertNotEqual(hash(Read("id", "AA", "!!")), hash(Read("id", "AA", "++")))
+        self.assertNotEqual(hash(Read('id', 'AA', '!!')),
+                            hash(Read('id', 'AA', '++')))
 
     def testHashIdenticalNoQuality(self):
         """
         The __hash__ value for two identical reads (with no quality strings)
         must be identical.
         """
-        self.assertEqual(hash(Read("id", "AA")), hash(Read("id", "AA")))
+        self.assertEqual(hash(Read('id', 'AA')),
+                         hash(Read('id', 'AA')))
 
     def testHashIdenticalWithQuality(self):
         """
         The __hash__ value for two identical reads (with quality strings) must
         be identical.
         """
-        self.assertEqual(hash(Read("id", "AA", "!!")), hash(Read("id", "AA", "!!")))
+        self.assertEqual(hash(Read('id', 'AA', '!!')),
+                         hash(Read('id', 'AA', '!!')))
 
     def testHashViaSet(self):
         """
         If two identical reads are put into a set, the set must have size one.
         """
-        read = Read("id", "AA", "!!")
+        read = Read('id', 'AA', '!!')
         self.assertEqual(1, len(set([read, read])))
 
     def testHashViaDict(self):
         """
         If two identical reads are used as keys in a dict, the dict must have
         size one.
         """
-        read = Read("id", "AA", "!!")
+        read = Read('id', 'AA', '!!')
         self.assertEqual(1, len(dict.fromkeys([read, read])))
 
     def testLowComplexityFractionEmptySequence(self):
         """
         A read with an empty sequence must return a zero result from its
         lowComplexityFraction method.
         """
-        read = Read("id", "")
+        read = Read('id', '')
         self.assertEqual(0.0, read.lowComplexityFraction())
 
     def testLowComplexityFractionZero(self):
         """
         A read with no low-complexity bases must return a zero result from its
         lowComplexityFraction method.
         """
-        read = Read("id", "ACGT")
+        read = Read('id', 'ACGT')
         self.assertEqual(0.0, read.lowComplexityFraction())
 
     def testLowComplexityFractionOne(self):
         """
         A read with all low-complexity bases must return a one result from its
         lowComplexityFraction method.
         """
-        read = Read("id", "acgt")
+        read = Read('id', 'acgt')
         self.assertEqual(1.0, read.lowComplexityFraction())
 
     def testLowComplexityFraction(self):
         """
         A read with all low-complexity bases must return the correct result
         from its lowComplexityFraction method.
         """
-        read = Read("id", "aCGT")
+        read = Read('id', 'aCGT')
         self.assertEqual(0.25, read.lowComplexityFraction())
 
     def testWalkHSPExactMatch(self):
         """
         If the HSP specifies that the entire read matches the subject exactly,
         walkHSP must return the correct results.
 
         Subject:     ACGT
         Read:        ACGT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=0,
-            readEndInSubject=4,
-            subjectStart=0,
-            subjectEnd=4,
-            readMatchedSequence="ACGT",
-            subjectMatchedSequence="ACGT",
-        )
-        self.assertEqual(
-            [(0, "A", True), (1, "C", True), (2, "G", True), (3, "T", True)],
-            list(read.walkHSP(hsp)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=0, readEnd=4, readStartInSubject=0,
+                  readEndInSubject=4, subjectStart=0, subjectEnd=4,
+                  readMatchedSequence='ACGT', subjectMatchedSequence='ACGT')
+        self.assertEqual([(0, 'A', True),
+                          (1, 'C', True),
+                          (2, 'G', True),
+                          (3, 'T', True)],
+                         list(read.walkHSP(hsp)))
 
     def testWalkHSPExactMatchWithGap(self):
         """
         If the HSP specifies that the entire read matches the subject exactly,
         including a gap, walkHSP must return the correct results.
 
         Subject:     ACGT
         Read:        A-GT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=0,
-            readEndInSubject=4,
-            subjectStart=0,
-            subjectEnd=4,
-            readMatchedSequence="A-GT",
-            subjectMatchedSequence="ACGT",
-        )
-        self.assertEqual(
-            [(0, "A", True), (1, "-", True), (2, "G", True), (3, "T", True)],
-            list(read.walkHSP(hsp)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=0, readEnd=4, readStartInSubject=0,
+                  readEndInSubject=4, subjectStart=0, subjectEnd=4,
+                  readMatchedSequence='A-GT', subjectMatchedSequence='ACGT')
+        self.assertEqual([(0, 'A', True),
+                          (1, '-', True),
+                          (2, 'G', True),
+                          (3, 'T', True)],
+                         list(read.walkHSP(hsp)))
 
     def testWalkHSPLeftOverhangingMatch(self):
         """
         If the HSP specifies that the entire read matches the subject, and
         also extends to the left of the subject, walkHSP must return the
         correct results.
 
         Subject:       GT.....
         Read:        ACGT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=2,
-            readEnd=4,
-            readStartInSubject=-2,
-            readEndInSubject=2,
-            subjectStart=0,
-            subjectEnd=2,
-            readMatchedSequence="GT",
-            subjectMatchedSequence="GT",
-        )
-        self.assertEqual(
-            [(-2, "A", False), (-1, "C", False), (0, "G", True), (1, "T", True)],
-            list(read.walkHSP(hsp)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=2, readEnd=4, readStartInSubject=-2,
+                  readEndInSubject=2, subjectStart=0, subjectEnd=2,
+                  readMatchedSequence='GT', subjectMatchedSequence='GT')
+        self.assertEqual([(-2, 'A', False),
+                          (-1, 'C', False),
+                          (0, 'G', True),
+                          (1, 'T', True)],
+                         list(read.walkHSP(hsp)))
 
     def testWalkHSPLeftOverhangingMatchNoWhiskers(self):
         """
         If the HSP specifies that the entire read matches the subject, and
         also extends to the left of the subject, walkHSP must return the
         correct results when it is told to not include whiskers.
 
         Subject:       GT.....
         Read:        ACGT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=2,
-            readEnd=4,
-            readStartInSubject=-2,
-            readEndInSubject=2,
-            subjectStart=0,
-            subjectEnd=2,
-            readMatchedSequence="GT",
-            subjectMatchedSequence="GT",
-        )
-        self.assertEqual(
-            [(0, "G", True), (1, "T", True)],
-            list(read.walkHSP(hsp, includeWhiskers=False)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=2, readEnd=4, readStartInSubject=-2,
+                  readEndInSubject=2, subjectStart=0, subjectEnd=2,
+                  readMatchedSequence='GT', subjectMatchedSequence='GT')
+        self.assertEqual([(0, 'G', True),
+                          (1, 'T', True)],
+                         list(read.walkHSP(hsp, includeWhiskers=False)))
 
     def testWalkHSPRightOverhangingMatch(self):
         """
         If the HSP specifies that the entire read matches the subject, and
         also extends to the right of the subject, walkHSP must return the
         correct results.
 
         Subject:       AC
         Read:          ACGT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=0,
-            readEnd=2,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=12,
-            readMatchedSequence="AC",
-            subjectMatchedSequence="AC",
-        )
-        self.assertEqual(
-            [(10, "A", True), (11, "C", True), (12, "G", False), (13, "T", False)],
-            list(read.walkHSP(hsp)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=0, readEnd=2, readStartInSubject=10,
+                  readEndInSubject=14, subjectStart=10, subjectEnd=12,
+                  readMatchedSequence='AC', subjectMatchedSequence='AC')
+        self.assertEqual([(10, 'A', True),
+                          (11, 'C', True),
+                          (12, 'G', False),
+                          (13, 'T', False)],
+                         list(read.walkHSP(hsp)))
 
     def testWalkHSPRightOverhangingMatchNoWhiskers(self):
         """
         If the HSP specifies that the entire read matches the subject, and
         also extends to the right of the subject, walkHSP must return the
         correct results when it is told to not include whiskers.
 
         Subject:       AC
         Read:          ACGT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=0,
-            readEnd=2,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=12,
-            readMatchedSequence="AC",
-            subjectMatchedSequence="AC",
-        )
-        self.assertEqual(
-            [(10, "A", True), (11, "C", True)],
-            list(read.walkHSP(hsp, includeWhiskers=False)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=0, readEnd=2, readStartInSubject=10,
+                  readEndInSubject=14, subjectStart=10, subjectEnd=12,
+                  readMatchedSequence='AC', subjectMatchedSequence='AC')
+        self.assertEqual([(10, 'A', True),
+                          (11, 'C', True)],
+                         list(read.walkHSP(hsp, includeWhiskers=False)))
 
     def testWalkHSPLeftAndRightOverhangingMatch(self):
         """
         If the HSP specifies that the read matches the entire subject, and
         also extends to both the left and right of the subject, walkHSP must
         return the correct results.
 
         Subject:        CG
         Read:          ACGT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=1,
-            readEnd=3,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=11,
-            subjectEnd=13,
-            readMatchedSequence="CG",
-            subjectMatchedSequence="CG",
-        )
-        self.assertEqual(
-            [(10, "A", False), (11, "C", True), (12, "G", True), (13, "T", False)],
-            list(read.walkHSP(hsp)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=1, readEnd=3, readStartInSubject=10,
+                  readEndInSubject=14, subjectStart=11, subjectEnd=13,
+                  readMatchedSequence='CG', subjectMatchedSequence='CG')
+        self.assertEqual([(10, 'A', False),
+                          (11, 'C', True),
+                          (12, 'G', True),
+                          (13, 'T', False)],
+                         list(read.walkHSP(hsp)))
 
     def testWalkHSPLeftAndRightOverhangingMatchNoWhiskers(self):
         """
         If the HSP specifies that the read matches the entire subject, and
         also extends to both the left and right of the subject, walkHSP must
         return the correct results when it is told to not include whiskers.
 
         Subject:        CG
         Read:          ACGT
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=1,
-            readEnd=3,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=11,
-            subjectEnd=13,
-            readMatchedSequence="CG",
-            subjectMatchedSequence="CG",
-        )
-        self.assertEqual(
-            [(11, "C", True), (12, "G", True)],
-            list(read.walkHSP(hsp, includeWhiskers=False)),
-        )
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=1, readEnd=3, readStartInSubject=10,
+                  readEndInSubject=14, subjectStart=11, subjectEnd=13,
+                  readMatchedSequence='CG', subjectMatchedSequence='CG')
+        self.assertEqual([(11, 'C', True),
+                          (12, 'G', True)],
+                         list(read.walkHSP(hsp, includeWhiskers=False)))
 
     def testCheckAlphabetwithReadMustBePermissive(self):
         """
         The checkAlphabet function must return the expected alphabet if a
         dark.Read is passed.
         """
-        read = Read("id", "ARSTGATGCASASASASASAS")
-        self.assertEqual(set("ACGSRT"), read.checkAlphabet())
+        read = Read('id', 'ARSTGATGCASASASASASAS')
+        self.assertEqual(set('ACGSRT'), read.checkAlphabet())
 
     def testCheckAlphabetAAReadMatchingReturnTrue(self):
         """
         If an AA read with an AARead readClass is passed in, the checkAlphabet
         function must return the alphabet of the sequence.
         """
-        read = AARead("id", "ARSTGATGCASASASASASAS")
-        self.assertEqual(set("ACGSRT"), read.checkAlphabet())
+        read = AARead('id', 'ARSTGATGCASASASASASAS')
+        self.assertEqual(set('ACGSRT'), read.checkAlphabet())
 
     def testCheckAlphabetDNAReadMatchingReturnTrue(self):
         """
         If a DNA read with a DNARead readClass is passed in, the checkAlphabet
         function must return the alphabet of the sequence.
         """
-        read = DNARead("id", "AAATTAACGGGCCTAGG")
-        self.assertEqual(set("ACTG"), read.checkAlphabet())
+        read = DNARead('id', 'AAATTAACGGGCCTAGG')
+        self.assertEqual(set('ACTG'), read.checkAlphabet())
 
     def testCheckAlphabetAAReadNotMatchingRaise(self):
         """
         If an AA read with a DNARead readClass is passed in, the checkAlphabet
         function must raise an IndexError.
         """
-        read = AARead("id", "AAATTAACGGGCCTAGG")
+        read = AARead('id', 'AAATTAACGGGCCTAGG')
         error = "It looks like a DNA sequence has been passed to AARead()."
         six.assertRaisesRegex(self, ValueError, error, read.checkAlphabet)
 
     def testCheckAlphabetDNAReadNotMatchingRaise(self):
         """
         If a DNA read with an AARead readClass is passed in, the checkAlphabet
         function must raise an IndexError.
         """
-        read = DNARead("id", "ARSTGATGCASASASASASAS")
-        error = (
-            r"Read alphabet \('ACGRST'\) is not a subset of expected "
-            r"alphabet \('ACGT'\) for read class DNARead."
-        )
+        read = DNARead('id', 'ARSTGATGCASASASASASAS')
+        error = (r"Read alphabet \('ACGRST'\) is not a subset of expected "
+                 r"alphabet \('ACGT'\) for read class DNARead.")
         six.assertRaisesRegex(self, ValueError, error, read.checkAlphabet)
 
     def testKeepSites(self):
         """
         If only a certain set of sites should be kept, newFromSites should
         return a read with the correct sequence.
         """
-        self.assertEqual(Read("id1", "TC"), Read("id1", "ATCGAT").newFromSites({1, 2}))
+        self.assertEqual(Read('id1', 'TC'),
+                         Read('id1', 'ATCGAT').newFromSites({1, 2}))
 
     def testKeepSitesNoSites(self):
         """
         If only the empty set of sites should be kept, newFromSites should
         return a read with the correct (empty) sequence.
         """
-        self.assertEqual(Read("id1", ""), Read("id1", "ATCGAT").newFromSites(set()))
+        self.assertEqual(Read('id1', ''),
+                         Read('id1', 'ATCGAT').newFromSites(set()))
 
     def testKeepSitesAllSites(self):
         """
         If all sites should be kept, newFromSites should return a read with
         the correct (full) sequence.
         """
-        self.assertEqual(
-            Read("id1", "ATCGAT"), Read("id1", "ATCGAT").newFromSites(set(range(6)))
-        )
+        self.assertEqual(Read('id1', 'ATCGAT'),
+                         Read('id1', 'ATCGAT').newFromSites(set(range(6))))
 
     def testKeepSitesWithQuality(self):
         """
         If only a certain set of sites should be kept, newFromSites should
         return a read with the correct sequence and quality.
         """
-        self.assertEqual(
-            Read("id1", "TC", "23"),
-            Read("id1", "ATCGAT", "123456").newFromSites({1, 2}),
-        )
+        self.assertEqual(Read('id1', 'TC', '23'),
+                         Read('id1', 'ATCGAT', '123456').newFromSites(
+                             {1, 2}))
 
     def testKeepSitesOutOfRange(self):
         """
         If only a certain set of sites should be kept, but the kept sites
         are higher than the length of the input sequences, newFromSites
         should return a read with the correct (empty) sequence.
         """
-        self.assertEqual(
-            Read("id1", ""), Read("id1", "ATCGAT").newFromSites({100, 200})
-        )
+        self.assertEqual(Read('id1', ''),
+                         Read('id1', 'ATCGAT').newFromSites({100, 200}))
 
     def testRemoveSites(self):
         """
         If only a certain set of sites should be removed, newFromSites
         should return a read with the correct sequence.
         """
-        self.assertEqual(
-            Read("id1", "AGAT"),
-            Read("id1", "ATCGAT").newFromSites({1, 2}, exclude=True),
-        )
+        self.assertEqual(Read('id1', 'AGAT'),
+                         Read('id1', 'ATCGAT').newFromSites({1, 2},
+                                                            exclude=True))
 
     def testRemoveSitesNoSites(self):
         """
         If no sites should be removed, newFromSites should return a read
         with the correct (full) sequence.
         """
-        self.assertEqual(
-            Read("id1", "ATCGAT"),
-            Read("id1", "ATCGAT").newFromSites(set(), exclude=True),
-        )
+        self.assertEqual(Read('id1', 'ATCGAT'),
+                         Read('id1', 'ATCGAT').newFromSites(set(),
+                                                            exclude=True))
 
     def testRemoveSitesAllSites(self):
         """
         If all sites should be removed, newFromSites should return a read
         with the correct (empty) sequence.
         """
-        self.assertEqual(
-            Read("id1", ""),
-            Read("id1", "ATCGAT").newFromSites(set(range(6)), exclude=True),
-        )
+        self.assertEqual(Read('id1', ''),
+                         Read('id1', 'ATCGAT').newFromSites(set(range(6)),
+                                                            exclude=True))
 
     def testRemoveSitesWithQuality(self):
         """
         If only a certain set of sites should be removed, newFromSites
         should return a read with the correct sequence and quality.
         """
-        self.assertEqual(
-            Read("id1", "AGAT", "1456"),
-            Read("id1", "ATCGAT", "123456").newFromSites({1, 2}, exclude=True),
-        )
+        self.assertEqual(Read('id1', 'AGAT', '1456'),
+                         Read('id1', 'ATCGAT', '123456').newFromSites(
+                             {1, 2}, exclude=True))
 
     def testRemoveSitesOutOfRange(self):
         """
         If only a certain set of sites should be removed, but the removed
         sites are higher than the length of the input sequences,
         newFromSites should return a read with the correct (full) sequence.
         """
-        self.assertEqual(
-            Read("id1", "ATCGAT"),
-            Read("id1", "ATCGAT").newFromSites({100, 200}, exclude=True),
-        )
+        self.assertEqual(Read('id1', 'ATCGAT'),
+                         Read('id1', 'ATCGAT').newFromSites({100, 200},
+                                                            exclude=True))
 
     def testReverseNoQuality(self):
         """
         The reverse method must work as expected when there is no quality
         string.
         """
-        self.assertEqual(Read("id1", "ATCGAT"), Read("id1", "TAGCTA").reverse())
+        self.assertEqual(Read('id1', 'ATCGAT'),
+                         Read('id1', 'TAGCTA').reverse())
 
     def testReverseWithQuality(self):
         """
         The reverse method must work as expected when there is a quality
         string.
         """
-        self.assertEqual(
-            Read("id1", "ATCGAT", "123456"), Read("id1", "TAGCTA", "654321").reverse()
-        )
+        self.assertEqual(Read('id1', 'ATCGAT', '123456'),
+                         Read('id1', 'TAGCTA', '654321').reverse())
 
 
 class TestDNARead(TestCase):
     """
     Tests for the DNARead class.
     """
-
     def testGetitemReturnsNewDNARead(self):
         """
         __getitem__ must return a new DNARead instance.
         """
-        self.assertIs(DNARead, DNARead("id", "ACGT")[0:3].__class__)
+        self.assertIs(DNARead, DNARead('id', 'ACGT')[0:3].__class__)
 
     def testReverseComplementReversesQuality(self):
         """
         The reverseComplement function must return a reversed quality string.
         """
-        read = DNARead("id", "atcg", quality="!@#$")
-        self.assertEqual("$#@!", read.reverseComplement().quality)
+        read = DNARead('id', 'atcg', quality='!@#$')
+        self.assertEqual('$#@!', read.reverseComplement().quality)
 
     def testReverseComplement(self):
         """
         The reverseComplement function must work.
         """
-        read = DNARead("id", "ATCG", quality="!@#$")
-        self.assertEqual("CGAT", read.reverseComplement().sequence)
+        read = DNARead('id', 'ATCG', quality='!@#$')
+        self.assertEqual('CGAT', read.reverseComplement().sequence)
 
     def testReverseComplementAmbiguous(self):
         """
         The reverseComplement function must work for a sequence that includes
         ambiguous bases.
         """
-        read = DNARead("id", "ATCGMRWSVHXN")
-        self.assertEqual("NXDBSWYKCGAT", read.reverseComplement().sequence)
+        read = DNARead('id', 'ATCGMRWSVHXN')
+        self.assertEqual('NXDBSWYKCGAT', read.reverseComplement().sequence)
 
     def testReverseComplementLowercaseLetters(self):
         """
         The reverseComplement function must correctly reverse complement
         lowercase letters. The issue is described here:
         https://github.com/acorg/dark-matter/issues/662
         """
-        read = DNARead("id", "CAGCAGctgcagcaccagcaccagcagcttcCACAT")
-        expected = "ATGTGgaagctgctggtgctggtgctgcagCTGCTG"
+        read = DNARead('id', 'CAGCAGctgcagcaccagcaccagcagcttcCACAT')
+        expected = ('ATGTGgaagctgctggtgctggtgctgcagCTGCTG')
         self.assertEqual(expected, read.reverseComplement().sequence)
 
     def testTranslationsOfEmptySequence(self):
         """
         The translations function must correctly return all six (empty)
         translations of the empty sequence.
         """
-        read = DNARead("id", "")
+        read = DNARead('id', '')
         self.assertEqual(
             [
-                TranslatedRead(read, "", 0, False),
-                TranslatedRead(read, "", 1, False),
-                TranslatedRead(read, "", 2, False),
-                TranslatedRead(read, "", 0, True),
-                TranslatedRead(read, "", 1, True),
-                TranslatedRead(read, "", 2, True),
+                TranslatedRead(read, '', 0, False),
+                TranslatedRead(read, '', 1, False),
+                TranslatedRead(read, '', 2, False),
+                TranslatedRead(read, '', 0, True),
+                TranslatedRead(read, '', 1, True),
+                TranslatedRead(read, '', 2, True)
             ],
-            list(read.translations()),
-        )
+            list(read.translations()))
 
     def testTranslationsOfOneBaseSequence(self):
         """
         The translations function must correctly return all six translations
         of a sequence with just one base.
         """
-        read = DNARead("id", "a")
+        read = DNARead('id', 'a')
         self.assertEqual(
             [
-                TranslatedRead(read, "X", 0, False),
-                TranslatedRead(read, "", 1, False),
-                TranslatedRead(read, "", 2, False),
-                TranslatedRead(read, "X", 0, True),
-                TranslatedRead(read, "", 1, True),
-                TranslatedRead(read, "", 2, True),
+                TranslatedRead(read, 'X', 0, False),
+                TranslatedRead(read, '', 1, False),
+                TranslatedRead(read, '', 2, False),
+                TranslatedRead(read, 'X', 0, True),
+                TranslatedRead(read, '', 1, True),
+                TranslatedRead(read, '', 2, True)
             ],
-            list(read.translations()),
-        )
+            list(read.translations()))
 
     def testTranslationsOfTwoBaseSequence(self):
         """
         The translations function must correctly return all six translations
         of a sequence with just two bases.
         """
-        read = DNARead("id", "AG")
+        read = DNARead('id', 'AG')
         self.assertEqual(
             [
-                TranslatedRead(read, "X", 0, False),
-                TranslatedRead(read, "X", 1, False),
-                TranslatedRead(read, "", 2, False),
-                TranslatedRead(read, "L", 0, True),
-                TranslatedRead(read, "X", 1, True),
-                TranslatedRead(read, "", 2, True),
+                TranslatedRead(read, 'X', 0, False),
+                TranslatedRead(read, 'X', 1, False),
+                TranslatedRead(read, '', 2, False),
+                TranslatedRead(read, 'L', 0, True),
+                TranslatedRead(read, 'X', 1, True),
+                TranslatedRead(read, '', 2, True)
             ],
-            list(read.translations()),
-        )
+            list(read.translations()))
 
     def testTranslationOfStopCodonTAG(self):
         """
         The translations function must correctly translate the TAG stop codon.
         """
-        read = DNARead("id", "tag")
-        self.assertEqual(TranslatedRead(read, "*", 0, False), next(read.translations()))
+        read = DNARead('id', 'tag')
+        self.assertEqual(
+            TranslatedRead(read, '*', 0, False),
+            next(read.translations()))
 
     def testTranslationOfStopCodonTGA(self):
         """
         The translations function must correctly translate the TGA stop codon.
         """
-        read = DNARead("id", "tga")
-        self.assertEqual(TranslatedRead(read, "*", 0, False), next(read.translations()))
+        read = DNARead('id', 'tga')
+        self.assertEqual(
+            TranslatedRead(read, '*', 0, False),
+            next(read.translations()))
 
     def testTranslationOfMultipleStopCodons(self):
         """
         The translations function must correctly translate multiple stop codons
         in a sequence.
         """
-        read = DNARead("id", "taatagtga")
+        read = DNARead('id', 'taatagtga')
         self.assertEqual(
-            TranslatedRead(read, "***", 0, False), next(read.translations())
-        )
+            TranslatedRead(read, '***', 0, False),
+            next(read.translations()))
 
     def testTranslationOfStartCodonATG(self):
         """
         The translations function must correctly translate the ATG start codon
         to a methionine (M).
         """
-        read = DNARead("id", "atg")
-        self.assertEqual(TranslatedRead(read, "M", 0, False), next(read.translations()))
+        read = DNARead('id', 'atg')
+        self.assertEqual(
+            TranslatedRead(read, 'M', 0, False),
+            next(read.translations()))
 
     def testTranslations(self):
         """
         The translations function must correctly return all six translations.
         """
-        read = DNARead("id", "ACCGTCAGG")
+        read = DNARead('id', 'ACCGTCAGG')
         self.assertEqual(
             [
-                TranslatedRead(read, "TVR", 0, False),
-                TranslatedRead(read, "PSG", 1, False),
-                TranslatedRead(read, "RQX", 2, False),
-                TranslatedRead(read, "PDG", 0, True),
-                TranslatedRead(read, "LTV", 1, True),
-                TranslatedRead(read, "*RX", 2, True),
+                TranslatedRead(read, 'TVR', 0, False),
+                TranslatedRead(read, 'PSG', 1, False),
+                TranslatedRead(read, 'RQX', 2, False),
+                TranslatedRead(read, 'PDG', 0, True),
+                TranslatedRead(read, 'LTV', 1, True),
+                TranslatedRead(read, '*RX', 2, True)
             ],
-            list(read.translations()),
-        )
+            list(read.translations()))
 
 
 class TestRNARead(TestCase):
     """
     Tests for the RNARead class.
     """
-
     def testGetitemReturnsNewRNARead(self):
         """
         __getitem__ must return a new RNARead instance.
         """
-        self.assertIs(RNARead, RNARead("id", "ACGU")[0:3].__class__)
+        self.assertIs(RNARead, RNARead('id', 'ACGU')[0:3].__class__)
 
     def testReverseComplement(self):
         """
         The reverseComplement function must work.
         """
-        read = RNARead("id", "AUCG")
-        self.assertEqual("CGAU", read.reverseComplement().sequence)
+        read = RNARead('id', 'AUCG')
+        self.assertEqual('CGAU', read.reverseComplement().sequence)
 
     def testReverseComplementAmbiguous(self):
         """
         The reverseComplement function must work for a sequence that includes
         ambiguous bases.
         """
-        read = RNARead("id", "AUCGMRWSYKVHXN")
-        self.assertEqual("NXDBMRSWYKCGAU", read.reverseComplement().sequence)
+        read = RNARead('id', 'AUCGMRWSYKVHXN')
+        self.assertEqual('NXDBMRSWYKCGAU', read.reverseComplement().sequence)
 
     def testTranslationOfStopCodonUAA(self):
         """
         The translations function must correctly translate the UAA stop codon.
         """
-        read = RNARead("id", "UAA")
-        self.assertEqual(TranslatedRead(read, "*", 0, False), next(read.translations()))
+        read = RNARead('id', 'UAA')
+        self.assertEqual(
+            TranslatedRead(read, '*', 0, False),
+            next(read.translations()))
 
 
 class TestDNAKozakRead(TestCase):
     """
     Test the DNAKozakRead class.
     """
-
     def testSequence(self):
         """
         A DNAKozakRead instance must have the correct sequence.
         """
-        originalRead = DNARead("id", "AAGTAAGGGCTGTGA")
+        originalRead = DNARead('id', 'AAGTAAGGGCTGTGA')
         read = DNAKozakRead(originalRead, 0, 4, 100.0)
-        self.assertEqual("AAGT", read.sequence)
+        self.assertEqual('AAGT', read.sequence)
 
     def testStart(self):
         """
         A DNAKozakRead instance must store the correct start offset.
         """
-        originalRead = DNARead("id", "AAGTAAGGGCTGTGA")
+        originalRead = DNARead('id', 'AAGTAAGGGCTGTGA')
         read = DNAKozakRead(originalRead, 2, 4, 100.0)
         self.assertEqual(2, read.start)
 
     def testStop(self):
         """
         A DNAKozakRead instance must store the correct stop offset.
         """
-        originalRead = DNARead("id", "AAGTAAGGGCTGTGA")
+        originalRead = DNARead('id', 'AAGTAAGGGCTGTGA')
         read = DNAKozakRead(originalRead, 2, 4, 100.0)
         self.assertEqual(4, read.stop)
         read = DNAKozakRead(originalRead, 4, 10, 100.0)
         self.assertEqual(10, read.stop)
 
     def testStartNegative(self):
         """
         A DNAKozakRead start offset must not be less than zero.
         """
-        originalRead = DNARead("id", "AAGTAAGGGCTGTGA")
-        error = r"^start offset \(-1\) less than zero$"
+        originalRead = DNARead('id', 'AAGTAAGGGCTGTGA')
+        error = r'^start offset \(-1\) less than zero$'
         six.assertRaisesRegex(
-            self, ValueError, error, DNAKozakRead, originalRead, -1, 6, 100.0
-        )
+            self, ValueError, error, DNAKozakRead, originalRead, -1, 6, 100.0)
 
     def testStartGreaterThanStop(self):
         """
         A DNAKozakRead start offset must not be greater than its stop offset.
         """
-        originalRead = DNARead("id", "AAGTAAGGGCTGTGA")
-        error = r"start offset \(4\) greater than stop offset \(0\)"
+        originalRead = DNARead('id', 'AAGTAAGGGCTGTGA')
+        error = r'start offset \(4\) greater than stop offset \(0\)'
         six.assertRaisesRegex(
-            self, ValueError, error, DNAKozakRead, originalRead, 4, 0, 100.0
-        )
+            self, ValueError, error, DNAKozakRead, originalRead, 4, 0, 100.0)
 
     def testStopGreaterThanOriginalSequenceLength(self):
         """
         A DNAKozakRead stop offset must not be greater than the length of the
         original sequence.
         """
-        originalRead = DNARead("id", "AAGTAA")
-        error = r"stop offset \(10\) > original read length \(6\)"
+        originalRead = DNARead('id', 'AAGTAA')
+        error = r'stop offset \(10\) > original read length \(6\)'
         six.assertRaisesRegex(
-            self, ValueError, error, DNAKozakRead, originalRead, 0, 10, 100.0
-        )
+            self, ValueError, error, DNAKozakRead, originalRead, 0, 10, 100.0)
 
     def testEqualFunction(self):
         """
         A DNAKozakRead needs to compare correctly to an equal other
         DNAKozakRead.
         """
-        originalRead = DNARead("id", "AAGTAAGGGCTGTGA")
+        originalRead = DNARead('id', 'AAGTAAGGGCTGTGA')
         kozakRead1 = DNAKozakRead(originalRead, 0, 4, 100.0)
         kozakRead2 = DNAKozakRead(originalRead, 0, 4, 100.0)
         self.assertEqual(kozakRead1, kozakRead2)
 
     def testEqualFunctionDifferentOriginalSequence(self):
         """
         A DNAKozakRead needs to compare correctly to a different other
         DNAKozakRead.
         """
-        originalRead1 = DNARead("id", "AAGTAAGGGCTGTGA")
-        originalRead2 = DNARead("id", "AAGTAAGGGCTGTGAAA")
+        originalRead1 = DNARead('id', 'AAGTAAGGGCTGTGA')
+        originalRead2 = DNARead('id', 'AAGTAAGGGCTGTGAAA')
         kozakRead1 = DNAKozakRead(originalRead1, 0, 4, 100.0)
         kozakRead2 = DNAKozakRead(originalRead2, 0, 4, 100.0)
         self.assertNotEqual(kozakRead1, kozakRead2)
 
     def testEqualFunctionDifferentKozakSequence(self):
         """
         A DNAKozakRead needs to compare correctly to a different other
         DNAKozakRead.
         """
-        originalRead1 = DNARead("id", "AAGTAAGGGCTGTGA")
-        originalRead2 = DNARead("id", "AAGTAAGGGCTGTGAAA")
+        originalRead1 = DNARead('id', 'AAGTAAGGGCTGTGA')
+        originalRead2 = DNARead('id', 'AAGTAAGGGCTGTGAAA')
         kozakRead1 = DNAKozakRead(originalRead1, 0, 4, 100.0)
         kozakRead2 = DNAKozakRead(originalRead2, 1, 5, 100.0)
         self.assertNotEqual(kozakRead1, kozakRead2)
 
 
 class TestAARead(TestCase):
     """
     Tests for the AARead class.
     """
-
     def testGetitemReturnsNewAARead(self):
         """
         __getitem__ must return a new AARead instance.
         """
-        self.assertIs(AARead, AARead("id", "ACGU")[0:3].__class__)
+        self.assertIs(AARead, AARead('id', 'ACGU')[0:3].__class__)
 
     def testPropertiesCorrectTranslation(self):
         """
         The properties function must work correctly.
         """
-        read = AARead("id", "ADR*")
+        read = AARead('id', 'ADR*')
         properties = read.properties()
         self.assertEqual(
             [
                 HYDROPHOBIC | SMALL | TINY,
                 HYDROPHILIC | SMALL | POLAR | NEGATIVE,
                 HYDROPHILIC | POLAR | BASIC_POSITIVE,
-                NONE,
+                NONE
             ],
-            list(properties),
+            list(properties)
         )
 
     def testPropertyDetailsCorrectTranslation(self):
         """
         The propertyDetails function must return the right property details
         sequence.
         """
-        read = AARead("id", "ADR*")
+        read = AARead('id', 'ADR*')
         properties = read.propertyDetails()
         self.assertEqual(
             [
                 {
-                    "polarity": -0.20987654321,
-                    "aliphaticity": 0.305785123967,
-                    "volume": -0.664670658683,
-                    "polar requirement": -0.463414634146,
-                    "hydropathy": 0.4,
-                    "iep": -0.191489361702,
-                    "hydroxythiolation": -0.265160523187,
-                    "aromaticity": -0.550128534704,
-                    "hydrogenation": 0.8973042362,
-                    "composition": -1.0,
+                    'polarity': -0.20987654321,
+                    'aliphaticity': 0.305785123967,
+                    'volume': -0.664670658683,
+                    'polar requirement': -0.463414634146,
+                    'hydropathy': 0.4,
+                    'iep': -0.191489361702,
+                    'hydroxythiolation': -0.265160523187,
+                    'aromaticity': -0.550128534704,
+                    'hydrogenation': 0.8973042362,
+                    'composition': -1.0
                 },
                 {
-                    "polarity": 1.0,
-                    "aliphaticity": -0.818181818182,
-                    "volume": -0.389221556886,
-                    "polar requirement": 1.0,
-                    "hydropathy": -0.777777777778,
-                    "iep": -1.0,
-                    "hydroxythiolation": -0.348394768133,
-                    "aromaticity": -1.0,
-                    "hydrogenation": -0.90243902439,
-                    "composition": 0.00363636363636,
+                    'polarity': 1.0,
+                    'aliphaticity': -0.818181818182,
+                    'volume': -0.389221556886,
+                    'polar requirement': 1.0,
+                    'hydropathy': -0.777777777778,
+                    'iep': -1.0,
+                    'hydroxythiolation': -0.348394768133,
+                    'aromaticity': -1.0,
+                    'hydrogenation': -0.90243902439,
+                    'composition': 0.00363636363636
                 },
                 {
-                    "polarity": 0.382716049383,
-                    "aliphaticity": -0.157024793388,
-                    "volume": 0.449101796407,
-                    "polar requirement": 0.0487804878049,
-                    "hydropathy": -1.0,
-                    "iep": 1.0,
-                    "hydroxythiolation": -0.51486325802,
-                    "aromaticity": -0.0642673521851,
-                    "hydrogenation": -0.401797175866,
-                    "composition": -0.527272727273,
+                    'polarity': 0.382716049383,
+                    'aliphaticity': -0.157024793388,
+                    'volume': 0.449101796407,
+                    'polar requirement': 0.0487804878049,
+                    'hydropathy': -1.0,
+                    'iep': 1.0,
+                    'hydroxythiolation': -0.51486325802,
+                    'aromaticity': -0.0642673521851,
+                    'hydrogenation': -0.401797175866,
+                    'composition': -0.527272727273
                 },
-                NONE,
-            ],
-            list(properties),
+                NONE],
+            list(properties)
         )
 
     def testORFsEmptySequence(self):
         """
         An AA read of length zero must not have any ORFs.
         """
-        read = AARead("id", "")
+        read = AARead('id', '')
         orfs = list(read.ORFs(True))
         self.assertEqual(0, len(orfs))
 
     def testORFsEmptySequenceWithStartStop(self):
         """
         An AA read with just a start and stop codon must not have any ORFs.
         """
-        read = AARead("id", "M*")
+        read = AARead('id', 'M*')
         orfs = list(read.ORFs(False))
         self.assertEqual(0, len(orfs))
 
     def testORFsEmptySequenceWithStartStopOpenORFs(self):
         """
         An AA read with just a start and stop codon must have one ORF.
         """
-        read = AARead("id", "M*")
+        read = AARead('id', 'M*')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
 
     def testORFsEmptySequenceWithStopStartOpenORFs(self):
         """
         An AA read with just a start and stop codon must have one ORF.
         """
-        read = AARead("id", "*M")
+        read = AARead('id', '*M')
         orfs = list(read.ORFs(True))
         self.assertEqual(0, len(orfs))
 
     def testORFsEmptySequenceWithStart(self):
         """
         An AA read with just a start codon must not have any ORFs.
         """
-        read = AARead("id", "M")
+        read = AARead('id', 'M')
         orfs = list(read.ORFs(False))
         self.assertEqual(0, len(orfs))
 
     def testORFsEmptySequenceWithStartOpenORFs(self):
         """
         An AA read with just a start codon must have one ORF.
         """
-        read = AARead("id", "M")
+        read = AARead('id', 'M')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
 
     def testORFsSequenceWithOneAAOpenORFs(self):
         """
         An AA read with just a start codon must have one ORF.
         """
-        read = AARead("id", "A")
+        read = AARead('id', 'A')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
 
     def testORFsWithOneStopCodon(self):
         """
         An AA read of a single stop codon must not have any ORFs.
         """
-        read = AARead("id", "*")
+        read = AARead('id', '*')
         orfs = list(read.ORFs(False))
         self.assertEqual(0, len(orfs))
 
     def testORFsWithOneStopCodonOpenORFs(self):
         """
         An AA read of a single stop codon must not have any ORFs.
         """
-        read = AARead("id", "*")
+        read = AARead('id', '*')
         orfs = list(read.ORFs(True))
         self.assertEqual(0, len(orfs))
 
     def testORFsWithTwoStopCodons(self):
         """
         An AA read of two stop codons must not have any ORFs.
         """
-        read = AARead("id", "**")
+        read = AARead('id', '**')
         orfs = list(read.ORFs(True))
         self.assertEqual(0, len(orfs))
 
     def testORFsWithJustStartsAndStops(self):
         """
         An AA read of only start and stop codons must not have any ORFs.
         """
-        read = AARead("id", "**MM*M**MMM*")
+        read = AARead('id', '**MM*M**MMM*')
         orfs = list(read.ORFs(False))
         self.assertEqual(2, len(orfs))
 
     def testOpenOpenORF(self):
         """
         An AA read that contains no start or stop codons should result in
         just one AAReadORF when its ORFs method is called. The ORF must have
         the correct start/stop offsets and its left and right side must be
         marked as open.
         """
-        read = AARead("id", "ADRADR")
+        read = AARead('id', 'ADRADR')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
         orf = orfs[0]
-        self.assertEqual("ADRADR", orf.sequence)
+        self.assertEqual('ADRADR', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(6, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertTrue(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:6)")
+        self.assertEqual(orf.id, 'id-(0:6)')
 
     def testOpenCloseORF(self):
         """
         An AA read that contains no start codon but one trailing stop
         codon should result in just one AAReadORF when its ORFs method is
         called. The ORF must have the correct start/stop offsets and its
         left and right sides must be marked as open and closed,
         respectively.
         """
-        read = AARead("id", "ADRADR*")
+        read = AARead('id', 'ADRADR*')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
         orf = orfs[0]
-        self.assertEqual("ADRADR", orf.sequence)
+        self.assertEqual('ADRADR', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(6, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:6]")
+        self.assertEqual(orf.id, 'id-(0:6]')
 
     def testOpenCloseORFWithMultipleStops(self):
         """
         An AA read that contains no start codon but multiple trailing
         stop codons should result in just one AAReadORF when its ORFs
         method is called. The ORF must have the correct start/stop offsets
         and its left and right sides must be marked as open and closed,
         respectively.
         """
-        read = AARead("id", "ADRADR***")
+        read = AARead('id', 'ADRADR***')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
         orf = orfs[0]
-        self.assertEqual("ADRADR", orf.sequence)
+        self.assertEqual('ADRADR', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(6, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:6]")
+        self.assertEqual(orf.id, 'id-(0:6]')
 
     def testCloseOpenORFWithMultipleStarts(self):
         """
         An AA read that contains multiple initial start codons but no
         stop codon should result in just one AAReadORF when its ORFs method
         is called. The ORF must have the correct start/stop offsets and its
         left and right sides must be marked as closed and open,
         respectively.
         """
-        read = AARead("id", "MMMADRADR")
+        read = AARead('id', 'MMMADRADR')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
         orf = orfs[0]
-        self.assertEqual("MMMADRADR", orf.sequence)
+        self.assertEqual('MMMADRADR', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(9, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertTrue(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:9)")
+        self.assertEqual(orf.id, 'id-(0:9)')
 
     def testCloseCloseORF(self):
         """
         An AA read that contains a start and a stop codon should result in
         just one AAReadORF when its ORFs method is called. The ORF must have
         the correct start/stop offsets and its left and right sides must be
         both marked as closed.
         """
-        read = AARead("id", "MADRADR*")
+        read = AARead('id', 'MADRADR*')
         orfs = list(read.ORFs(False))
         self.assertEqual(1, len(orfs))
         orf = orfs[0]
-        self.assertEqual("ADRADR", orf.sequence)
+        self.assertEqual('ADRADR', orf.sequence)
         self.assertEqual(1, orf.start)
         self.assertEqual(7, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[1:7]")
+        self.assertEqual(orf.id, 'id-[1:7]')
 
     def testCloseCloseORFWithJunk(self):
         """
         An AA read that contains a start and a stop codon should result in
         just one AAReadORF when its ORFs method is called. The ORF must have
         the correct start/stop offsets and its left and right sides must be
         both marked as closed.
         """
-        read = AARead("id", "AAAMADRADR*")
+        read = AARead('id', 'AAAMADRADR*')
         [orf] = list(read.ORFs(False))
-        self.assertEqual("ADRADR", orf.sequence)
+        self.assertEqual('ADRADR', orf.sequence)
         self.assertEqual(4, orf.start)
         self.assertEqual(10, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[4:10]")
+        self.assertEqual(orf.id, 'id-[4:10]')
 
     def testOpenCloseThenCloseOpenORF(self):
         """
         An AA read that contains an ORF that is left open and right closed
         followed by an ORF that is left closed and right open must have the
         ORFs detected correctly when its ORFs method is called.
         """
-        read = AARead("id", "ADR*MRRR")
+        read = AARead('id', 'ADR*MRRR')
         orfs = list(read.ORFs(True))
         self.assertEqual(2, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(3, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:3]")
+        self.assertEqual(orf.id, 'id-(0:3]')
 
         orf = orfs[1]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(5, orf.start)
         self.assertEqual(8, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertTrue(orf.openRight)
-        self.assertEqual(orf.id, "id-[5:8)")
+        self.assertEqual(orf.id, 'id-[5:8)')
 
     def testCloseCloseThenCloseOpenORF(self):
         """
         An AA read that contains an ORF that is left and right closed
         followed by an ORF that is left closed and right open must have the
         ORFs detected correctly when its ORFs method is called.
         """
-        read = AARead("id", "*MADR*MRRR")
+        read = AARead('id', '*MADR*MRRR')
         orfs = list(read.ORFs(True))
         self.assertEqual(2, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(2, orf.start)
         self.assertEqual(5, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[2:5]")
+        self.assertEqual(orf.id, 'id-[2:5]')
 
         orf = orfs[1]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(7, orf.start)
         self.assertEqual(10, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertTrue(orf.openRight)
-        self.assertEqual(orf.id, "id-[7:10)")
+        self.assertEqual(orf.id, 'id-[7:10)')
 
     def testCloseCloseThenCloseCloseORF(self):
         """
         An AA read that contains two ORFs that are both left and right closed
         must have the ORFs detected correctly when its ORFs method is called.
         """
-        read = AARead("id", "MADR*MRRR*")
+        read = AARead('id', 'MADR*MRRR*')
         orfs = list(read.ORFs(False))
         self.assertEqual(2, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(1, orf.start)
         self.assertEqual(4, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[1:4]")
+        self.assertEqual(orf.id, 'id-[1:4]')
 
         orf = orfs[1]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(6, orf.start)
         self.assertEqual(9, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[6:9]")
+        self.assertEqual(orf.id, 'id-[6:9]')
 
     def testOpenCloseThenCloseCloseThenCloseOpenORF(self):
         """
         An AA read that contains an ORF that is left open and right closed
         followed by an internal ORF, followed by an ORF that is left closed
         and right open must have the ORFs detected correctly when its ORFs
         method is called.
         """
-        read = AARead("id", "ADR*MAAA*MRRR")
+        read = AARead('id', 'ADR*MAAA*MRRR')
         orfs = list(read.ORFs(True))
         self.assertEqual(3, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(3, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:3]")
+        self.assertEqual(orf.id, 'id-(0:3]')
 
         orf = orfs[1]
-        self.assertEqual("AAA", orf.sequence)
+        self.assertEqual('AAA', orf.sequence)
         self.assertEqual(5, orf.start)
         self.assertEqual(8, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[5:8]")
+        self.assertEqual(orf.id, 'id-[5:8]')
 
         orf = orfs[2]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(10, orf.start)
         self.assertEqual(13, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertTrue(orf.openRight)
-        self.assertEqual(orf.id, "id-[10:13)")
+        self.assertEqual(orf.id, 'id-[10:13)')
 
     def testCloseCloseThenCloseCloseThenNothingORF(self):
         """
         An AA read that contains an ORF that is left and right closed
         followed by an internal ORF, followed by an ORF that is left closed
         and right open must have the ORFs detected correctly when its ORFs
         method is called.
         """
-        read = AARead("id", "MADR*MAAA*MRRR")
+        read = AARead('id', 'MADR*MAAA*MRRR')
         orfs = list(read.ORFs(False))
         self.assertEqual(2, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(1, orf.start)
         self.assertEqual(4, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[1:4]")
+        self.assertEqual(orf.id, 'id-[1:4]')
 
         orf = orfs[1]
-        self.assertEqual("AAA", orf.sequence)
+        self.assertEqual('AAA', orf.sequence)
         self.assertEqual(6, orf.start)
         self.assertEqual(9, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[6:9]")
+        self.assertEqual(orf.id, 'id-[6:9]')
 
     def testCloseCloseThenCloseCloseThenCloseCloseORF(self):
         """
         An AA read that contains an ORF that is left and right closed
         followed by an internal ORF, followed by an ORF that is left and
         right closed must have the ORFs detected correctly when its ORFs
         method is called.
         """
-        read = AARead("id", "MADR*MAAA*MRRR*")
+        read = AARead('id', 'MADR*MAAA*MRRR*')
         orfs = list(read.ORFs(False))
         self.assertEqual(3, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(1, orf.start)
         self.assertEqual(4, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[1:4]")
+        self.assertEqual(orf.id, 'id-[1:4]')
 
         orf = orfs[1]
-        self.assertEqual("AAA", orf.sequence)
+        self.assertEqual('AAA', orf.sequence)
         self.assertEqual(6, orf.start)
         self.assertEqual(9, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[6:9]")
+        self.assertEqual(orf.id, 'id-[6:9]')
 
         orf = orfs[2]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(11, orf.start)
         self.assertEqual(14, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[11:14]")
+        self.assertEqual(orf.id, 'id-[11:14]')
 
     def testOpenCloseThenCloseCloseThenCloseOpenORFWithJunk(self):
         """
         An AA read that contains an ORF that is left open and right closed
         followed by an internal ORF, followed by an ORF that is left closed
         and right open must have the ORFs detected correctly when its ORFs
         method is called, including when there are intermediate start and
         stop codons.
         """
-        read = AARead("id", "ADR***M*MAAA***MMM*MRRR")
+        read = AARead('id', 'ADR***M*MAAA***MMM*MRRR')
         orfs = list(read.ORFs(True))
         self.assertEqual(4, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(3, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:3]")
+        self.assertEqual(orf.id, 'id-(0:3]')
 
         orf = orfs[1]
-        self.assertEqual("AAA", orf.sequence)
+        self.assertEqual('AAA', orf.sequence)
         self.assertEqual(9, orf.start)
         self.assertEqual(12, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[9:12]")
+        self.assertEqual(orf.id, 'id-[9:12]')
 
         orf = orfs[2]
-        self.assertEqual("MM", orf.sequence)
+        self.assertEqual('MM', orf.sequence)
         self.assertEqual(16, orf.start)
         self.assertEqual(18, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[16:18]")
+        self.assertEqual(orf.id, 'id-[16:18]')
 
         orf = orfs[3]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(20, orf.start)
         self.assertEqual(23, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertTrue(orf.openRight)
-        self.assertEqual(orf.id, "id-[20:23)")
+        self.assertEqual(orf.id, 'id-[20:23)')
 
     def testCloseCloseThenCloseCloseThenCloseOpenORFWithJunk(self):
         """
         An AA read that contains an ORF that is left and right closed
         followed by an internal ORF, followed by an ORF that is left closed
         and right open must have the ORFs detected correctly when its ORFs
         method is called.
         """
-        read = AARead("id", "**MADR***MM**MAAA***M*MRRR")
+        read = AARead('id', '**MADR***MM**MAAA***M*MRRR')
         orfs = list(read.ORFs(True))
         self.assertEqual(4, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(3, orf.start)
         self.assertEqual(6, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[3:6]")
+        self.assertEqual(orf.id, 'id-[3:6]')
 
         orf = orfs[1]
-        self.assertEqual("M", orf.sequence)
+        self.assertEqual('M', orf.sequence)
         self.assertEqual(10, orf.start)
         self.assertEqual(11, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[10:11]")
+        self.assertEqual(orf.id, 'id-[10:11]')
 
         orf = orfs[2]
-        self.assertEqual("AAA", orf.sequence)
+        self.assertEqual('AAA', orf.sequence)
         self.assertEqual(14, orf.start)
         self.assertEqual(17, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[14:17]")
+        self.assertEqual(orf.id, 'id-[14:17]')
 
         orf = orfs[3]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(23, orf.start)
         self.assertEqual(26, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertTrue(orf.openRight)
-        self.assertEqual(orf.id, "id-[23:26)")
+        self.assertEqual(orf.id, 'id-[23:26)')
 
     def testCloseCloseThenCloseCloseThenCloseCloseORFWithJunk(self):
         """
         An AA read that contains an ORF that is left and right closed
         followed by an internal ORF, followed by an ORF that is left and
         right closed must have the ORFs detected correctly when its ORFs
         method is called.
         """
-        read = AARead("id", "M***MADR***MAAA***MRRR***MM")
+        read = AARead('id', 'M***MADR***MAAA***MRRR***MM')
         orfs = list(read.ORFs(False))
         self.assertEqual(3, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("ADR", orf.sequence)
+        self.assertEqual('ADR', orf.sequence)
         self.assertEqual(5, orf.start)
         self.assertEqual(8, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[5:8]")
+        self.assertEqual(orf.id, 'id-[5:8]')
 
         orf = orfs[1]
-        self.assertEqual("AAA", orf.sequence)
+        self.assertEqual('AAA', orf.sequence)
         self.assertEqual(12, orf.start)
         self.assertEqual(15, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[12:15]")
+        self.assertEqual(orf.id, 'id-[12:15]')
 
         orf = orfs[2]
-        self.assertEqual("RRR", orf.sequence)
+        self.assertEqual('RRR', orf.sequence)
         self.assertEqual(19, orf.start)
         self.assertEqual(22, orf.stop)
         self.assertFalse(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-[19:22]")
+        self.assertEqual(orf.id, 'id-[19:22]')
 
     def testNoStartCodon_GithubIssue239(self):
         """
         If there is no start codon in a sequence, it should not be returned
         as an ORF.
         """
         # Example from https://github.com/acorg/dark-matter/issues/239
-        read = AARead("id", "KK*LLILFSCQRWSRKSICVHLTQR*G*")
+        read = AARead('id', 'KK*LLILFSCQRWSRKSICVHLTQR*G*')
         orfs = list(read.ORFs(True))
         self.assertEqual(1, len(orfs))
 
         orf = orfs[0]
-        self.assertEqual("KK", orf.sequence)
+        self.assertEqual('KK', orf.sequence)
         self.assertEqual(0, orf.start)
         self.assertEqual(2, orf.stop)
         self.assertTrue(orf.openLeft)
         self.assertFalse(orf.openRight)
-        self.assertEqual(orf.id, "id-(0:2]")
+        self.assertEqual(orf.id, 'id-(0:2]')
 
 
 class TestAAReadWithX(TestCase):
     """
     Tests for the TestAAReadWithX class.
     """
-
     def testGetitemReturnsNewAAReadWithX(self):
         """
         __getitem__ must return a new AAReadWithX instance.
         """
-        self.assertIs(AAReadWithX, AAReadWithX("id", "ACGU")[0:3].__class__)
+        self.assertIs(AAReadWithX, AAReadWithX('id', 'ACGU')[0:3].__class__)
 
     def testAlphabet(self):
         """
         The correct alphabet must be used.
         """
-        read = AAReadWithX("id", "ATFDX")
-        expected = set("ACDEFGHIKLMNPQRSTVWXY")
+        read = AAReadWithX('id', 'ATFDX')
+        expected = set('ACDEFGHIKLMNPQRSTVWXY')
         self.assertEqual(expected, read.ALPHABET)
 
     def testAlphabetChecking(self):
         """
         The alphabet check must work.
         """
-        read = AAReadWithX("id", "ARDGGCFFXEE")
-        self.assertEqual(set("ARDGCFFXE"), read.checkAlphabet())
+        read = AAReadWithX('id', 'ARDGGCFFXEE')
+        self.assertEqual(set('ARDGCFFXE'), read.checkAlphabet())
 
 
 class TestAAReadORF(TestCase):
     """
     Test the AAReadORF class.
     """
-
     def testSequence(self):
         """
         An AAReadORF instance must have the correct sequence.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 0, 4, True, True)
-        self.assertEqual("ADRA", read.sequence)
+        self.assertEqual('ADRA', read.sequence)
 
     def testStart(self):
         """
         An AAReadORF instance must store the correct start offset.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 3, 4, True, True)
         self.assertEqual(3, read.start)
         read = AAReadORF(originalRead, 4, 4, True, True)
         self.assertEqual(4, read.start)
 
     def testStop(self):
         """
         An AAReadORF instance must store the correct stop offset.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 0, 4, True, True)
         self.assertEqual(4, read.stop)
         read = AAReadORF(originalRead, 0, 6, True, True)
         self.assertEqual(6, read.stop)
 
     def testOpenLeft(self):
         """
         An AAReadORF instance must store the correct openLeft value.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 0, 4, True, True)
         self.assertTrue(read.openLeft)
         read = AAReadORF(originalRead, 0, 4, False, True)
         self.assertFalse(read.openLeft)
 
     def testOpenRight(self):
         """
         An AAReadORF instance must store the correct openRight value.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 0, 4, True, True)
         self.assertTrue(read.openRight)
         read = AAReadORF(originalRead, 0, 4, True, False)
         self.assertFalse(read.openRight)
 
     def testStartGreaterThanStop(self):
         """
         An AAReadORF start offset must not be greater than its stop offset.
         """
-        originalRead = AARead("id", "ADRADR")
-        error = r"start offset \(4\) greater than stop offset \(0\)"
+        originalRead = AARead('id', 'ADRADR')
+        error = r'start offset \(4\) greater than stop offset \(0\)'
         six.assertRaisesRegex(
-            self, ValueError, error, AAReadORF, originalRead, 4, 0, True, True
-        )
+            self, ValueError, error, AAReadORF, originalRead, 4, 0, True, True)
 
     def testStartNegative(self):
         """
         An AAReadORF start offset must not be less than zero.
         """
-        originalRead = AARead("id", "ADRADR")
-        error = r"start offset \(-1\) less than zero"
+        originalRead = AARead('id', 'ADRADR')
+        error = r'start offset \(-1\) less than zero'
         six.assertRaisesRegex(
-            self, ValueError, error, AAReadORF, originalRead, -1, 6, True, True
-        )
+            self, ValueError, error, AAReadORF, originalRead, -1, 6, True,
+            True)
 
     def testStopGreaterThanOriginalSequenceLength(self):
         """
         An AAReadORF stop offset must not be greater than the length of the
         original sequence.
         """
-        originalRead = AARead("id", "ADRADR")
-        error = r"stop offset \(10\) > original read length \(6\)"
+        originalRead = AARead('id', 'ADRADR')
+        error = r'stop offset \(10\) > original read length \(6\)'
         six.assertRaisesRegex(
-            self, ValueError, error, AAReadORF, originalRead, 0, 10, True, True
-        )
+            self, ValueError, error, AAReadORF, originalRead, 0, 10, True,
+            True)
 
     def testOpenOpenId(self):
         """
         An AAReadORF instance must have a correctly annotated (containing the
         sequence offsets) id when the left and right sides of the ORF are open.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 3, 4, True, True)
-        self.assertEqual("id-(3:4)", read.id)
+        self.assertEqual('id-(3:4)', read.id)
 
     def testOpenClosedId(self):
         """
         An AAReadORF instance must have a correctly annotated (containing the
         sequence offsets) id when the left side of the ORF is open and the
         right is closed.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 3, 4, True, False)
-        self.assertEqual("id-(3:4]", read.id)
+        self.assertEqual('id-(3:4]', read.id)
 
     def testClosedOpenId(self):
         """
         An AAReadORF instance must have a correctly annotated (containing the
         sequence offsets) id when the left side of the ORF is closed and the
         right is open.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 3, 4, False, True)
-        self.assertEqual("id-[3:4)", read.id)
+        self.assertEqual('id-[3:4)', read.id)
 
     def testClosedClosedId(self):
         """
         An AAReadORF instance must have a correctly annotated (containing the
         sequence offsets) id when both sides of the ORF are closed.
         """
-        originalRead = AARead("id", "ADRADR")
+        originalRead = AARead('id', 'ADRADR')
         read = AAReadORF(originalRead, 3, 4, False, False)
-        self.assertEqual("id-[3:4]", read.id)
+        self.assertEqual('id-[3:4]', read.id)
 
     def testToDict(self):
         """
         toDict must return the correct dictionary.
         """
-        originalRead = AARead("id3", "ACGT", "!!2&")
+        originalRead = AARead('id3', 'ACGT', '!!2&')
         read = AAReadORF(originalRead, 1, 3, True, False)
         self.assertEqual(
             {
-                "id": "id3-(1:3]",
-                "sequence": "CG",
-                "quality": "!2",
-                "start": 1,
-                "stop": 3,
-                "openLeft": True,
-                "openRight": False,
+                'id': 'id3-(1:3]',
+                'sequence': 'CG',
+                'quality': '!2',
+                'start': 1,
+                'stop': 3,
+                'openLeft': True,
+                'openRight': False,
             },
-            read.toDict(),
-        )
+            read.toDict())
 
     def testFromDict(self):
         """
         fromDict must return the expected instance.
         """
-        originalRead = AARead("id3", "ACGT", "!!2&")
+        originalRead = AARead('id3', 'ACGT', '!!2&')
         self.assertEqual(
             AAReadORF(originalRead, 1, 3, True, False),
-            AAReadORF.fromDict(
-                {
-                    "id": "id3-(1:3]",
-                    "sequence": "CG",
-                    "quality": "!2",
-                    "start": 1,
-                    "stop": 3,
-                    "openLeft": True,
-                    "openRight": False,
-                }
-            ),
-        )
+            AAReadORF.fromDict({
+                'id': 'id3-(1:3]',
+                'sequence': 'CG',
+                'quality': '!2',
+                'start': 1,
+                'stop': 3,
+                'openLeft': True,
+                'openRight': False,
+            }))
 
 
-class _TestSSAAReadMixin:
+class _TestSSAAReadMixin(object):
     """
     Mixin class with tests for the SSAARead and SSAAReadWithX classes.
     """
-
     def testSequenceLengthMatchesStructureLength(self):
         """
         An SSAARead (or SSAAReadWithX) must have sequence and structure
         lengths that are the same.
         """
-        error = r"^Invalid read: sequence length \(4\) != structure " r"length \(3\)$"
+        error = (
+            r'^Invalid read: sequence length \(4\) != structure '
+            r'length \(3\)$')
         with six.assertRaisesRegex(self, ValueError, error):
-            self.CLASS("id", "ACGT", "!!!")
+            self.CLASS('id', 'ACGT', '!!!')
 
     def testCorrectAttributes(self):
         """
         An SSAARead (or SSAAReadWithX) must have the correct attributes.
         """
-        read = self.CLASS("id", "AFGGCED", "HHH  HH")
-        self.assertEqual("id", read.id)
-        self.assertEqual("AFGGCED", read.sequence)
-        self.assertEqual("HHH  HH", read.structure)
+        read = self.CLASS('id', 'AFGGCED', 'HHH  HH')
+        self.assertEqual('id', read.id)
+        self.assertEqual('AFGGCED', read.sequence)
+        self.assertEqual('HHH  HH', read.structure)
         self.assertIs(None, read.quality)
 
     def testReads(self):
         """
         It must be possible to make a dark.Reads object out of SSAARead
         (or SSAAReadWithX) instances, and the result must have the correct
         length.
         """
         reads = Reads()
-        reads.add(self.CLASS("id1", "AFGGCED", "HHHHHHH"))
-        reads.add(self.CLASS("id2", "AFGGKLL", "HHHHIII"))
+        reads.add(self.CLASS('id1', 'AFGGCED', 'HHHHHHH'))
+        reads.add(self.CLASS('id2', 'AFGGKLL', 'HHHHIII'))
         self.assertEqual(2, len(list(reads)))
 
     def testGetitemReturnsNewRead(self):
         """
         __getitem__ must return a new instance of the correct class.
         """
-        self.assertIs(self.CLASS, self.CLASS("id", "ACGT", "HHHH")[0:3].__class__)
+        self.assertIs(self.CLASS,
+                      self.CLASS('id', 'ACGT', 'HHHH')[0:3].__class__)
 
     def testGetitemId(self):
         """
         __getitem__ must return a new instance with the same read id.
         """
-        self.assertEqual("id-12", self.CLASS("id-12", "FFRR", "HHHH")[0:3].id)
+        self.assertEqual('id-12', self.CLASS('id-12', 'FFRR', 'HHHH')[0:3].id)
 
     def testGetitemSequence(self):
         """
         __getitem__ must return a new instance with the expected sequence.
         """
-        self.assertEqual("RM", self.CLASS("id", "FRML", "HHHH")[1:3].sequence)
+        self.assertEqual('RM', self.CLASS('id', 'FRML', 'HHHH')[1:3].sequence)
 
     def testGetitemStructure(self):
         """
         __getitem__ must return a new instance with the expected structure.
         """
-        self.assertEqual("HE", self.CLASS("id", "FFRR", "HEIS")[0:2].structure)
+        self.assertEqual('HE', self.CLASS('id', 'FFRR', 'HEIS')[0:2].structure)
 
     def testGetitemLength(self):
         """
         __getitem__ must return a new instance of the expected length.
         """
-        self.assertEqual(3, len(self.CLASS("id-1234", "FFMM", "HHHH")[0:3]))
+        self.assertEqual(3, len(self.CLASS('id-1234', 'FFMM', 'HHHH')[0:3]))
 
     def testGetitemSingleIndex(self):
         """
         A single-index __getitem__ must return a length-one instance.
         """
-        self.assertEqual(1, len(self.CLASS("id", "FRFR", "HHHH")[0]))
+        self.assertEqual(1, len(self.CLASS('id', 'FRFR', 'HHHH')[0]))
 
     def testGetitemFullCopy(self):
         """
         A full copy __getitem__ must return the expected result.
         """
-        self.assertEqual(
-            self.CLASS("id", "RRFF", "HEIH"), self.CLASS("id", "RRFF", "HEIH")[:]
-        )
+        self.assertEqual(self.CLASS('id', 'RRFF', 'HEIH'),
+                         self.CLASS('id', 'RRFF', 'HEIH')[:])
 
     def testGetitemWithStep(self):
         """
         A stepped __getitem__ must return the expected result.
         """
-        self.assertEqual(
-            self.CLASS("id", "FR", "HS"), self.CLASS("id", "FMRL", "HESE")[::2]
-        )
+        self.assertEqual(self.CLASS('id', 'FR', 'HS'),
+                         self.CLASS('id', 'FMRL', 'HESE')[::2])
 
     def testGetitemReversed(self):
         """
         A reverse copy __getitem__ must return the expected result.
         """
-        self.assertEqual(
-            self.CLASS("id", "FRML", "HESB"), self.CLASS("id", "LMRF", "BSEH")[::-1]
-        )
+        self.assertEqual(self.CLASS('id', 'FRML', 'HESB'),
+                         self.CLASS('id', 'LMRF', 'BSEH')[::-1])
 
     def testToString(self):
         """
         toString must return the expected 2 FASTA records (one of which is
         the structure information).
         """
         self.assertEqual(
-            ">id-1234\n" "FFMM\n" ">id-1234:structure\n" "HHHH\n",
-            self.CLASS("id-1234", "FFMM", "HHHH").toString(),
-        )
+            '>id-1234\n'
+            'FFMM\n'
+            '>id-1234:structure\n'
+            'HHHH\n',
+            self.CLASS('id-1234', 'FFMM', 'HHHH').toString())
 
     def testToStringWithStructureSuffix(self):
         """
         toString must return the expected 2 FASTA records when given a
         specific structure id suffix.
         """
         self.assertEqual(
-            ">id-12\n" "FFMM\n" ">id-12:x\n" "HHHH\n",
-            self.CLASS("id-12", "FFMM", "HHHH").toString(structureSuffix=":x"),
-        )
+            '>id-12\n'
+            'FFMM\n'
+            '>id-12:x\n'
+            'HHHH\n',
+            self.CLASS('id-12', 'FFMM', 'HHHH').toString(structureSuffix=':x'))
 
     def testToStringWithExplicitFastaSSFormat(self):
         """
         toString must return the expected 2 FASTA records when 'fasta-ss' is
         passed as the C{format_} argument.
         """
         self.assertEqual(
-            ">id-1234\n" "FFMM\n" ">id-1234:structure\n" "HHHH\n",
-            self.CLASS("id-1234", "FFMM", "HHHH").toString(format_="fasta-ss"),
-        )
+            '>id-1234\n'
+            'FFMM\n'
+            '>id-1234:structure\n'
+            'HHHH\n',
+            self.CLASS('id-1234', 'FFMM', 'HHHH').toString(format_='fasta-ss'))
 
     def testToStringWithExplicitFastaFormat(self):
         """
         toString must return normal FASTA when 'fasta' is passed as the
         C{format_} argument.
         """
         self.assertEqual(
-            ">id-1234\n" "FFMM\n",
-            self.CLASS("id-1234", "FFMM", "HHHH").toString(format_="fasta"),
-        )
+            '>id-1234\n'
+            'FFMM\n',
+            self.CLASS('id-1234', 'FFMM', 'HHHH').toString(format_='fasta'))
 
     def testToStringWithUnknownFormat(self):
         """
         toString must raise ValueError when something other than 'fasta' or
         'fasta-ss' is passed as the C{format_} argument.
         """
-        read = self.CLASS("id-1234", "FFMM", "HHHH")
+        read = self.CLASS('id-1234', 'FFMM', 'HHHH')
         error = r"^Format must be either 'fasta', 'fastq' or 'fasta-ss'\."
-        six.assertRaisesRegex(self, ValueError, error, read.toString, format_="pasta")
+        six.assertRaisesRegex(
+            self, ValueError, error, read.toString, format_='pasta')
 
     def testToDict(self):
         """
         toDict must return the correct dictionary.
         """
-        read = SSAARead("id3", "ACGT", "HHEE")
+        read = SSAARead('id3', 'ACGT', 'HHEE')
         self.assertEqual(
             {
-                "id": "id3",
-                "sequence": "ACGT",
-                "structure": "HHEE",
+                'id': 'id3',
+                'sequence': 'ACGT',
+                'structure': 'HHEE',
             },
-            read.toDict(),
-        )
+            read.toDict())
 
     def testFromDict(self):
         """
         fromDict must return the expected instance.
         """
         self.assertEqual(
-            SSAARead("id3", "ACGT", "HHEE"),
-            SSAARead.fromDict(
-                {
-                    "id": "id3",
-                    "sequence": "ACGT",
-                    "structure": "HHEE",
-                }
-            ),
-        )
+            SSAARead('id3', 'ACGT', 'HHEE'),
+            SSAARead.fromDict({
+                'id': 'id3',
+                'sequence': 'ACGT',
+                'structure': 'HHEE',
+            }))
 
     def testHashDiffersIfIdDiffers(self):
         """
         The __hash__ value for two reads must differ if their ids differ.
         """
-        self.assertNotEqual(
-            hash(self.CLASS("id1", "AA", "HH")), hash(self.CLASS("id2", "AA", "HH"))
-        )
+        self.assertNotEqual(hash(self.CLASS('id1', 'AA', 'HH')),
+                            hash(self.CLASS('id2', 'AA', 'HH')))
 
     def testHashDiffersIfSequenceDiffers(self):
         """
         The __hash__ value for two reads must differ if their sequence strings
         differ.
         """
-        self.assertNotEqual(
-            hash(self.CLASS("id", "MMR", "HHH")), hash(self.CLASS("id", "MMF", "HHH"))
-        )
+        self.assertNotEqual(hash(self.CLASS('id', 'MMR', 'HHH')),
+                            hash(self.CLASS('id', 'MMF', 'HHH')))
 
     def testHashDiffersIfStructureDiffers(self):
         """
         The __hash__ value for two reads must differ if their structure strings
         differ.
         """
-        self.assertNotEqual(
-            hash(self.CLASS("id", "AA", "HH")), hash(self.CLASS("id", "AA", "HE"))
-        )
+        self.assertNotEqual(hash(self.CLASS('id', 'AA', 'HH')),
+                            hash(self.CLASS('id', 'AA', 'HE')))
 
     def testHashViaSet(self):
         """
         If two identical reads are put into a set, the set must have size one.
         """
-        read = self.CLASS("id", "AA", "HH")
+        read = self.CLASS('id', 'AA', 'HH')
         self.assertEqual(1, len(set([read, read])))
 
     def testHashViaDict(self):
         """
         If two identical reads are used as keys in a dict, the dict must have
         size one.
         """
-        read = self.CLASS("id", "AA", "HH")
+        read = self.CLASS('id', 'AA', 'HH')
         self.assertEqual(1, len(dict.fromkeys([read, read])))
 
     def testKeepSites(self):
         """
         If only a certain set of sites should be kept, newFromSites should
         return a read with the correct sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "TC", "HG"),
-            self.CLASS("id1", "ATCGAT", "CHGCCX").newFromSites({1, 2}),
-        )
+        self.assertEqual(self.CLASS('id1', 'TC', 'HG'),
+                         self.CLASS('id1', 'ATCGAT', 'CHGCCX').newFromSites(
+                             {1, 2}))
 
     def testKeepSitesNoSites(self):
         """
         If an empty set of sites should be kept, newFromSites should
         return a read with the correct (empty) sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "", ""),
-            self.CLASS("id1", "ATCGAT", "CHGCCC").newFromSites(set()),
-        )
+        self.assertEqual(self.CLASS('id1', '', ''),
+                         self.CLASS('id1', 'ATCGAT', 'CHGCCC').newFromSites(
+                             set()))
 
     def testKeepSitesAllSites(self):
         """
         If all sites should be kept, newFromSites should return a read
         with the correct (full) sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "ATCGAT", "CHGCCC"),
-            self.CLASS("id1", "ATCGAT", "CHGCCC").newFromSites(set(range(6))),
-        )
+        self.assertEqual(self.CLASS('id1', 'ATCGAT', 'CHGCCC'),
+                         self.CLASS('id1', 'ATCGAT', 'CHGCCC').newFromSites(
+                             set(range(6))))
 
     def testKeepSitesOutOfRange(self):
         """
         If only a certain set of sites should be kept, but the kept sites
         are higher than the length of the input sequences, newFromSites
         should return a read with the correct (empty) sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "", ""),
-            self.CLASS("id1", "ATCGAT", "CHGCCC").newFromSites({100, 200}),
-        )
+        self.assertEqual(self.CLASS('id1', '', ''),
+                         self.CLASS('id1', 'ATCGAT', 'CHGCCC').newFromSites(
+                             {100, 200}))
 
     def testRemoveSites(self):
         """
         If only a certain set of sites should be removed, newFromSites
         should return a read with the correct sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "AGAT", "CSHG"),
-            self.CLASS("id1", "ATCGAT", "CXXSHG").newFromSites({1, 2}, exclude=True),
-        )
+        self.assertEqual(self.CLASS('id1', 'AGAT', 'CSHG'),
+                         self.CLASS('id1', 'ATCGAT', 'CXXSHG').newFromSites(
+                             {1, 2}, exclude=True))
 
     def testRemoveSitesNoSites(self):
         """
         If the empty set of sites should be removed, newFromSites
         should return a read with the correct (full) sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "ATCGAT", "CXXSHG"),
-            self.CLASS("id1", "ATCGAT", "CXXSHG").newFromSites(set(), exclude=True),
-        )
+        self.assertEqual(self.CLASS('id1', 'ATCGAT', 'CXXSHG'),
+                         self.CLASS('id1', 'ATCGAT', 'CXXSHG').newFromSites(
+                             set(), exclude=True))
 
     def testRemoveSitesAllSites(self):
         """
         If all sites should be removed, newFromSites should return a read
         with the correct (empty) sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "", ""),
-            self.CLASS("id1", "ATCGAT", "CXXSHG").newFromSites(
-                set(range(6)), exclude=True
-            ),
-        )
+        self.assertEqual(self.CLASS('id1', '', ''),
+                         self.CLASS('id1', 'ATCGAT', 'CXXSHG').newFromSites(
+                             set(range(6)), exclude=True))
 
     def testRemoveSitesOutOfRange(self):
         """
         If only a certain set of sites should be removed, but the removed
         sites are higher than the length of the input sequences,
         newFromSites should return a read with the correct (full) sequence.
         """
-        self.assertEqual(
-            self.CLASS("id1", "ATCGAT", "HGSTCC"),
-            self.CLASS("id1", "ATCGAT", "HGSTCC").newFromSites(
-                {100, 200}, exclude=True
-            ),
-        )
+        self.assertEqual(self.CLASS('id1', 'ATCGAT', 'HGSTCC'),
+                         self.CLASS('id1', 'ATCGAT', 'HGSTCC').newFromSites(
+                             {100, 200}, exclude=True))
 
 
 class TestSSAARead(TestCase, _TestSSAAReadMixin):
     """
     Tests for the SSAARead class.
     """
-
     CLASS = SSAARead
 
 
 class TestSSAAReadWithX(TestCase, _TestSSAAReadMixin):
     """
     Tests for the SSAAReadWithX class.
     """
-
     CLASS = SSAAReadWithX
 
     def testSequenceContainingX(self):
         """
         An SSAAReadWithX must be able to contain an 'X' character.
         """
-        self.assertEqual("AFGX", SSAAReadWithX("id", "AFGX", "HHHH").sequence)
+        self.assertEqual('AFGX', SSAAReadWithX('id', 'AFGX', 'HHHH').sequence)
 
 
 class TestTranslatedRead(TestCase):
     """
     Test the TranslatedRead class.
     """
 
     def testExpectedAttributes(self):
         """
         A TranslatedRead instance must have the expected attributes.
         """
-        read = Read("id", "atcgatcgatcg")
-        translated = TranslatedRead(read, "IRDS", 0)
-        self.assertEqual("IRDS", translated.sequence)
+        read = Read('id', 'atcgatcgatcg')
+        translated = TranslatedRead(read, 'IRDS', 0)
+        self.assertEqual('IRDS', translated.sequence)
         self.assertEqual(0, translated.frame)
 
     def testSequence(self):
         """
         A TranslatedRead instance must have the expected sequence.
         """
-        read = Read("id", "atcgatcgatcg")
-        translated = TranslatedRead(read, "IRDS", 0)
-        self.assertEqual("IRDS", translated.sequence)
+        read = Read('id', 'atcgatcgatcg')
+        translated = TranslatedRead(read, 'IRDS', 0)
+        self.assertEqual('IRDS', translated.sequence)
 
     def testOutOfRangeFrame(self):
         """
         A TranslatedRead instance must raise a ValueError if the passed frame
         is not 0, 1, or 2.
         """
-        read = Read("id", "atcgatcgatcg")
-        error = "Frame must be 0, 1, or 2"
-        six.assertRaisesRegex(self, ValueError, error, TranslatedRead, read, "IRDS", 3)
+        read = Read('id', 'atcgatcgatcg')
+        error = 'Frame must be 0, 1, or 2'
+        six.assertRaisesRegex(self, ValueError, error, TranslatedRead, read,
+                              'IRDS', 3)
 
     def testExpectedFrame(self):
         """
         A TranslatedRead instance must have the expected frame.
         """
-        read = Read("id", "atcgatcgatcg")
-        translated = TranslatedRead(read, "IRDS", 2)
+        read = Read('id', 'atcgatcgatcg')
+        translated = TranslatedRead(read, 'IRDS', 2)
         self.assertEqual(2, translated.frame)
 
     def testReverseComplemented(self):
         """
         A TranslatedRead instance must have the expected reversedComplemented
         value.
         """
-        read = Read("id", "atcgatcgatcg")
-        translated = TranslatedRead(read, "IRDS", 0)
+        read = Read('id', 'atcgatcgatcg')
+        translated = TranslatedRead(read, 'IRDS', 0)
         self.assertFalse(translated.reverseComplemented)
-        translated = TranslatedRead(read, "IRDS", 0, reverseComplemented=True)
+        translated = TranslatedRead(read, 'IRDS', 0, reverseComplemented=True)
         self.assertTrue(translated.reverseComplemented)
 
     def testId(self):
         """
         A TranslatedRead instance must put the the frame information into its
         read id.
         """
-        read = Read("id", "atcgatcgatcg")
-        translated = TranslatedRead(read, "IRDS", 0)
-        self.assertEqual("id-frame0", translated.id)
+        read = Read('id', 'atcgatcgatcg')
+        translated = TranslatedRead(read, 'IRDS', 0)
+        self.assertEqual('id-frame0', translated.id)
 
     def testIdReverseComplemented(self):
         """
         A TranslatedRead instance must put the the frame information into its
         read id when the original read was reverse complemented.
         """
-        read = Read("id", "atcgatcgatcg")
-        translated = TranslatedRead(read, "IRDS", 1, True)
-        self.assertEqual("id-frame1rc", translated.id)
+        read = Read('id', 'atcgatcgatcg')
+        translated = TranslatedRead(read, 'IRDS', 1, True)
+        self.assertEqual('id-frame1rc', translated.id)
 
     def testMaximumORFLengthNoStops(self):
         """
         The maximumORFLength function must return the correct value when
         there are no stop codons in a translated read.
         """
-        read = Read("id", "atcgatcgatcg")
-        translated = TranslatedRead(read, "IRDS", 0)
+        read = Read('id', 'atcgatcgatcg')
+        translated = TranslatedRead(read, 'IRDS', 0)
         self.assertEqual(4, translated.maximumORFLength())
 
     def testMaximumORFLength(self):
         """
         The maximumORFLength function must return the correct value.
         """
-        read = Read("id", "acctagatggttgtttag")
-        translated = TranslatedRead(read, "T*MVV*", 0)
+        read = Read('id', 'acctagatggttgtttag')
+        translated = TranslatedRead(read, 'T*MVV*', 0)
         self.assertEqual(2, translated.maximumORFLength())
 
     def testMaximumORFLengthNoOpenORF(self):
         """
         The maximumORFLength function must return the correct value if
         open ORFs are not allowed.
         """
-        read = Read("id", "atgacctagatggttgtttag")
-        translated = TranslatedRead(read, "MT*MVV*", 0)
+        read = Read('id', 'atgacctagatggttgtttag')
+        translated = TranslatedRead(read, 'MT*MVV*', 0)
         self.assertEqual(2, translated.maximumORFLength(False))
 
     def testToDict(self):
         """
         toDict must return the correct dictionary.
         """
-        originalRead = AARead("id3", "ACGT", "!!2&")
-        read = TranslatedRead(originalRead, "MMMM", 0, True)
+        originalRead = AARead('id3', 'ACGT', '!!2&')
+        read = TranslatedRead(originalRead, 'MMMM', 0, True)
         self.assertEqual(
             {
-                "id": "id3-frame0rc",
-                "sequence": "MMMM",
-                "quality": None,
-                "frame": 0,
-                "reverseComplemented": True,
+                'id': 'id3-frame0rc',
+                'sequence': 'MMMM',
+                'quality': None,
+                'frame': 0,
+                'reverseComplemented': True,
             },
-            read.toDict(),
-        )
+            read.toDict())
 
     def testFromDict(self):
         """
         fromDict must return the expected instance.
         """
-        originalRead = AARead("id3", "ACGT")
+        originalRead = AARead('id3', 'ACGT')
         self.assertEqual(
-            TranslatedRead(originalRead, "MMMM", 0, True),
-            TranslatedRead.fromDict(
-                {
-                    "id": "id3-frame0rc",
-                    "sequence": "MMMM",
-                    "quality": None,
-                    "frame": 0,
-                    "reverseComplemented": True,
-                }
-            ),
-        )
+            TranslatedRead(originalRead, 'MMMM', 0, True),
+            TranslatedRead.fromDict({
+                'id': 'id3-frame0rc',
+                'sequence': 'MMMM',
+                'quality': None,
+                'frame': 0,
+                'reverseComplemented': True,
+            }))
 
 
 class TestReadClassNameToClass(TestCase):
     """
     Test that the light.reads.readClassNameToClass dictionary is correct.
     """
-
     def testNames(self):
         self.assertEqual(9, len(readClassNameToClass))
-        self.assertIs(AARead, readClassNameToClass["AARead"])
-        self.assertIs(AAReadORF, readClassNameToClass["AAReadORF"])
-        self.assertIs(AAReadWithX, readClassNameToClass["AAReadWithX"])
-        self.assertIs(DNARead, readClassNameToClass["DNARead"])
-        self.assertIs(RNARead, readClassNameToClass["RNARead"])
-        self.assertIs(Read, readClassNameToClass["Read"])
-        self.assertIs(SSAARead, readClassNameToClass["SSAARead"])
-        self.assertIs(SSAAReadWithX, readClassNameToClass["SSAAReadWithX"])
-        self.assertIs(TranslatedRead, readClassNameToClass["TranslatedRead"])
+        self.assertIs(AARead, readClassNameToClass['AARead'])
+        self.assertIs(AAReadORF, readClassNameToClass['AAReadORF'])
+        self.assertIs(AAReadWithX, readClassNameToClass['AAReadWithX'])
+        self.assertIs(DNARead, readClassNameToClass['DNARead'])
+        self.assertIs(RNARead, readClassNameToClass['RNARead'])
+        self.assertIs(Read, readClassNameToClass['Read'])
+        self.assertIs(SSAARead, readClassNameToClass['SSAARead'])
+        self.assertIs(SSAAReadWithX, readClassNameToClass['SSAAReadWithX'])
+        self.assertIs(TranslatedRead, readClassNameToClass['TranslatedRead'])
 
 
 class TestReads(TestCase):
     """
     Test the Reads class.
     """
 
@@ -2266,16 +2152,16 @@
         self.assertEqual(0, len(list(reads)))
 
     def testManuallyAddedReads(self):
         """
         A Reads instance with reads added manually must be able to be listed.
         """
         reads = Reads()
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         self.assertEqual([read1, read2], list(reads))
 
     def testEmptyInitialReads(self):
         """
         A Reads instance must be able to accept an empty initial iterable of
@@ -2285,68 +2171,68 @@
         self.assertEqual([], list(reads))
 
     def testInitialReads(self):
         """
         A Reads instance must be able to accept a non-empty initial iterable
         of reads.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads = Reads(initialReads=[read1, read2])
         self.assertEqual([read1, read2], list(reads))
 
     def testManuallyAddedReadsLength(self):
         """
         A Reads instance with reads added manually must have the correct
         length.
         """
         reads = Reads()
-        reads.add(Read("id1", "AT"))
-        reads.add(Read("id2", "AC"))
+        reads.add(Read('id1', 'AT'))
+        reads.add(Read('id2', 'AC'))
         self.assertEqual(2, len(list(reads)))
 
     def testSubclass(self):
         """
         A Reads subclass with an iter method must result in an instance
         with a correct iterator.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
 
         class ReadsSubclass(Reads):
             def iter(self):
                 yield read1
                 yield read2
 
         reads = ReadsSubclass()
         self.assertEqual([read1, read2], list(reads))
 
     def testSubclassLength(self):
         """
         A Reads subclass with an iter method must result in an instance
         with a correct length.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
 
         class ReadsSubclass(Reads):
             def iter(self):
                 yield read1
                 yield read2
 
         reads = ReadsSubclass()
         self.assertEqual(2, len(list(reads)))
 
     def testRepeatedIter(self):
         """
         A Reads subclass with an iter method must be able to be listed
         more than once.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
 
         class ReadsSubclass(Reads):
             def iter(self):
                 yield read1
                 yield read2
 
         reads = ReadsSubclass()
@@ -2354,17 +2240,17 @@
         self.assertEqual([read1, read2], list(reads))
 
     def testSubclassWithAdditionalReads(self):
         """
         A Reads subclass with an iter method that is then added to manually
         must result in an instance with a correct iterator.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
-        read3 = Read("id3", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
+        read3 = Read('id3', 'AC')
 
         class ReadsSubclass(Reads):
             def iter(self):
                 yield read1
                 yield read2
 
         reads = ReadsSubclass()
@@ -2373,150 +2259,147 @@
 
     def testSaveWithUnknownFormat(self):
         """
         A Reads instance must raise ValueError if asked to save in an unknown
         format.
         """
         reads = Reads()
-        read1 = Read("id1", "AT", "!!")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT', '!!')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         error = r"Format must be either 'fasta', 'fastq' or 'fasta-ss'\."
-        six.assertRaisesRegex(self, ValueError, error, reads.save, "file", "xxx")
+        six.assertRaisesRegex(self, ValueError, error, reads.save, 'file',
+                              'xxx')
         # The output file must not exist following the save() failure.
         error = "No such file or directory: 'file'"
-        six.assertRaisesRegex(self, OSError, error, stat, "file")
+        six.assertRaisesRegex(self, OSError, error, stat, 'file')
 
     def testSaveFASTAIsDefault(self):
         """
         A Reads instance must save in FASTA format by default.
         """
         reads = Reads()
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         mockOpener = mock_open()
-        with patch.object(builtins, "open", mockOpener):
-            reads.save("filename")
+        with patch.object(builtins, 'open', mockOpener):
+            reads.save('filename')
         handle = mockOpener()
-        self.assertEqual(
-            [call(">id1\nAT\n"), call(">id2\nAC\n")], handle.write.mock_calls
-        )
+        self.assertEqual([call('>id1\nAT\n'), call('>id2\nAC\n')],
+                         handle.write.mock_calls)
 
     def testSaveAsFASTA(self):
         """
         A Reads instance must be able to save in FASTA format.
         """
         reads = Reads()
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         mockOpener = mock_open()
-        with patch.object(builtins, "open", mockOpener):
-            reads.save("filename", "fasta")
+        with patch.object(builtins, 'open', mockOpener):
+            reads.save('filename', 'fasta')
         handle = mockOpener()
-        self.assertEqual(
-            [call(">id1\nAT\n"), call(">id2\nAC\n")], handle.write.mock_calls
-        )
+        self.assertEqual([call('>id1\nAT\n'), call('>id2\nAC\n')],
+                         handle.write.mock_calls)
 
     def testSaveReturnsReadCount(self):
         """
         The save method on a Reads instance must return the number
         of reads in the instance.
         """
         reads = Reads()
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         mockOpener = mock_open()
-        with patch.object(builtins, "open", mockOpener):
-            result = reads.save("filename")
+        with patch.object(builtins, 'open', mockOpener):
+            result = reads.save('filename')
             self.assertIs(2, result)
 
     def testSaveWithUppercaseFormat(self):
         """
         A Reads instance must save correctly when the format string is
         given in upper case.
         """
         reads = Reads()
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         mockOpener = mock_open()
-        with patch.object(builtins, "open", mockOpener):
-            reads.save("filename", "FASTA")
+        with patch.object(builtins, 'open', mockOpener):
+            reads.save('filename', 'FASTA')
         handle = mockOpener()
-        self.assertEqual(
-            [call(">id1\nAT\n"), call(">id2\nAC\n")], handle.write.mock_calls
-        )
+        self.assertEqual([call('>id1\nAT\n'), call('>id2\nAC\n')],
+                         handle.write.mock_calls)
 
     def testSaveAsFASTQ(self):
         """
         A Reads instance must be able to save in FASTQ format.
         """
         reads = Reads()
-        read1 = Read("id1", "AT", "!!")
-        read2 = Read("id2", "AC", "@@")
+        read1 = Read('id1', 'AT', '!!')
+        read2 = Read('id2', 'AC', '@@')
         reads.add(read1)
         reads.add(read2)
         mockOpener = mock_open()
-        with patch.object(builtins, "open", mockOpener):
-            reads.save("filename", "fastq")
+        with patch.object(builtins, 'open', mockOpener):
+            reads.save('filename', 'fastq')
         handle = mockOpener()
         self.assertEqual(
-            [call("@id1\nAT\n+id1\n!!\n"), call("@id2\nAC\n+id2\n@@\n")],
-            handle.write.mock_calls,
-        )
+            [call('@id1\nAT\n+id1\n!!\n'), call('@id2\nAC\n+id2\n@@\n')],
+            handle.write.mock_calls)
 
     def testSaveAsFASTQFailsOnReadWithNoQuality(self):
         """
         A Reads instance must raise a ValueError if asked to save in FASTQ
         format and there is a read with no quality present.
         """
         reads = Reads()
-        read1 = Read("id1", "AT", "!!")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT', '!!')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         error = "Read 'id2' has no quality information"
-        six.assertRaisesRegex(self, ValueError, error, reads.save, "file", "fastq")
+        six.assertRaisesRegex(self, ValueError, error, reads.save, 'file',
+                              'fastq')
         # The output file must not exist following the save() failure.
         error = "No such file or directory: 'file'"
-        six.assertRaisesRegex(self, OSError, error, stat, "file")
+        six.assertRaisesRegex(self, OSError, error, stat, 'file')
 
     def testSaveToFileDescriptor(self):
         """
         A Reads instance must save to a file-like object if not passed a string
         filename.
         """
         reads = Reads()
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         fp = StringIO()
         reads.save(fp)
-        self.assertEqual(">id1\nAT\n>id2\nAC\n", fp.getvalue())
+        self.assertEqual('>id1\nAT\n>id2\nAC\n', fp.getvalue())
 
     def testUnfilteredLengthBeforeIterating(self):
         """
         A Reads instance must raise RuntimeError if its unfilteredLength method
         is called before it has been iterated.
         """
         reads = Reads()
-        error = (
-            r"^The unfiltered length of a Reads instance is unknown "
-            r"until it has been iterated\.$"
-        )
-        six.assertRaisesRegex(self, RuntimeError, error, reads.unfilteredLength)
+        error = (r'^The unfiltered length of a Reads instance is unknown '
+                 r'until it has been iterated\.$')
+        six.assertRaisesRegex(self, RuntimeError, error,
+                              reads.unfilteredLength)
 
     def testUnfilteredLengthNoReads(self):
         """
         A Reads instance with no reads must have an unfiltered length of zero.
         """
         reads = Reads()
         list(reads)
@@ -2524,100 +2407,100 @@
 
     def testUnfilteredLengthAdditionalReads(self):
         """
         A Reads instance that has been added to manually must have the correct
         unfiltered length.
         """
         reads = Reads()
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         list(reads)
         self.assertEqual(2, reads.unfilteredLength())
 
     def testUnfilteredLengthAdditionalReadsAfterFiltering(self):
         """
         A Reads instance that has been added to manually and then filtered must
         have the correct (original) unfiltered length and the filtered list it
         returns must be correct.
         """
         reads = Reads()
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'AC')
         reads.add(read1)
         reads.add(read2)
         reads.filter(minLength=3)
         self.assertEqual([read1], list(reads))
         self.assertEqual(2, reads.unfilteredLength())
 
     def testUnfilteredLengthInitialReads(self):
         """
         A Reads instance that has been given reads initially must have the
         correct unfiltered length.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
         reads = Reads([read1, read2])
         list(reads)
         self.assertEqual(2, reads.unfilteredLength())
 
     def testUnfilteredLengthInitialReadsAfterFiltering(self):
         """
         A Reads instance that has been given reads intially and then filtered
         must have the correct (original) unfiltered length and the filtered
         list it returns must be correct.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'AC')
         reads = Reads([read1, read2])
         reads.filter(minLength=3)
         self.assertEqual([read1], list(reads))
         self.assertEqual(2, reads.unfilteredLength())
 
     def testUnfilteredLengthInitialReadsIsReads(self):
         """
         A Reads instance that has been given another filtered Reads instance
         intially must have the correct (original) unfiltered length and the
         filtered list it returns must be correct.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'AC')
         initialReads = Reads([read1, read2])
         initialReads.filter(minLength=3)
 
         reads = Reads(initialReads)
         self.assertEqual([read1], list(reads))
         self.assertEqual(2, reads.unfilteredLength())
 
     def testUnfilteredLengthInitialReadsIsReadsWithAdditional(self):
         """
         A Reads instance that has been given another filtered Reads instance
         intially and then an additional read must have the correct (original)
         unfiltered length and the filtered list it returns must be correct.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'AC')
         initialReads = Reads([read1, read2])
         initialReads.filter(minLength=3)
 
-        read3 = Read("id3", "AC")
+        read3 = Read('id3', 'AC')
         reads = Reads(initialReads)
         reads.add(read3)
         self.assertEqual(sorted((read1, read3)), sorted(reads))
         self.assertEqual(3, reads.unfilteredLength())
 
     def testUnfilteredLengthInitialSubclassWithNoLen(self):
         """
         If a Reads instance is given a Reads subclass (with no __len__)
         instance intially, it must have the correct (original)
         unfiltered length and the filtered list it returns must be correct.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'AC')
 
         class Subclass(Reads):
             def iter(self):
                 yield read1
                 yield read2
 
         reads = Reads(Subclass())
@@ -2626,16 +2509,16 @@
 
     def testUnfilteredLengthInitialSubclassThenFiltered(self):
         """
         If a Reads instance is given a Reads subclass instance intially and is
         then filtered, it must have the correct (original) unfiltered length
         and the filtered list it returns must be correct.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'AC')
 
         class Subclass(Reads):
             def iter(self):
                 yield read1
                 yield read2
 
         reads = Reads(Subclass())
@@ -2646,17 +2529,17 @@
     def testUnfilteredLengthInitialSubclassWithAdditionalThenFiltered(self):
         """
         If a Reads instance is given a Reads subclass instance that has been
         added to intially and is then filtered, it must have the correct
         (original) unfiltered length and the filtered list it returns must be
         correct.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "AC")
-        read3 = Read("id3", "AC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'AC')
+        read3 = Read('id3', 'AC')
 
         class Subclass(Reads):
             def iter(self):
                 yield read1
                 yield read2
 
         initial = Subclass()
@@ -2667,321 +2550,321 @@
         self.assertEqual(3, reads.unfilteredLength())
 
     def testMaxNFractionAllPassNoNs(self):
         """
         Test filtering by maximum fraction of Ns. If there are no Ns in the
         sequences, all must pass the filtering.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "ATTAAC")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'ATTAAC')
         initialReads = Reads([read1, read2])
         initialReads.filter(maxNFraction=0.9)
 
         reads = Reads(initialReads)
         self.assertEqual([read1, read2], list(reads))
 
     def testMaxNFractionOnePasses(self):
         """
         Test filtering by maximum fraction of Ns. If there are too many Ns in
         one of the sequences, only one must pass the filtering.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "ATTNNN")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'ATTNNN')
         initialReads = Reads([read1, read2])
         initialReads.filter(maxNFraction=0.4)
 
         reads = Reads(initialReads)
         self.assertEqual([read1], list(reads))
 
     def testMaxNFractionAllPassNs(self):
         """
         Test filtering by maximum fraction of Ns. If there are Ns in the
         sequence, but below the threshold, all sequences must pass the
         filtering.
         """
-        read1 = Read("id1", "ATTA")
-        read2 = Read("id2", "ATTNNN")
+        read1 = Read('id1', 'ATTA')
+        read2 = Read('id2', 'ATTNNN')
         initialReads = Reads([read1, read2])
         initialReads.filter(maxNFraction=0.6)
 
         reads = Reads(initialReads)
         self.assertEqual([read1, read2], list(reads))
 
     def testNoVariableSitesConfirm(self):
         """
         If two Reads have no bases that are variable, nothing should be
         returned by the C{variableSites} method when confirm is True.
         """
-        read1 = Read("id1", "AC")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AC')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=True)
         self.assertEqual([], list(varSites))
 
     def testNoVariableSitesUnconfirm(self):
         """
         If two Reads have no bases that are variable, nothing should be
         returned by the C{variableSites} method when confirm is False.
         """
-        read1 = Read("id1", "AC")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AC')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=False)
         self.assertEqual([], list(varSites))
 
     def testOneVariableSitesConfirm(self):
         """
         If two Reads have one base that is variable, the site must be returned
         by the C{variableSites} method when confirm is True.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=True)
         self.assertEqual([1], list(varSites))
 
     def testOneVariableSitesUnconfirm(self):
         """
         If two Reads have one base that is variable, the site must be returned
         by the C{variableSites} method when confirm is False.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=False)
         self.assertEqual([1], list(varSites))
 
     def testOneAmbiguousIncompatibleVariableSitesConfirm(self):
         """
         If two Reads have one base that is variable and ambiguous (but
         incompatible) in one read, the site must be returned by the
         C{variableSites} method when confirm is True.
         """
-        read1 = Read("id1", "AW")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AW')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=True)
         self.assertEqual([1], list(varSites))
 
     def testOneAmbiguousIncompatibleVariableSitesUnconfirm(self):
         """
         If two Reads have one base that is variable and ambiguous (but
         incompatible) in one read, the site must be returned by the
         C{variableSites} method when confirm is False.
         """
-        read1 = Read("id1", "AW")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AW')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=False)
         self.assertEqual([1], list(varSites))
 
     def testOneAmbiguousCompatibleVariableSitesConfirm(self):
         """
         If two Reads have one base that is variable and ambiguous (and
         compatible) in one read, the site must not be returned by the
         C{variableSites} method when confirm is True.
         """
-        read1 = Read("id1", "AM")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AM')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=True)
         self.assertEqual([], list(varSites))
 
     def testOneAmbiguousCompatibleVariableSitesUnconfirm(self):
         """
         If two Reads have one base that is variable and ambiguous (and
         compatible) in one read, the site must be returned by the
         C{variableSites} method when confirm is False.
         """
-        read1 = Read("id1", "AM")
-        read2 = Read("id2", "AC")
+        read1 = Read('id1', 'AM')
+        read2 = Read('id2', 'AC')
 
         reads = Reads([read1, read2])
         varSites = reads.variableSites(confirm=False)
         self.assertEqual([1], list(varSites))
 
     def testVariableSitesTooHomogeneous(self):
         """
         If three Reads have one base that is variable but the site
         is too homogeneous, the site must not be returned by the
         C{variableSites} method.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
-        read3 = Read("id3", "AC")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
+        read3 = Read('id3', 'AC')
 
         reads = Reads([read1, read2, read3])
         varSites = reads.variableSites(homogeneityLevel=0.6)
         self.assertEqual([], list(varSites))
 
     def testVariableSitesHeterogeneous(self):
         """
         If three Reads have one base that is variable and the site
         is not too homogeneous, the site must be returned by the
         C{variableSites} method.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
-        read3 = Read("id3", "AG")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
+        read3 = Read('id3', 'AG')
 
         reads = Reads([read1, read2, read3])
         varSites = reads.variableSites(homogeneityLevel=0.6)
         self.assertEqual([1], list(varSites))
 
     def testVariableSitesHeterogeneousCounts(self):
         """
         If three Reads have one base that is variable and the site
         is not too homogeneous, the site must be returned by the
         C{variableSites} method and the counts must be as expected.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "AC")
-        read3 = Read("id3", "AG")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'AC')
+        read3 = Read('id3', 'AG')
 
         reads = Reads([read1, read2, read3])
         varSites = reads.variableSites(homogeneityLevel=0.6)
         self.assertEqual([1], list(varSites))
-        self.assertEqual({"T": 1.0, "C": 1.0, "G": 1.0}, varSites[1].counts)
+        self.assertEqual(
+            {'T': 1.0, 'C': 1.0, 'G': 1.0}, varSites[1].counts)
 
     def testVariableSitesUnequalLengths(self):
         """
         The C{variableSites} method must raise a ReadLengthsNotIdenticalError
         if all reads do not have the same length.
         """
-        read1 = Read("id1", "AT")
-        read2 = Read("id2", "ACG")
+        read1 = Read('id1', 'AT')
+        read2 = Read('id2', 'ACG')
 
         reads = Reads([read1, read2])
-        error = r"^$"
-        six.assertRaisesRegex(
-            self, ReadLengthsNotIdenticalError, error, reads.variableSites
-        )
+        error = r'^$'
+        six.assertRaisesRegex(self, ReadLengthsNotIdenticalError, error,
+                              reads.variableSites)
 
     def testCombineReadsIdentical(self):
         """
         Reads that are identical at a position must result in the correct
         combination.
         """
-        read1 = Read("id1", "A")
-        read2 = Read("id2", "A")
+        read1 = Read('id1', 'A')
+        read2 = Read('id2', 'A')
 
         reads = Reads([read1, read2])
         combined = reads.combineReads()
-        self.assertEqual("A", combined)
+        self.assertEqual('A', combined)
 
     def testCombineReadsNBaseTwoReads(self):
         """
         Reads where one has an N and the other has a base must result in the
         correct combination.
         """
-        read1 = Read("id1", "A")
-        read2 = Read("id2", "N")
+        read1 = Read('id1', 'A')
+        read2 = Read('id2', 'N')
 
         reads = Reads([read1, read2])
         combined = reads.combineReads()
-        self.assertEqual("A", combined)
+        self.assertEqual('A', combined)
 
     def testCombineReadsNBaseThreeReads(self):
         """
         Reads where one has an N and the other two have a base must result in
         the correct combination.
         """
-        read1 = Read("id1", "A")
-        read2 = Read("id2", "N")
-        read3 = Read("id3", "A")
+        read1 = Read('id1', 'A')
+        read2 = Read('id2', 'N')
+        read3 = Read('id3', 'A')
 
         reads = Reads([read1, read2, read3])
         combined = reads.combineReads()
-        self.assertEqual("A", combined)
+        self.assertEqual('A', combined)
 
     def testCombineReadsTwoDifferentBases(self):
         """
         Reads which have two different bases must return the correct
         combination.
         """
-        read1 = Read("id1", "T")
-        read2 = Read("id2", "A")
+        read1 = Read('id1', 'T')
+        read2 = Read('id2', 'A')
 
         reads = Reads([read1, read2])
         combined = reads.combineReads()
-        self.assertEqual("W", combined)
+        self.assertEqual('W', combined)
 
     def testCombineReadsThreeDifferentBases(self):
         """
         Reads which have three different bases must return the correct
         combination.
         """
-        read1 = Read("id1", "T")
-        read2 = Read("id2", "A")
-        read3 = Read("id3", "G")
+        read1 = Read('id1', 'T')
+        read2 = Read('id2', 'A')
+        read3 = Read('id3', 'G')
 
         reads = Reads([read1, read2, read3])
         combined = reads.combineReads()
-        self.assertEqual("D", combined)
+        self.assertEqual('D', combined)
 
     def testCombineReadsAmbiguityBase(self):
         """
         Reads where one has an ambiguity and the other has a base must result
         in the correct combination.
         """
-        read1 = Read("id1", "T")
-        read2 = Read("id2", "S")
+        read1 = Read('id1', 'T')
+        read2 = Read('id2', 'S')
 
         reads = Reads([read1, read2])
         combined = reads.combineReads()
-        self.assertEqual("B", combined)
+        self.assertEqual('B', combined)
 
     def testCombineReadsTwoAmbiguities(self):
         """
         Reads where one has an ambiguity and the other has a base must result
         in the correct combination.
         """
-        read1 = Read("id1", "M")
-        read2 = Read("id2", "S")
+        read1 = Read('id1', 'M')
+        read2 = Read('id2', 'S')
 
         reads = Reads([read1, read2])
         combined = reads.combineReads()
-        self.assertEqual("V", combined)
+        self.assertEqual('V', combined)
 
     def testCombineReadsNGap(self):
         """
         Positions with an N and a gap must result in the correct combination.
         """
-        read1 = Read("id1", "N")
-        read2 = Read("id2", "-")
+        read1 = Read('id1', 'N')
+        read2 = Read('id2', '-')
 
         reads = Reads([read1, read2])
         combined = reads.combineReads()
-        self.assertEqual("N", combined)
+        self.assertEqual('N', combined)
 
     def testCombineReadsBaseGap(self):
         """
         Positions with a base and a gap must result in the correct combination.
         """
-        read1 = Read("id1", "A")
-        read2 = Read("id2", "-")
+        read1 = Read('id1', 'A')
+        read2 = Read('id2', '-')
 
         reads = Reads([read1, read2])
         combined = reads.combineReads()
-        self.assertEqual("A", combined)
+        self.assertEqual('A', combined)
 
     def testCombineReadsUnequalLengthAssertionError(self):
         """
         If combineReads is called with reads of unequal length an
         AssertionError must be raised.
         """
-        read1 = Read("id1", "AAAA")
-        read2 = Read("id2", "T")
+        read1 = Read('id1', 'AAAA')
+        read2 = Read('id2', 'T')
 
         reads = Reads([read1, read2])
         self.assertRaises(AssertionError, reads.combineReads)
 
 
 class TestReadsFiltering(TestCase):
     """
@@ -2996,16 +2879,16 @@
     """
 
     def testFilterNoArgs(self):
         """
         Filtering must return the same list when not asked to do anything.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ACG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ACG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter()
         self.assertEqual([read1, read2], list(result))
 
     def testFilterReturnsReadInstance(self):
         """
@@ -3015,399 +2898,396 @@
 
     def testFilteredReadsInstanceHasExpectedLength(self):
         """
         After filtering, the returned Reads instance must have the expected
         length.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ACG")
-        read3 = Read("id3", "AC")
-        read4 = Read("id4", "A")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ACG')
+        read3 = Read('id3', 'AC')
+        read4 = Read('id4', 'A')
         reads.add(read1)
         reads.add(read2)
         reads.add(read3)
         reads.add(read4)
         result = reads.filter(minLength=3)
         self.assertEqual(2, len(list(result)))
 
     def testAddFiltersThenClearFilters(self):
         """
         If filters are added and then all filters are cleared, the result must
         be the same as the reads that were originally added.
         """
-        initial = [
-            Read("id1", "ATCG"),
-            Read("id2", "ACG"),
-            Read("id3", "AC"),
-            Read("id4", "A"),
-        ]
+        initial = [Read('id1', 'ATCG'), Read('id2', 'ACG'), Read('id3', 'AC'),
+                   Read('id4', 'A')]
         reads = Reads(initial)
         result = reads.filter(minLength=3).filter(maxLength=3).clearFilters()
         self.assertEqual(initial, list(result))
 
     def testFilterOnMinLength(self):
         """
         Filtering on minimal length must work.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ACG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ACG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(minLength=4)
         self.assertEqual([read1], list(result))
 
     def testFilterOnMaxLength(self):
         """
         Filtering on maximal length must work.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ACG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ACG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(maxLength=3)
         self.assertEqual([read2], list(result))
 
     def testFilterOnLengthNothingMatches(self):
         """
         When filtering on length, no reads must be returned if none of them
         satisfy the length requirements.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ACG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ACG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(minLength=10, maxLength=15)
         self.assertEqual([], list(result))
 
     def testFilterOnLengthEverythingMatches(self):
         """
         When filtering on length, all reads must be returned if they all
         satisfy the length requirements.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ACG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ACG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(minLength=2, maxLength=5)
         self.assertEqual([read1, read2], list(result))
 
     def testFilterWithMinLengthEqualToMaxLength(self):
         """
         When filtering on length, a read must be returned if its length
         equals a passed minimum and maximum length.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ACG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ACG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(minLength=4, maxLength=4)
         self.assertEqual([read1], list(result))
 
     def testFilterRemoveGaps(self):
         """
         Filtering must be able to remove gaps.
         """
         reads = Reads()
-        reads.add(Read("id", "-AT--CG-"))
+        reads.add(Read('id', '-AT--CG-'))
         result = reads.filter(removeGaps=True)
-        self.assertEqual([Read("id", "ATCG")], list(result))
+        self.assertEqual([Read('id', 'ATCG')], list(result))
 
     def testFilterRemoveGapsWithQuality(self):
         """
         Filtering must be able to remove gaps, treating the quality string
         properly.
         """
         reads = Reads()
-        reads.add(Read("id", "-AT--CG-", "12345678"))
+        reads.add(Read('id', '-AT--CG-', '12345678'))
         result = reads.filter(removeGaps=True)
-        self.assertEqual([Read("id", "ATCG", "2367")], list(result))
+        self.assertEqual([Read('id', 'ATCG', '2367')], list(result))
 
     def testFilterNegativeRegex(self):
         """
         Filtering must be able to filter reads based on a negative regular
         expression.
         """
         reads = Reads()
-        reads.add(Read("cats", "ATCG"))
-        reads.add(Read("kittens", "ATCG"))
-        reads.add(Read("dogs", "ATCG"))
-        reads.add(Read("puppies", "ATCG"))
-        reads.add(Read("lion", "ATCG"))
-        result = reads.filter(negativeTitleRegex="s")
-        self.assertEqual([Read("lion", "ATCG")], list(result))
+        reads.add(Read('cats', 'ATCG'))
+        reads.add(Read('kittens', 'ATCG'))
+        reads.add(Read('dogs', 'ATCG'))
+        reads.add(Read('puppies', 'ATCG'))
+        reads.add(Read('lion', 'ATCG'))
+        result = reads.filter(negativeTitleRegex='s')
+        self.assertEqual([Read('lion', 'ATCG')], list(result))
 
     def testFilterPositiveRegex(self):
         """
         Filtering must be able to filter reads based on a positive regular
         expression.
         """
         reads = Reads()
-        reads.add(Read("cats", "ATCG"))
-        reads.add(Read("kittens", "ATCG"))
-        reads.add(Read("dogs", "ATCG"))
-        reads.add(Read("puppies", "ATCG"))
-        reads.add(Read("lion", "ATCG"))
-        result = reads.filter(titleRegex="tt")
-        self.assertEqual([Read("kittens", "ATCG")], list(result))
+        reads.add(Read('cats', 'ATCG'))
+        reads.add(Read('kittens', 'ATCG'))
+        reads.add(Read('dogs', 'ATCG'))
+        reads.add(Read('puppies', 'ATCG'))
+        reads.add(Read('lion', 'ATCG'))
+        result = reads.filter(titleRegex='tt')
+        self.assertEqual([Read('kittens', 'ATCG')], list(result))
 
     def testFilterWhitelist(self):
         """
         Filtering must be able to filter reads based on a whitelist.
         """
         reads = Reads()
-        reads.add(Read("cats", "ATCG"))
-        reads.add(Read("kittens", "ATCG"))
-        reads.add(Read("dogs", "ATCG"))
-        reads.add(Read("puppies", "ATCG"))
-        reads.add(Read("lion", "ATCG"))
-        result = reads.filter(negativeTitleRegex=".", whitelist=["lion"])
-        self.assertEqual([Read("lion", "ATCG")], list(result))
+        reads.add(Read('cats', 'ATCG'))
+        reads.add(Read('kittens', 'ATCG'))
+        reads.add(Read('dogs', 'ATCG'))
+        reads.add(Read('puppies', 'ATCG'))
+        reads.add(Read('lion', 'ATCG'))
+        result = reads.filter(negativeTitleRegex='.', whitelist=['lion'])
+        self.assertEqual([Read('lion', 'ATCG')], list(result))
 
     def testFilterBlacklist(self):
         """
         Filtering must be able to filter reads based on a blacklist.
         """
         reads = Reads()
-        reads.add(Read("cats", "ATCG"))
-        reads.add(Read("kittens", "ATCG"))
-        reads.add(Read("dogs", "ATCG"))
-        reads.add(Read("puppies", "ATCG"))
-        reads.add(Read("lion", "ATCG"))
-        result = reads.filter(
-            titleRegex=".", blacklist=["cats", "kittens", "dogs", "puppies"]
-        )
-        self.assertEqual([Read("lion", "ATCG")], list(result))
+        reads.add(Read('cats', 'ATCG'))
+        reads.add(Read('kittens', 'ATCG'))
+        reads.add(Read('dogs', 'ATCG'))
+        reads.add(Read('puppies', 'ATCG'))
+        reads.add(Read('lion', 'ATCG'))
+        result = reads.filter(titleRegex='.',
+                              blacklist=['cats', 'kittens', 'dogs', 'puppies'])
+        self.assertEqual([Read('lion', 'ATCG')], list(result))
 
     def testFilterTruncateTitles(self):
         """
         Filtering must be able to filter reads based on a blacklist.
         """
         reads = Reads()
-        reads.add(Read("cat 400", "AA"))
-        reads.add(Read("cat 500", "GG"))
-        result = reads.filter(truncateTitlesAfter="cat")
-        self.assertEqual([Read("cat 400", "AA")], list(result))
+        reads.add(Read('cat 400', 'AA'))
+        reads.add(Read('cat 500', 'GG'))
+        result = reads.filter(truncateTitlesAfter='cat')
+        self.assertEqual([Read('cat 400', 'AA')], list(result))
 
     def testFilterKeepSequencesNoSequences(self):
         """
         Filtering must be able to filter reads based on their sequential
         number when no sequences are wanted.
         """
-        reads = Reads((Read("cow", "A"), Read("dog", "G"), Read("cat", "T")))
+        reads = Reads((Read('cow', 'A'), Read('dog', 'G'), Read('cat', 'T')))
         result = reads.filter(keepSequences=set())
         self.assertEqual([], list(result))
 
     def testFilterKeepSequences(self):
         """
         Filtering must be able to filter reads based on their sequential
         number.
         """
         reads = Reads()
-        reads.add(Read("cow", "AA"))
-        reads.add(Read("dog", "GG"))
-        reads.add(Read("cat", "TT"))
+        reads.add(Read('cow', 'AA'))
+        reads.add(Read('dog', 'GG'))
+        reads.add(Read('cat', 'TT'))
         result = reads.filter(keepSequences=set([0, 2]))
-        self.assertEqual([Read("cow", "AA"), Read("cat", "TT")], list(result))
+        self.assertEqual([Read('cow', 'AA'), Read('cat', 'TT')], list(result))
 
     def testFilterRemoveSequencesNoSequences(self):
         """
         Filtering must be able to filter reads based on their sequential
         number when no sequences are excluded.
         """
-        animals = [Read("cow", "A"), Read("dog", "G"), Read("cat", "T")]
+        animals = [Read('cow', 'A'), Read('dog', 'G'), Read('cat', 'T')]
         reads = Reads(animals)
         result = reads.filter(removeSequences=set())
         self.assertEqual(animals, list(result))
 
     def testFilterRemoveSequences(self):
         """
         Filtering must be able to exclude reads based on their sequential
         number.
         """
         reads = Reads()
-        reads.add(Read("cow", "AA"))
-        reads.add(Read("dog", "GG"))
-        reads.add(Read("cat", "TT"))
+        reads.add(Read('cow', 'AA'))
+        reads.add(Read('dog', 'GG'))
+        reads.add(Read('cat', 'TT'))
         result = reads.filter(removeSequences=set([1]))
-        self.assertEqual([Read("cow", "AA"), Read("cat", "TT")], list(result))
+        self.assertEqual([Read('cow', 'AA'), Read('cat', 'TT')], list(result))
 
     def testFilterHeadZero(self):
         """
         Filtering must be able to filter just the first N of a set of reads,
         including when N=0.
         """
         reads = Reads()
-        reads.add(Read("cow", "AA"))
-        reads.add(Read("dog", "GG"))
-        reads.add(Read("cat", "TT"))
+        reads.add(Read('cow', 'AA'))
+        reads.add(Read('dog', 'GG'))
+        reads.add(Read('cat', 'TT'))
         result = reads.filter(head=0)
         self.assertEqual([], list(result))
 
     def testFilterHead(self):
         """
         Filtering must be able to filter just the first N of a set of reads.
         """
         reads = Reads()
-        reads.add(Read("cow", "AA"))
-        reads.add(Read("dog", "GG"))
-        reads.add(Read("cat", "TT"))
+        reads.add(Read('cow', 'AA'))
+        reads.add(Read('dog', 'GG'))
+        reads.add(Read('cat', 'TT'))
         result = reads.filter(head=2)
-        self.assertEqual([Read("cow", "AA"), Read("dog", "GG")], list(result))
+        self.assertEqual([Read('cow', 'AA'), Read('dog', 'GG')], list(result))
 
     def testFilterDuplicates(self):
         """
         Filtering on sequence duplicates must work correctly. The first of a
         set of duplicated reads is the one that should be retained.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(removeDuplicates=True)
         self.assertEqual([read1], list(result))
 
     def testFilterDuplicatesById(self):
         """
         Filtering on read id duplicates must work correctly. The first of a
         set of duplicated reads is the one that should be retained.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id1", "ATTT")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id1', 'ATTT')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(removeDuplicatesById=True)
         self.assertEqual([read1], list(result))
 
     def testFilterDuplicatesUseMD5(self):
         """
         Filtering on sequence duplicates must work correctly when MD5 sums
         are used instead of the sequence. The first of a set of duplicated
         reads is the one that should be retained.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads.add(read1)
         reads.add(read2)
-        result = reads.filter(removeDuplicates=True, removeDuplicatesUseMD5=True)
+        result = reads.filter(removeDuplicates=True,
+                              removeDuplicatesUseMD5=True)
         self.assertEqual([read1], list(result))
 
     def testFilterDuplicatesByIdMD5(self):
         """
         Filtering on read id duplicates must work correctly when MD5 sums
         are used instead of the read id. The first of a set of duplicated
         reads is the one that should be retained.
         """
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id1", "ATTT")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id1', 'ATTT')
         reads.add(read1)
         reads.add(read2)
-        result = reads.filter(removeDuplicatesById=True, removeDuplicatesUseMD5=True)
+        result = reads.filter(removeDuplicatesById=True,
+                              removeDuplicatesUseMD5=True)
         self.assertEqual([read1], list(result))
 
     def testFilterRemoveDescriptions(self):
         """
         Removing read id descriptions must work correctly.
         """
-        read1 = Read("id1 description", "ATCG")
-        read2 = Read("id2 another description", "ATTT")
-        read3 = Read("id3", "ATT")
+        read1 = Read('id1 description', 'ATCG')
+        read2 = Read('id2 another description', 'ATTT')
+        read3 = Read('id3', 'ATT')
         reads = Reads([read1, read2, read3])
         result = reads.filter(removeDescriptions=True)
-        self.assertEqual(["id1", "id2", "id3"], [read.id for read in result])
+        self.assertEqual(['id1', 'id2', 'id3'],
+                         [read.id for read in result])
 
     def testFilterDoNotRemoveDescriptions(self):
         """
         Not removing read id descriptions must work correctly.
         """
-        read1 = Read("id1 description", "ATCG")
-        read2 = Read("id2 another description", "ATTT")
-        read3 = Read("id3", "ATT")
+        read1 = Read('id1 description', 'ATCG')
+        read2 = Read('id2 another description', 'ATTT')
+        read3 = Read('id3', 'ATT')
         reads = Reads([read1, read2, read3])
         result = reads.filter(removeDescriptions=False)
         self.assertEqual([read1, read2, read3], list(result))
 
     def testFilterWithModifierThatOmits(self):
         """
         Filtering with a modifier function must work correctly if the modifier
         returns C{None} for some reads.
         """
-
         def modifier(read):
-            if read.id == "id1":
+            if read.id == 'id1':
                 return read
 
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(modifier=modifier)
         self.assertEqual([read1], list(result))
 
     def testFilterWithModifierThatChangesIds(self):
         """
         Filtering with a modifier function must work correctly if the modifier
         changes the ids of reads.
         """
-
         def modifier(read):
             read.id = read.id.upper()
             return read
 
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(modifier=modifier)
-        self.assertEqual([Read("ID1", "ATCG"), Read("ID2", "ATCG")], list(result))
+        self.assertEqual([Read('ID1', 'ATCG'), Read('ID2', 'ATCG')],
+                         list(result))
 
     def testFilterWithModifierThatOmitsAndChangesIds(self):
         """
         Filtering with a modifier function must work correctly if the modifier
         omits some reads and changes the ids of others.
         """
-
         def modifier(read):
-            if read.id == "id1":
-                read.id = "xxx"
+            if read.id == 'id1':
+                read.id = 'xxx'
                 return read
 
         reads = Reads()
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads.add(read1)
         reads.add(read2)
         result = reads.filter(modifier=modifier)
-        self.assertEqual([Read("xxx", "ATCG")], list(result))
+        self.assertEqual([Read('xxx', 'ATCG')], list(result))
 
     def testFilterRandomSubsetSizeZeroNoReads(self):
         """
         Asking for a random subset of length zero must work as expected when
         there are no reads in the Reads instance.
         """
-        self.assertEqual([], list(Reads().filter(randomSubset=0, trueLength=0)))
+        self.assertEqual([],
+                         list(Reads().filter(randomSubset=0, trueLength=0)))
 
     def testFilterRandomSubsetSizeZeroTwoReads(self):
         """
         Asking for a random subset of length zero from a set of two reads must
         work as expected.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads = Reads(initialReads=[read1, read2])
         result = reads.filter(randomSubset=0, trueLength=2)
         self.assertEqual([], list(result))
 
     def testFilterRandomSubsetOfZeroReads(self):
         """
         Asking for a non-zero random subset of a set of zero reads must work
@@ -3418,471 +3298,456 @@
         self.assertEqual([], list(result))
 
     def testFilterRandomSubsetOfOneFromOneRead(self):
         """
         Asking for a size one random subset of a set of one read must work
         as expected.
         """
-        read = Read("id", "ATCG")
+        read = Read('id', 'ATCG')
         reads = Reads(initialReads=[read])
         result = reads.filter(randomSubset=1, trueLength=1)
         self.assertEqual([read], list(result))
 
     def testFilterRandomSubsetOfFiveFromOneRead(self):
         """
         Asking for a size five random subset of a set of one read must work
         as expected.
         """
-        read = Read("id", "ATCG")
+        read = Read('id', 'ATCG')
         reads = Reads(initialReads=[read])
         result = reads.filter(randomSubset=5, trueLength=1)
         self.assertEqual([read], list(result))
 
     def testFilterRandomSubsetOfFiveFromFiveReads(self):
         """
         Asking for a size five random subset of a set of five reads must work
         as expected.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATCG")
-        read4 = Read("id4", "ATCG")
-        read5 = Read("id5", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATCG')
+        read4 = Read('id4', 'ATCG')
+        read5 = Read('id5', 'ATCG')
         reads = Reads(initialReads=[read1, read2, read3, read4, read5])
         result = reads.filter(randomSubset=5, trueLength=5)
         self.assertEqual([read1, read2, read3, read4, read5], list(result))
 
     def testFilterRandomSubsetOfTwoFromFiveReads(self):
         """
         Asking for a size two random subset of a set of five reads must return
         two (different) reads.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATCG")
-        read4 = Read("id4", "ATCG")
-        read5 = Read("id5", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATCG')
+        read4 = Read('id4', 'ATCG')
+        read5 = Read('id5', 'ATCG')
         reads = Reads(initialReads=[read1, read2, read3, read4, read5])
         result = reads.filter(randomSubset=2, trueLength=5)
         self.assertEqual(2, len(set(result)))
 
     def testSampleFractionAndRandomSubsetRaisesValueError(self):
         """
         Asking for filtering of a sample fraction and a random subset at the
         same time must raise a ValueError.
         """
         reads = Reads()
-        error = (
-            r"^randomSubset and sampleFraction cannot be used "
-            r"simultaneously in a filter. Make two read filters "
-            r"instead\.$"
-        )
-        six.assertRaisesRegex(
-            self, ValueError, error, reads.filter, sampleFraction=0.1, randomSubset=3
-        )
+        error = (r"^randomSubset and sampleFraction cannot be used "
+                 r"simultaneously in a filter. Make two read filters "
+                 r"instead\.$")
+        six.assertRaisesRegex(self, ValueError, error, reads.filter,
+                              sampleFraction=0.1, randomSubset=3)
 
     def testSampleFractionAndNoTrueLengthRaisesValueError(self):
         """
         Asking for filtering of a sample fraction without passing a trueLength
         must raise a ValueError.
         """
         reads = Reads()
         error = r"^trueLength must be supplied if randomSubset is specified\.$"
-        six.assertRaisesRegex(self, ValueError, error, reads.filter, randomSubset=3)
+        six.assertRaisesRegex(self, ValueError, error, reads.filter,
+                              randomSubset=3)
 
     def testSampleFractionZero(self):
         """
         Asking for a sample fraction of 0.0 from a set of five reads must
         return the empty list.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATCG")
-        read4 = Read("id4", "ATCG")
-        read5 = Read("id5", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATCG')
+        read4 = Read('id4', 'ATCG')
+        read5 = Read('id5', 'ATCG')
         reads = Reads(initialReads=[read1, read2, read3, read4, read5])
         result = reads.filter(sampleFraction=0.0)
         self.assertEqual(0, len(list(result)))
 
     def testSampleFractionOne(self):
         """
         Asking for a sample fraction of 1.0 from a set of five reads must
         return all reads.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATCG")
-        read4 = Read("id4", "ATCG")
-        read5 = Read("id5", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATCG')
+        read4 = Read('id4', 'ATCG')
+        read5 = Read('id5', 'ATCG')
         reads = Reads(initialReads=[read1, read2, read3, read4, read5])
         result = reads.filter(sampleFraction=1.0)
         self.assertEqual([read1, read2, read3, read4, read5], list(result))
 
     def testSampleFractionPointOne(self):
         """
         Asking for a sample fraction of 0.1 from a set of 100 reads must
         return 11 reads (given a particular random seed value).
         """
         seed(1)
-        reads = Reads(initialReads=[Read("id1", "ATCG")] * 100)
+        reads = Reads(initialReads=[Read('id1', 'ATCG')] * 100)
         result = reads.filter(sampleFraction=0.1)
         self.assertEqual(11, len(list(result)))
 
     def testLineNumberFileFirstLineTooSmall(self):
         """
         If a line number file is passed to filter but its first line is
         less than 1, a ValueError must be raised.
         """
-        data = "0\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
+        data = '0\n'
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
             reads = Reads([])
-            error = (
-                r"^First line of sequence number file 'file' must be at " r"least 1\.$"
-            )
+            error = (r"^First line of sequence number file 'file' must be at "
+                     r"least 1\.$")
             with six.assertRaisesRegex(self, ValueError, error):
-                reads.filter(sequenceNumbersFile="file")
+                reads.filter(sequenceNumbersFile='file')
 
     def testLineNumberFileNonAscending(self):
         """
         If a line number file is passed to filter but it contains non-ascending
         line numbers, a ValueError must be raised.
         """
-        data = "2\n2\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            read1 = Read("id1", "ATCG")
-            read2 = Read("id2", "ATCG")
-            read3 = Read("id3", "ATCG")
+        data = '2\n2\n'
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            read1 = Read('id1', 'ATCG')
+            read2 = Read('id2', 'ATCG')
+            read3 = Read('id3', 'ATCG')
             reads = Reads(initialReads=[read1, read2, read3])
-            error = (
-                r"^Line number file 'file' contains non-ascending "
-                r"numbers 2 and 2\.$"
-            )
+            error = (r"^Line number file 'file' contains non-ascending "
+                     r"numbers 2 and 2\.$")
             with six.assertRaisesRegex(self, ValueError, error):
-                list(reads.filter(sequenceNumbersFile="file"))
+                list(reads.filter(sequenceNumbersFile='file'))
 
     def testLineNumberFileEmpty(self):
         """
         If an empty line number file is passed to filter, no sequences should
         be returned.
         """
-        data = ""
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            read1 = Read("id1", "ATCG")
-            read2 = Read("id2", "ATCG")
+        data = ''
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            read1 = Read('id1', 'ATCG')
+            read2 = Read('id2', 'ATCG')
             reads = Reads(initialReads=[read1, read2])
-            result = reads.filter(sequenceNumbersFile="file")
+            result = reads.filter(sequenceNumbersFile='file')
             self.assertEqual([], list(result))
 
     def testLineNumberFile(self):
         """
         If a line number file is passed to filter, the correct sequences should
         be returned.
         """
-        data = "1\n3\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            read1 = Read("id1", "ATCG")
-            read2 = Read("id2", "ATCG")
-            read3 = Read("id3", "ATCG")
-            read4 = Read("id4", "ATCG")
+        data = '1\n3\n'
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            read1 = Read('id1', 'ATCG')
+            read2 = Read('id2', 'ATCG')
+            read3 = Read('id3', 'ATCG')
+            read4 = Read('id4', 'ATCG')
             reads = Reads(initialReads=[read1, read2, read3, read4])
-            result = reads.filter(sequenceNumbersFile="file")
+            result = reads.filter(sequenceNumbersFile='file')
             self.assertEqual([read1, read3], list(result))
 
     def testLineNumberFileRunOutOfSequences(self):
         """
         If a line number file is passed to filter, and it contains numbers that
         are bigger than the number of sequences, the correct sequences should
         be returned.
         """
-        data = "1\n3\n200\n"
-        with patch.object(builtins, "open", mock_open(read_data=data)):
-            read1 = Read("id1", "ATCG")
-            read2 = Read("id2", "ATCG")
-            read3 = Read("id3", "ATCG")
-            read4 = Read("id4", "ATCG")
+        data = '1\n3\n200\n'
+        with patch.object(builtins, 'open', mock_open(read_data=data)):
+            read1 = Read('id1', 'ATCG')
+            read2 = Read('id2', 'ATCG')
+            read3 = Read('id3', 'ATCG')
+            read4 = Read('id4', 'ATCG')
             reads = Reads(initialReads=[read1, read2, read3, read4])
-            result = reads.filter(sequenceNumbersFile="file")
+            result = reads.filter(sequenceNumbersFile='file')
             self.assertEqual([read1, read3], list(result))
 
     def testKeepSites(self):
         """
         If only a certain set of sites should be kept, the correct sequences
         should be returned.
         """
-        read1 = Read("id1", "ATCGAT")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATC")
-        read4 = Read("id4", "AT")
+        read1 = Read('id1', 'ATCGAT')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATC')
+        read4 = Read('id4', 'AT')
         reads = Reads(initialReads=[read1, read2, read3, read4])
         result = reads.filter(keepSites={1, 2})
         self.assertEqual(
             [
-                Read("id1", "TC"),
-                Read("id2", "TC"),
-                Read("id3", "TC"),
-                Read("id4", "T"),
+                Read('id1', 'TC'),
+                Read('id2', 'TC'),
+                Read('id3', 'TC'),
+                Read('id4', 'T'),
             ],
-            list(result),
-        )
+            list(result))
 
     def testKeepSitesNoSites(self):
         """
         If the empty set of sites should be kept, the correct (empty)
         sequences should be returned.
         """
-        read1 = Read("id1", "ATCGAT")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATC")
-        read4 = Read("id4", "AT")
+        read1 = Read('id1', 'ATCGAT')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATC')
+        read4 = Read('id4', 'AT')
         reads = Reads(initialReads=[read1, read2, read3, read4])
         result = reads.filter(keepSites=set())
         self.assertEqual(
             [
-                Read("id1", ""),
-                Read("id2", ""),
-                Read("id3", ""),
-                Read("id4", ""),
+                Read('id1', ''),
+                Read('id2', ''),
+                Read('id3', ''),
+                Read('id4', ''),
             ],
-            list(result),
-        )
+            list(result))
 
     def testKeepSitesAllSites(self):
         """
         If the set of all sites should be kept, the correct (full) sequences
         should be returned.
         """
-        read1 = Read("id1", "ATCGAT")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATC")
-        read4 = Read("id4", "AT")
+        read1 = Read('id1', 'ATCGAT')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATC')
+        read4 = Read('id4', 'AT')
         reads = Reads(initialReads=[read1, read2, read3, read4])
         result = reads.filter(keepSites=set(range(6)))
         self.assertEqual([read1, read2, read3, read4], list(result))
 
     def testKeepSitesWithQuality(self):
         """
         If only a certain set of sites should be kept, the correct sequences
         should be returned, including a modified quality string.
         """
-        reads = Reads(initialReads=[Read("id1", "ATCGAT", "123456")])
+        reads = Reads(initialReads=[Read('id1', 'ATCGAT', '123456')])
         result = reads.filter(keepSites={1, 2})
-        self.assertEqual([Read("id1", "TC", "23")], list(result))
+        self.assertEqual([Read('id1', 'TC', '23')], list(result))
 
     def testKeepSitesOutOfRange(self):
         """
         If only a certain set of sites should be kept, but the kept sites
         are higher than the length of the input sequences, the correct
         (empty) sequences should be returned.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCGCC")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCGCC')
         reads = Reads(initialReads=[read1, read2])
         result = reads.filter(keepSites={100, 200})
         self.assertEqual(
             [
-                Read("id1", ""),
-                Read("id2", ""),
+                Read('id1', ''),
+                Read('id2', ''),
             ],
-            list(result),
-        )
+            list(result))
 
     def testRemoveSites(self):
         """
         If a certain set of sites should be removed, the correct sequences
         should be returned.
         """
-        read1 = Read("id1", "ATCGCC")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATC")
-        read4 = Read("id4", "A")
+        read1 = Read('id1', 'ATCGCC')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATC')
+        read4 = Read('id4', 'A')
         reads = Reads(initialReads=[read1, read2, read3, read4])
         result = reads.filter(removeSites={1, 2})
         self.assertEqual(
             [
-                Read("id1", "AGCC"),
-                Read("id2", "AG"),
-                Read("id3", "A"),
-                Read("id4", "A"),
+                Read('id1', 'AGCC'),
+                Read('id2', 'AG'),
+                Read('id3', 'A'),
+                Read('id4', 'A'),
             ],
-            list(result),
-        )
+            list(result))
 
     def testRemoveSitesNoSites(self):
         """
         If the empty set of sites should be removed, the correct (full)
         sequences should be returned.
         """
-        read1 = Read("id1", "ATCGCC")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATC")
-        read4 = Read("id4", "A")
+        read1 = Read('id1', 'ATCGCC')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATC')
+        read4 = Read('id4', 'A')
         reads = Reads(initialReads=[read1, read2, read3, read4])
         result = reads.filter(removeSites=set())
-        self.assertEqual([read1, read2, read3, read4], list(result))
+        self.assertEqual([read1, read2, read3, read4],
+                         list(result))
 
     def testRemoveSitesAllSites(self):
         """
         If the full set of sites should be removed, the correct (empty)
         sequences should be returned.
         """
-        read1 = Read("id1", "ATCGCC")
-        read2 = Read("id2", "ATCG")
-        read3 = Read("id3", "ATC")
-        read4 = Read("id4", "A")
+        read1 = Read('id1', 'ATCGCC')
+        read2 = Read('id2', 'ATCG')
+        read3 = Read('id3', 'ATC')
+        read4 = Read('id4', 'A')
         reads = Reads(initialReads=[read1, read2, read3, read4])
         result = reads.filter(removeSites=set(range(6)))
         self.assertEqual(
             [
-                Read("id1", ""),
-                Read("id2", ""),
-                Read("id3", ""),
-                Read("id4", ""),
+                Read('id1', ''),
+                Read('id2', ''),
+                Read('id3', ''),
+                Read('id4', ''),
             ],
-            list(result),
-        )
+            list(result))
 
     def testRemoveSitesWithQuality(self):
         """
         If a certain set of sites should be removed, the correct sequences
         should be returned, including a modified quality string.
         """
-        reads = Reads(initialReads=[Read("id1", "ATCGAT", "123456")])
+        reads = Reads(initialReads=[Read('id1', 'ATCGAT', '123456')])
         result = reads.filter(removeSites={1, 2})
-        self.assertEqual([Read("id1", "AGAT", "1456")], list(result))
+        self.assertEqual([Read('id1', 'AGAT', '1456')], list(result))
 
     def testRemoveSitesOutOfRange(self):
         """
         If a certain set of sites should be removed, but the sites
         are higher than the length of the input sequences, the correct
         (full) sequences should be returned.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCGAA")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCGAA')
         reads = Reads(initialReads=[read1, read2])
         result = reads.filter(removeSites={100, 200})
         self.assertEqual([read1, read2], list(result))
 
     def testRemoveAndKeepSites(self):
         """
         Passing a keepSites and a removeSites set to reads.filter
         must result in a ValueError.
         """
-        error = (
-            r"^Cannot simultaneously filter using keepSites and "
-            r"removeSites\. Call filter twice in succession instead\.$"
-        )
-        six.assertRaisesRegex(
-            self, ValueError, error, Reads().filter, keepSites={4}, removeSites={5}
-        )
+        error = (r'^Cannot simultaneously filter using keepSites and '
+                 r'removeSites\. Call filter twice in succession instead\.$')
+        six.assertRaisesRegex(self, ValueError, error, Reads().filter,
+                              keepSites={4}, removeSites={5})
 
     def testIdLambda(self):
         """
         A passed idLambda function should produce the expected read ids.
         """
-        read = Read("id1", "ATCGCC")
+        read = Read('id1', 'ATCGCC')
         reads = Reads(initialReads=[read])
         result = reads.filter(idLambda='lambda id: "x-" + id.upper()')
-        self.assertEqual("x-ID1", list(result)[0].id)
+        self.assertEqual('x-ID1', list(result)[0].id)
 
     def testIdLambdaReturningNone(self):
         """
         A passed idLambda function should produce the expected read ids,
         including when it returns None.
         """
-        read1 = Read("id1", "ATCGCC")
-        read2 = Read("id2", "GGATCG")
+        read1 = Read('id1', 'ATCGCC')
+        read2 = Read('id2', 'GGATCG')
         reads = Reads(initialReads=[read1, read2])
-        result = reads.filter(idLambda='lambda id: "aa" if id.find("1") > -1 else None')
+        result = reads.filter(
+            idLambda='lambda id: "aa" if id.find("1") > -1 else None')
         (result,) = list(result)
-        self.assertEqual("aa", result.id)
+        self.assertEqual('aa', result.id)
 
     def testReadLambda(self):
         """
         A passed readLambda function should produce the expected reads.
         """
-        read = Read("id1", "ATCGCC")
+        read = Read('id1', 'ATCGCC')
         reads = Reads(initialReads=[read])
         result = reads.filter(readLambda='lambda r: Read("hey", "AAA")')
         (result,) = list(result)
-        self.assertEqual(Read("hey", "AAA"), result)
+        self.assertEqual(Read('hey', 'AAA'), result)
 
     def testReadLambdaReturningNone(self):
         """
         A passed readLambda function should produce the expected reads,
         including when it returns None.
         """
-        read1 = Read("xid1", "ATCGCC")
-        read2 = Read("yid2", "GGATCG")
+        read1 = Read('xid1', 'ATCGCC')
+        read2 = Read('yid2', 'GGATCG')
         reads = Reads(initialReads=[read1, read2])
         result = reads.filter(
-            readLambda=(
-                'lambda r: Read(r.id + "-x", r.sequence[:2]) '
-                'if r.id.startswith("x") else None'
-            )
-        )
+            readLambda=('lambda r: Read(r.id + "-x", r.sequence[:2]) '
+                        'if r.id.startswith("x") else None'))
         (result,) = list(result)
-        self.assertEqual(Read("xid1-x", "AT"), result)
+        self.assertEqual(Read('xid1-x', 'AT'), result)
 
     def testReverse(self):
         """
         When reverse=True, reads with the expected sequences and qualities
         must be returned.
         """
-        read1 = Read("id1", "ATCGCC", "123456")
-        read2 = Read("id2", "GGATCG", "987654")
+        read1 = Read('id1', 'ATCGCC', '123456')
+        read2 = Read('id2', 'GGATCG', '987654')
         reads = Reads(initialReads=[read1, read2])
         result1, result2 = list(reads.filter(reverse=True))
-        self.assertEqual(Read("id1", "CCGCTA", "654321"), result1)
-        self.assertEqual(Read("id2", "GCTAGG", "456789"), result2)
+        self.assertEqual(Read('id1', 'CCGCTA', '654321'), result1)
+        self.assertEqual(Read('id2', 'GCTAGG', '456789'), result2)
 
     def testReverseComplement(self):
         """
         When reverseComplement=True, reads with the expected sequences and
         qualities must be returned when the reads are of type DNARead.
         """
-        read1 = DNARead("id1", "ATCGCC", "123456")
-        read2 = DNARead("id2", "GGATCG", "987654")
+        read1 = DNARead('id1', 'ATCGCC', '123456')
+        read2 = DNARead('id2', 'GGATCG', '987654')
         reads = Reads(initialReads=[read1, read2])
         result1, result2 = list(reads.filter(reverseComplement=True))
-        self.assertEqual(Read("id1", "GGCGAT", "654321"), result1)
-        self.assertEqual(Read("id2", "CGATCC", "456789"), result2)
+        self.assertEqual(Read('id1', 'GGCGAT', '654321'), result1)
+        self.assertEqual(Read('id2', 'CGATCC', '456789'), result2)
 
     def testReverseAndReverseComplement(self):
         """
         When reverseComplement=True and reverse=True, the expected reads must
         be returned (reverse complemented) when the reads are of type DNARead.
         """
-        read1 = DNARead("id1", "ATCGCC", "123456")
-        read2 = DNARead("id2", "GGATCG", "987654")
+        read1 = DNARead('id1', 'ATCGCC', '123456')
+        read2 = DNARead('id2', 'GGATCG', '987654')
         reads = Reads(initialReads=[read1, read2])
-        result1, result2 = list(reads.filter(reverseComplement=True, reverse=True))
-        self.assertEqual(Read("id1", "GGCGAT", "654321"), result1)
-        self.assertEqual(Read("id2", "CGATCC", "456789"), result2)
+        result1, result2 = list(reads.filter(reverseComplement=True,
+                                             reverse=True))
+        self.assertEqual(Read('id1', 'GGCGAT', '654321'), result1)
+        self.assertEqual(Read('id2', 'CGATCC', '456789'), result2)
 
     def testReverseComplementNonDNA(self):
         """
         When reverseComplement=True and the read is not a DNARead, an
         AttributeError must be raised.
         """
-        reads = Reads(initialReads=[Read("id1", "ATCGCC", "123456")])
+        reads = Reads(initialReads=[Read('id1', 'ATCGCC', '123456')])
         error = "^'Read' object has no attribute 'reverseComplement'$"
-        six.assertRaisesRegex(
-            self, AttributeError, error, list, reads.filter(reverseComplement=True)
-        )
+        six.assertRaisesRegex(self, AttributeError, error, list,
+                              reads.filter(reverseComplement=True))
 
     def testReverseComplementAARead(self):
         """
         When reverseComplement=True and the read is an AARead, an
         AttributeError must be raised.
         """
-        reads = Reads(initialReads=[AARead("id1", "ATCGCC", "123456")])
+        reads = Reads(initialReads=[AARead('id1', 'ATCGCC', '123456')])
         error = "^'AARead' object has no attribute 'reverseComplement'$"
-        six.assertRaisesRegex(
-            self, AttributeError, error, list, reads.filter(reverseComplement=True)
-        )
+        six.assertRaisesRegex(self, AttributeError, error, list,
+                              reads.filter(reverseComplement=True))
 
 
 class TestReadsInRAM(TestCase):
     """
     Test the ReadsInRAM class.
     """
 
@@ -3894,550 +3759,270 @@
         self.assertEqual([], list(reads))
 
     def testAdd(self):
         """
         It must be possible to add reads to a ReadsInRAM instance.
         """
         reads = ReadsInRAM()
-        read = Read("id", "ACGT")
+        read = Read('id', 'ACGT')
         reads.add(read)
         self.assertEqual([read], list(reads))
 
     def testOneReadLength(self):
         """
         A ReadsInRAM instance with one read must have length one.
         """
-        read1 = Read("id1", "ATCG")
+        read1 = Read('id1', 'ATCG')
         reads = ReadsInRAM([read1])
         self.assertEqual(1, len(reads))
 
     def testOneReadList(self):
         """
         A ReadsInRAM instance with one read must iterate as expected.
         """
-        read1 = Read("id1", "ATCG")
+        read1 = Read('id1', 'ATCG')
         reads = ReadsInRAM([read1])
         self.assertEqual([read1], list(reads))
 
     def testOneReadIndex(self):
         """
         A ReadsInRAM instance with one read must be able to be indexed.
         """
-        read1 = Read("id1", "ATCG")
+        read1 = Read('id1', 'ATCG')
         reads = ReadsInRAM([read1])
         self.assertEqual(read1, reads[0])
 
     def testTwoReadsLength(self):
         """
         A ReadsInRAM instance with two reads must have length one.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads = ReadsInRAM([read1, read2])
         self.assertEqual(2, len(reads))
 
     def testTwoReadsList(self):
         """
         A ReadsInRAM instance with two reads must iterate as expected.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads = ReadsInRAM([read1, read2])
         self.assertEqual([read1, read2], list(reads))
 
     def testTwoReadsIndex(self):
         """
         A ReadsInRAM instance with two reads must be able to be indexed.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads = ReadsInRAM([read1, read2])
         self.assertEqual(read1, reads[0])
         self.assertEqual(read2, reads[1])
 
     def testFromReads(self):
         """
         A ReadsInRAM instance must be able to initialize itself from a Reads
         instance.
         """
-        read1 = Read("id1", "ATCG")
-        read2 = Read("id2", "ATCG")
+        read1 = Read('id1', 'ATCG')
+        read2 = Read('id2', 'ATCG')
         reads = Reads([read1, read2])
         readsInRAM = ReadsInRAM(reads)
         self.assertEqual(2, len(readsInRAM))
         self.assertEqual(read1, readsInRAM[0])
         self.assertEqual(read2, readsInRAM[1])
 
     def testFastaFile(self):
         """
         A ReadsInRAM instance should be able to be initialized from a
         FastaReads instance and be iterated twice without the underlying file
         being opened twice.
         """
-
-        class SideEffect:
+        class SideEffect(object):
             def __init__(self, test):
                 self.test = test
                 self.count = 0
 
             def sideEffect(self, filename, **kwargs):
                 if self.count == 0:
-                    self.test.assertEqual("file1.fasta", filename)
+                    self.test.assertEqual('file1.fasta', filename)
                     self.count += 1
-                    return StringIO(">id1\nACTG\n>id2\nAA\n")
+                    return StringIO('>id1\nACTG\n>id2\nAA\n')
                 else:
-                    self.test.fail("We are only supposed to be called once!")
+                    self.test.fail('We are only supposed to be called once!')
 
         sideEffect = SideEffect(self)
-        with patch.object(builtins, "open") as mockMethod:
+        with patch.object(builtins, 'open') as mockMethod:
             mockMethod.side_effect = sideEffect.sideEffect
-            reads = FastaReads("file1.fasta")
+            reads = FastaReads('file1.fasta')
             readsInRAM = ReadsInRAM(reads)
-            expected = [Read("id1", "ACTG"), Read("id2", "AA")]
+            expected = [Read('id1', 'ACTG'), Read('id2', 'AA')]
             self.assertEqual(expected, list(readsInRAM))
             self.assertEqual(expected, list(readsInRAM))
             self.assertEqual(1, sideEffect.count)
 
     def testSetItem(self):
         """
         It must be possible to set a value for a ReadsInRAM index.
         """
-        read1 = Read("id1", "ATCG")
+        read1 = Read('id1', 'ATCG')
         reads = ReadsInRAM([read1])
-        read2 = Read("id2", "ATCG")
+        read2 = Read('id2', 'ATCG')
         reads[0] = read2
         self.assertEqual(read2, reads[0])
 
 
 class TestSummarizePosition(TestCase):
     """
     Tests for the reads.summarizePosition function.
     """
-
     def testFrequenciesNoReads(self):
         """
         Must return empty counts if no reads are present.
         """
         reads = Reads()
         result = reads.summarizePosition(2)
-        self.assertEqual({}, result["countAtPosition"])
+        self.assertEqual({}, result['countAtPosition'])
 
     def testNumberOfExclusionsNoReads(self):
         """
         The excluded count must be zero if no reads are present.
         """
         reads = Reads()
         result = reads.summarizePosition(2)
-        self.assertEqual(0, result["excludedCount"])
+        self.assertEqual(0, result['excludedCount'])
 
     def testExcludeShortSequences(self):
         """
         Sequences that are too short should be ignored.
         """
         reads = Reads()
-        reads.add(Read("id1", "agtcagtcagtc"))
-        reads.add(Read("id2", "acctg"))
-        reads.add(Read("id3", "atg"))
+        reads.add(Read('id1', 'agtcagtcagtc'))
+        reads.add(Read('id2', 'acctg'))
+        reads.add(Read('id3', 'atg'))
         result = reads.summarizePosition(9)
-        self.assertEqual(2, result["excludedCount"])
+        self.assertEqual(2, result['excludedCount'])
 
     def testIndexLargerThanSequenceLength(self):
         """
         Must not count residues in sequences that are too short.
         """
         reads = Reads()
-        reads.add(Read("id1", "aaaaaa"))
-        reads.add(Read("id2", "aaca"))
-        reads.add(Read("id3", "aat"))
+        reads.add(Read('id1', 'aaaaaa'))
+        reads.add(Read('id2', 'aaca'))
+        reads.add(Read('id3', 'aat'))
         result = reads.summarizePosition(5)
-        self.assertEqual({"a": 1}, result["countAtPosition"])
+        self.assertEqual({'a': 1}, result['countAtPosition'])
 
     def testCorrectFrequencies(self):
         """
         Must return the correct frequencies.
         """
         reads = Reads()
-        reads.add(Read("id1", "aaaaaa"))
-        reads.add(Read("id2", "aata"))
-        reads.add(Read("id3", "aataaaaaa"))
+        reads.add(Read('id1', 'aaaaaa'))
+        reads.add(Read('id2', 'aata'))
+        reads.add(Read('id3', 'aataaaaaa'))
         result = reads.summarizePosition(2)
-        self.assertEqual({"a": 1, "t": 2}, result["countAtPosition"])
-
-    def testReadCount(self):
-        """
-        Must return the correct number of reads.
-        """
-        reads = Reads()
-        reads.add(Read("id1", "aaaaaa"))
-        reads.add(Read("id2", "aata"))
-        reads.add(Read("id3", "aataaaaaa"))
-        result = reads.summarizePosition(2)
-        self.assertEqual(3, result["readCount"])
+        self.assertEqual({'a': 1, 't': 2}, result['countAtPosition'])
 
 
 class TestSitesMatching(TestCase):
     """
     Tests for the Reads.sitesMatching method.
     """
-
     def testNoMatches(self):
         """
         If no reads match the target bases, sitesMatching must return the
         empty set.
         """
         reads = Reads()
-        reads.add(Read("id1", "aaaaaa"))
-        result = reads.sitesMatching({"b"}, matchCase=True, any_=True)
+        reads.add(Read('id1', 'aaaaaa'))
+        result = reads.sitesMatching({'b'}, matchCase=True, any_=True)
         self.assertEqual(set(), result)
 
     def testAllMatches(self):
         """
         If a read's sites all match the target bases, sitesMatching must
         return the full set of sites.
         """
         reads = Reads()
-        reads.add(Read("id1", "aaaga"))
-        result = reads.sitesMatching({"a", "g"}, matchCase=True, any_=True)
+        reads.add(Read('id1', 'aaaga'))
+        result = reads.sitesMatching({'a', 'g'}, matchCase=True, any_=True)
         self.assertEqual(set(range(5)), result)
 
     def testPartialMatch(self):
         """
         If some of a read's sites all match the target bases, sitesMatching
         must return the expected set of sites.
         """
         reads = Reads()
-        reads.add(Read("id1", "aaaga"))
-        result = reads.sitesMatching({"a"}, matchCase=True, any_=True)
+        reads.add(Read('id1', 'aaaga'))
+        result = reads.sitesMatching({'a'}, matchCase=True, any_=True)
         self.assertEqual({0, 1, 2, 4}, result)
 
     def testMatchCase(self):
         """
         If only some of a read's sites all match the target bases with
         matching case, sitesMatching must return the expected set of sites.
         """
         reads = Reads()
-        reads.add(Read("id1", "aAAga"))
-        result = reads.sitesMatching({"a"}, matchCase=True, any_=False)
+        reads.add(Read('id1', 'aAAga'))
+        result = reads.sitesMatching({'a'}, matchCase=True, any_=False)
         self.assertEqual({0, 4}, result)
 
     def testIgnoreCase(self):
         """
         If only some of a read's sites all match the target bases with
         matching case, sitesMatching must return the expected set of sites
         when we tell it to ignore case.
         """
         reads = Reads()
-        reads.add(Read("id1", "aAAga"))
-        result = reads.sitesMatching({"a"}, matchCase=False, any_=False)
+        reads.add(Read('id1', 'aAAga'))
+        result = reads.sitesMatching({'a'}, matchCase=False, any_=False)
         self.assertEqual({0, 1, 2, 4}, result)
 
     def testMultipleReadsAny(self):
         """
         If multiple reads are given, sitesMatching must return the expected
         set of sites when we pass any_=True.
         """
         reads = Reads()
-        reads.add(Read("id1", "aaaga"))
-        reads.add(Read("id2", "caata"))
-        result = reads.sitesMatching({"c", "g"}, matchCase=False, any_=True)
+        reads.add(Read('id1', 'aaaga'))
+        reads.add(Read('id2', 'caata'))
+        result = reads.sitesMatching({'c', 'g'}, matchCase=False, any_=True)
         self.assertEqual({0, 3}, result)
 
     def testMultipleReadsAll(self):
         """
         If multiple reads are given, sitesMatching must return the expected
         set of sites when we pass any_=False.
         """
         reads = Reads()
-        reads.add(Read("id1", "aaaga"))
-        reads.add(Read("id2", "caaga"))
-        result = reads.sitesMatching({"c", "g"}, matchCase=False, any_=False)
+        reads.add(Read('id1', 'aaaga'))
+        reads.add(Read('id2', 'caaga'))
+        result = reads.sitesMatching({'c', 'g'}, matchCase=False, any_=False)
         self.assertEqual({3}, result)
 
     def testMultipleReadsAllWithDifferingLengths(self):
         """
         If multiple reads are given, sitesMatching must return the expected
         set of sites when we pass any_=False and the reads have differing
         lengths.
         """
         reads = Reads()
-        reads.add(Read("id2", "caa-agt-"))
-        reads.add(Read("id1", "-aa-a"))
-        result = reads.sitesMatching({"-"}, matchCase=False, any_=False)
+        reads.add(Read('id2', 'caa-agt-'))
+        reads.add(Read('id1', '-aa-a'))
+        result = reads.sitesMatching({'-'}, matchCase=False, any_=False)
         self.assertEqual({3}, result)
 
     def testMultipleReadsAnyWithDifferingLengths(self):
         """
         If multiple reads are given, sitesMatching must return the expected
         set of sites when we pass any_=True and the reads have differing
         lengths.
         """
         reads = Reads()
-        reads.add(Read("id2", "caa-agt-"))
-        reads.add(Read("id1", "-aa-a"))
-        result = reads.sitesMatching({"-"}, matchCase=False, any_=True)
+        reads.add(Read('id2', 'caa-agt-'))
+        reads.add(Read('id1', '-aa-a'))
+        result = reads.sitesMatching({'-'}, matchCase=False, any_=True)
         self.assertEqual({0, 3, 7}, result)
-
-
-class TestFindORF(TestCase):
-    """
-    Tests for the DNARead.findORF method.
-    """
-
-    def testEmpty(self):
-        """
-        If an empty read is passed we must get back a dictionary indicating
-        failure to find anything.
-        """
-        read = DNARead("id", "")
-        self.assertEqual(
-            {
-                "foundStartCodon": False,
-                "foundStopCodon": False,
-                "length": 0,
-                "sequence": "",
-                "translation": "",
-            },
-            read.findORF(0),
-        )
-
-    def testLengthOne(self):
-        """
-        If a read of length one is passed we must get back a dictionary
-        indicating failure to find anything.
-        """
-        read = DNARead("id", "A")
-        self.assertEqual(
-            {
-                "foundStartCodon": False,
-                "foundStopCodon": False,
-                "length": 0,
-                "sequence": "",
-                "translation": "",
-            },
-            read.findORF(0),
-        )
-
-    def testLengthTwo(self):
-        """
-        If a read of length two is passed we must get back a dictionary
-        indicating failure to find anything.
-        """
-        read = DNARead("id", "AT")
-        self.assertEqual(
-            {
-                "foundStartCodon": False,
-                "foundStopCodon": False,
-                "length": 0,
-                "sequence": "",
-                "translation": "",
-            },
-            read.findORF(0),
-        )
-
-    def testOffsetOutOfRangeForward(self):
-        """
-        If an out-of-range offset and forward is True, is passed we must get
-        back a dictionary indicating failure to find anything.
-        """
-        read = DNARead("id", "")
-        self.assertEqual(
-            {
-                "foundStartCodon": False,
-                "foundStopCodon": False,
-                "length": 0,
-                "sequence": "",
-                "translation": "",
-            },
-            read.findORF(10, forward=True),
-        )
-
-    def testOffsetOutOfRangeReverse(self):
-        """
-        If an out-of-range offset and forward is False, is passed we must get
-        back a dictionary indicating failure to find anything.
-        """
-        read = DNARead("id", "")
-        self.assertEqual(
-            {
-                "foundStartCodon": False,
-                "foundStopCodon": False,
-                "length": 0,
-                "sequence": "",
-                "translation": "",
-            },
-            read.findORF(10, forward=False),
-        )
-
-    def testRequireStartCodonForward(self):
-        """
-        If a start codon is required but is not present when forward is True,
-        we must get back a dictionary indicating failure to find anything.
-        """
-        read = DNARead("id", "CCAGG")
-        self.assertEqual(
-            {
-                "foundStartCodon": False,
-                "foundStopCodon": False,
-                "length": 0,
-                "sequence": "",
-                "translation": "",
-            },
-            read.findORF(0, requireStartCodon=True, forward=True),
-        )
-
-    def testRequireStartCodonReverse(self):
-        """
-        If a start codon is required but is not present when forward is False,
-        we must get back a dictionary indicating failure to find anything.
-        """
-        read = DNARead("id", "CCAGG")
-        self.assertEqual(
-            {
-                "foundStartCodon": False,
-                "foundStopCodon": False,
-                "length": 0,
-                "sequence": "",
-                "translation": "",
-            },
-            read.findORF(0, requireStartCodon=True, forward=False),
-        )
-
-    def testOnlyStartCodonForward(self):
-        """
-        If a read consists just of a start codon and forward is True we must
-        get the expected result.
-        """
-        read = DNARead("id", "ATG")
-        self.assertEqual(
-            {
-                "foundStartCodon": True,
-                "foundStopCodon": False,
-                "length": 1,
-                "sequence": "ATG",
-                "translation": "M",
-            },
-            read.findORF(0, forward=True),
-        )
-
-    def testOnlyStartCodonReverse(self):
-        """
-        If a read consists just of a start codon and forward is False we must
-        get the expected result.
-        """
-        read = DNARead("id", "CAT")
-        self.assertEqual(
-            {
-                "foundStartCodon": True,
-                "foundStopCodon": False,
-                "length": 1,
-                "sequence": "ATG",
-                "translation": "M",
-            },
-            read.findORF(0, forward=False),
-        )
-
-    def testOnlyStartStopCodonForward(self):
-        """
-        If a read consists just of a start codon and then a stop codon
-        and forward is True we must get the expected result.
-        """
-        read = DNARead("id", "ATGTAG")
-        self.assertEqual(
-            {
-                "foundStartCodon": True,
-                "foundStopCodon": True,
-                "length": 2,
-                "sequence": "ATGTAG",
-                "translation": "M*",
-            },
-            read.findORF(0, forward=True),
-        )
-
-    def testOnlyStartStopCodonReverse(self):
-        """
-        If a read consists just of a start codon and then a stop codon
-        and forward is False we must get the expected result.
-        """
-        read = DNARead("id", "CTACAT")
-        self.assertEqual(
-            {
-                "foundStartCodon": True,
-                "foundStopCodon": True,
-                "length": 2,
-                "sequence": "ATGTAG",
-                "translation": "M*",
-            },
-            read.findORF(0, forward=False),
-        )
-
-    def testStartAndNoStopCodonForward(self):
-        """
-        If a read consists just of a start codon and then a non-stop codon
-        and forward is True we must get the expected result.
-        """
-        read = DNARead("id", "ATGTCC")
-        self.assertEqual(
-            {
-                "foundStartCodon": True,
-                "foundStopCodon": False,
-                "length": 2,
-                "sequence": "ATGTCC",
-                "translation": "MS",
-            },
-            read.findORF(0, forward=True),
-        )
-
-    def testStartAndNoStopCodonReverse(self):
-        """
-        If a read consists just of a start codon and then a stop codon
-        and forward is False we must get the expected result.
-        """
-        read = DNARead("id", "CTCCAT")
-        self.assertEqual(
-            {
-                "foundStartCodon": True,
-                "foundStopCodon": False,
-                "length": 2,
-                "sequence": "ATGGAG",
-                "translation": "ME",
-            },
-            read.findORF(0, forward=False),
-        )
-
-
-class TestGetNoCoverageCounts(TestCase):
-    """
-    Test the getNoCoverageCounts function.
-    """
-
-    def testNoCoverageCharsNone(self):
-        """
-        When None is passed for the no-coverage chars, the result
-        counts must all be zero.
-        """
-        reads = Reads()
-        reads.add(Read("id1", "aaa"))
-        reads.add(Read("id2", "caa"))
-        result = getNoCoverageCounts(reads, None)
-        self.assertEqual({"id1": 0, "id2": 0}, result)
-
-    def testNoCoverageCharsEmptyString(self):
-        """
-        When an empty string is passed for the no-coverage chars, the result
-        counts must all be zero.
-        """
-        reads = Reads()
-        reads.add(Read("id1", "aaa"))
-        reads.add(Read("id2", "caa"))
-        result = getNoCoverageCounts(reads, "")
-        self.assertEqual({"id1": 0, "id2": 0}, result)
-
-    def testExpected(self):
-        """
-        When a non-empty string is passed for the no-coverage chars, the result
-        must be as expected.
-        """
-        reads = Reads()
-        reads.add(Read("id1", "aaa--c"))
-        reads.add(Read("id2", "caa?g"))
-        result = getNoCoverageCounts(reads, "-?")
-        self.assertEqual({"id1": 2, "id2": 1}, result)
```

### Comparing `dark-matter-4.0.84/test/test_score.py` & `dark-matter-4.0.9/test/test_score.py`

 * *Files identical despite different names*

### Comparing `dark-matter-4.0.84/test/test_sequence.py` & `dark-matter-4.0.9/test/test_sequence.py`

 * *Files 10% similar despite different names*

```diff
@@ -8,159 +8,162 @@
     Tests for the dark.sequence.findPrimer function.
     """
 
     def testNotFound(self):
         """
         If a primer is not found, the empty list must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual([], findPrimer("BLAH", seq))
+        seq = Seq('ACGT')
+        self.assertEqual([], findPrimer('BLAH', seq))
 
     def testFoundAtStart(self):
         """
         If a primer is found at the start of a sequence, a list containing 0
         must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual([0], findPrimer("AC", seq))
+        seq = Seq('ACGT')
+        self.assertEqual([0], findPrimer('AC', seq))
 
     def testFoundAtEnd(self):
         """
         If a primer is found at the end of a sequence, the correct value
         must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual([2], findPrimer("GT", seq))
+        seq = Seq('ACGT')
+        self.assertEqual([2], findPrimer('GT', seq))
 
     def testFoundMultiple(self):
         """
         If a primer is found multiple times, the correct value
         must be returned.
         """
-        seq = Seq("ACGTACGT")
-        self.assertEqual([0, 4], findPrimer("ACG", seq))
+        seq = Seq('ACGTACGT')
+        self.assertEqual([0, 4], findPrimer('ACG', seq))
 
     def testOverlapping(self):
         """
         If a primer is present twice but is overlapping, only the first
         instance should be returned.
         """
-        seq = Seq("GAAA")
-        self.assertEqual([1], findPrimer("AA", seq))
+        seq = Seq('GAAA')
+        self.assertEqual([1], findPrimer('AA', seq))
 
 
 class TestFindPrimerBidi(TestCase):
     """
     Tests for the dark.sequence.findPrimerBidi function.
     """
 
     def testNotFound(self):
         """
         If a primer is not found, empty lists must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual(([], []), findPrimerBidi("BLAH", seq))
+        seq = Seq('ACGT')
+        self.assertEqual(([], []), findPrimerBidi('BLAH', seq))
 
     def testFoundStartEnd(self):
         """
         If a primer is found in both directions in a sequence (start of
         the forward sequence, end of the reverse complement), the
         correct value must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual(([0], [2]), findPrimerBidi("AC", seq))
+        seq = Seq('ACGT')
+        self.assertEqual(([0], [2]), findPrimerBidi('AC', seq))
 
     def testFoundEndStart(self):
         """
         If a primer is found in both directions in a sequence (end of
         the forward sequence, start of the reverse complement), the
         correct value must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual(([2], [0]), findPrimerBidi("GT", seq))
+        seq = Seq('ACGT')
+        self.assertEqual(([2], [0]), findPrimerBidi('GT', seq))
 
     def testFoundMultiple(self):
         """
         If a primer is found multiple times, the correct value
         must be returned.
         """
-        seq = Seq("ACGTACGT")
-        self.assertEqual(([0, 4], [1, 5]), findPrimerBidi("ACG", seq))
+        seq = Seq('ACGTACGT')
+        self.assertEqual(([0, 4], [1, 5]), findPrimerBidi('ACG', seq))
 
     def testOverlappingForwards(self):
         """
         If a primer is present twice forwards but is overlapping, only
         the first instance should be returned.
         """
-        seq = Seq("GAAA")
-        self.assertEqual(([1], []), findPrimerBidi("AA", seq))
+        seq = Seq('GAAA')
+        self.assertEqual(([1], []), findPrimerBidi('AA', seq))
 
     def testOverlappingBackwards(self):
         """
         If a primer is present twice backwards but is overlapping, only
         the first instance should be returned.
         """
-        seq = Seq("GTTT")
-        self.assertEqual(([], [1]), findPrimerBidi("AA", seq))
+        seq = Seq('GTTT')
+        self.assertEqual(([], [1]), findPrimerBidi('AA', seq))
 
 
 class TestFindPrimerBidiLimits(TestCase):
     """
     Tests for the dark.sequence.findPrimerBidiLimits function.
     """
 
     def testNotFound(self):
         """
         If a primer is not found, the returned offsets must include
         the whole sequence.
         """
-        seq = Seq("ACGT")
-        self.assertEqual((0, 4), findPrimerBidiLimits("BLAH", seq))
+        seq = Seq('ACGT')
+        self.assertEqual((0, 4), findPrimerBidiLimits('BLAH', seq))
 
     def testFoundStartEnd(self):
         """
         If a primer is found in both directions in a sequence (start of
         the forward sequence, end of the reverse complement), the
         correct value must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual((2, 2), findPrimerBidiLimits("AC", seq))
+        seq = Seq('ACGT')
+        self.assertEqual((2, 2), findPrimerBidiLimits('AC', seq))
 
     def testFoundEndStart(self):
         """
         If a primer is found in both directions in a sequence (end of
         the forward sequence, start of the reverse complement), the
         correct value must be returned.
         """
-        seq = Seq("ACGT")
-        self.assertEqual((4, 4), findPrimerBidiLimits("GT", seq))
+        seq = Seq('ACGT')
+        self.assertEqual((4, 4), findPrimerBidiLimits('GT', seq))
 
     def testFoundMultiple(self):
         """
         If a primer is found multiple times, the correct value
         must be returned.
         """
-        seq = Seq("ACGTACGT")
-        self.assertEqual((7, 8), findPrimerBidiLimits("ACG", seq))
+        seq = Seq('ACGTACGT')
+        self.assertEqual((7, 8), findPrimerBidiLimits('ACG', seq))
 
     def testOverlappingForwards(self):
         """
         If a primer is present twice forwards but is overlapping, only
         the first instance should be returned.
         """
-        seq = Seq("GAAA")
-        self.assertEqual((3, 4), findPrimerBidiLimits("AA", seq))
+        seq = Seq('GAAA')
+        self.assertEqual((3, 4), findPrimerBidiLimits('AA', seq))
 
     def testOverlappingBackwards(self):
         """
         If a primer is present twice backwards but is overlapping, only
         the first instance should be returned.
         """
-        seq = Seq("GTTT")
-        self.assertEqual((0, 1), findPrimerBidiLimits("AA", seq))
+        seq = Seq('GTTT')
+        self.assertEqual((0, 1), findPrimerBidiLimits('AA', seq))
 
     def testLonger(self):
         """
         Test a longer sequence.
         """
-        seq = Seq("AAAAAAAAAA" "GGGGGGGGGG" "AAAAAAAAAA" "AAAAAAAAAA")
-        self.assertEqual((20, 40), findPrimerBidiLimits("GGGGGGGGGG", seq))
+        seq = Seq('AAAAAAAAAA'
+                  'GGGGGGGGGG'
+                  'AAAAAAAAAA'
+                  'AAAAAAAAAA')
+        self.assertEqual((20, 40), findPrimerBidiLimits('GGGGGGGGGG', seq))
```

### Comparing `dark-matter-4.0.84/test/test_simplify.py` & `dark-matter-4.0.9/test/test_simplify.py`

 * *Files 7% similar despite different names*

```diff
@@ -9,54 +9,50 @@
     """
 
     def testEmptyTitle(self):
         """
         Simplifying an empty title with a non-empty target should return
         an empty title.
         """
-        self.assertEqual("", simplifyTitle("", "xxx"))
+        self.assertEqual('', simplifyTitle('', 'xxx'))
 
     def testEmtpyTitleWithEmptyTarget(self):
         """
         Simplifying an empty title should return an empty title.
         """
-        self.assertEqual("", simplifyTitle("", ""))
+        self.assertEqual('', simplifyTitle('', ''))
 
     def testPrefix(self):
         """
         When the target is a prefix, the title up to the target (including the
         whole word that has the prefix) should be returned.
         """
         self.assertEqual(
-            "Funny sea lion polyoma",
-            simplifyTitle("Funny sea lion polyomavirus 1 CSL6994", "polyoma"),
-        )
+            'Funny sea lion polyoma',
+            simplifyTitle('Funny sea lion polyomavirus 1 CSL6994', 'polyoma'))
 
     def testSuffix(self):
         """
         When the target is a suffix, the title up to the target (including the
         whole word that has the suffix) should be returned.
         """
         self.assertEqual(
-            "Funny sea lion polyomavirus",
-            simplifyTitle("Funny sea lion polyomavirus 1 CSL6994", "virus"),
-        )
+            'Funny sea lion polyomavirus',
+            simplifyTitle('Funny sea lion polyomavirus 1 CSL6994', 'virus'))
 
     def testContained(self):
         """
         When the target is contained, the title up to the target (including the
         prefix of the word that has the target) should be returned.
         """
         self.assertEqual(
-            "Funny sea lion polyoma",
-            simplifyTitle("Funny sea lion polyomavirus 1 CSL6994", "yoma"),
-        )
+            'Funny sea lion polyoma',
+            simplifyTitle('Funny sea lion polyomavirus 1 CSL6994', 'yoma'))
 
     def testExact(self):
         """
         When the target is the same as a word in the title, the title up to
         and including the target should be returned.
         """
         self.assertEqual(
-            "Funny sea lion",
-            simplifyTitle("Funny sea lion polyomavirus 1 CSL6994", "lion"),
-        )
+            'Funny sea lion',
+            simplifyTitle('Funny sea lion polyomavirus 1 CSL6994', 'lion'))
```

### Comparing `dark-matter-4.0.84/test/test_taxonomy.py` & `dark-matter-4.0.9/test/test_utils.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,635 +1,543 @@
+import bz2
+import gzip
+from six.moves import builtins
 from unittest import TestCase
-import six
-import sqlite3
+from unittest.mock import mock_open
+from six import assertRaisesRegex
+from collections import Counter
 
-from dark.taxonomy import (
-    LineageElement as LE,
-    LineageFetcher,
-    Taxonomy,
-    isRetrovirus,
-    isRNAVirus,
-    isAllowedTaxonomicRank,
-)
+try:
+    from unittest.mock import patch
+except ImportError:
+    from mock import patch
 
+from io import BytesIO
 
-class FakeCursor:
-    def __init__(self, results):
-        self._results = results
-        self._index = -1
+from dark.utils import (
+    numericallySortFilenames, median, asHandle, parseRangeString,
+    parseRangeExpression, pct, StringIO, baseCountsToStr, nucleotidesToStr,
+    countPrint, take)
 
-    def execute(self, p):
-        pass
 
-    def fetchone(self):
-        self._index += 1
-        return self._results[self._index]
+class TestNumericallySortFilenames(TestCase):
+    """
+    Test the numericallySortFilenames function.
+    """
 
-    def close(self):
-        pass
+    def testNoNames(self):
+        """
+        An empty list must be returned when an empty list is given.
+        """
+        self.assertEqual([], numericallySortFilenames([]))
 
+    def testOneNonNumericName(self):
+        """
+        A list with a single non-numeric name should result in that same
+        name being returned.
+        """
+        self.assertEqual(['hey'], numericallySortFilenames(['hey']))
 
-class FakeDbConnection:
-    def __init__(self, results):
-        self._results = results
-        self.open = True
+    def testOneNumericName(self):
+        """
+        A list with a single numeric name should result in that same
+        name being returned.
+        """
+        self.assertEqual(['3.json'], numericallySortFilenames(['3.json']))
 
-    def cursor(self):
-        return FakeCursor(self._results)
+    def testSeveralNames(self):
+        """
+        A list with several numeric names should result in a correctly
+        sorted list of names being returned.
+        """
+        self.assertEqual(
+            ['1.json', '2.json', '3.json'],
+            numericallySortFilenames(['3.json', '1.json', '2.json']))
 
-    def close(self):
-        self.open = False
+    def testSeveralNamesWithUnequalPrefixLengths(self):
+        """
+        A list with several numeric names whose numeric prefixes differ
+        in length should result in a correctly sorted list of names being
+        returned.
+        """
+        self.assertEqual(
+            ['2.json', '3.json', '21.json', '35.json', '250.json'],
+            numericallySortFilenames(
+                ['3.json', '21.json', '35.json', '250.json', '2.json']))
 
+    def testBasename(self):
+        """
+        Sorting must be according to file basename.
+        """
+        self.assertEqual(
+            ['../output/2.json', '../output/3.json', '../output/21.json',
+             '../output/35.json', '../output/250.json'],
+            numericallySortFilenames(
+                ['../output/3.json', '../output/21.json', '../output/35.json',
+                 '../output/250.json', '../output/2.json']))
 
-class TestLineageFetcher(TestCase):
+
+class TestMedian(TestCase):
     """
-    Test LineageFetcher class.
+    Tests for the median function.
     """
 
-    def testGetTaxonomy(self):
+    def testEmptyArgRaises(self):
         """
-        Test if the LineageFetcher class works properly.
+        An empty list must cause median to raise ValueError.
         """
-        title = "gi|5|gb|EU375804.1| Merkel cell polyomavirus"
+        error = '^arg is an empty sequence$'
+        assertRaisesRegex(self, ValueError, error, median, [])
 
-        db = FakeDbConnection(
-            [
-                [15],
-                ["Merkel cell polyomavirus"],
-                [4],
-                ["Polyomavirus"],
-                [3],
-                ["dsDNA viruses"],
-                [2],
-                ["Vira"],
-                [1],
-            ]
-        )
-        cursor = db.cursor()
+    def testMedianOfOne(self):
+        """
+        The median function must work on a list of length one.
+        """
+        self.assertEqual(3, median([3]))
 
-        lineageFetcher = LineageFetcher(db=db, cursor=cursor)
+    def testMedianOfTwo(self):
+        """
+        The median function must work on a list of length two.
+        """
+        self.assertEqual(4.5, median([3.1, 5.9]))
 
-        lineage = lineageFetcher.lineage(title)
-        self.assertEqual(
-            [
-                (15, "Merkel cell polyomavirus"),
-                (4, "Polyomavirus"),
-                (3, "dsDNA viruses"),
-                (2, "Vira"),
-            ],
-            lineage,
-        )
+    def testMedianOfThree(self):
+        """
+        The median function must work on a list of length threee.
+        """
+        self.assertEqual(5.9, median([3.1, 7.6, 5.9]))
+
+    def testMedianOfFour(self):
+        """
+        The median function must work on a list of length four.
+        """
+        self.assertEqual(4.5, median([3.1, 1.3, 7.6, 5.9]))
+
+    def testMedianOfFive(self):
+        """
+        The median function must work on a list of length five.
+        """
+        self.assertEqual(5.9, median([3.1, 1.3, 7.6, 9.9, 5.9]))
 
 
-class TestTaxonomy(TestCase):
+class TestAsHandle(TestCase):
     """
-    Test the Taxonomy class.
+    Test the asHandle function
     """
 
-    def _makeFetcher(self, data):
+    def testOpenFile(self):
         """
-        Make a taxonomy database and put it into an Taxonomy
-        instance.
-
-        @param data: A C{dict} with 'taxids', 'names', and 'nodes' keys,
-            each of which is a C{list} of C{tuple}s containing values to
-            insert into the respective tables.
-        @return: A C{Taxonomy} instance.
-        """
-        db = sqlite3.connect(":memory:")
-        cursor = db.cursor()
-
-        # The tables created here must be identical to those expected by
-        # the Taxonomy class. See also
-        # https://github.com/acorg/ncbi-taxonomy-database
-        cursor.executescript(
-            """
-            CREATE TABLE nodes (
-                taxid INTEGER NOT NULL,
-                parent_taxid INTEGER NOT NULL,
-                rank VARCHAR NOT NULL
-            );
-
-            CREATE TABLE accession_taxid (
-                accession VARCHAR UNIQUE PRIMARY KEY,
-                taxid INTEGER NOT NULL
-            );
-
-            CREATE TABLE names (
-                taxid INTEGER NOT NULL,
-                name VARCHAR NOT NULL
-            );
-
-            CREATE INDEX nodes_idx ON nodes(taxid);
-            CREATE INDEX accession_idx ON accession_taxid(accession);
-            CREATE INDEX name_idx ON names(taxid);
+        When an open file pointer is passed to asHandle, that same file
+        pointer must be returned.
         """
-        )
+        with patch.object(builtins, 'open', mock_open()):
+            fp = open('file')
+            with asHandle(fp) as newfp:
+                self.assertIs(fp, newfp)
+
+    def testStr(self):
+        """
+        When a string filename is passed to asHandle, it must be possible to
+        read the correct data from the fp that is returned.
+        """
+        mockOpener = mock_open(read_data='xxx')
+        with patch.object(builtins, 'open', mockOpener):
+            with asHandle('file') as fp:
+                self.assertEqual('xxx', fp.read())
 
-        execute = cursor.execute
+    def testBZ2(self):
+        """
+        When a string '*.bz2' filename is passed to asHandle, it must be
+        possible to read the correct data from the fp that is returned.
+        """
+        result = BytesIO(b'xxx')
 
-        for accession, taxid in data.get("taxids", []):
-            execute("INSERT INTO accession_taxid VALUES (?, ?)", (accession, taxid))
+        with patch.object(bz2, 'BZ2File') as mockMethod:
+            mockMethod.return_value = result
+            with asHandle('file.bz2') as fp:
+                self.assertEqual('xxx', fp.read())
 
-        for taxid, name in data.get("names", []):
-            execute("INSERT INTO names VALUES (?, ?)", (taxid, name))
+    def testGzip(self):
+        """
+        When a string '*.gz' filename is passed to asHandle, it must be
+        possible to read the correct data from the fp that is returned.
+        """
+        result = BytesIO(b'xxx')
 
-        for taxid, parentTaxid, rank in data.get("nodes", []):
-            execute("INSERT INTO nodes VALUES (?, ?, ?)", (taxid, parentTaxid, rank))
+        with patch.object(gzip, 'GzipFile') as mockMethod:
+            mockMethod.return_value = result
+            with asHandle('file.gz') as fp:
+                self.assertEqual('xxx', fp.read())
 
-        return Taxonomy(db)
 
-    def testUnknownTaxid(self):
+class TestParseRangeString(TestCase):
+    """
+    Check that the parseRangeString function works as expected.
+    """
+    def testEmptyString(self):
         """
-        If a taxonomy id is not present in the accession_taxid table, the
-        lineage fetcher must raise a C{ValueError}.
+        An empty string must produce an empty set of indices.
         """
-        fetcher = self._makeFetcher({})
-        error = r"^Could not find 'DQ011818\.1' in accession_taxid or names " r"tables$"
-        six.assertRaisesRegex(self, ValueError, error, fetcher.lineage, "DQ011818.1")
-        fetcher.close()
+        error = ("^Illegal range ''. Ranges must single numbers or "
+                 "number-number\\.$")
+        assertRaisesRegex(self, ValueError, error, parseRangeString, '')
 
-    def testReusingClosedFetcher(self):
+    def testSingleNumber(self):
         """
-        Trying to re-use a closed fetcher must result in an AttributeError
-        being raised.
+        A single number must result in the expected set.
         """
-        fetcher = self._makeFetcher({})
-        fetcher.close()
-        error = "^'NoneType' object has no attribute 'cursor'$"
-        six.assertRaisesRegex(
-            self, AttributeError, error, fetcher.lineage, "DQ011818.1"
-        )
+        self.assertEqual({6}, parseRangeString('6'))
 
-    def testTaxidNotInNamesTable(self):
+    def testSingleNumberSpaceBefore(self):
         """
-        If a taxonomy id is not present in the names table, a ValueError must
-        be raised.
+        A single number preceeded by whitespace must result in the expected
+        set.
         """
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-            }
-        )
-        error = "^Could not find taxonomy id 500 in names table$"
-        six.assertRaisesRegex(self, ValueError, error, fetcher.lineage, "DQ011818.1")
-        fetcher.close()
-
-    def testTaxidNotInNodesTable(self):
-        """
-        If a taxonomy id is not present in the nodes table, a ValueError must
-        be raised.
-        """
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-                "names": ((500, "Porcine endogenous retrovirus A"),),
-            }
-        )
-        error = "^Could not find taxonomy id 500 in nodes table$"
-        six.assertRaisesRegex(self, ValueError, error, fetcher.lineage, "DQ011818.1")
-        fetcher.close()
-
-    def testLookupByAccession(self):
-        """
-        The full taxonomy of an accession number must be retrievable.
-        """
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-                "names": (
-                    (500, "Porcine endogenous retrovirus A"),
-                    (400, "Retroviruses"),
-                    (300, "Viruses"),
-                ),
-                "nodes": (
-                    (500, 400, "species"),
-                    (400, 300, "genus"),
-                    (300, 1, "realm"),
-                ),
-            }
-        )
+        self.assertEqual({6}, parseRangeString('  6'))
 
-        self.assertEqual(
-            (
-                (500, "Porcine endogenous retrovirus A", "species"),
-                (400, "Retroviruses", "genus"),
-                (300, "Viruses", "realm"),
-            ),
-            fetcher.lineage("DQ011818.1"),
-        )
-        fetcher.close()
+    def testSingleNumberSpaceAfter(self):
+        """
+        A single number followed by whitespace must result in the expected
+        set.
+        """
+        self.assertEqual({6}, parseRangeString('6  '))
 
-    def testLookupByName(self):
+    def testSingleNumberSpaceBeforeAndAfter(self):
         """
-        The taxonomy must be retrievable by name.
+        A single number preceeded and followed by whitespace must result in
+        the expected set.
         """
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-                "names": (
-                    (500, "Porcine endogenous retrovirus A"),
-                    (400, "Retroviruses"),
-                    (300, "Viruses"),
-                ),
-                "nodes": (
-                    (500, 400, "species"),
-                    (400, 300, "genus"),
-                    (300, 1, "realm"),
-                ),
-            }
-        )
+        self.assertEqual({6}, parseRangeString(' 6  '))
 
-        self.assertEqual(
-            (
-                (500, "Porcine endogenous retrovirus A", "species"),
-                (400, "Retroviruses", "genus"),
-                (300, "Viruses", "realm"),
-            ),
-            fetcher.lineage("Porcine endogenous retrovirus A"),
-        )
-        fetcher.close()
+    def testSingleRange(self):
+        """
+        A single range must result in the expected set.
+        """
+        self.assertEqual({6, 7, 8, 9, 10}, parseRangeString('6-10'))
 
-    def testLookupByTaxid(self):
+    def testSingleRangeWithSpaceBeforeHyphen(self):
         """
-        The taxonomy must be retrievable by taxonomy id.
+        A single range with a space before the hyphen must result in the
+        expected set.
         """
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-                "names": (
-                    (500, "Porcine endogenous retrovirus A"),
-                    (400, "Retroviruses"),
-                    (300, "Viruses"),
-                ),
-                "nodes": (
-                    (500, 400, "species"),
-                    (400, 300, "genus"),
-                    (300, 1, "realm"),
-                ),
-            }
-        )
+        self.assertEqual({6, 7, 8, 9, 10}, parseRangeString('6 -10'))
 
-        self.assertEqual(
-            (
-                (500, "Porcine endogenous retrovirus A", "species"),
-                (400, "Retroviruses", "genus"),
-                (300, "Viruses", "realm"),
-            ),
-            fetcher.lineage(500),
-        )
-        fetcher.close()
+    def testSingleRangeWithSpaceAfterHyphen(self):
+        """
+        A single range with a space after the hyphen must result in the
+        expected set.
+        """
+        self.assertEqual({6, 7, 8, 9, 10}, parseRangeString('6- 10'))
 
-    def testLookupWithSkip(self):
+    def testSingleRangeWithSpaceBeforeAfterHyphen(self):
         """
-        It must be possible to skip a level when retrieving a taxonomy.
+        A single range with spaces before and after the hyphen must result in
+        the expected set.
         """
+        self.assertEqual({6, 7, 8, 9, 10}, parseRangeString('6 - 10'))
 
-        def skipFunc(lineageElement):
-            return lineageElement.rank == "genus"
-
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-                "names": (
-                    (500, "Porcine endogenous retrovirus A"),
-                    (400, "Retroviruses"),
-                    (300, "Viruses"),
-                ),
-                "nodes": (
-                    (500, 400, "species"),
-                    (400, 300, "genus"),
-                    (300, 1, "realm"),
-                ),
-            }
-        )
+    def testTwoRanges(self):
+        """
+        Two ranges must result in the expected set.
+        """
+        self.assertEqual({6, 7, 8, 9, 10}, parseRangeString('6-8,9-10'))
 
-        self.assertEqual(
-            (
-                (500, "Porcine endogenous retrovirus A", "species"),
-                (300, "Viruses", "realm"),
-            ),
-            fetcher.lineage(500, skipFunc=skipFunc),
-        )
-        fetcher.close()
+    def testTwoOverlappingRanges(self):
+        """
+        Two overlapping ranges must result in the expected set.
+        """
+        self.assertEqual({6, 7, 8, 9, 10}, parseRangeString('6-9,7-10'))
 
-    def testLookupWithStop(self):
+    def testTwoRangesAndANumber(self):
         """
-        It must be possible to stop at a level when retrieving a taxonomy.
+        Two ranges and a number must result in the expected set.
         """
+        self.assertEqual({6, 7, 8, 10}, parseRangeString('6-8,10'))
 
-        def stopFunc(lineageElement):
-            return lineageElement.rank == "genus"
-
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-                "names": (
-                    (500, "Porcine endogenous retrovirus A"),
-                    (400, "Retroviruses"),
-                    (300, "Viruses"),
-                ),
-                "nodes": (
-                    (500, 400, "species"),
-                    (400, 300, "genus"),
-                    (300, 1, "realm"),
-                ),
-            }
-        )
+    def testTwoRangesAndTwoNumbers(self):
+        """
+        Two ranges and two numbers must result in the expected set.
+        """
+        self.assertEqual({4, 6, 7, 8, 9, 10, 11, 12},
+                         parseRangeString('6-8,9,10-12,4'))
+
+    def testZeroConversion(self):
+        """
+        If we ask for zero conversion, the result must be as expected.
+        """
+        self.assertEqual({3, 5, 6, 7, 8, 9, 10, 11},
+                         parseRangeString('6-8,9,10-12,4',
+                                          convertToZeroBased=True))
 
-        self.assertEqual(
-            (
-                (500, "Porcine endogenous retrovirus A", "species"),
-                (400, "Retroviruses", "genus"),
-            ),
-            fetcher.lineage(500, stopFunc=stopFunc),
-        )
-        fetcher.close()
 
-    def testLookupWithSkipAndStop(self):
+class TestParseRangeExpression(TestCase):
+    """
+    Check that the parseRangeExpression function works as expected.
+    """
+    def testInvalidExpression(self):
         """
-        It must be possible to stop at a level when retrieving a taxonomy
-        and skip the last (stopping) level.
+        An invalid string must raise a ValueError.
         """
+        error = r'^\($'
+        assertRaisesRegex(self, ValueError, error, parseRangeExpression, '(')
+        error = r'^hey$'
+        assertRaisesRegex(self, ValueError, error, parseRangeExpression, 'hey')
 
-        def skipFunc(lineageElement):
-            return lineageElement.rank == "genus"
-
-        def stopFunc(lineageElement):
-            return lineageElement.rank == "genus"
-
-        fetcher = self._makeFetcher(
-            {
-                "taxids": (("DQ011818.1", 500),),
-                "names": (
-                    (500, "Porcine endogenous retrovirus A"),
-                    (400, "Retroviruses"),
-                    (300, "Viruses"),
-                ),
-                "nodes": (
-                    (500, 400, "species"),
-                    (400, 300, "genus"),
-                    (300, 1, "realm"),
-                ),
-            }
-        )
+    def testEmptyString(self):
+        """
+        An empty string must produce an empty set.
+        """
+        self.assertEqual(set(), parseRangeExpression(''))
 
-        self.assertEqual(
-            ((500, "Porcine endogenous retrovirus A", "species"),),
-            fetcher.lineage(500, skipFunc=skipFunc, stopFunc=stopFunc),
-        )
-        fetcher.close()
+    def testOneRange(self):
+        """
+        A simple 3-4 string must produce the expected set.
+        """
+        self.assertEqual({3, 4}, parseRangeExpression('3-4'))
 
-    def testSubsetLineageByRanks(self):
+    def testOneRangeZeroBased(self):
         """
-        Test the Taxonomy.subsetLineageByRanks static method.
+        A simple 3-4 string must produce the expected set when
+        convertToZeroBased is True.
         """
-        lineage = (
-            LE(11234, "Measles morbillivirus", "species"),
-            LE(11229, "Morbillivirus", "genus"),
-            LE(2560076, "Orthoparamyxovirinae", "subfamily"),
-            LE(11158, "Paramyxoviridae", "family"),
-            LE(11157, "Mononegavirales", "order"),
-            LE(2497574, "Monjiviricetes", "class"),
-            LE(2497570, "Haploviricotina", "subphylum"),
-            LE(2497569, "Negarnaviricota", "phylum"),
-            LE(2559587, "Riboviria", "realm"),
-            LE(10239, "Viruses", "superkingdom"),
-        )
+        self.assertEqual({2, 3}, parseRangeExpression('3-4', True))
 
-        def filterFunc(rank):
-            return rank in {"phylum", "genus"}
+    def testCommas(self):
+        """
+        A simple 3,4,5 string must produce the expected set.
+        """
+        self.assertEqual({3, 4, 5}, parseRangeExpression('3,4,5'))
 
-        self.assertEqual(
-            (
-                LE(11229, "Morbillivirus", "genus"),
-                LE(2497569, "Negarnaviricota", "phylum"),
-            ),
-            tuple(Taxonomy.subsetLineageByRanks(lineage, filterFunc)),
-        )
+    def testCommasAndRange(self):
+        """
+        A simple 3,4,5-7 string must produce the expected set.
+        """
+        self.assertEqual({3, 4, 5, 6, 7}, parseRangeExpression('3,4,5-7'))
 
+    def testTwoRanges(self):
+        """
+        A simple 3-4,6-8 string must produce the expected set.
+        """
+        self.assertEqual({3, 4, 6, 7, 8}, parseRangeExpression('3-4,6-8'))
 
-class TestIsRetrovirus(TestCase):
-    """
-    Test the isRetrovirus function.
-    """
+    def testTwoRangesWithSpace(self):
+        """
+        A simple 3-4, 6-8 string must produce the expected set.
+        """
+        self.assertEqual({3, 4, 6, 7, 8}, parseRangeExpression('3-4, 6-8'))
 
-    def testYes(self):
+    def testUnion(self):
         """
-        A retrovirus must be detected.
+        A union such as 3-4 | 6-8 must produce the expected set.
         """
-        self.assertTrue(
-            isRetrovirus(
-                (
-                    LE(11676, "Human immunodeficiency virus 1", "species"),
-                    LE(11646, "Lentivirus", "genus"),
-                    LE(327045, "Orthoretrovirinae", "subfamily"),
-                    LE(11632, "Retroviridae", "family"),
-                    LE(2169561, "Ortervirales", "order"),
-                    LE(10239, "Viruses", "superkingdom"),
-                )
-            )
-        )
+        self.assertEqual({3, 4, 6, 7, 8}, parseRangeExpression('3-4 | 6-8'))
 
-    def testNo(self):
+    def testIntersection(self):
         """
-        A non-retrovirus must be detected.
+        An intersection such as 3-4 & 4-8 must produce the expected set.
         """
-        self.assertFalse(
-            isRetrovirus(
-                (
-                    LE(10310, "Human alphaherpesvirus 2", "species"),
-                    LE(10294, "Simplexvirus", "genus"),
-                    LE(10293, "Alphaherpesvirinae", "subfamily"),
-                    LE(10292, "Herpesviridae", "family"),
-                    LE(548681, "Herpesvirales", "order"),
-                    LE(10239, "Viruses", "superkingdom"),
-                )
-            )
-        )
+        self.assertEqual({4}, parseRangeExpression('3-4 & 4-8'))
 
+    def testDifferenceNoSpaces(self):
+        """
+        A difference such as 6-10-7-8 must produce the expected set.
+        """
+        self.assertEqual({6, 9, 10}, parseRangeExpression('6-10-7-8'))
+
+    def testDifferenceWithSpaces(self):
+        """
+        A difference such as 6-10 - 7-8 must produce the expected set.
+        """
+        self.assertEqual({6, 9, 10}, parseRangeExpression('6-10 - 7-8'))
 
-class TestIsRNAVirus(TestCase):
+    def testParens(self):
+        """
+        A difference with parentheses such as '(3-5 | 7-9) & 5-7' must produce
+        the expected set.
+        """
+        self.assertEqual({5, 7}, parseRangeExpression('(3-5 | 7-9) & 5-7'))
+
+    def testDoubleParens(self):
+        """
+        A difference with two parentheses such as '(3-5 | 7-9) & (5-7 | 9-11)'
+        must produce the expected set.
+        """
+        self.assertEqual({5, 7, 9},
+                         parseRangeExpression('(3-5 | 7-9) & (5-7 | 9-11)'))
+
+
+class TestStringIO(TestCase):
     """
-    Test the isRNAVirus function.
+    Tests for our StringIO class.
     """
+    def testInitiallyEmpty(self):
+        """
+        A StringIO instance must initially be empty.
+        """
+        self.assertEqual('', StringIO().getvalue())
 
-    def testByRealm(self):
+    def testWriteRead(self):
         """
-        Anything in the Riboviria realm must be classified as an RNA virus.
+        It must be possible to write and read to/from a StringIO instance as
+        normal.
         """
-        self.assertTrue(
-            isRNAVirus(
-                (
-                    LE(11234, "Measles morbillivirus", "species"),
-                    LE(11229, "Morbillivirus", "genus"),
-                    LE(2560076, "Orthoparamyxovirinae", "subfamily"),
-                    LE(11158, "Paramyxoviridae", "family"),
-                    LE(11157, "Mononegavirales", "order"),
-                    LE(2497574, "Monjiviricetes", "class"),
-                    LE(2497570, "Haploviricotina", "subphylum"),
-                    LE(2497569, "Negarnaviricota", "phylum"),
-                    LE(2559587, "Riboviria", "realm"),
-                    LE(10239, "Viruses", "superkingdom"),
-                )
-            )
-        )
+        s = StringIO()
+        s.write('hey')
+        self.assertEqual('hey', s.getvalue())
 
-    def testHBV(self):
+    def testInitializedRead(self):
         """
-        An HBV virus must not be classified as an RNA virus.
+        It must be possible to read from a StringIO instance that is
+        initialized on creation.
         """
-        self.assertFalse(
-            isRNAVirus(
-                (
-                    LE(1508712, "Tent-making bat hepatitis B virus", "species"),
-                    LE(10405, "Orthohepadnavirus", "genus"),
-                    LE(10404, "Hepadnaviridae", "family"),
-                    LE(10239, "Viruses", "superkingdom"),
-                )
-            )
-        )
+        s = StringIO('hey')
+        self.assertEqual('hey', s.getvalue())
 
-    def testHIV(self):
+    def testContextManager(self):
         """
-        An HIV virus must be classified as an RNA virus.
+        It must be possible to use a StringIO instance as a context manager.
         """
-        self.assertTrue(
-            isRNAVirus(
-                (
-                    LE(11676, "Human immunodeficiency virus 1", "species"),
-                    LE(11646, "Lentivirus", "genus"),
-                    LE(327045, "Orthoretrovirinae", "subfamily"),
-                    LE(11632, "Retroviridae", "family"),
-                    LE(2169561, "Ortervirales", "order"),
-                    LE(10239, "Viruses", "superkingdom"),
-                )
-            )
-        )
+        with StringIO() as s:
+            s.write('hey')
+            self.assertEqual('hey', s.getvalue())
 
 
-class TestAllowedTaxonomicRank(TestCase):
+class TestBaseCountsToStr(TestCase):
     """
-    Test the isAllowedTaxonomicRank function.
+    Test the baseCountsToStr function.
     """
-
-    def testNoRanksAllowed(self):
+    def testSimple(self):
         """
-        The function must return False when no taxonomic ranks are allowed.
+        A simple example must work as expected.
         """
-        allowed = set()
-        lineage = (
-            LE(245, "x", "realm"),
-            LE(246, "bacteria", "kingdom"),
-            LE(247, "y", "species"),
-        )
-        self.assertFalse(isAllowedTaxonomicRank(allowed, lineage))
+        counts = Counter()
+        counts['A'] += 1
+        counts['G'] += 2
+        self.assertEqual('A:1 G:2',
+                         baseCountsToStr(counts))
+
 
-    def testEmptyLineage(self):
+class TestNucleotidesToStr(TestCase):
+    """
+    Test the nucleotidesToStr function.
+    """
+    def testSimple(self):
         """
-        The function must return False when the passed lineage is empty.
+        A simple example must work as expected.
         """
-        allowed = set((("bacteria", "kingdom"),))
-        lineage = ()
-        self.assertFalse(isAllowedTaxonomicRank(allowed, lineage))
+        counts1 = Counter()
+        counts1['A'] += 1
+        counts1['G'] += 2
+        counts2 = Counter()
+        counts2['C'] += 1
+        counts2['T'] += 3
+        self.assertEqual(
+            '0: A:1 G:2\n7: C:1 T:3',
+            nucleotidesToStr(
+                {
+                    0: counts1,
+                    7: counts2,
+                }
+            )
+        )
+
 
-    def testExactCase(self):
+class TestCountPrint(TestCase):
+    """
+    Test the countPrint function and the contained percentage function.
+    """
+    def testSimple(self):
         """
-        The function must return True when case matches exactly.
+        A simple example must work as expected.
         """
-        allowed = set((("bacteria", "kingdom"),))
-        lineage = (
-            LE(245, "x", "realm"),
-            LE(246, "bacteria", "kingdom"),
-            LE(247, "y", "species"),
-        )
-        self.assertTrue(isAllowedTaxonomicRank(allowed, lineage))
+        count = 2
+        len1 = 10
+        self.assertEqual('Count is: 2/10 (20.00%)',
+                         countPrint('Count is', count, len1))
 
-    def testNonMatchingCase(self):
+    def testTwoSequences(self):
         """
-        The function must return True when case doesn't match.
+        An example involving two different lengths must work as expected.
         """
-        allowed = set((("BACTERIA", "KINGDOM"),))
-        lineage = (
-            LE(245, "x", "realm"),
-            LE(246, "bacteria", "kingdom"),
-            LE(247, "y", "species"),
+        count = 2
+        len1 = 10
+        len2 = 8
+        self.assertEqual(
+            'Count is: 2/10 (20.00%) of sequence 1,'
+            ' 2/8 (25.00%) of sequence 2',
+            countPrint('Count is', count, len1, len2)
         )
-        self.assertTrue(isAllowedTaxonomicRank(allowed, lineage))
 
-    def testMultipleMatches(self):
+
+class TestPct(TestCase):
+    """
+    Test the pct function.
+    """
+    def testZeroNumerator(self):
         """
-        The function must return True when more than one part of the lineage matches.
+        The pct function must produce the correct result if the numerator is
+        zero.
         """
-        allowed = set((("bacteria", "kingdom"), ("y", "species")))
-        lineage = (
-            LE(245, "x", "realm"),
-            LE(246, "bacteria", "kingdom"),
-            LE(247, "y", "species"),
-        )
-        self.assertTrue(isAllowedTaxonomicRank(allowed, lineage))
+        self.assertEqual('0/10 (0.000%)', pct(0, 10))
 
-    def testRankMismatch(self):
+    def testZeroDenominator(self):
         """
-        The function must return False when the name matches but the rank does not.
+        The pct function must produce the correct result if the denominator is
+        zero.
         """
-        allowed = set((("bacteria", "species"),))
-        lineage = (
-            LE(245, "x", "realm"),
-            LE(246, "bacteria", "kingdom"),
-            LE(247, "y", "species"),
-        )
-        self.assertFalse(isAllowedTaxonomicRank(allowed, lineage))
+        self.assertEqual('0/0 (0.000%)', pct(0, 0))
 
-    def testNameMismatch(self):
+    def testOneHalf(self):
         """
-        The function must return False when the rank matches but the name does not.
+        The pct function must produce the correct result if the numerator is
+        one half of the denominator.
         """
-        allowed = set((("virus", "kingdom"),))
-        lineage = (
-            LE(245, "x", "realm"),
-            LE(246, "bacteria", "kingdom"),
-            LE(247, "y", "species"),
-        )
-        self.assertFalse(isAllowedTaxonomicRank(allowed, lineage))
+        self.assertEqual('5/10 (50.000%)', pct(5, 10))
 
-    def testNameAndRankMismatch(self):
+    def testOneSeventh(self):
         """
-        The function must return False when the name and rank both do not match.
+        The pct function must produce the correct result if the numerator is
+        one seventh of the denominator.
         """
-        allowed = set((("virus", "genus"),))
-        lineage = (
-            LE(245, "x", "realm"),
-            LE(246, "bacteria", "kingdom"),
-            LE(247, "y", "species"),
-        )
-        self.assertFalse(isAllowedTaxonomicRank(allowed, lineage))
+        self.assertEqual('2/14 (14.286%)', pct(2, 14))
 
 
-class TestLineageElement(TestCase):
+class TestTake(TestCase):
     """
-    Test the LineageElement named tuple.
+    Test the take function.
     """
+    def testNLessThanOne(self):
+        """
+        The take function must raise an AssertionError if passed n < 1.
+        list.
+        """
+        self.assertRaises(AssertionError, next, take([], 0))
+
+    def testEmpty(self):
+        """
+        The take function must return an empty generator if passed an empty
+        list.
+        """
+        self.assertEqual([], list(take([], 4)))
 
-    def testTaxid(self):
+    def testOne(self):
         """
-        The taxid attribute must be set as expected.
+        The take function must return individual items if passed n=1.
         """
-        element = LE(245, "no name", "species")
-        self.assertEqual(245, element.taxid)
-        self.assertEqual(245, element[0])
+        self.assertEqual([[3], [4], [5]],
+                         list(take([3, 4, 5], 1)))
 
-    def testName(self):
+    def testNBiggerThanPassedList(self):
         """
-        The name attribute must be set as expected.
+        The take function must return all items if passed an n that is bigger
+        than the passed list.
         """
-        element = LE(245, "no name", "species")
-        self.assertEqual("no name", element.name)
-        self.assertEqual("no name", element[1])
+        self.assertEqual([[3, 4, 5]],
+                         list(take([3, 4, 5], 100)))
 
-    def testRank(self):
+    def testThree(self):
         """
-        The rank attribute must be set as expected.
+        The take function must return three items at a time if passed n=3, and
+        also return the extra two items.
         """
-        element = LE(245, "no name", "species")
-        self.assertEqual("species", element.rank)
-        self.assertEqual("species", element[2])
+        self.assertEqual([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10]],
+                         list(take(range(11), 3)))
```

### Comparing `dark-matter-4.0.84/test/test_titles.py` & `dark-matter-4.0.9/test/test_titles.py`

 * *Files 13% similar despite different names*

```diff
@@ -2,1155 +2,977 @@
 #       and diamond/test_titles.py because that class needs a concrete
 #       (iterable) dark.alignments.ReadsAlignments class passed to its
 #       __init__.  The tests below test the simpler dark.titles classes,
 #       TitleAlignment and TitleAlignments.
 
 from collections import Counter
 import six
+import warnings
+import platform
 from unittest import TestCase
 
 from dark.titles import TitleAlignment, TitleAlignments
 from dark.reads import Read
 from dark.hsp import HSP, LSP
 
+_pypy = platform.python_implementation() == 'PyPy'
+
+
+class WarningTestMixin(object):
+    """
+    Provide an assertion test which checks to see that a specified warning
+    was raised.
+    """
+    # Taken from
+    # http://stackoverflow.com/questions/3892218/
+    # how-to-test-with-pythons-unittest-that-a-warning-has-been-thrown
+
+    def assertWarns(self, warning, callable, *args, **kwds):
+        with warnings.catch_warnings(record=True) as warning_list:
+            warnings.simplefilter('always')
+            callable(*args, **kwds)
+            self.assertTrue(
+                any(item.category == warning for item in warning_list))
+
 
 class TestTitleAlignment(TestCase):
     """
     Test the TitleAlignment class.
     """
 
     def testExpectedAttributes(self):
         """
         An instance of TitleAlignment must have the expected attributes.
         """
-        read = Read("id", "AAA")
+        read = Read('id', 'AAA')
         titleAlignment = TitleAlignment(read, [])
         self.assertEqual(read, titleAlignment.read)
         self.assertEqual([], titleAlignment.hsps)
 
     def testToDict(self):
         """
         The toDict method must return the expected result.
         """
-        read = Read("the-id", "AAA")
-        hsp1 = HSP(
-            0,
-            readStart=1,
-            readEnd=2,
-            readStartInSubject=3,
-            readEndInSubject=4,
-            subjectStart=5,
-            subjectEnd=6,
-            readMatchedSequence="aaa",
-            subjectMatchedSequence="ccc",
-            readFrame=7,
-            subjectFrame=8,
-            identicalCount=9,
-            percentIdentical=31.3,
-            positiveCount=10,
-            percentPositive=4.5,
-        )
-        hsp2 = HSP(
-            10,
-            readStart=11,
-            readEnd=12,
-            readStartInSubject=13,
-            readEndInSubject=14,
-            subjectStart=15,
-            subjectEnd=16,
-            readMatchedSequence="ggg",
-            subjectMatchedSequence="ttt",
-            readFrame=17,
-            subjectFrame=18,
-            identicalCount=19,
-            percentIdentical=32.3,
-            positiveCount=20,
-            percentPositive=4.6,
-        )
+        read = Read('the-id', 'AAA')
+        hsp1 = HSP(0, readStart=1, readEnd=2,
+                   readStartInSubject=3, readEndInSubject=4,
+                   subjectStart=5, subjectEnd=6,
+                   readMatchedSequence='aaa', subjectMatchedSequence='ccc',
+                   readFrame=7, subjectFrame=8, identicalCount=9,
+                   percentIdentical=31.3, positiveCount=10,
+                   percentPositive=4.5)
+        hsp2 = HSP(10, readStart=11, readEnd=12,
+                   readStartInSubject=13, readEndInSubject=14,
+                   subjectStart=15, subjectEnd=16,
+                   readMatchedSequence='ggg', subjectMatchedSequence='ttt',
+                   readFrame=17, subjectFrame=18, identicalCount=19,
+                   percentIdentical=32.3, positiveCount=20,
+                   percentPositive=4.6)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
 
         self.assertEqual(
             {
-                "hsps": [
+                'hsps': [
                     {
-                        "score": 0,
-                        "readStart": 1,
-                        "readEnd": 2,
-                        "readStartInSubject": 3,
-                        "readEndInSubject": 4,
-                        "subjectStart": 5,
-                        "subjectEnd": 6,
-                        "readFrame": 7,
-                        "subjectFrame": 8,
-                        "identicalCount": 9,
-                        "percentIdentical": 31.3,
-                        "positiveCount": 10,
-                        "percentPositive": 4.5,
-                        "readMatchedSequence": "aaa",
-                        "subjectMatchedSequence": "ccc",
+                        'score': 0,
+                        'readStart': 1,
+                        'readEnd': 2,
+                        'readStartInSubject': 3,
+                        'readEndInSubject': 4,
+                        'subjectStart': 5,
+                        'subjectEnd': 6,
+                        'readFrame': 7,
+                        'subjectFrame': 8,
+                        'identicalCount': 9,
+                        'percentIdentical': 31.3,
+                        'positiveCount': 10,
+                        'percentPositive': 4.5,
+                        'readMatchedSequence': 'aaa',
+                        'subjectMatchedSequence': 'ccc',
                     },
                     {
-                        "score": 10,
-                        "readStart": 11,
-                        "readEnd": 12,
-                        "readStartInSubject": 13,
-                        "readEndInSubject": 14,
-                        "subjectStart": 15,
-                        "subjectEnd": 16,
-                        "readFrame": 17,
-                        "subjectFrame": 18,
-                        "identicalCount": 19,
-                        "percentIdentical": 32.3,
-                        "positiveCount": 20,
-                        "percentPositive": 4.6,
-                        "readMatchedSequence": "ggg",
-                        "subjectMatchedSequence": "ttt",
+                        'score': 10,
+                        'readStart': 11,
+                        'readEnd': 12,
+                        'readStartInSubject': 13,
+                        'readEndInSubject': 14,
+                        'subjectStart': 15,
+                        'subjectEnd': 16,
+                        'readFrame': 17,
+                        'subjectFrame': 18,
+                        'identicalCount': 19,
+                        'percentIdentical': 32.3,
+                        'positiveCount': 20,
+                        'percentPositive': 4.6,
+                        'readMatchedSequence': 'ggg',
+                        'subjectMatchedSequence': 'ttt',
                     },
                 ],
-                "read": {
-                    "id": "the-id",
-                    "quality": None,
-                    "sequence": "AAA",
+                'read': {
+                    'id': 'the-id',
+                    'quality': None,
+                    'sequence': 'AAA',
                 },
             },
-            titleAlignment.toDict(),
-        )
+            titleAlignment.toDict())
 
 
-class TestTitleAlignments(TestCase):
+class TestTitleAlignments(WarningTestMixin, TestCase):
     """
     Test the TitleAlignments class.
     """
 
     def testExpectedAttributes(self):
         """
         An instance of TitleAlignments must have the expected attributes.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        self.assertEqual("subject title", titleAlignments.subjectTitle)
+        titleAlignments = TitleAlignments('subject title', 55)
+        self.assertEqual('subject title', titleAlignments.subjectTitle)
         self.assertEqual(55, titleAlignments.subjectLength)
         self.assertEqual([], titleAlignments)
 
     def testAddAlignment(self):
         """
         It must be possible to add an alignment to an instance of
         TitleAlignments.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id', 'AAA')
         titleAlignment = TitleAlignment(read, [])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(read, titleAlignments[0].read)
         self.assertEqual([], titleAlignments[0].hsps)
 
     def testHSPs(self):
         """
         The hsps function must produce a list of all HSPs.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(14)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
-        self.assertEqual(
-            [7, 14, 21], [hsp.score.score for hsp in titleAlignments.hsps()]
-        )
+        self.assertEqual([7, 14, 21],
+                         [hsp.score.score for hsp in titleAlignments.hsps()])
 
     def testReadsEmpty(self):
         """
         The reads function must return an empty Reads instance if there are no
         reads for the title.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
         self.assertEqual(0, len(list(titleAlignments.reads())))
 
     def testReads(self):
         """
         The reads function must return a Reads instance with the reads for
         the title.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(14)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read1 = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read1 = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read1, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read2 = Read("id2", "AAA")
+        read2 = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read2, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual([read1, read2], list(titleAlignments.reads()))
 
     def testReadCountZero(self):
         """
         The readCount function must return zero if no reads matched a title.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
         self.assertEqual(0, titleAlignments.readCount())
 
     def testReadCount(self):
         """
         The readCount function must indicate how many reads matched a title.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(14)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(2, titleAlignments.readCount())
 
     def testHspCountZero(self):
         """
         The hspCount function must return zero if no reads matched a title.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
         self.assertEqual(0, titleAlignments.hspCount())
 
     def testHspCount(self):
         """
         The hspCount function must indicate how many HSPs were found in
         total for all the alignments to a title.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(14)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(3, titleAlignments.hspCount())
 
     def testMedianScoreWithNoAlignments(self):
         """
         The medianScore function must raise IndexError (due to no inputs)
         if there are no alignments matching a title.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        error = "^arg is an empty sequence$"
-        six.assertRaisesRegex(self, ValueError, error, titleAlignments.medianScore)
+        titleAlignments = TitleAlignments('subject title', 55)
+        error = '^arg is an empty sequence$'
+        six.assertRaisesRegex(self, ValueError, error,
+                              titleAlignments.medianScore)
 
     def testMedianScoreWithNoHsps(self):
         """
         The medianScore function must raise ValueError if there are no HSPs.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [])
         titleAlignments.addAlignment(titleAlignment)
-        error = "^arg is an empty sequence$"
-        six.assertRaisesRegex(self, ValueError, error, titleAlignments.medianScore)
+        error = '^arg is an empty sequence$'
+        six.assertRaisesRegex(self, ValueError, error,
+                              titleAlignments.medianScore)
 
     def testMedianScoreOfTwo(self):
         """
         The medianScore function must return the median score for the HSPs in
         all the alignments matching a title when given 2 scores.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(15)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(11, titleAlignments.medianScore())
 
     def testMedianScoreOfThree(self):
         """
         The medianScore function must return the median score for the HSPs in
         all the alignments matching a title when given 3 scores.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(15)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(15, titleAlignments.medianScore())
 
     def testBestHspWithNoHsps(self):
         """
         The bestHsp function must raise ValueError if there are no HSPs.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [])
         titleAlignments.addAlignment(titleAlignment)
-        error = "^max\\(\\) arg is an empty sequence$"
+        if _pypy:
+            error = '^arg is an empty sequence$'
+        else:
+            error = '^max\\(\\) arg is an empty sequence$'
         six.assertRaisesRegex(self, ValueError, error, titleAlignments.bestHsp)
 
     def testBestHsp(self):
         """
         The bestHsp function must return the HSP with the best score for all
         the HSPs for all the alignments matching a title.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(15)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(hsp3, titleAlignments.bestHsp())
 
     def testWorstHspWithNoHsps(self):
         """
         The worstHsp function must raise ValueError if there are no HSPs.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [])
         titleAlignments.addAlignment(titleAlignment)
-        error = "^min\\(\\) arg is an empty sequence$"
-        six.assertRaisesRegex(self, ValueError, error, titleAlignments.worstHsp)
+        if _pypy:
+            error = '^arg is an empty sequence$'
+        else:
+            error = '^min\\(\\) arg is an empty sequence$'
+        six.assertRaisesRegex(self, ValueError, error,
+                              titleAlignments.worstHsp)
 
     def testWorstHsp(self):
         """
         The worstHsp function must return the HSP with the worst score for all
         the HSPs for all the alignments matching a title.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(15)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(hsp1, titleAlignments.worstHsp())
 
     def testBetterThanFalse(self):
         """
         The hasScoreBetterThan function must return False if there is no HSP
         with a score better than the passed value.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(15)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertFalse(titleAlignments.hasScoreBetterThan(21))
 
     def testBetterThanTrue(self):
         """
         The hasScoreBetterThan function must return True if there is an HSP
         with a score better than the passed value.
         """
         hsp1 = HSP(7)
         hsp2 = HSP(15)
         hsp3 = HSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertTrue(titleAlignments.hasScoreBetterThan(20))
 
     def testCoverageNoReads(self):
         """
         The coverage method must return zero when a title alignments has no
         alignments (and therefore no coverage).
         """
-        titleAlignments = TitleAlignments("subject title", 100)
+        titleAlignments = TitleAlignments('subject title', 100)
         self.assertEqual(0.0, titleAlignments.coverage())
 
     def testFullCoverage(self):
         """
         The coverage method must return the correct value when the title is
         fully covered by its reads.
         """
         hsp1 = HSP(7, subjectStart=0, subjectEnd=50)
         hsp2 = HSP(8, subjectStart=50, subjectEnd=100)
-        titleAlignments = TitleAlignments("subject title", 100)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 100)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(1.0, titleAlignments.coverage())
 
     def testPartialCoverage(self):
         """
         The coverage method must return the correct value when the title is
         partially covered by its reads.
         """
         hsp1 = HSP(7, subjectStart=10, subjectEnd=20)
         hsp2 = HSP(15, subjectStart=30, subjectEnd=40)
         hsp3 = HSP(21, subjectStart=50, subjectEnd=60)
-        titleAlignments = TitleAlignments("subject title", 100)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 100)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(0.3, titleAlignments.coverage())
 
     def testFullCoverageCounts(self):
         """
         The coverageCounts method must return the correct result when the title
         is fully covered by its reads.
         """
         hsp1 = HSP(7, subjectStart=0, subjectEnd=5)
         hsp2 = HSP(8, subjectStart=5, subjectEnd=10)
-        titleAlignments = TitleAlignments("subject title", 10)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 10)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         c = Counter([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
         self.assertEqual(c, titleAlignments.coverageCounts())
 
     def testCoverageCounts(self):
         """
         The coverageCounts method must return the correct results when the
         title is partially covered by its reads.
         """
         hsp1 = HSP(7, subjectStart=1, subjectEnd=2)
         hsp2 = HSP(15, subjectStart=3, subjectEnd=4)
         hsp3 = HSP(21, subjectStart=5, subjectEnd=6)
-        titleAlignments = TitleAlignments("subject title", 10)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 10)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         c = Counter([1, 3, 5])
         self.assertEqual(c, titleAlignments.coverageCounts())
 
     def testCoverageCountsOverlap(self):
         """
         The coverageCounts method must return the correct results when the
         title is partially covered by its reads that overlap.
         """
         hsp1 = HSP(7, subjectStart=1, subjectEnd=2)
         hsp2 = HSP(15, subjectStart=3, subjectEnd=6)
         hsp3 = HSP(21, subjectStart=5, subjectEnd=6)
-        titleAlignments = TitleAlignments("subject title", 10)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 10)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         c = Counter([1, 3, 4, 5, 5])
         self.assertEqual(c, titleAlignments.coverageCounts())
 
     def testCoverageInfoNoReads(self):
         """
         When a title has no reads aligned to it, the coverageInfo method
         must return an empty result.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
         coverage = titleAlignments.coverageInfo()
         self.assertEqual({}, coverage)
 
     def testCoverageInfoOneReadWithOneHSP(self):
         """
         When a title has one read with one HSP aligned to it, the coverageInfo
         method must return just the indices and bases from that read.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        hsp = HSP(15, subjectStart=3, subjectEnd=6, readMatchedSequence="CGT")
-        read = Read("id1", "AAACGT")
+        titleAlignments = TitleAlignments('subject title', 55)
+        hsp = HSP(15, subjectStart=3, subjectEnd=6, readMatchedSequence='CGT')
+        read = Read('id1', 'AAACGT')
         titleAlignment = TitleAlignment(read, [hsp])
         titleAlignments.addAlignment(titleAlignment)
         coverage = titleAlignments.coverageInfo()
         self.assertEqual(
             {
-                3: [(15, "C")],
-                4: [(15, "G")],
-                5: [(15, "T")],
+                3: [(15, 'C')],
+                4: [(15, 'G')],
+                5: [(15, 'T')],
             },
-            coverage,
-        )
+            coverage)
 
     def testCoverageInfoOneReadWithTwoHSPs(self):
         """
         When a title has one read with two HSPs aligned to it, the coverageInfo
         method must return the correct indices and bases from that read.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        hsp1 = HSP(15, subjectStart=1, subjectEnd=4, readMatchedSequence="A-A")
-        hsp2 = HSP(10, subjectStart=3, subjectEnd=6, readMatchedSequence="CGT")
-        read = Read("id1", "AAACGT")
+        titleAlignments = TitleAlignments('subject title', 55)
+        hsp1 = HSP(15, subjectStart=1, subjectEnd=4, readMatchedSequence='A-A')
+        hsp2 = HSP(10, subjectStart=3, subjectEnd=6, readMatchedSequence='CGT')
+        read = Read('id1', 'AAACGT')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         coverage = titleAlignments.coverageInfo()
         self.assertEqual(
             {
-                1: [(15, "A")],
-                2: [(15, "-")],
-                3: [(15, "A"), (10, "C")],
-                4: [(10, "G")],
-                5: [(10, "T")],
+                1: [(15, 'A')],
+                2: [(15, '-')],
+                3: [(15, 'A'), (10, 'C')],
+                4: [(10, 'G')],
+                5: [(10, 'T')],
             },
-            coverage,
-        )
+            coverage)
 
     def testCoverageInfoTwoReadsWithThreeHSPs(self):
         """
         When a title has two reads (one with two HSPs, one with one) aligned
         to it, the coverageInfo method must return the correct indices and
         bases from the read.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
 
         # First read.
-        hsp1 = HSP(15, subjectStart=1, subjectEnd=4, readMatchedSequence="A-A")
-        hsp2 = HSP(10, subjectStart=3, subjectEnd=6, readMatchedSequence="CGT")
-        read = Read("id1", "AAACGT")
+        hsp1 = HSP(15, subjectStart=1, subjectEnd=4, readMatchedSequence='A-A')
+        hsp2 = HSP(10, subjectStart=3, subjectEnd=6, readMatchedSequence='CGT')
+        read = Read('id1', 'AAACGT')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
 
         # Second read.
-        hsp1 = HSP(20, subjectStart=5, subjectEnd=10, readMatchedSequence="CGGTA")
-        read = Read("id2", "AAACGTCGGTAAAA")
+        hsp1 = HSP(20, subjectStart=5, subjectEnd=10,
+                   readMatchedSequence='CGGTA')
+        read = Read('id2', 'AAACGTCGGTAAAA')
         titleAlignment = TitleAlignment(read, [hsp1])
         titleAlignments.addAlignment(titleAlignment)
 
         coverage = titleAlignments.coverageInfo()
         self.assertEqual(
             {
-                1: [(15, "A")],
-                2: [(15, "-")],
-                3: [(15, "A"), (10, "C")],
-                4: [(10, "G")],
-                5: [(10, "T"), (20, "C")],
-                6: [(20, "G")],
-                7: [(20, "G")],
-                8: [(20, "T")],
-                9: [(20, "A")],
+                1: [(15, 'A')],
+                2: [(15, '-')],
+                3: [(15, 'A'), (10, 'C')],
+                4: [(10, 'G')],
+                5: [(10, 'T'), (20, 'C')],
+                6: [(20, 'G')],
+                7: [(20, 'G')],
+                8: [(20, 'T')],
+                9: [(20, 'A')],
             },
-            coverage,
-        )
+            coverage)
 
     def testResidueCountsNoReads(self):
         """
         When a title has no reads aligned to it, the residueCounts method
         must return an empty result.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
         counts = titleAlignments.residueCounts()
         self.assertEqual(0, len(counts))
 
     def testResidueCountsUnknownCaseConversion(self):
         """
         The residueCounts method must raise a ValueError when asked to do an
         unknown case conversion.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
         error = "convertCaseTo must be one of 'none', 'lower', or 'upper'"
         six.assertRaisesRegex(
-            self, ValueError, error, titleAlignments.residueCounts, convertCaseTo="xxx"
-        )
+            self, ValueError, error, titleAlignments.residueCounts,
+            convertCaseTo='xxx')
 
     def testResidueCountsOneReadOneHSP(self):
         """
         The residueCounts method must return the correct result when just one
         read with one HSP is aligned to a title.
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=0,
-            readEndInSubject=4,
-            subjectStart=0,
-            subjectEnd=4,
-            readMatchedSequence="ACGT",
-            subjectMatchedSequence="ACGT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=0, readEnd=4, readStartInSubject=0,
+                  readEndInSubject=4, subjectStart=0, subjectEnd=4,
+                  readMatchedSequence='ACGT', subjectMatchedSequence='ACGT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                0: {"A": 1},
-                1: {"C": 1},
-                2: {"G": 1},
-                3: {"T": 1},
+                0: {'A': 1},
+                1: {'C': 1},
+                2: {'G': 1},
+                3: {'T': 1},
             },
-            titleAlignments.residueCounts(),
-        )
+            titleAlignments.residueCounts())
 
     def testResidueCountsOneReadOneHSPPartialMatch(self):
         """
         The residueCounts method must return the correct result when just one
         read with one HSP is aligned to a title and only part of the read
         matched the subject (all the read bases are still counted and
         returned).
         """
-        read = Read("id", "ACGT")
-        hsp = HSP(
-            33,
-            readStart=0,
-            readEnd=2,
-            readStartInSubject=0,
-            readEndInSubject=4,
-            subjectStart=0,
-            subjectEnd=4,
-            readMatchedSequence="ACGT",
-            subjectMatchedSequence="ACGT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp = HSP(33, readStart=0, readEnd=2, readStartInSubject=0,
+                  readEndInSubject=4, subjectStart=0, subjectEnd=4,
+                  readMatchedSequence='ACGT', subjectMatchedSequence='ACGT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                0: {"A": 1},
-                1: {"C": 1},
-                2: {"G": 1},
-                3: {"T": 1},
+                0: {'A': 1},
+                1: {'C': 1},
+                2: {'G': 1},
+                3: {'T': 1},
             },
-            titleAlignments.residueCounts(),
-        )
+            titleAlignments.residueCounts())
 
     def testResidueCountsOneReadTwoHSPsAtStartOfSubject(self):
         """
         The residueCounts method must return the correct result when just one
         read with two HSPs is aligned to a title and the leftmost HSP is
         aligned with the left edge of the subject.
 
         HSP1:       ACGT
         HSP2:        CGTT
         """
-        read = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=0,
-            readEndInSubject=4,
-            subjectStart=0,
-            subjectEnd=4,
-            readMatchedSequence="ACGT",
-            subjectMatchedSequence="ACGT",
-        )
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=1,
-            readEndInSubject=5,
-            subjectStart=1,
-            subjectEnd=5,
-            readMatchedSequence="CGTT",
-            subjectMatchedSequence="CGTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=0,
+                   readEndInSubject=4, subjectStart=0, subjectEnd=4,
+                   readMatchedSequence='ACGT', subjectMatchedSequence='ACGT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=1,
+                   readEndInSubject=5, subjectStart=1, subjectEnd=5,
+                   readMatchedSequence='CGTT', subjectMatchedSequence='CGTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                0: {"A": 1},
-                1: {"C": 2},
-                2: {"G": 2},
-                3: {"T": 2},
-                4: {"T": 1},
+                0: {'A': 1},
+                1: {'C': 2},
+                2: {'G': 2},
+                3: {'T': 2},
+                4: {'T': 1},
             },
-            titleAlignments.residueCounts(),
-        )
+            titleAlignments.residueCounts())
 
     def testResidueCountsOneReadTwoHSPsNotAtStartOfSubject(self):
         """
         The residueCounts method must return the correct result when just one
         read with two HSPs is aligned to a title and the leftmost HSP is not
         aligned with the left edge of the subject.
 
         HSP1:       ACGT
         HSP2:        CGTT
         """
-        read = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=14,
-            readMatchedSequence="ACGT",
-            subjectMatchedSequence="ACGT",
-        )
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=11,
-            readEndInSubject=15,
-            subjectStart=11,
-            subjectEnd=15,
-            readMatchedSequence="CGTT",
-            subjectMatchedSequence="CGTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=10,
+                   readEndInSubject=14, subjectStart=10, subjectEnd=14,
+                   readMatchedSequence='ACGT', subjectMatchedSequence='ACGT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=11,
+                   readEndInSubject=15, subjectStart=11, subjectEnd=15,
+                   readMatchedSequence='CGTT', subjectMatchedSequence='CGTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                10: {"A": 1},
-                11: {"C": 2},
-                12: {"G": 2},
-                13: {"T": 2},
-                14: {"T": 1},
+                10: {'A': 1},
+                11: {'C': 2},
+                12: {'G': 2},
+                13: {'T': 2},
+                14: {'T': 1},
             },
-            titleAlignments.residueCounts(),
-        )
+            titleAlignments.residueCounts())
 
     def testResidueCountsNoCaseConversion(self):
         """
         The residueCounts method must return the correct result when asked not
         to convert case.
 
         HSP1:       AcgT
         HSP2:        CGTT
         """
-        read = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=14,
-            readMatchedSequence="AcgT",
-            subjectMatchedSequence="ACGT",
-        )
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=11,
-            readEndInSubject=15,
-            subjectStart=11,
-            subjectEnd=15,
-            readMatchedSequence="CGTT",
-            subjectMatchedSequence="CGTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=10,
+                   readEndInSubject=14, subjectStart=10, subjectEnd=14,
+                   readMatchedSequence='AcgT', subjectMatchedSequence='ACGT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=11,
+                   readEndInSubject=15, subjectStart=11, subjectEnd=15,
+                   readMatchedSequence='CGTT', subjectMatchedSequence='CGTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                10: {"A": 1},
-                11: {"C": 1, "c": 1},
-                12: {"G": 1, "g": 1},
-                13: {"T": 2},
-                14: {"T": 1},
+                10: {'A': 1},
+                11: {'C': 1, 'c': 1},
+                12: {'G': 1, 'g': 1},
+                13: {'T': 2},
+                14: {'T': 1},
             },
-            titleAlignments.residueCounts(convertCaseTo="none"),
-        )
+            titleAlignments.residueCounts(convertCaseTo='none'))
 
     def testResidueCountsCaseConvertLower(self):
         """
         The residueCounts method must return the correct result when asked to
         convert residues to lower case.
 
         HSP1:       AcgT
         HSP2:        CGTT
         """
-        read = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=14,
-            readMatchedSequence="AcgT",
-            subjectMatchedSequence="ACGT",
-        )
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=11,
-            readEndInSubject=15,
-            subjectStart=11,
-            subjectEnd=15,
-            readMatchedSequence="CGTT",
-            subjectMatchedSequence="CGTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=10,
+                   readEndInSubject=14, subjectStart=10, subjectEnd=14,
+                   readMatchedSequence='AcgT', subjectMatchedSequence='ACGT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=11,
+                   readEndInSubject=15, subjectStart=11, subjectEnd=15,
+                   readMatchedSequence='CGTT', subjectMatchedSequence='CGTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                10: {"a": 1},
-                11: {"c": 2},
-                12: {"g": 2},
-                13: {"t": 2},
-                14: {"t": 1},
+                10: {'a': 1},
+                11: {'c': 2},
+                12: {'g': 2},
+                13: {'t': 2},
+                14: {'t': 1},
             },
-            titleAlignments.residueCounts(convertCaseTo="lower"),
-        )
+            titleAlignments.residueCounts(convertCaseTo='lower'))
 
     def testResidueCountsCaseConvertUpper(self):
         """
         The residueCounts method must return the correct result when asked to
         convert residues to upper case.
 
         HSP1:       AcgT
         HSP2:        CGTT
         """
-        read = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=14,
-            readMatchedSequence="AcgT",
-            subjectMatchedSequence="ACGT",
-        )
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=11,
-            readEndInSubject=15,
-            subjectStart=11,
-            subjectEnd=15,
-            readMatchedSequence="CGTT",
-            subjectMatchedSequence="CGTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=10,
+                   readEndInSubject=14, subjectStart=10, subjectEnd=14,
+                   readMatchedSequence='AcgT', subjectMatchedSequence='ACGT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=11,
+                   readEndInSubject=15, subjectStart=11, subjectEnd=15,
+                   readMatchedSequence='CGTT', subjectMatchedSequence='CGTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                10: {"A": 1},
-                11: {"C": 2},
-                12: {"G": 2},
-                13: {"T": 2},
-                14: {"T": 1},
+                10: {'A': 1},
+                11: {'C': 2},
+                12: {'G': 2},
+                13: {'T': 2},
+                14: {'T': 1},
             },
-            titleAlignments.residueCounts(convertCaseTo="upper"),
-        )
+            titleAlignments.residueCounts(convertCaseTo='upper'))
 
     def testResidueCountsCaseConvertUpperIsDefault(self):
         """
         The residueCounts method must convert to uppercase by default.
 
         HSP1:       AcgT
         HSP2:        CGTT
         """
-        read = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=14,
-            readMatchedSequence="AcgT",
-            subjectMatchedSequence="ACGT",
-        )
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=11,
-            readEndInSubject=15,
-            subjectStart=11,
-            subjectEnd=15,
-            readMatchedSequence="CGTT",
-            subjectMatchedSequence="CGTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=10,
+                   readEndInSubject=14, subjectStart=10, subjectEnd=14,
+                   readMatchedSequence='AcgT', subjectMatchedSequence='ACGT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=11,
+                   readEndInSubject=15, subjectStart=11, subjectEnd=15,
+                   readMatchedSequence='CGTT', subjectMatchedSequence='CGTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                10: {"A": 1},
-                11: {"C": 2},
-                12: {"G": 2},
-                13: {"T": 2},
-                14: {"T": 1},
+                10: {'A': 1},
+                11: {'C': 2},
+                12: {'G': 2},
+                13: {'T': 2},
+                14: {'T': 1},
             },
-            titleAlignments.residueCounts(),
-        )
+            titleAlignments.residueCounts())
 
     def testResidueCountsTwoReadsTwoHSPsLeftOverhang(self):
         """
         The residueCounts method must return the correct result when two
         reads, each with one HSP are aligned to a title and the leftmost HSP
         is aligned before the left edge of the subject (i.e, will include
         negative subject offsets).
 
         Subject:      GTT
         HSP1:       ACGT
         HSP2:        CGTT
         """
-        read1 = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=-2,
-            readEndInSubject=2,
-            subjectStart=0,
-            subjectEnd=2,
-            readMatchedSequence="GT",
-            subjectMatchedSequence="GT",
-        )
-        read2 = Read("id", "CGTT")
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=-1,
-            readEndInSubject=3,
-            subjectStart=0,
-            subjectEnd=3,
-            readMatchedSequence="GTT",
-            subjectMatchedSequence="GTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read1 = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=-2,
+                   readEndInSubject=2, subjectStart=0, subjectEnd=2,
+                   readMatchedSequence='GT', subjectMatchedSequence='GT')
+        read2 = Read('id', 'CGTT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=-1,
+                   readEndInSubject=3, subjectStart=0, subjectEnd=3,
+                   readMatchedSequence='GTT', subjectMatchedSequence='GTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read1, [hsp1])
         titleAlignments.addAlignment(titleAlignment)
         titleAlignment = TitleAlignment(read2, [hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                -2: {"A": 1},
-                -1: {"C": 2},
-                0: {"G": 2},
-                1: {"T": 2},
-                2: {"T": 1},
+                -2: {'A': 1},
+                -1: {'C': 2},
+                0: {'G': 2},
+                1: {'T': 2},
+                2: {'T': 1},
             },
-            titleAlignments.residueCounts(),
-        )
+            titleAlignments.residueCounts())
 
     def testResidueCountsOneReadTwoHSPsNotOverlapping(self):
         """
         The residueCounts method must return the correct result when just one
         read with two HSPs is aligned to a title and the HSPs do not overlap
         one another.
 
         HSP1:    ACGT
         HSP2:              CGTT
         """
-        read = Read("id", "ACGT")
-        hsp1 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=0,
-            readEndInSubject=4,
-            subjectStart=0,
-            subjectEnd=4,
-            readMatchedSequence="ACGT",
-            subjectMatchedSequence="ACGT",
-        )
-        hsp2 = HSP(
-            33,
-            readStart=0,
-            readEnd=4,
-            readStartInSubject=10,
-            readEndInSubject=14,
-            subjectStart=10,
-            subjectEnd=14,
-            readMatchedSequence="CGTT",
-            subjectMatchedSequence="CGTT",
-        )
-        titleAlignments = TitleAlignments("subject title", 55)
+        read = Read('id', 'ACGT')
+        hsp1 = HSP(33, readStart=0, readEnd=4, readStartInSubject=0,
+                   readEndInSubject=4, subjectStart=0, subjectEnd=4,
+                   readMatchedSequence='ACGT', subjectMatchedSequence='ACGT')
+        hsp2 = HSP(33, readStart=0, readEnd=4, readStartInSubject=10,
+                   readEndInSubject=14, subjectStart=10, subjectEnd=14,
+                   readMatchedSequence='CGTT', subjectMatchedSequence='CGTT')
+        titleAlignments = TitleAlignments('subject title', 55)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(
             {
-                0: {"A": 1},
-                1: {"C": 1},
-                2: {"G": 1},
-                3: {"T": 1},
-                10: {"C": 1},
-                11: {"G": 1},
-                12: {"T": 1},
-                13: {"T": 1},
+                0: {'A': 1},
+                1: {'C': 1},
+                2: {'G': 1},
+                3: {'T': 1},
+                10: {'C': 1},
+                11: {'G': 1},
+                12: {'T': 1},
+                13: {'T': 1},
             },
-            titleAlignments.residueCounts(),
-        )
+            titleAlignments.residueCounts())
 
     def testSummaryWhenEmpty(self):
         """
         If summary is called on an instance of TitleAlignments with no
         alignments a ValueError must be raised.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
-        error = "^max\\(\\) arg is an empty sequence$"
+        titleAlignments = TitleAlignments('subject title', 55)
+        error = '^max\\(\\) arg is an empty sequence$'
         six.assertRaisesRegex(self, ValueError, error, titleAlignments.summary)
 
     def testSummary(self):
         """
         The summary method must return the correct result.
         """
-        titleAlignments = TitleAlignments("subject title", 10)
+        titleAlignments = TitleAlignments('subject title', 10)
         titleAlignments.addAlignment(
-            TitleAlignment(
-                Read("id1", "ACGT"),
-                [
-                    HSP(30, subjectStart=0, subjectEnd=2),
-                ],
-            )
-        )
+            TitleAlignment(Read('id1', 'ACGT'), [
+                HSP(30, subjectStart=0, subjectEnd=2),
+            ]))
         titleAlignments.addAlignment(
-            TitleAlignment(
-                Read("id2", "ACGT"),
-                [
-                    HSP(55, subjectStart=2, subjectEnd=4),
-                    HSP(40, subjectStart=8, subjectEnd=9),
-                ],
-            )
-        )
+            TitleAlignment(Read('id2', 'ACGT'), [
+                HSP(55, subjectStart=2, subjectEnd=4),
+                HSP(40, subjectStart=8, subjectEnd=9),
+            ]))
         self.assertEqual(
             {
-                "bestScore": 55,
-                "coverage": 0.5,
-                "hspCount": 3,
-                "medianScore": 40,
-                "readCount": 2,
-                "subjectLength": 10,
-                "subjectTitle": "subject title",
+                'bestScore': 55,
+                'coverage': 0.5,
+                'hspCount': 3,
+                'medianScore': 40,
+                'readCount': 2,
+                'subjectLength': 10,
+                'subjectTitle': 'subject title',
             },
-            titleAlignments.summary(),
-        )
+            titleAlignments.summary())
 
     def testToDict(self):
         """
         The toDict method must return the expected result.
         """
-        read = Read("the-id", "AAA")
-        hsp1 = HSP(
-            0,
-            readStart=1,
-            readEnd=2,
-            readStartInSubject=3,
-            readEndInSubject=4,
-            subjectStart=5,
-            subjectEnd=6,
-            readMatchedSequence="aaa",
-            subjectMatchedSequence="ccc",
-            readFrame=7,
-            subjectFrame=8,
-            identicalCount=9,
-            percentIdentical=17.9,
-            positiveCount=10,
-            percentPositive=3.9,
-        )
-        hsp2 = HSP(
-            10,
-            readStart=11,
-            readEnd=12,
-            readStartInSubject=13,
-            readEndInSubject=14,
-            subjectStart=15,
-            subjectEnd=16,
-            readMatchedSequence="ggg",
-            subjectMatchedSequence="ttt",
-            readFrame=17,
-            subjectFrame=18,
-            identicalCount=19,
-            percentIdentical=27.9,
-            positiveCount=20,
-            percentPositive=3.8,
-        )
+        read = Read('the-id', 'AAA')
+        hsp1 = HSP(0, readStart=1, readEnd=2,
+                   readStartInSubject=3, readEndInSubject=4,
+                   subjectStart=5, subjectEnd=6,
+                   readMatchedSequence='aaa', subjectMatchedSequence='ccc',
+                   readFrame=7, subjectFrame=8, identicalCount=9,
+                   percentIdentical=17.9, positiveCount=10,
+                   percentPositive=3.9)
+        hsp2 = HSP(10, readStart=11, readEnd=12,
+                   readStartInSubject=13, readEndInSubject=14,
+                   subjectStart=15, subjectEnd=16,
+                   readMatchedSequence='ggg', subjectMatchedSequence='ttt',
+                   readFrame=17, subjectFrame=18, identicalCount=19,
+                   percentIdentical=27.9, positiveCount=20,
+                   percentPositive=3.8)
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
-        titleAlignments = TitleAlignments("subject title", 10)
+        titleAlignments = TitleAlignments('subject title', 10)
         titleAlignments.addAlignment(titleAlignment)
 
         self.assertEqual(
             {
-                "subjectTitle": "subject title",
-                "subjectLength": 10,
-                "titleAlignments": [
+                'subjectTitle': 'subject title',
+                'subjectLength': 10,
+                'titleAlignments': [
                     {
-                        "hsps": [
+                        'hsps': [
                             {
-                                "score": 0,
-                                "readStart": 1,
-                                "readEnd": 2,
-                                "readStartInSubject": 3,
-                                "readEndInSubject": 4,
-                                "subjectStart": 5,
-                                "subjectEnd": 6,
-                                "readFrame": 7,
-                                "subjectFrame": 8,
-                                "identicalCount": 9,
-                                "percentIdentical": 17.9,
-                                "positiveCount": 10,
-                                "percentPositive": 3.9,
-                                "readMatchedSequence": "aaa",
-                                "subjectMatchedSequence": "ccc",
+                                'score': 0,
+                                'readStart': 1,
+                                'readEnd': 2,
+                                'readStartInSubject': 3,
+                                'readEndInSubject': 4,
+                                'subjectStart': 5,
+                                'subjectEnd': 6,
+                                'readFrame': 7,
+                                'subjectFrame': 8,
+                                'identicalCount': 9,
+                                'percentIdentical': 17.9,
+                                'positiveCount': 10,
+                                'percentPositive': 3.9,
+                                'readMatchedSequence': 'aaa',
+                                'subjectMatchedSequence': 'ccc',
                             },
                             {
-                                "score": 10,
-                                "readStart": 11,
-                                "readEnd": 12,
-                                "readStartInSubject": 13,
-                                "readEndInSubject": 14,
-                                "subjectStart": 15,
-                                "subjectEnd": 16,
-                                "readFrame": 17,
-                                "subjectFrame": 18,
-                                "identicalCount": 19,
-                                "percentIdentical": 27.9,
-                                "positiveCount": 20,
-                                "percentPositive": 3.8,
-                                "readMatchedSequence": "ggg",
-                                "subjectMatchedSequence": "ttt",
+                                'score': 10,
+                                'readStart': 11,
+                                'readEnd': 12,
+                                'readStartInSubject': 13,
+                                'readEndInSubject': 14,
+                                'subjectStart': 15,
+                                'subjectEnd': 16,
+                                'readFrame': 17,
+                                'subjectFrame': 18,
+                                'identicalCount': 19,
+                                'percentIdentical': 27.9,
+                                'positiveCount': 20,
+                                'percentPositive': 3.8,
+                                'readMatchedSequence': 'ggg',
+                                'subjectMatchedSequence': 'ttt',
                             },
                         ],
-                        "read": {
-                            "id": "the-id",
-                            "quality": None,
-                            "sequence": "AAA",
+                        'read': {
+                            'id': 'the-id',
+                            'quality': None,
+                            'sequence': 'AAA',
                         },
                     },
                 ],
             },
-            titleAlignments.toDict(),
-        )
+            titleAlignments.toDict())
 
 
 class TestTitleAlignmentsLSP(TestCase):
     """
     Test the TitleAlignments class using LSPs. The only tests here are ones
     that depend on lower scores being better.
     """
@@ -1159,91 +981,91 @@
         """
         The bestHsp function must return the HSP with the best score for the
         HSPs all the alignments matching a title.
         """
         hsp1 = LSP(7)
         hsp2 = LSP(15)
         hsp3 = LSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(hsp1, titleAlignments.bestHsp())
 
     def testWorstHsp(self):
         """
         The worstHsp function must return the HSP with the worst score for all
         the HSPs for all the alignments matching a title.
         """
         hsp1 = LSP(7)
         hsp2 = LSP(15)
         hsp3 = LSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertEqual(hsp3, titleAlignments.worstHsp())
 
     def testBetterThanFalse(self):
         """
         The hasScoreBetterThan function must return False if there is no HSP
         with a score better than the passed value.
         """
         hsp1 = LSP(7)
         hsp2 = LSP(15)
         hsp3 = LSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertFalse(titleAlignments.hasScoreBetterThan(7))
 
     def testBetterThanTrue(self):
         """
         The hasScoreBetterThan function must return True if there is an HSP
         with a score better than the passed value.
         """
         hsp1 = LSP(7)
         hsp2 = LSP(15)
         hsp3 = LSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
         self.assertTrue(titleAlignments.hasScoreBetterThan(9))
 
     def testReadIdsEmpty(self):
         """
         The readIds function must return the empty set if no reads matched a
         title.
         """
-        titleAlignments = TitleAlignments("subject title", 55)
+        titleAlignments = TitleAlignments('subject title', 55)
         self.assertEqual(0, len(titleAlignments.readIds()))
 
     def testReadIds(self):
         """
         The readIds function must return the set of read ids for the alignments
         matching a title.
         """
         hsp1 = LSP(7)
         hsp2 = LSP(15)
         hsp3 = LSP(21)
-        titleAlignments = TitleAlignments("subject title", 55)
-        read = Read("id1", "AAA")
+        titleAlignments = TitleAlignments('subject title', 55)
+        read = Read('id1', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp1, hsp2])
         titleAlignments.addAlignment(titleAlignment)
-        read = Read("id2", "AAA")
+        read = Read('id2', 'AAA')
         titleAlignment = TitleAlignment(read, [hsp3])
         titleAlignments.addAlignment(titleAlignment)
-        self.assertEqual(set(["id1", "id2"]), titleAlignments.readIds())
+        self.assertEqual(set(['id1', 'id2']), titleAlignments.readIds())
```

